{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pymysql\n",
    "from faker import Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymysql.connect(\n",
    "    host='localhost',  # Replace with your host name\n",
    "    user='Victorsilog',  # Replace with your MySQL username\n",
    "    password='',  # Replace with your MySQL password\n",
    "    database='ipamssearch'  # Replace with your database name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = open('data_input.csv', 'r')\n",
    "csv_reader = csv.reader(csv_file)\n",
    "\n",
    "# Check if there are any rows in the CSV file\n",
    "try:\n",
    "    first_row = next(csv_reader)\n",
    "except StopIteration:\n",
    "    print(\"No rows found in the CSV file.\")\n",
    "    csv_file.close()\n",
    "    # Handle the error or exit the program if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " 'Turing machines and G\\\\\"odel numbers are important pillars of the theory of computation. Thus, any computational architecture needs to show how it could relate to Turing machines and how stable implementations of Turing computation are possible. In this chapter, we implement universal Turing computation in a neural field environment. To this end, we employ the canonical symbologram representation of a Turing machine obtained from a G\\\\\"odel encoding of its symbolic repertoire and generalized shifts. The resulting nonlinear dynamical automaton (NDA) is a piecewise affine-linear map acting on the unit square that is partitioned into rectangular domains. Instead of looking at point dynamics in phase space, we then consider functional dynamics of probability distributions functions (p.d.f.s) over phase space. This is generally described by a Frobenius-Perron integral transformation that can be regarded as a neural field equation over the unit square as feature space of a dynamic field theory (DFT). Solving the Frobenius-Perron equation yields that uniform p.d.f.s with rectangular support are mapped onto uniform p.d.f.s with rectangular support, again. We call the resulting representation \\\\emph{dynamic field automaton}.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(csv_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "try:\n",
    "    current_id = 1  # Set the starting id value\n",
    "    for row in csv_reader:\n",
    "        abstract = row[1]\n",
    "\n",
    "        # Generate other random values\n",
    "        title = fake.sentence()\n",
    "        for_commercialization = fake.random_element(elements=(0, 1))\n",
    "        psed_classification_id = random.choice([46, 89, 47, 54, 58])\n",
    "\n",
    "        # Generate a random date between 2015-2022\n",
    "        start_date = datetime(year=2015, month=1, day=1)\n",
    "        end_date = datetime(year=2022, month=12, day=31)\n",
    "        random_date = start_date + timedelta(days=random.randint(0, (end_date - start_date).days))\n",
    "        date_uploaded = random_date.strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "\n",
    "        query = \"INSERT INTO records_recordmodel (id, abstract, title, for_commercialization, psed_classification_id, date_uploaded) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "        cursor.execute(query, (current_id, abstract, title, for_commercialization, psed_classification_id, date_uploaded))\n",
    "        connection.commit()\n",
    "\n",
    "        current_id += 1  # Increment the id for the next record\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred during insertion: {str(e)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
