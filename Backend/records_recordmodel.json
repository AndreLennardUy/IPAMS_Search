[
{"type":"header","version":"5.2.1","comment":"Export to JSON plugin for PHPMyAdmin"},
{"type":"database","name":"ipamssearch"},
{"type":"table","name":"records_recordmodel","database":"ipamssearch","data":
[
{"id":"0","title":"Laugh throw particular gun him production these.","abstract":"In arXiv:1109.6438v1 [math.AG] we introduced and studied a notion of algebraic entropy. In this paper we will give an application of algebraic entropy in proving Kunz Regularity Criterion for all contracting self-maps of finite length of Noetherian local rings in arbitrary characteristic. Some conditions of Kunz Criterion have already been extended to the general case by Avramov, Iyengar and Miller in arXiv:math\/0312412v2 [math.AC], using different methods.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2018-05-18 00:00:00.000000"},
{"id":"1","title":"Help huge American research white.","abstract":"The Fermilab Linac delivers a variable intensity, 400-MeV beam to the The MuCool Test Area experimental hall via a beam line specifically designed to facilitate measurements of the Linac beam emittance and properties. A 10 m, dispersion-free and magnet-free straight utilizes an upstream quadrupole focusing triplet in combination with the necessary in-straight beam diagnostics to fully characterize the transverse beam properties. Since the Linac does not produce a strictly elliptical phase space, tomography must be performed on the profile data to retrieve the actual particle distribution in phase space. This is achieved by rotating the phase space distribution using different waist focusing conditions of the upstream triplet and performing a de-convolution of the profile data. Preliminary measurements using this diagnostic section are reported here.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2015-11-28 00:00:00.000000"},
{"id":"2","title":"Central notice speech opportunity compare ok write.","abstract":"Let R be the quotient of a polynomial ring over a field k by an ideal generated by monomials. We derive a formula for the multigraded Poincare' series of R, i.e., the generating function for the ranks of the modules in a minimal multigraded free resolution of k over R. The formula can be expressed in terms of the homology of lower intervals in a certain lattice associated to the minimal set of generators for the ideal.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2015-12-11 00:00:00.000000"},
{"id":"3","title":"Case hope ask including different whose white.","abstract":"Discontinuity preserving smoothing is a fundamentally important procedure that is useful in a wide variety of image processing contexts. It is directly useful for noise reduction, and frequently used as an intermediate step in higher level algorithms. For example, it can be particularly useful in edge detection and segmentation. Three well known algorithms for discontinuity preserving smoothing are nonlinear anisotropic diffusion, bilateral filtering, and mean shift filtering. Although slight differences make them each better suited to different tasks, all are designed to preserve discontinuities while smoothing. However, none of them satisfy this goal perfectly: they each have exception cases in which smoothing may occur across hard edges. The principal contribution of this paper is the identification of a property we call edge awareness that should be satisfied by any discontinuity preserving smoothing algorithm. This constraint can be incorporated into existing algorithms to improve quality, and usually has negligible changes in runtime performance and\/or complexity. We present modifications necessary to augment diffusion and mean shift, as well as a new formulation of the bilateral filter that unifies the spatial and range spaces to achieve edge awareness.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2016-10-19 00:00:00.000000"},
{"id":"4","title":"Challenge subject worker bring affect.","abstract":"We investigate the properties of the Hybrid Monte-Carlo algorithm (HMC) in high dimensions. HMC develops a Markov chain reversible w.r.t. a given target distribution $\\Pi$ by using separable Hamiltonian dynamics with potential $-\\log\\Pi$. The additional momentum variables are chosen at random from the Boltzmann distribution and the continuous-time Hamiltonian dynamics are then discretised using the leapfrog scheme. The induced bias is removed via a Metropolis-Hastings accept\/reject rule. In the simplified scenario of independent, identically distributed components, we prove that, to obtain an $\\mathcal{O}(1)$ acceptance probability as the dimension $d$ of the state space tends to $\\infty$, the leapfrog step-size $h$ should be scaled as $h= l \\times d^{-1\/4}$. Therefore, in high dimensions, HMC requires $\\mathcal{O}(d^{1\/4})$ steps to traverse the state space. We also identify analytically the asymptotically optimal acceptance probability, which turns out to be 0.651 (to three decimal places). This is the choice which optimally balances the cost of generating a proposal, which {\\em decreases} as $l$ increases, against the cost related to the average number of proposals required to obtain acceptance, which {\\em increases} as $l$ increases.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2020-10-19 00:00:00.000000"},
{"id":"5","title":"Final unit reveal throw fire fine fill.","abstract":"Consider an Erd\\\"os-Renyi random graph in which each edge is present independently with probability 1\/2, except for a subset $\\sC_N$ of the vertices that form a clique (a completely connected subgraph). We consider the problem of identifying the clique, given a realization of such a random graph.   The best known algorithm provably finds the clique in linear time with high probability, provided $|\\sC_N|\\ge 1.261\\sqrt{N}$ \\cite{dekel2011finding}. Spectral methods can be shown to fail on cliques smaller than $\\sqrt{N}$. In this paper we describe a nearly linear time algorithm that succeeds with high probability for $|\\sC_N|\\ge (1+\\eps)\\sqrt{N\/e}$ for any $\\eps>0$. This is the first algorithm that provably improves over spectral methods.   We further generalize the hidden clique problem to other background graphs (the standard case corresponding to the complete graph on $N$ vertices). For large girth regular graphs of degree $(\\Delta+1)$ we prove that `local' algorithms succeed if $|\\sC_N|\\ge (1+\\eps)N\/\\sqrt{e\\Delta}$ and fail if $|\\sC_N|\\le(1-\\eps)N\/\\sqrt{e\\Delta}$.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2021-04-15 00:00:00.000000"},
{"id":"6","title":"Fear word everything choose seat government.","abstract":"We show how to exploit symmetries of a graph to efficiently compute the fastest mixing Markov chain on the graph (i.e., find the transition probabilities on the edges to minimize the second-largest eigenvalue modulus of the transition probability matrix). Exploiting symmetry can lead to significant reduction in both the number of variables and the size of matrices in the corresponding semidefinite program, thus enable numerical solution of large-scale instances that are otherwise computationally infeasible. We obtain analytic or semi-analytic results for particular classes of graphs, such as edge-transitive and distance-transitive graphs. We describe two general approaches for symmetry exploitation, based on orbit theory and block-diagonalization, respectively. We also establish the connection between these two approaches.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2015-09-30 00:00:00.000000"},
{"id":"7","title":"Improve trip factor director.","abstract":"We present a discussion on some physical aspects of gravitational collapse which is based on a list of questions related to relevant issues in the study of that phenomenon. Providing answers to those questions we bring out the role played by different physical processes in the dynamics of spherical collapse.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2018-08-30 00:00:00.000000"},
{"id":"8","title":"Clearly skin its prove respond.","abstract":"SOM is a type of unsupervised learning where the goal is to discover some underlying structure of the data. In this paper, a new extraction method based on the main idea of Concurrent Self-Organizing Maps (CSOM), representing a winner-takes-all collection of small SOM networks is proposed. Each SOM of the system is trained individually to provide best results for one class only. The experiments confirm that the proposed features based CSOM is capable to represent image content better than extracted features based on a single big SOM and these proposed features improve the final decision of the CAD. Experiments held on Mammographic Image Analysis Society (MIAS) dataset.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2015-12-20 00:00:00.000000"},
{"id":"9","title":"Case church above traditional past leave.","abstract":"After a more than decade-long period of relatively little research activity in the area of recurrent neural networks, several new developments will be reviewed here that have allowed substantial progress both in understanding and in technical solutions towards more efficient training of recurrent networks. These advances have been motivated by and related to the optimization issues surrounding deep learning. Although recurrent networks are extremely powerful in what they can in principle represent in terms of modelling sequences,their training is plagued by two aspects of the same issue regarding the learning of long-term dependencies. Experiments reported here evaluate the use of clipping gradients, spanning longer time ranges with leaky integration, advanced momentum techniques, using more powerful output probability models, and encouraging sparser gradients to help symmetry breaking and credit assignment. The experiments are performed on text and music data and show off the combined effects of these techniques in generally improving both training and test error.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2017-11-08 00:00:00.000000"},
{"id":"10","title":"Probably she development concern student change site material.","abstract":"The ever-increasing quantity and complexity of scientific production have made it difficult for researchers to keep track of advances in their own fields. This, together with growing popularity of online scientific communities, calls for the development of effective information filtering tools. We propose here a method to simultaneously compute reputation of users and quality of scientific artifacts in an online scientific community. Evaluation on artificially-generated data and real data from the Econophysics Forum is used to determine the method's best-performing variants. We show that when the method is extended by considering author credit, its performance improves on multiple levels. In particular, top papers have higher citation count and top authors have higher $h$-index than top papers and top authors chosen by other algorithms.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2019-09-18 00:00:00.000000"},
{"id":"11","title":"Majority imagine such their some similar.","abstract":"This paper reviews recent developments of robust estimation in linear time series models, with short and long memory correlation structures, in the presence of additive outliers. Based on the manuscripts Fajardo et al. (2009) and L\\'evy-Leduc et al. (2011a), the emphasis in this paper is given in the following directions; the influence of additive outliers in the estimation of a time series, the asymptotic properties of a robust autocovariance function and a robust semiparametric estimation method of the fractional parameter d in ARFIMA(p, d, q) models. Some simulations are used to support the use of the robust method when a time series has additive outliers. The invariance property of the estimators for the first difference in ARFIMA model with outliers is also discussed. In general, the robust long-memory estimator leads to be outlier resistant and is invariant to first differencing.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2020-11-09 00:00:00.000000"},
{"id":"12","title":"Threat assume public.","abstract":"The principal time properties - the one-dimensionality and the irreversibility -, the space metric properties and the spatial-temporal principles of the theory of the relativity are deduced from three natural logic properties of the information, obtained by a physics device. Hence, the transformations of the complete Poincare group are deduced from that.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2020-11-03 00:00:00.000000"},
{"id":"13","title":"Phone hand and send.","abstract":"Main characteristics of Google Scholar Metrics new version (july 2013) are presented. We outline the novelties and the weaknesses detected after a first analysis. As main conclusion, we remark the lack of new functionalities with respect to last editions, as the only modification is the update of the timeframe (2008-2012). Hence, problems pointed out in our last reviews still remain active. Finally, it seems Google Scholar Metrics will be updated in a yearly basis","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2021-05-20 00:00:00.000000"},
{"id":"14","title":"Home world role act play.","abstract":"Gaussian graphical models represent the backbone of the statistical toolbox for analyzing continuous multivariate systems. However, due to the intrinsic properties of the multivariate normal distribution, use of this model family may hide certain forms of context-specific independence that are natural to consider from an applied perspective. Such independencies have been earlier introduced to generalize discrete graphical models and Bayesian networks into more flexible model families. Here we adapt the idea of context-specific independence to Gaussian graphical models by introducing a stratification of the Euclidean space such that a conditional independence may hold in certain segments but be absent elsewhere. It is shown that the stratified models define a curved exponential family, which retains considerable tractability for parameter estimation and model selection.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2016-09-13 00:00:00.000000"},
{"id":"15","title":"Miss collection price cell report soon.","abstract":"Recently, connections have been explored between the complexity of finite problems in graph theory and the complexity of their infinite counterparts. As is shown in our paper (and in independent work of Tirza Hirst and D. Harel from a different angle) there is no firm connection between these complexities, namely finite problems of equal complexity can have radically different complexity for the infinite versions and vice versa. Furthermore, the complexity of an infinite counterpart can depend heavily on precisely how the finite problem is rephrased in the infinite case.   The finite problems we address include colorability of graphs and existence of subgraph isomorphisms. In particular, we give three infinite versions of the 3-colorability problem that vary considerably in their recursion theoretic and proof theoretic complexity. Additionally, we show that three subgraph isomorphism problems of varying finite complexity have infinite versions with identical recursion theoretic and proof theoretic content.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2016-05-10 00:00:00.000000"},
{"id":"16","title":"Theory mission set mother mouth perhaps.","abstract":"We present a generic approach for treating the effect of nuclear motion in the high-order harmonic generation from polyatomic molecules. Our procedure relies on a separation of nuclear and electron dynamics where we account for the electronic part using the Lewenstein model and nuclear motion enters as a nuclear correlation function. We express the nuclear correlation function in terms of Franck-Condon factors which allows us to decompose nuclear motion into modes and identify the modes that are dominant in the high-order harmonic generation process. We show results for the isotopes CH$_4$ and CD$_4$ and thereby provide direct theoretical support for a recent experiment [Baker {\\it et al.}, Science {\\bf 312}, 424 (2006)] that uses high-order harmonic generation to probe the ultra-fast structural nuclear rearrangement of ionized methane.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2018-10-05 00:00:00.000000"},
{"id":"17","title":"Address trial mention sea always.","abstract":"The problem of distributed learning and channel access is considered in a cognitive network with multiple secondary users. The availability statistics of the channels are initially unknown to the secondary users and are estimated using sensing decisions. There is no explicit information exchange or prior agreement among the secondary users. We propose policies for distributed learning and access which achieve order-optimal cognitive system throughput (number of successful secondary transmissions) under self play, i.e., when implemented at all the secondary users. Equivalently, our policies minimize the regret in distributed learning and access. We first consider the scenario when the number of secondary users is known to the policy, and prove that the total regret is logarithmic in the number of transmission slots. Our distributed learning and access policy achieves order-optimal regret by comparing to an asymptotic lower bound for regret under any uniformly-good learning and access policy. We then consider the case when the number of secondary users is fixed but unknown, and is estimated through feedback. We propose a policy in this scenario whose asymptotic sum regret which grows slightly faster than logarithmic in the number of transmission slots.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2015-01-01 00:00:00.000000"},
{"id":"18","title":"Everything machine size radio us affect model.","abstract":"Handling visual complexity is a challenging problem in visualization owing to the subjectiveness of its definition and the difficulty in devising generalizable quantitative metrics. In this paper we address this challenge by measuring the visual complexity of two common forms of cluster-based visualizations: scatter plots and parallel coordinatess. We conceptualize visual complexity as a form of visual uncertainty, which is a measure of the degree of difficulty for humans to interpret a visual representation correctly. We propose an algorithm for estimating visual complexity for the aforementioned visualizations using Allen's interval algebra. We first establish a set of primitive 2-cluster cases in scatter plots and another set for parallel coordinatess based on symmetric isomorphism. We confirm that both are the minimal sets and verify the correctness of their members computationally. We score the uncertainty of each primitive case based on its topological properties, including the existence of overlapping regions, splitting regions and meeting points or edges. We compare a few optional scoring schemes against a set of subjective scores by humans, and identify the one that is the most consistent with the subjective scores. Finally, we extend the 2-cluster measure to k-cluster measure as a general purpose estimator of visual complexity for these two forms of cluster-based visualization.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2015-06-11 00:00:00.000000"},
{"id":"19","title":"Choose hospital media control.","abstract":"Spiking Neural P systems, SNP systems for short, are biologically inspired computing devices based on how neurons perform computations. SNP systems use only one type of symbol, the spike, in the computations. Information is encoded in the time differences of spikes or the multiplicity of spikes produced at certain times. SNP systems with delays (associated with rules) and those without delays are two of several Turing complete SNP system variants in literature. In this work we investigate how restricted forms of SNP systems with delays can be simulated by SNP systems without delays. We show the simulations for the following spike routing constructs: sequential, iteration, join, and split.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2017-01-20 00:00:00.000000"},
{"id":"20","title":"Shoulder year apply out.","abstract":"We propose maximum likelihood estimation for learning Gaussian graphical models with a Gaussian (ell_2^2) prior on the parameters. This is in contrast to the commonly used Laplace (ell_1) prior for encouraging sparseness. We show that our optimization problem leads to a Riccati matrix equation, which has a closed form solution. We propose an efficient algorithm that performs a singular value decomposition of the training data. Our algorithm is O(NT^2)-time and O(NT)-space for N variables and T samples. Our method is tailored to high-dimensional problems (N gg T), in which sparseness promoting methods become intractable. Furthermore, instead of obtaining a single solution for a specific regularization parameter, our algorithm finds the whole solution path. We show that the method has logarithmic sample complexity under the spiked covariance model. We also propose sparsification of the dense solution with provable performance guarantees. We provide techniques for using our learnt models, such as removing unimportant variables, computing likelihoods and conditional distributions. Finally, we show promising results in several gene expressions datasets.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2015-07-21 00:00:00.000000"},
{"id":"21","title":"Reality show role analysis example.","abstract":"We investigate the effect of shear in the flow of charged particle equilibria that are unstable to the Coherent Synchrotron Radiation (CSR) instability.   Shear may act to quench this instability because it acts to limit the size of the region with a fixed phase relation between emitters.   The results are important for the understanding of astrophysical sources of coherent radiation where shear in the flow is likely.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2015-12-20 00:00:00.000000"},
{"id":"22","title":"One let market majority party support us sit.","abstract":"In this paper, concept of possibility neutrosophic soft set and its operations are defined, and their properties are studied. An application of this theory in decision making is investigated. Also a similarity measure of two possibility neutrosophic soft sets is introduced and discussed. Finally an application of this similarity measure is given to select suitable person for position in a firm.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2020-10-09 00:00:00.000000"},
{"id":"23","title":"Gun professor or another that no brother.","abstract":"In this paper we establish a Hermite- Hadamard type inequality for operator preinvex functions and an estimate of the right hand side of a Hermite- Hadamard type inequality in which some operator preinvex functions of selfadjoint operators in Hilbert spaces are involved.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2017-08-27 00:00:00.000000"},
{"id":"24","title":"Bed take business box ahead operation because language.","abstract":"After negative temperature is restated, we find that it will derive necessarily decrease of entropy. Negative temperature is based on the Kelvin scale and the condition dU>0 and dS<0. Conversely, there is also negative temperature for dU<0 and dS>0. But, negative temperature is contradiction with usual meaning of temperature and with some basic concepts of physics and mathematics. It is a question in nonequilibrium thermodynamics. We proposed a possibility of decrease of entropy due to fluctuation magnified and internal interactions in some isolated systems. From this we discuss some possible examples and theories.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2019-12-17 00:00:00.000000"},
{"id":"25","title":"Training less stop these break deep note.","abstract":"In many important applications -- such as search engines and relational database systems -- data is stored in the form of arrays of integers. Encoding and, most importantly, decoding of these arrays consumes considerable CPU time. Therefore, substantial effort has been made to reduce costs associated with compression and decompression. In particular, researchers have exploited the superscalar nature of modern processors and SIMD instructions. Nevertheless, we introduce a novel vectorized scheme called SIMD-BP128 that improves over previously proposed vectorized approaches. It is nearly twice as fast as the previously fastest schemes on desktop processors (varint-G8IU and PFOR). At the same time, SIMD-BP128 saves up to 2 bits per integer. For even better compression, we propose another new vectorized scheme (SIMD-FastPFOR) that has a compression ratio within 10% of a state-of-the-art scheme (Simple-8b) while being two times faster during decoding.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2015-12-17 00:00:00.000000"},
{"id":"26","title":"Support soldier culture possible color.","abstract":"We extend the Falceto-Zambon version of Marsden-Ratiu Poisson reduction to Poisson quasi-Nijenhuis structures with background on manifolds. We define gauge transformations of Poisson quasi-Nijenhuis structures with background, study some of their properties and show that they are compatible with reduction procedure. We use gauge transformations to construct Poisson quasi-Nijenhuis structures with background.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2018-03-19 00:00:00.000000"},
{"id":"27","title":"Name positive will value cause section world.","abstract":"This paper gives an account of our progress towards performing femtosecond time-resolved photoelectron diffraction on gas-phase molecules in a pump-probe setup combining optical lasers and an X-ray Free-Electron Laser. We present results of two experiments aimed at measuring photoelectron angular distributions of laser-aligned 1-ethynyl-4-fluorobenzene (C8H5F) and dissociating, laseraligned 1,4-dibromobenzene (C6H4Br2) molecules and discuss them in the larger context of photoelectron diffraction on gas-phase molecules. We also show how the strong nanosecond laser pulse used for adiabatically laser-aligning the molecules influences the measured electron and ion spectra and angular distributions, and discuss how this may affect the outcome of future time-resolved photoelectron diffraction experiments.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2020-05-20 00:00:00.000000"},
{"id":"28","title":"Investment almost name light participant rather.","abstract":"Persistent homology is a widely used tool in Topological Data Analysis that encodes multiscale topological information as a multi-set of points in the plane called a persistence diagram. It is difficult to apply statistical theory directly to a random sample of diagrams. Instead, we can summarize the persistent homology with the persistence landscape, introduced by Bubenik, which converts a diagram into a well-behaved real-valued function. We investigate the statistical properties of landscapes, such as weak convergence of the average landscapes and convergence of the bootstrap. In addition, we introduce an alternate functional summary of persistent homology, which we call the silhouette, and derive an analogous statistical theory.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2022-10-26 00:00:00.000000"},
{"id":"29","title":"Industry everything market point create.","abstract":"Almost sure asymptotic stabilization of a discrete-time switched stochastic system is investigated. Information on the active operation mode of the switched system is assumed to be available for control purposes only at random time instants. We propose a stabilizing feedback control framework that utilizes the information obtained through mode observations. We first consider the case where stochastic properties of mode observation instants are fully known. We obtain sufficient asymptotic stabilization conditions for the closed-loop switched stochastic system under our proposed control law. We then explore the case where exact knowledge of the stochastic properties of mode observation instants is not available. We present a set of alternative stabilization conditions for this case. The results for both cases are predicated on the analysis of a sequence-valued process that encapsulates the stochastic nature of the evolution of active operation mode between mode observation instants. Finally, we demonstrate the efficacy of our results with numerical examples.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2018-05-20 00:00:00.000000"},
{"id":"30","title":"Administration sister tree.","abstract":"Over the last few decades, climate scientists have devoted much effort to the development of large numerical models of the atmosphere and the ocean. While there is no question that such models provide important and useful information on complicated aspects of atmosphere and ocean dynamics, skillful prediction also requires a phenomenological approach, particularly for very slow processes, such as glacial-interglacial cycles. Phenomenological models are often represented as low-order dynamical systems. These are tractable, and a rich source of insights about climate dynamics, but they also ignore large bodies of information on the climate system, and their parameters are generally not operationally defined. Consequently, if they are to be used to predict actual climate system behaviour, then we must take very careful account of the uncertainty introduced by their limitations. In this paper we consider the problem of the timing of the next glacial inception, about which there is on-going debate. Our model is the three-dimensional stochastic system of Saltzman and Maasch (1991), and our inference takes place within a Bayesian framework that allows both for the limitations of the model as a description of the propagation of the climate state vector, and for parametric uncertainty. Our inference takes the form of a data assimilation with unknown static parameters, which we perform with a variant on a Sequential Monte Carlo technique (`particle filter'). Provisional results indicate peak glacial conditions in 60,000 years.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2018-08-13 00:00:00.000000"},
{"id":"31","title":"Leg significant tell us structure floor.","abstract":"We introduce the notion of graphic cocircuits and show that a large class of regular matroids with graphic cocircuits belongs to the class of signed-graphic matroids. Moreover, we provide an algorithm which determines whether a cographic matroid with graphic cocircuits is signed-graphic or not.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2022-05-12 00:00:00.000000"},
{"id":"32","title":"Lay pressure see describe.","abstract":"We have investigated the non-static Lorentzian Wormhole model in presence of anisotropic pressure. We have presented some exact solutions of Einstein equations for anisotropic pressure case. Introducing two EoS parameters we have shown that these solutions give very rich dynamics of the universe yielding to the different expansion history of it in the $r$ - direction and in the $T$ - direction. The corresponding explicit forms of the shape function $b(r)$ is presented.We have shown that the Einstein's field equations and unified first law are equivalent for the dynamical wormhole model. The first law of thermodynamics has been derived by using the Unified first law. The physical quantities including surface gravity and the temperature are derived for the wormhole. Here we have obtained all the results without any choice of the shape function. The validity of generalized second law (GSL) of thermodynamics has been examined at apparent and event horizons for the evolving Lorentzian wormhole.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2021-03-06 00:00:00.000000"},
{"id":"33","title":"Room machine reality factor grow decade again.","abstract":"We study losses for binary classification and class probability estimation and extend the understanding of them from margin losses to general composite losses which are the composition of a proper loss with a link function. We characterise when margin losses can be proper composite losses, explicitly show how to determine a symmetric loss in full from half of one of its partial losses, introduce an intrinsic parametrisation of composite binary losses and give a complete characterisation of the relationship between proper losses and ``classification calibrated'' losses. We also consider the question of the ``best'' surrogate binary loss. We introduce a precise notion of ``best'' and show there exist situations where two convex surrogate losses are incommensurable. We provide a complete explicit characterisation of the convexity of composite binary losses in terms of the link function and the weight function associated with the proper loss which make up the composite loss. This characterisation suggests new ways of ``surrogate tuning''. Finally, in an appendix we present some new algorithm-independent results on the relationship between properness, convexity and robustness to misclassification noise for binary losses and show that all convex proper losses are non-robust to misclassification noise.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2015-08-15 00:00:00.000000"},
{"id":"34","title":"World reveal financial human answer.","abstract":"In this paper we consider a semigroup of completely positive maps $\\tau=(\\tau_t,t \\ge 0)$ with a faithful normal invariant state $\\phi$ on a type-$II_1$ factor $\\cla_0$ and propose an index theory. We :achieve this via a more general Kolmogorov's type of construction for stationary Markov processes which naturally associate a nested isomorphic von-Neumann algebras. In particular this construction generalizes well known Jones construction associated with a sub-factor of type-II$_1$ factor.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2018-05-19 00:00:00.000000"},
{"id":"35","title":"She ability near magazine.","abstract":"Sparse systems are usually parameterized by a tuning parameter that determines the sparsity of the system. How to choose the right tuning parameter is a fundamental and difficult problem in learning the sparse system. In this paper, by treating the the tuning parameter as an additional dimension, persistent homological structures over the parameter space is introduced and explored. The structures are then further exploited in speeding up the computation using the proposed soft-thresholding technique. The topological structures are further used as multivariate features in the tensor-based morphometry (TBM) in characterizing white matter alterations in children who have experienced severe early life stress and maltreatment. These analyses reveal that stress-exposed children exhibit more diffuse anatomical organization across the whole white matter region.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2019-04-30 00:00:00.000000"},
{"id":"36","title":"Still recent enjoy low wrong social.","abstract":"The existence of incentive-compatible computationally-efficient protocols for combinatorial auctions with decent approximation ratios is the paradigmatic problem in computational mechanism design. It is believed that in many cases good approximations for combinatorial auctions may be unattainable due to an inherent clash between truthfulness and computational efficiency. However, to date, researchers lack the machinery to prove such results. In this paper, we present a new approach that we believe holds great promise for making progress on this important problem. We take the first steps towards the development of new technologies for lower bounding the VC dimension of k-tuples of disjoint sets. We apply this machinery to prove the first computational-complexity inapproximability results for incentive-compatible mechanisms for combinatorial auctions. These results hold for the important class of VCG-based mechanisms, and are based on the complexity assumption that NP has no polynomial-size circuits.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2016-10-22 00:00:00.000000"},
{"id":"37","title":"Effort natural financial north enough travel always several.","abstract":"In this contribution we present a decentralized power allocation algorithm for the uplink interleave division multiple access (IDMA) channel. Within the proposed optimal strategy for power allocation, each user aims at selfishly maximizing its own utility function. An iterative chip by chip (CBC) decoder at the receiver and a rational selfish behavior of all the users according to a classical game-theoretical framework are the underlying assumptions of this work. This approach leads to a power allocation based on a channel inversion policy where the optimal power level is set locally at each terminal based on the knowledge of its own channel realization, the noise level at the receiver and the number of active users in the network.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2016-02-14 00:00:00.000000"},
{"id":"38","title":"Candidate east argue feel.","abstract":"We establish a uniform comparison between the spectrum of the rough Laplacian (acting on sections of a vector bundle of complex rank one or of harmonic curvature) with the spectrum of a discrete operator (a generalization of a discrete magnetic Laplacian added with a potential) acting on a finite dimensional space coming from a discretization process. As an application, we obtain a comparison of the first positive eigenvalue of the rough Laplacian with the holonomy.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2022-02-02 00:00:00.000000"},
{"id":"39","title":"Production various usually art million.","abstract":"We call a CNF formula linear if any two clauses have at most one variable in common. Let m(k) be the largest integer m such that any linear k-CNF formula with <= m clauses is satisfiable. We show that 4^k \/ (4e^2k^3) <= m(k) < ln(2) k^4 4^k. More generally, a (k,d)-CSP is a constraint satisfaction problem in conjunctive normal form where each variable can take on one of d values, and each constraint contains k variables and forbids exacty one of the d^k possible assignments to these variables. Call a (k,d)-CSP l-disjoint if no two distinct constraints have l or more variables in common. Let m_l(k,d) denote the largest integer m such that any l-disjoint (k,d)-CSP with at most m constraints is satisfiable. We show that 1\/k (d^k\/(ed^(l-1)k))^(1+1\/(l-1))<= m_l(k,d) < c (k^2\/l ln(d) d^k)^(1+1\/(l-1)). for some constant c. This means for constant l, upper and lower bound differ only in a polynomial factor in d and k.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2016-12-05 00:00:00.000000"},
{"id":"40","title":"Miss season too.","abstract":"We study the effects of higher order transversal modes in a model of a singly-resonant OPO, using both numerical solutions and mode expansions including up to two radial modes. The numerical and two-mode solutions predict lower threshold and higher conversion than the single-mode solution at negative dispersion. Relative power in the zero order radial mode ranges from about 88% at positive and small negative dispersion to 48% at larger negative dispersion, with most of the higher mode content in the first mode, and less than 2% in higher modes.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2017-07-10 00:00:00.000000"},
{"id":"41","title":"Old man laugh say here special respond.","abstract":"A hypotheses of energy loss for polarization of e-e+ vacuum by a photon passing interstellar space is considered. An excitation and relaxation of vacuum can't run with speed of light due to very small but finite fraction of e-e+ pair mass that creates a retardment in recuperation of deposited energy back to photon. This \"forgotten\" by many photons energy is finally splashed out in real space as a Relic Radiation. An assumption that such energy loss is proportional to a photon energy conforms to Hubble low of Red Shift and experimental data treated as accelerated expansion of Universe. A possibility of an observation of this type energy loss is considered at high-energy accelerators where energy deposition may reach up hundreds MeV in second.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2015-12-26 00:00:00.000000"},
{"id":"42","title":"Contain should than think.","abstract":"We show for an arbitrary $\\ell_p$ norm that the property that a random geometric graph $\\mathcal G(n,r)$ contains a Hamiltonian cycle exhibits a sharp threshold at $r=r(n)=\\sqrt{\\frac{\\log n}{\\alpha_p n}}$, where $\\alpha_p$ is the area of the unit disk in the $\\ell_p$ norm. The proof is constructive and yields a linear time algorithm for finding a Hamiltonian cycle of $\\RG$ a.a.s., provided $r=r(n)\\ge\\sqrt{\\frac{\\log n}{(\\alpha_p -\\epsilon)n}}$ for some fixed $\\epsilon > 0$.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2016-11-09 00:00:00.000000"},
{"id":"43","title":"Hundred year travel democratic room.","abstract":"A theoretical thermodynamic cycle more efficient than an infinite set of Carnot engines is presented. This result is unexpected from the point of view of classical thermodynamics.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2015-06-01 00:00:00.000000"},
{"id":"44","title":"Knowledge task son reason important kind.","abstract":"Here we propose a new design paradigm for a superconducting nanowire single photon detector that uses a multi-layer architecture that places the electric leads beneath the nanowires. This allows for a very large number of detector elements, which we will call pixels in analogy to a conventional CCD camera, to be placed in close proximity. This leads to significantly better photon number resolution than current single and multi-nanowire meanders, while maintaining similar detection areas. We discuss the reset time of the pixels and how the design can be modified to avoid the latching failure seen in extremely short superconducting nanowires. These advantages give a multi-layer superconducting number-resolving photon detector significant advantages over the current design paradigm of long superconducting nanowire meanders. Such advantages are desirable in a wide array of photonics applications.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2022-12-16 00:00:00.000000"},
{"id":"45","title":"Any though lead watch action represent.","abstract":"We consider the counting rate estimation of an unknown radioactive source, which emits photons at times modeled by an homogeneous Poisson process. A spectrometer converts the energy of incoming photons into electrical pulses, whose number provides a rough estimate of the intensity of the Poisson process. When the activity of the source is high, a physical phenomenon known as pileup effect distorts direct measurements, resulting in a significant bias to the standard estimators of the source activities used so far in the field. We show in this paper that the problem of counting rate estimation can be interpreted as a sparse regression problem. We suggest a post-processed, non-negative, version of the Least Absolute Shrinkage and Selection Operator (LASSO) to estimate the photon arrival times. The main difficulty in this problem is that no theoretical conditions can guarantee consistency in sparsity of LASSO, because the dictionary is not ideal and the signal is sampled. We therefore derive theoretical conditions and bounds which illustrate that the proposed method can none the less provide a good, close to the best attainable, estimate of the counting rate activity. The good performances of the proposed approach are studied on simulations and real datasets.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2015-05-15 00:00:00.000000"},
{"id":"46","title":"Fire early player across possible off.","abstract":"In this paper we complete the proof of Ryba's modular moonshine conjectures. We do this by applying Hodge theory to the cohomology of the monster Lie algebra over the ring of p-adic integers in order to calculate the Tate cohomology groups of elements of the monster acting on the monster vertex algebra.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2016-06-06 00:00:00.000000"},
{"id":"47","title":"Never recent left series.","abstract":"We report on the formation and development of the photonic band gap in two-dimensional 8-, 10- and 12-fold symmetry quasicrystalline lattices of low index contrast. Finite size structures made of dielectric cylindrical rods were studied and measured in the microwave region, and their properties compared with a conventional hexagonal crystal. Band gap characteristics were investigated by changing the direction of propagation of the incident beam inside the crystal. Various angles of incidence from 0 \\degree to 30\\degree were used in order to investigate the isotropic nature of the band gap. The arbitrarily high rotational symmetry of aperiodically ordered structures could be practically exploited to manufacture isotropic band gap materials, which are perfectly suitable for hosting waveguides or cavities.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2022-06-16 00:00:00.000000"},
{"id":"48","title":"Environment represent work later boy area.","abstract":"Tavenas has recently proved that any n^{O(1)}-variate and degree n polynomial in VP can be computed by a depth-4 circuit of size 2^{O(\\sqrt{n}\\log n)}. So to prove VP not equal to VNP, it is sufficient to show that an explicit polynomial in VNP of degree n requires 2^{\\omega(\\sqrt{n}\\log n)} size depth-4 circuits. Soon after Tavenas's result, for two different explicit polynomials, depth-4 circuit size lower bounds of 2^{\\Omega(\\sqrt{n}\\log n)} have been proved Kayal et al. and Fournier et al. In particular, using combinatorial design Kayal et al.\\ construct an explicit polynomial in VNP that requires depth-4 circuits of size 2^{\\Omega(\\sqrt{n}\\log n)} and Fournier et al.\\ show that iterated matrix multiplication polynomial (which is in VP) also requires 2^{\\Omega(\\sqrt{n}\\log n)} size depth-4 circuits.   In this paper, we identify a simple combinatorial property such that any polynomial f that satisfies the property would achieve similar circuit size lower bound for depth-4 circuits. In particular, it does not matter whether f is in VP or in VNP. As a result, we get a very simple unified lower bound analysis for the above mentioned polynomials.   Another goal of this paper is to compare between our current knowledge of depth-4 circuit size lower bounds and determinantal complexity lower bounds. We prove the that the determinantal complexity of iterated matrix multiplication polynomial is \\Omega(dn) where d is the number of matrices and n is the dimension of the matrices. So for d=n, we get that the iterated matrix multiplication polynomial achieves the current best known lower bounds in both fronts: depth-4 circuit size and determinantal complexity. To the best of our knowledge, a \\Theta(n) bound for the determinantal complexity for the iterated matrix multiplication polynomial was known only for constant d>1 by Jansen.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2017-02-01 00:00:00.000000"},
{"id":"49","title":"Avoid discussion now age billion billion recognize.","abstract":"We propose an axiomatic generic framework for modelling weak memory. We show how to instantiate this framework for SC, TSO, C++ restricted to release-acquire atomics, and Power. For Power, we compare our model to a preceding operational model in which we found a flaw. To do so, we define an operational model that we show equivalent to our axiomatic model.   We also propose a model for ARM. Our testing on this architecture revealed a behaviour later acknowledged as a bug by ARM, and more recently 33 additional anomalies.   We offer a new simulation tool, called herd, which allows the user to specify the model of his choice in a concise way. Given a specification of a model, the tool becomes a simulator for that model. The tool relies on an axiomatic description; this choice allows us to outperform all previous simulation tools. Additionally, we confirm that verification time is vastly improved, in the case of bounded model-checking.   Finally, we put our models in perspective, in the light of empirical data obtained by analysing the C and C++ code of a Debian Linux distribution. We present our new analysis tool, called mole, which explores a piece of code to find the weak memory idioms that it uses.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2020-11-17 00:00:00.000000"},
{"id":"50","title":"Through natural history program.","abstract":"The automobile is always a point of interest where new technology has been deployed. Because of this interest, human-vehicle interaction has been an appealing area for much research in recent years. The current in-vehicle design has been improved but still possesses some of the design from the traditional interaction style. In this paper, we propose a new user-oriented model for in-vehicle interaction model known as i-Interaction. The i-Interaction model provides user with an intuitive approach to interact with the In-Vehicle Information System (IVIS) by the keypad entry. It is the intent that the proposed usability testing for this model will help improve the way research and development is implemented from this topic. This model does not only provide the user with a direct interaction in vehicles but also introduce a new prospective that other research has not addressed.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2016-11-21 00:00:00.000000"},
{"id":"51","title":"Apply improve officer.","abstract":"The validation of data from sensors has become an important issue in the operation and control of modern industrial plants. One approach is to use knowledge based techniques to detect inconsistencies in measured data. This article presents a probabilistic model for the detection of such inconsistencies. Based on probability propagation, this method is able to find the existence of a possible fault among the set of sensors. That is, if an error exists, many sensors present an apparent fault due to the propagation from the sensor(s) with a real fault. So the fault detection mechanism can only tell if a sensor has a potential fault, but it can not tell if the fault is real or apparent. So the central problem is to develop a theory, and then an algorithm, for distinguishing real and apparent faults, given that one or more sensors can fail at the same time. This article then, presents an approach based on two levels: (i) probabilistic reasoning, to detect a potential fault, and (ii) constraint management, to distinguish the real fault from the apparent ones. The proposed approach is exemplified by applying it to a power plant model.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2017-10-18 00:00:00.000000"},
{"id":"52","title":"Environmental what meet fact big seem great.","abstract":"In here we define the concept of fibered symmetric bimonoidal categories. These are roughly speaking fibered categories D->C whose fibers are symmetric monoidal categories parametrized by C and such that both D and C have a further structure of a symmetric monoidal category that satisfy certain coherences that we describe. Our goal is to show that we can correspond to a fibered symmetric bimonoidal category an E_{\\infty}-ring spectrum in a functorial way.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2022-05-19 00:00:00.000000"},
{"id":"53","title":"Born main treatment arm other.","abstract":"Beam tail effect of multi-bunches will influence the electron beam performances in high intensity thermionic RF gun. Beam dynamic calculations that illustrate the working states of single and multi-pulse fed-in of performance-enhanced EC-ITC (External Cathode Independent Tunable Cavity) RF gun for FEL (Free Electron Laser) injector are performed to estimate extracted bunch properties. By using both Parmela and homemade MATLAB codes, the effects of single beam tail as well as interactions of multi-pulses are analyzed, where ring-based electron algorithm is adopted to calculated RF fields and space charge field. Furthermore, the procedure of unexpected deviated-energy particles mixed with effective bunch head is described by MATLAB code as well. As a result, performance-enhanced EC-ITC RF gun is proved to have the capability to extract continual stable bunches which are suitable for high requirement THz-FEL.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2019-07-09 00:00:00.000000"},
{"id":"54","title":"Man guy road drug important condition maintain trade.","abstract":"In a recent study by Ginther et al., the probability of receiving a U.S. National Institutes of Health (NIH) RO1 award was related to the applicant's race\/ethnicity. The results indicate black\/African-American applicants were 10% less likely than white peers to receive an award, after controlling for background and qualifications. It has generated a widespread debate regarding the unfairness of the NIH grant review process and its correction. In this paper, the work by Ginther et al. was augmented by pairing analysis, axiomatically-individualized productivity and normalized funding success measurement. Although there are racial differences in R01 grant success rates, normalized figures of merit for funding success explain the discrepancy. The suggested \"leverage points for policy intervention\" are in question and require deeper and more thorough investigations. Further adjustments in policies to remove racial disparity should be made more systematically for equal opportunity, rather than being limited to the NIH review process.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2016-05-30 00:00:00.000000"},
{"id":"55","title":"Tonight capital attack smile.","abstract":"We construct isospectral non isometric metrics on real and complex projective space. We recall the construction using isometric torus actions by Carolyn Gordon in chapter 2. In chapter 3 we will recall some facts about complex projective space. In chapter 4 we build the isospectral metrics. Chapter 5 is devoted to the non isometry proof of the metrics built in chapter 4. In chapter 6 isospectral metrics on real projective space are derived from metrics on the sphere.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2020-10-22 00:00:00.000000"},
{"id":"56","title":"Those which report kitchen.","abstract":"Nonresponse is present in almost all surveys and can severely bias estimates. It is usually distinguished between unit and item nonresponse: in the former, we completely fail to have information from a unit selected in the sample, while in the latter, we observe only part of the information on the selected unit. Unit nonresponse is usually dealt with by reweighting: each unit selected in the sample has associated a sampling weight and an unknown response probability; the initial sampling weight is multiplied by the inverse of estimated response probability. Item nonresponse is usually dealt with by imputation. By noting that for a particular survey variable, we just have observed and unobserved values, in this work we exploit the connection between unit and item nonresponse. In particular, we assume that the factors that drive unit response are the same as those that drive item response on selected variables of interest. Response probabilities are then estimated by using a logistic regression with a latent covariate that measures such will to respond and that can explain part of the unknown behavior of a unit to participate in the survey. The latent covariate is estimated using latent trait models. Such approach is particularly relevant for sensitive items and, therefore, can handle non-ignorable nonresponse. Auxiliary information known for both respondents and nonrespondents can be included either in the latent variable model or in the logistic model. The approach can be also used when auxiliary information is not available, and we focus here on this case. The theoretical properties of the proposed estimators are sketched and simulations studies are conducted to illustrate their finite size sample performance.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2017-11-10 00:00:00.000000"},
{"id":"57","title":"Take her language personal else all carry.","abstract":"A simple variational Lagrangian is proposed for the time development of an arbitrary density matrix, employing the \"factorization\" of the density. Only the \"kinetic energy\" appears in the Lagrangian. The formalism applies to pure and mixed state cases, the Navier-Stokes equations of hydrodynamics, transport theory, etc. It recaptures the Least Dissipation Function condition of Rayleigh-Onsager {\\bf and in practical applications is flexible}. The variational proposal is tested on a two level system interacting that is subject, in one instance, to an interaction with a single oscillator and, in another, that evolves in a dissipative mode.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2015-01-25 00:00:00.000000"},
{"id":"58","title":"Approach could be if find blood shoulder.","abstract":"Hypergraphs allow one to encode higher-order relationships in data and are thus a very flexible modeling tool. Current learning methods are either based on approximations of the hypergraphs via graphs or on tensor methods which are only applicable under special conditions. In this paper, we present a new learning framework on hypergraphs which fully uses the hypergraph structure. The key element is a family of regularization functionals based on the total variation on hypergraphs.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2020-08-26 00:00:00.000000"},
{"id":"59","title":"Could family if act lose century security.","abstract":"Let r be a real number, 0<r<1, given as a dual number. With the sequence of \"0\", \"1\" we define a path in a hexagonal lattice. Relations between the properties of r and its path are considered. Generalisations to other bases and lattices.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2019-11-26 00:00:00.000000"},
{"id":"60","title":"Image city ahead.","abstract":"As it is well-known, the year 2005 has been the centenary of the \"annus mirabilis\" (1905) during which Albert Einstein published four fundamental papers of his. But already in 1979, for the centenary of Einstein's birth, the world celebrated his monumantal work. In Italy too, there appeared scientific books, and many semi-popularization (or popularization) articles. The present paper represents a talk delivered in Italian, at the invitation of the Nobel Foundation (Sanremo, IM; Italy), in time for its publication in 1979. This article has been however reprinted, much more recently, in 2002, by the \"Centro DIEA\", Faculty of Engineering, University of Bologna, Bologna, Italy [and its source-file, in html, has been prepared with DIEA's collaboration]. We present here a description of the human, philosophycal and scientific background, starting from which Einstein produced his amazing results: Indeed, we try to show why Einstein's writings today are still so important not only for pure physics (and technology!), but also for our epistemological understanding of the procedures followed by science, and by our own mind, in their development, as well as for our philosophical views about the world we live in; without forgetting the teachings that come (or should come) from Einstein's life and claims for modern pedagogy.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2021-05-12 00:00:00.000000"},
{"id":"61","title":"Fight everybody anything ever.","abstract":"This is an expository account of the edge eigenvalue distributions in random matrix theory and their application in multivariate statistics. The emphasis is on the Painlev\\'e representations of these distributions.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2019-06-22 00:00:00.000000"},
{"id":"62","title":"Probably girl answer none.","abstract":"A classic problem of the motion of a point mass (projectile) thrown at an angle to the horizon is reviewed. The air drag force is taken into account with the drag factor assumed to be constant. Analytic approach is used for investigation. The problem of finding an optimal angle of launching a point mass in a medium with quadratic drag force is considered. An equation for determining a value of this angle is obtained. After finding the optimal angle of launching, eight main parameters of the point mass motion are analytically determined. These parameters are used to construct analytically six main functional relationships of the problem. Simple analytic formulas are used to solve two problems of optimization aimed to maximize the flight range of a point mass and minimize the initial speed of the point mass for getting to the given point on the plane. The motion of a baseball is presented as an example.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2015-07-29 00:00:00.000000"},
{"id":"63","title":"Measure change against possible economic.","abstract":"We continue the study of the following Hamiltonian equation on the Hardy space of the circle, $$i\\partial _tu=\\Pi(|u|^2u)\\ ,$$ where $\\Pi $ denotes the Szeg\\\"o projector. This equation can be seen as a toy model for totally non dispersive evolution equations. In a previous work, we proved that this equation admits a Lax pair, and that it is completely integrable. In this paper, we construct the action-angle variables, which reduces the explicit resolution of the equation to a diagonalisation problem. As a consequence, we solve an inverse spectral problem for Hankel operators. Moreover, we establish the stability of the corresponding invariant tori. Furthermore, from the explicit formulae, we deduce the classification of orbitally stable and unstable traveling waves.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2019-01-05 00:00:00.000000"},
{"id":"64","title":"One improve agent including doctor.","abstract":"We consider the problem of selecting covariates in spatial linear models with Gaussian process errors. Penalized maximum likelihood estimation (PMLE) that enables simultaneous variable selection and parameter estimation is developed and, for ease of computation, PMLE is approximated by one-step sparse estimation (OSE). To further improve computational efficiency, particularly with large sample sizes, we propose penalized maximum covariance-tapered likelihood estimation (PMLE$_{\\mathrm{T}}$) and its one-step sparse estimation (OSE$_{\\mathrm{T}}$). General forms of penalty functions with an emphasis on smoothly clipped absolute deviation are used for penalized maximum likelihood. Theoretical properties of PMLE and OSE, as well as their approximations PMLE$_{\\mathrm{T}}$ and OSE$_{\\mathrm{T}}$ using covariance tapering, are derived, including consistency, sparsity, asymptotic normality and the oracle properties. For covariance tapering, a by-product of our theoretical results is consistency and asymptotic normality of maximum covariance-tapered likelihood estimates. Finite-sample properties of the proposed methods are demonstrated in a simulation study and, for illustration, the methods are applied to analyze two real data sets.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2021-10-10 00:00:00.000000"},
{"id":"65","title":"Identify discover person man.","abstract":"The structure of a network dramatically affects the spreading phenomena unfolding upon it. The contact distribution of the nodes has long been recognized as the key ingredient in influencing the outbreak events. However, limited knowledge is currently available on the role of the weight of the edges on the persistence of a pathogen. At the same time, recent works showed a strong influence of temporal network dynamics on disease spreading. In this work we provide an analytical understanding, corroborated by numerical simulations, about the conditions for infected stable state in weighted networks. In particular, we reveal the role of heterogeneity of edge weights and of the dynamic assignment of weights on the ties in the network in driving the spread of the epidemic. In this context we show that when weights are dynamically assigned to ties in the network an heterogeneous distribution is able to hamper the diffusion of the disease, contrary to what happens when weights are fixed in time.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2016-08-18 00:00:00.000000"},
{"id":"66","title":"Play trade risk whatever be.","abstract":"We summarise the main results from a number of our recent articles on the subject of probabilistic temperature forecasting.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2021-07-26 00:00:00.000000"},
{"id":"67","title":"Not admit fire sign mother impact.","abstract":"We derive and study SQMC (Sequential Quasi-Monte Carlo), a class of algorithms obtained by introducing QMC point sets in particle filtering. SQMC is related to, and may be seen as an extension of, the array-RQMC algorithm of \\cite{LEcuyer2006}. The complexity of SQMC is $\\bigO(N\\log N)$, where $N$ is the number of simulations at each iteration, and its error rate is smaller than the Monte Carlo rate $\\bigO_P(N^{-1\/2})$. The only requirement to implement SQMC is the ability to write the simulation of particle $\\bx_{t}^{n}$ given $\\bx_{t-1}^{n}$ as a deterministic function of $\\bx_{t-1}^{n}$ and a fixed number of uniform variates. We show that SQMC is amenable to the same extensions as standard SMC, such as forward smoothing, backward smoothing, unbiased likelihood evaluation, and so on. In particular, SQMC may replace SMC within a PMCMC (particle Markov chain Monte Carlo) algorithm. We establish several convergence results. We provide numerical evidence that SQMC may significantly outperform SMC in practical scenarios.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2017-12-19 00:00:00.000000"},
{"id":"68","title":"Three exist consider newspaper several what.","abstract":"The nonlinear diffusion in multicomponent liquids under chemical reactions influence has been studied. The theory is applied to the analysis of mass transfer in a solution of acetone-benzene. It has been shown, that the creation of molecular complexes should be taken into account for the explanation of the experimental data on concentration dependence of diffusion coefficients. The matrix of mutual diffusivities has been found and effective parameters of the system have been computed.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2022-02-08 00:00:00.000000"},
{"id":"69","title":"Pull nor three fight.","abstract":"The geometric objects of study in this paper are K3 surfaces which admit a polarization by the unique even unimodular lattice of signature (1,17). A standard Hodge-theoretic observation about this special class of K3 surfaces is that their polarized Hodge structures are identical with the polarized Hodge structures of abelian surfaces that are cartesian products of elliptic curves. Earlier work of the first two authors gives an explicit normal form and construction of the moduli space for these surfaces. In the present work, this normal form is used to derive Picard-Fuchs differential equations satisfied by periods of these surfaces. We also investigate the subloci of the moduli space on which the polarization is enhanced. In these cases, we derive information about the Picard-Fuchs differential equations satisfied by periods of these subfamilies, and we relate this information to the theory of genus zero quotients of the upper half-plane by Moonshine groups. For comparison, we also examine the analogous theory for elliptic curves in Weierstrass form.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2015-05-18 00:00:00.000000"},
{"id":"70","title":"Per by capital specific.","abstract":"A theoretical mechanism of laminar-turbulent transition originated from the deceleration of fluid streams on the walls of the channel or pipe is proposed. For Poiseuille flow an analytical expression relating the critical Reynolds number with the degree of disturbance of the flow is derived.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2017-07-05 00:00:00.000000"},
{"id":"71","title":"Light bad argue market mother water.","abstract":"The long-standing assumption that the stellar initial mass function (IMF) is universal has recently been challenged by a number of observations. Several studies have shown that a \"heavy\" IMF (e.g., with a Salpeter-like abundance of low mass stars and thus normalisation) is preferred for massive early-type galaxies, while this IMF is inconsistent with the properties of less massive, later-type galaxies. These discoveries motivate the hypothesis that the IMF may vary (possibly very slightly) across galaxies and across components of individual galaxies (e.g. bulges vs discs). In this paper we use a sample of 19 late-type strong gravitational lenses from the SWELLS survey to investigate the IMFs of the bulges and discs in late-type galaxies. We perform a joint analysis of the galaxies' total masses (constrained by strong gravitational lensing) and stellar masses (constrained by optical and near-infrared colours in the context of a stellar population synthesis [SPS] model, up to an IMF normalisation parameter). Using minimal assumptions apart from the physical constraint that the total stellar mass within any aperture must be less than the total mass within the aperture, we find that the bulges of the galaxies cannot have IMFs heavier (i.e. implying high mass per unit luminosity) than Salpeter, while the disc IMFs are not well constrained by this data set. We also discuss the necessity for hierarchical modelling when combining incomplete information about multiple astronomical objects. This modelling approach allows us to place upper limits on the size of any departures from universality. More data, including spatially resolved kinematics (as in paper V) and stellar population diagnostics over a range of bulge and disc masses, are needed to robustly quantify how the IMF varies within galaxies.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2020-03-07 00:00:00.000000"},
{"id":"72","title":"Animal deep year act.","abstract":"Researchers are developing mobile sensing platforms to facilitate public awareness of environmental conditions. However, turning such awareness into practical community action and political change requires more than just collecting and presenting data. To inform research on mobile environmental sensing, we conducted design fieldwork with government, private, and public interest stakeholders. In parallel, we built an environmental air quality sensing system and deployed it on street sweeping vehicles in a major U.S. city; this served as a \"research vehicle\" by grounding our interviews and affording us status as environmental action researchers. In this paper, we present a qualitative analysis of the landscape of environmental action, focusing on insights that will help researchers frame meaningful technological interventions.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2015-01-11 00:00:00.000000"},
{"id":"73","title":"Expect under three party player dream.","abstract":"In this paper it is shown that statistical mechanics in the form of thermodynamic entropy can be used as a measure of the severity of individual injuries (AIS), and that the correct way to account for multiple injuries is to sum the entropies. It is further shown that summing entropies according to the Planck-Boltzmann (P-B) definition of entropy is formally the same as ISS, which is why ISS works. Approximate values of the probabilities of fatality are used to calculate the Gibb's entropy, which is more accurate than the P-B entropy far from equilibrium, and are shown to be again proportional to ISS. For the categorisation of injury using entropies it is necessary to consider the underlying entropy of the individuals morbidity to which is added the entropy of trauma, which then may result in death. Adding in the underlying entropy and summing entropies of all AIS3+ values gives a more extended scale than ISS, and so entropy is considered the preferred measure. A small scale trial is conducted of these concepts using the APROSYS In-Depth Pedestrian database, and the differences between the measures are illustrated. It is shown that adopting an entropy approach to categorising injury severity highlights the position of the elderly, who have a reduced physiological reserve to resist further traumatic onslaught. There are other informational entropy-like measures, here called i-entropy, which can also be used to classify injury severity, which are outlined. A large scale trial of these various entropy or i-entropy measures needs to be conducted to assess the usefulness of the measures. In the meantime, an age compensated ISS measure such as ASCOT or TRISS is recommended.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2018-10-12 00:00:00.000000"},
{"id":"74","title":"Investment usually land former other.","abstract":"We present elastic and inelastic spin-changing cross sections for cold and ultracold NH($X\\,^3\\Sigma^-$) + NH($X\\,^3\\Sigma^-$) collisions, obtained from full quantum scattering calculations on an accurate \\textit{ab initio} quintet potential-energy surface. Although we consider only collisions in zero field, we focus on the cross sections relevant for magnetic trapping experiments. It is shown that evaporative cooling of both fermionic $^{14}$NH and bosonic $^{15}$NH is likely to be successful for hyperfine states that allow for s-wave collisions. The calculated cross sections are very sensitive to the details of the interaction potential, due to the presence of (quasi-)bound state resonances. The remaining inaccuracy of the \\textit{ab initio} potential-energy surface therefore gives rise to an uncertainty in the numerical cross-section values. However, based on a sampling of the uncertainty range of the \\textit{ab initio} calculations, we conclude that the exact potential is likely to be such that the elastic-to-inelastic cross-section ratio is sufficiently large to achieve efficient evaporative cooling. This likelihood is only weakly dependent on the size of the channel basis set used in the scattering calculations.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2018-06-22 00:00:00.000000"},
{"id":"75","title":"Some assume summer call sing night.","abstract":"We prove that for a topological space X with the property that $H_p(U)=0$ for $p\\geq d$ and every open subset $U$ of $X$, a finite family of open sets in $X$ has nonempty intersection if for any subfamily of size $j$, $1\\leq j \\leq d+1$, the $(d-j)$-dimensional homology group of its intersection is zero. We use this theorem to prove new results concerning transversal affine planes to families of convex sets.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2015-01-17 00:00:00.000000"},
{"id":"76","title":"Sure she six wonder heart economy subject.","abstract":"We investigate a new class of nonlinear control systems of O.D.E., which are not feedback linearizable in general. Our class is a generalization of the well-known feedback linearizable systems, and moreover it is a generalization of the triangular (or pure-feedback) forms studied before. The definition of our class is global, and coordinate-free, which is why the problem of the equivalence is solved for our class in the whole state space at the very beginning. The goal of this paper is to prove the global controllability of our nonlinear systems. We propose to treat our class as a new canonical form which is a nonlinear global analog of the Brunovsky canonical form on the one hand, and is a global and coordinate-free generalization of the triangular form on the other hand.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2016-09-04 00:00:00.000000"},
{"id":"77","title":"Interesting administration onto.","abstract":"An experiment investigating the angle of Cerenkov light emitted by 3-MeV electrons traversing an acrylic detector has been developed for use in the advanced physics laboratory course at the University of Rochester. In addition to exploring the experimental phenomena of Cerenkov radiation and total internal reflection, the experiment introduces students to several experimental techniques used in actual high energy and nuclear physics experiments, as well as to analysis techniques involving Poisson statistics. [to be published in Am. J. Phys. 67 (Oct\/Nov 1999).]","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2022-10-24 00:00:00.000000"},
{"id":"78","title":"Student seven woman down.","abstract":"Within the quasichemical approach, the hydration free energy of an ion is decomposed into a chemical term accounting for ion specific ion-water interactions within the coordination sphere and nonspecific contributions accounting for packing (excluded volume) and long range interactions. The change in the chemical term with a change in the radius of the coordination sphere is the compressive force exerted by the bulk solvent medium on the surface of the coordination sphere. For the Na+, K+, F-, and Cl- ions considered here this compressive force becomes equal for similarly charged ions for coordination radii of about 0.39 nm, not much larger than a water molecule. These results show that ion specific effects are short ranged and arise primarily due to differences in the local ion-water interactions.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2019-11-22 00:00:00.000000"},
{"id":"79","title":"Possible by responsibility recently.","abstract":"Kinetic instabilities in weakly collisional, high beta plasmas are investigated using two-dimensional hybrid expanding box simulations with Coulomb collisions modeled through the Langevin equation (corresponding to the Fokker-Planck one). The expansion drives a parallel or perpendicular temperature anisotropy (depending on the orientation of the ambient magnetic field). For the chosen parameters the Coulomb collisions are important with respect to the driver but are not strong enough to keep the system stable with respect to instabilities driven by the proton temperature anisotropy. In the case of the parallel temperature anisotropy the dominant oblique fire hose instability efficiently reduces the anisotropy in a quasilinear manner. In the case of the perpendicular temperature anisotropy the dominant mirror instability generates coherent compressive structures which scatter protons and reduce the temperature anisotropy. For both the cases the instabilities generate temporarily enough wave energy so that the corresponding (anomalous) transport coefficients dominate over the collisional ones and their properties are similar to those in collisionless plasmas.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2015-01-19 00:00:00.000000"},
{"id":"80","title":"Pretty middle purpose.","abstract":"MaxEnt's variational principle, in conjunction with Shannon's logarithmic information measure, yields only exponential functional forms in straightforward fashion. In this communication we show how to overcome this limitation via the incorporation, into the variational process, of suitable dynamical information. As a consequence, we are able to formulate a somewhat generalized Shannonian Maximum Entropy approach which provides a unifying \"thermodynamic-like\" explanation for the scale-invariant phenomena observed in social contexts, as city-population distributions. We confirm the MaxEnt predictions by means of numerical experiments with random walkers, and compare them with some empirical data.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2021-01-16 00:00:00.000000"},
{"id":"81","title":"Exist mother new get.","abstract":"We study the set $S_{ann-nc}$ of permutations of $\\{1, ..., p+q \\}$ which are non-crossing in an annulus with $p$ points marked on its external circle and $q$ points marked on its internal circle. The algebraic approach to $S_{ann-nc}$ goes by identifying three possible crossing patterns in an annulus, and by defining a permutation to be annular non-crossing when it does not display any of these patterns. We prove the annular counterpart for a ``geodesic condition'' shown by Biane to characterize non-crossing permutations in a disc. We point out that, as a consequence, annular non-crossing permutations appear in the description of the second order asymptotics for the joint moments of certain families (Wishart and GUE) of random matrices. We examine the relation between $S_{ann-nc}$ and the set $NC_{ann}$ of annular non-crossing partitions of $\\{1, ..., p+q \\}$, and observe that (unlike in the disc case) the natural map from $S_{ann-nc}$ onto $NC_{ann}$ has a pathology which prevents it from being injective.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2022-09-06 00:00:00.000000"},
{"id":"82","title":"Stay event hard age ability that fast.","abstract":"Testing for white noise has been well studied in the literature of econometrics and statistics. For most of the proposed test statistics, such as the well-known Box-Pierce's test statistic with fixed lag truncation number, the asymptotic null distributions are obtained under independent and identically distributed assumptions and may not be valid for the dependent white noise. Due to recent popularity of conditional heteroscedastic models (e.g., GARCH models), which imply nonlinear dependence with zero autocorrelation, there is a need to understand the asymptotic properties of the existing test statistics under unknown dependence. In this paper, we showed that the asymptotic null distribution of Box-Pierce's test statistic with general weights still holds under unknown weak dependence so long as the lag truncation number grows at an appropriate rate with increasing sample size. Further applications to diagnostic checking of the ARMA and FARIMA models with dependent white noise errors are also addressed. Our results go beyond earlier ones by allowing non-Gaussian and conditional heteroscedastic errors in the ARMA and FARIMA models and provide theoretical support for some empirical findings reported in the literature.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2021-02-10 00:00:00.000000"},
{"id":"83","title":"Left right low street college peace coach open.","abstract":"It is shown as experiments and theories about the nature of light led to the special theory of relativity. The most important facts for the emergence of the theory proposed by Einstein in 1905 are presented.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2020-02-26 00:00:00.000000"},
{"id":"84","title":"Consumer sister degree dark environment worker brother.","abstract":"The recent nuclear accident in Japan revealed the confusion and the inadequate knowledge of the citizens about the issues of nuclear energy, nuclear applications, radioactivity and their consequences In this work we present the first results of an ongoing study which aims to evaluate the knowledge and the views of Greek undergraduate students on the above issues. A web based survey was conducted and 131 students from TEI Piraeus answered a multiple choice questionnaire with questions of general interest on nuclear energy, nuclear applications, radioactivity and their consequences. The survey showed that students, like the general population, have a series of faulty views on general interest nuclear issues. Furthermore, the first results indicate that our educational system is not so effective as source of information on these issues in comparison to the media and internet","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2021-09-16 00:00:00.000000"},
{"id":"85","title":"Middle challenge policy success.","abstract":"We propose a lexical account of action nominals, in particular of deverbal nominalisations, whose meaning is related to the event expressed by their base verb. The literature about nominalisations often assumes that the semantics of the base verb completely defines the structure of action nominals. We argue that the information in the base verb is not sufficient to completely determine the semantics of action nominals. We exhibit some data from different languages, especially from Romance language, which show that nominalisations focus on some aspects of the verb semantics. The selected aspects, however, seem to be idiosyncratic and do not automatically result from the internal structure of the verb nor from its interaction with the morphological suffix. We therefore propose a partially lexicalist approach view of deverbal nouns. It is made precise and computable by using the Montagovian Generative Lexicon, a type theoretical framework introduced by Bassac, Mery and Retor\\'e in this journal in 2010. This extension of Montague semantics with a richer type system easily incorporates lexical phenomena like the semantics of action nominals in particular deverbals, including their polysemy and (in)felicitous copredications.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2021-06-14 00:00:00.000000"},
{"id":"86","title":"Several government actually hold coach PM.","abstract":"Analysis how to use Internet influence to the process of political communication, marketing and the management of public relations, what kind of online communication methods are used by political parties, and to assess satisfaction, means of communication and the services they provide to their partys voters (people) and other interest groups and whether social networks can affect the political and economic changes in the state, and the political power of one party.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2020-06-16 00:00:00.000000"},
{"id":"87","title":"Democratic statement rock lead hard.","abstract":"In this paper we address the decision problem for a fragment of set theory with restricted quantification which extends the language studied in [4] with pair related quantifiers and constructs, in view of possible applications in the field of knowledge representation. We will also show that the decision problem for our language has a non-deterministic exponential time complexity. However, for the restricted case of formulae whose quantifier prefixes have length bounded by a constant, the decision problem becomes NP-complete. We also observe that in spite of such restriction, several useful set-theoretic constructs, mostly related to maps, are expressible. Finally, we present some undecidable extensions of our language, involving any of the operators domain, range, image, and map composition.   [4] Michael Breban, Alfredo Ferro, Eugenio G. Omodeo and Jacob T. Schwartz (1981): Decision procedures for elementary sublanguages of set theory. II. Formulas involving restricted quantifiers, together with ordinal, integer, map, and domain notions. Communications on Pure and Applied Mathematics 34, pp. 177-195","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2021-12-17 00:00:00.000000"},
{"id":"88","title":"Lawyer rest computer clearly room.","abstract":"Equilibrium statistics of Hamiltonian systems is correctly described by the microcanonical ensemble. Classically this is the manifold of all points in the $N-$body phase space with the given total energy. Due to Boltzmann's principle, $e^S=tr(\\delta(E-H))$, its geometrical size is related to the entropy $S(E,N,...)$. This definition does not invoke any information theory, no thermodynamic limit, no extensivity, and no homogeneity assumption, as are needed in conventional (canonical) thermo-statistics. Therefore, it describes the equilibrium statistics of extensive as well of non-extensive systems. Due to this fact it is the {\\em fundamental} definition of any classical equilibrium statistics. It can address nuclei and astrophysical objects as well. All kind of phase transitions can be distinguished sharply and uniquely for even small systems. It is further shown that the second law is a natural consequence of the statistical nature of thermodynamics which describes all systems with the same -- redundant -- set of few control parameters simultaneously. It has nothing to do with the thermodynamic limit. It even works in systems which are by far {\\em larger} than any thermodynamic \"limit\".","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2021-04-12 00:00:00.000000"},
{"id":"89","title":"Certain add suggest then remember.","abstract":"A major challenge in testing software product lines is efficiency. In particular, testing a product line should take less effort than testing each and every product individually. We address this issue in the context of input-output conformance testing, which is a formal theory of model-based testing. We extend the notion of conformance testing on input-output featured transition systems with the novel concept of spinal test suites. We show how this concept dispenses with retesting the common behavior among different, but similar, products of a software product line.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2022-02-05 00:00:00.000000"},
{"id":"90","title":"Bit agreement guy white line usually.","abstract":"The existence of resonant enhanced transmission and collimation of light waves by subwavelength slits in metal films [for example, see T.W. Ebbesen et al., Nature (London) 391, 667 (1998) and H.J. Lezec et al., Science, 297, 820 (2002)] leads to the basic question: Can a light be enhanced and simultaneously localized in space and time by a subwavelength slit? To address this question, the spatial distribution of the energy flux of an ultrashort (femtosecond) wave-packet diffracted by a subwavelength (nanometer-size) slit was analyzed by using the conventional approach based on the Neerhoff and Mur solution of Maxwell's equations. The results show that a light can be enhanced by orders of magnitude and simultaneously localized in the near-field diffraction zone at the nm- and fs-scales. Possible applications in nanophotonics are discussed.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2017-05-28 00:00:00.000000"},
{"id":"91","title":"Home goal house vote.","abstract":"This paper discusses a stylized communications problem where one wishes to transmit a real-valued signal x in R^n (a block of n pieces of information) to a remote receiver. We ask whether it is possible to transmit this information reliably when a fraction of the transmitted codeword is corrupted by arbitrary gross errors, and when in addition, all the entries of the codeword are contaminated by smaller errors (e.g. quantization errors).   We show that if one encodes the information as Ax where A is a suitable m by n coding matrix (m >= n), there are two decoding schemes that allow the recovery of the block of n pieces of information x with nearly the same accuracy as if no gross errors occur upon transmission (or equivalently as if one has an oracle supplying perfect information about the sites and amplitudes of the gross errors). Moreover, both decoding strategies are very concrete and only involve solving simple convex optimization programs, either a linear program or a second-order cone program. We complement our study with numerical simulations showing that the encoder\/decoder pair performs remarkably well.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2020-11-23 00:00:00.000000"},
{"id":"92","title":"Join husband account many scientist.","abstract":"With the development of nanotechnology, the measurement of electrical properties in local area of materials and devices has become a great need. Although a lot kind of scanning probe microscope have been developed for satisfying the requirement of nanotechnology, a microscope technique which can determine electrical properties in local area of materials and devices is not yet developed. Recently, microwave microscope has been an interest to many researchers, due to its potential in the evaluation of electrical properties of materials and devices. The advance of microwave is that the response of materials is directly relative to the electromagnetic properties of materials. However, because of the problem of the structure of probes, nanometer-scale resolution has not been successful. To achieve the goal, a new structure microwave probe is required. In this paper, we report a nanostructural microwave probe. To restrain the attenuation of microwave in the probe, GaAs was used as the substrate of the probe. To obtain the desired structure, wet etching was used to fabricate the probe. Different with the dry etching, a side-etching will occur under the etching mask. Utilizing this property, a micro tip can be fabricated by etching a wafer, of which a small mask was introduced on the surface in advance.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2022-06-10 00:00:00.000000"},
{"id":"93","title":"Accept feel thus discussion figure out of person.","abstract":"In the framework of noisy quantum homodyne tomography with efficiency parameter $1\/2 < \\eta \\leq 1$, we propose a novel estimator of a quantum state whose density matrix elements $\\rho_{m,n}$ decrease like $Ce^{-B(m+n)^{r\/ 2}}$, for fixed $C\\geq 1$, $B>0$ and $0<r\\leq 2$. On the contrary to previous works, we focus on the case where $r$, $C$ and $B$ are unknown. The procedure estimates the matrix coefficients by a projection method on the pattern functions, and then by soft-thresholding the estimated coefficients.   We prove that under the $\\mathbb{L}_2$ -loss our procedure is adaptive rate-optimal, in the sense that it achieves the same rate of conversgence as the best possible procedure relying on the knowledge of $(r,B,C)$. Finite sample behaviour of our adaptive procedure are explored through numerical experiments.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2021-03-10 00:00:00.000000"},
{"id":"94","title":"Parent send learn.","abstract":"Answer-Set Programming (ASP) is an established declarative programming paradigm. However, classical ASP lacks subprogram calls as in procedural programming, and access to external computations (like remote procedure calls) in general. The feature is desired for increasing modularity and---assuming proper access in place---(meta-)reasoning over subprogram results. While HEX-programs extend classical ASP with external source access, they do not support calls of (sub-)programs upfront. We present nested HEX-programs, which extend HEX-programs to serve the desired feature, in a user-friendly manner. Notably, the answer sets of called sub-programs can be individually accessed. This is particularly useful for applications that need to reason over answer sets like belief set merging, user-defined aggregate functions, or preferences of answer sets.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2020-09-23 00:00:00.000000"},
{"id":"95","title":"Sense clearly catch brother age edge doctor.","abstract":"We show that the left (right) sample quantile tends to the left (right) distribution quantile at p in [0,1], if the left and right quantiles are identical at p. We show that the sample quantiles diverge almost surely otherwise. The latter can be considered as a generalization of the well-known result that the sum of a random sample of a fair coin with 1 denoting heads and -1 denoting tails is 0 infinitely often. In the case that the sample quantiles do not converge we show that the limsup is the right quantile and the liminf is the left quantile.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2017-12-21 00:00:00.000000"},
{"id":"96","title":"Down huge actually central its.","abstract":"In this paper, we consider the problem of estimating the eigenvalues and eigenfunctions of the covariance kernel (i.e., the functional principal components) from sparse and irregularly observed longitudinal data. We approach this problem through a maximum likelihood method assuming that the covariance kernel is smooth and finite dimensional. We exploit the smoothness of the eigenfunctions to reduce dimensionality by restricting them to a lower dimensional space of smooth functions. The estimation scheme is developed based on a Newton-Raphson procedure using the fact that the basis coefficients representing the eigenfunctions lie on a Stiefel manifold. We also address the selection of the right number of basis functions, as well as that of the dimension of the covariance kernel by a second order approximation to the leave-one-curve-out cross-validation score that is computationally very efficient. The effectiveness of our procedure is demonstrated by simulation studies and an application to a CD4 counts data set. In the simulation studies, our method performs well on both estimation and model selection. It also outperforms two existing approaches: one based on a local polynomial smoothing of the empirical covariances, and another using an EM algorithm.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2017-12-02 00:00:00.000000"},
{"id":"97","title":"Now person adult heavy strategy hair.","abstract":"We address the problem of multiresolution module detection in dense weighted networks, where the modular structure is encoded in the weights rather than topology. We discuss a weighted version of the q-state Potts method, which was originally introduced by Reichardt and Bornholdt. This weighted method can be directly applied to dense networks. We discuss the dependence of the resolution of the method on its tuning parameter and network properties, using sparse and dense weighted networks with built-in modules as example cases. Finally, we apply the method to data on stock price correlations, and show that the resulting modules correspond well to known structural properties of this correlation network.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2016-06-12 00:00:00.000000"},
{"id":"98","title":"Suffer store second mind oil recent color.","abstract":"Calculations of the leading quantum electrodynamics effects in few electron systems involve singular matrix elements of the inter-electronic distances of the form $1\/r_i^3$ and $1\/r_{ij}^3$. Integrals that result when the nonrelativistic wave function is represented with a Hylleraas basis representation are studied. Recursion relations for various powers of the electron coordinates and the master integrals are derived in a form suited for high precision numerical evaluations.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2020-05-21 00:00:00.000000"},
{"id":"99","title":"Usually interesting simple assume.","abstract":"The surrounding of a vertex in a network can be more or less symmetric. We derive measures of a specific kind of symmetry of a vertex which we call degree symmetry -- the property that many paths going out from a vertex have overlapping degree sequences. These measures are evaluated on artificial and real networks. Specifically we consider vertices in the human metabolic network. We also measure the average degree-symmetry coefficient for different classes of real-world network. We find that most studied examples are weakly positively degree-symmetric. The exceptions are an airport network (having a negative degree-symmetry coefficient) and one-mode projections of social affiliation networks that are rather strongly degree-symmetric.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2021-03-27 00:00:00.000000"},
{"id":"100","title":"Wish fight condition everybody red thus.","abstract":"We consider linear models for stochastic dynamics. To any such model can be associated a network (namely a directed graph) describing which degrees of freedom interact under the dynamics. We tackle the problem of learning such a network from observation of the system trajectory over a time interval $T$.   We analyze the $\\ell_1$-regularized least squares algorithm and, in the setting in which the underlying network is sparse, we prove performance guarantees that are \\emph{uniform in the sampling rate} as long as this is sufficiently high. This result substantiates the notion of a well defined `time complexity' for the network inference problem.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2021-12-02 00:00:00.000000"},
{"id":"101","title":"Suffer truth shoulder type media but.","abstract":"The screened QED corrections of the first orders in \\alpha and 1\/Z to the g factor and the hyperfine splitting of lithiumlike ions are evaluated within ab initio quantum electrodynamical approach. The complete gauge-invariant set of the two-electron self-energy diagrams in the presence of the magnetic field and a dominant part of the two-electron vacuum-polarization diagrams are calculated. The most accurate values of the g factor of Li-like lead and uranium are presented. The theoretical prediction for the specific difference of the hyperfine splittings of H- and Li-like bismuth is improved.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2021-09-17 00:00:00.000000"},
{"id":"102","title":"Wear get water source where.","abstract":"InGaAs avalanche photodiodes (APDs) are convenient for single photon detection in the near-infrared (NIR) including the fibre communication bands (1.31\/1.55 $\\mu$m). However, to suppress afterpulse noise due to trapped avalanche charge, they must be gated with MHz repetition frequencies, thereby severely limiting the count rate in NIR applications. Here we show gating frequencies for InGaAs-APDs well beyond 1 GHz. Using a self-differencing technique to sense much weaker avalanches, we reduce drastically afterpulse noise. At 1.25 GHz, we obtain a detection efficiency of 10.8% with an afterpulse probability of 6.16%. In addition, the detector features low jitter (55 ps) and a count rate of 100 MHz.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2017-12-21 00:00:00.000000"},
{"id":"103","title":"Phone eat eight.","abstract":"We use critical block sensitivity, a new complexity measure introduced by Huynh and Nordstr\\\"om (STOC 2012), to study the communication complexity of search problems. To begin, we give a simple new proof of the following central result of Huynh and Nordstr\\\"om: if $S$ is a search problem with critical block sensitivity $b$, then every randomised two-party protocol solving a certain two-party lift of $S$ requires $\\Omega(b)$ bits of communication. Besides simplicity, our proof has the advantage of generalising to the multi-party setting. We combine these results with new critical block sensitivity lower bounds for Tseitin and Pebbling search problems to obtain the following applications:   (1) Monotone Circuit Depth: We exhibit a monotone function on $n$ variables whose monotone circuits require depth $\\Omega(n\/\\log n)$; previously, a bound of $\\Omega(\\sqrt{n})$ was known (Raz and Wigderson, JACM 1992). Moreover, we prove a tight $\\Theta(\\sqrt{n})$ monotone depth bound for a function in monotone P. This implies an average-case hierarchy theorem within monotone P similar to a result of Filmus et al. (FOCS 2013).   (2) Proof Complexity: We prove new rank lower bounds as well as obtain the first length--space lower bounds for semi-algebraic proof systems, including Lov\\'asz--Schrijver and Lasserre (SOS) systems. In particular, these results extend and simplify the works of Beame et al. (SICOMP 2007) and Huynh and Nordstr\\\"om.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2022-02-10 00:00:00.000000"},
{"id":"104","title":"Believe campaign begin great.","abstract":"According to numerous press reports, in 2007 at Minot US Air Force Base six AGM-129 Advanced Cruise Missiles mistakenly armed with W80-1 thermonuclear warheads were loaded on a B-52H heavy bomber in place of six unarmed AGM-129 missiles that were awaiting transport to Barksdale US Air Force Base for disposal. The live nuclear missiles were not reported missing, and stood unsecured and unguarded while mounted to the aircraft for a period of 36 hours. The present work investigates the radiological hazards associated with a worst-case postulated accident that would disperse the nuclear material of the six warheads in large metropolitan cities. Using computer simulations approximate estimates are derived for the ensuing cancer mortality and land contamination after the accident. Health, decontamination and evacuation costs are also estimated in the framework of the linear risk model.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2020-06-26 00:00:00.000000"},
{"id":"105","title":"Turn people half size friend open.","abstract":"Let us consider a finite set of pairs consisting of good $U'_q(g)$-modules and invertible elements. The distribution of poles of normalized R-matrices yields Khovanov-Lauda-Rouquier algebras We define a functor from the category of finite-dimensional modules over the KLR algebra to the category of finite-dimensional $U_q'(g)$-modules. We show that the functor sends convolution products to tensor products and is exact if the KLR albera is of type A, D, E.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2018-04-06 00:00:00.000000"},
{"id":"106","title":"Enough nice ahead military condition half word.","abstract":"The difference between the rf voltage seen by the beam and the accelerating voltage required to match the rate of change of the Booster magnetic field is used to estimate the energy loss per beam turn. Because the rf voltage (RFSUM) and the synchronous phase can be experimentally measured, they can be used to calculate the effective accelerating voltage. Also an RFSUM reduction technique has been applied to measure experimentally the RFSUM limit at which the beam loss starts. With information on beam energy loss, the running conditions, especially for the high intensity beam, can be optimized in order to achieve a higher intensity beam from the Fermilab Booster.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2015-08-26 00:00:00.000000"},
{"id":"107","title":"Investment say third head short example possible.","abstract":"We study intersection matrix algebras im(A^d) that arise from affinizing a Cartan matrix A of type B_r with d arbitrary long roots in the root system $\\Delta_{B_r}$, where $r \\geq 3$. We show that im(A^d) is isomorphic to the universal covering algebra of $so_{2r+1}(a,\\eta,C,\\chi)$, where $a$ is an associative algebra with involution $\\eta$, and $C$ is an $a$-module with hermitian form $\\chi$. We provide a description of all four of the components $a$, $\\eta$, $C$, and $\\chi$.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2021-07-11 00:00:00.000000"},
{"id":"108","title":"Center spring hard child.","abstract":"Abductive reasoning (or Abduction, for short) is among the most fundamental AI reasoning methods, with a broad range of applications, including fault diagnosis, belief revision, and automated planning. Unfortunately, Abduction is of high computational complexity; even propositional Abduction is \\Sigma_2^P-complete and thus harder than NP and coNP. This complexity barrier rules out the existence of a polynomial transformation to propositional satisfiability (SAT). In this work we use structural properties of the Abduction instance to break this complexity barrier. We utilize the problem structure in terms of small backdoor sets. We present fixed-parameter tractable transformations from Abduction to SAT, which make the power of today's SAT solvers available to Abduction.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2016-08-05 00:00:00.000000"},
{"id":"109","title":"East up budget suddenly chair summer.","abstract":"This project presents the analysis, design, implementation and results of Reconstruction Xicocotitlan Tollan-through augmented reality, which will release information about the Toltec culture supplemented by presenting an overview of the main premises of the Xicocotitlan Tollan city supported dimensional models based on the augmented reality technique showing the user a virtual representation of buildings in Tollan.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2015-01-07 00:00:00.000000"},
{"id":"110","title":"Challenge talk lawyer couple send century unit.","abstract":"We give an explicit construction of a large subset of F^n, where F is a finite field, that has small intersection with any affine variety of fixed dimension and bounded degree. Our construction generalizes a recent result of Dvir and Lovett (STOC 2012) who considered varieties of degree one (affine subspaces).","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2016-10-16 00:00:00.000000"},
{"id":"111","title":"Author skill evening push responsibility tough allow.","abstract":"Quasisymmetric stellarators are a type of optimized stellarators for which flows are undamped to lowest order in an expansion in the normalized Larmor radius. However, perfect quasisymmetry is impossible. Since large flows may be desirable as a means to reduce turbulent transport, it is important to know when a stellarator can be considered to be sufficiently close to quasisymmetry. The answer to this question depends strongly on the size of the spatial gradients of the deviation from quasisymmetry and on the collisionality regime. Recently, formal criteria for closeness to quasisymmetry have been derived in a variety of situations. In particular, the case of deviations with large gradients was solved in the $1\/\\nu$ regime. Denoting by $\\alpha$ a parameter that gives the size of the deviation from quasisymmetry, it was proven that particle fluxes do not scale with $\\alpha^{3\/2}$, as typically claimed, but with $\\alpha$. It was also shown that ripple wells are not necessarily the main cause of transport. This paper reviews those works and presents a new result in another collisionality regime, in which particles trapped in ripple wells are collisional and the rest are collisionless.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2019-12-29 00:00:00.000000"},
{"id":"112","title":"Crime local grow wrong road reach TV.","abstract":"Gaussian processes (GP) are Bayesian non-parametric models that are widely used for probabilistic regression. Unfortunately, it cannot scale well with large data nor perform real-time predictions due to its cubic time cost in the data size. This paper presents two parallel GP regression methods that exploit low-rank covariance matrix approximations for distributing the computational load among parallel machines to achieve time efficiency and scalability. We theoretically guarantee the predictive performances of our proposed parallel GPs to be equivalent to that of some centralized approximate GP regression methods: The computation of their centralized counterparts can be distributed among parallel machines, hence achieving greater time efficiency and scalability. We analytically compare the properties of our parallel GPs such as time, space, and communication complexity. Empirical evaluation on two real-world datasets in a cluster of 20 computing nodes shows that our parallel GPs are significantly more time-efficient and scalable than their centralized counterparts and exact\/full GP while achieving predictive performances comparable to full GP.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2015-03-26 00:00:00.000000"},
{"id":"113","title":"Find yourself fire learn.","abstract":"We define the notion of universal lift of a projective complex based on non-commutative parameter algebras, and prove its existence and uniqueness. We investigate the properties of parameter algebras for universal lifts.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2016-06-02 00:00:00.000000"},
{"id":"114","title":"Visit blue reality better under player particular.","abstract":"Some normal logic programs under the answer set (stable model) semantics lack the appealing property of \"cautious monotonicity.\" That is, augmenting a program with one of its consequences may cause it to lose another of its consequences. The syntactic condition of \"order-consistency\" was shown by Fages to guarantee existence of an answer set. This note establishes that order-consistent programs are not only consistent, but cautiously monotonic.   From this it follows that they are also \"cumulative.\" That is, augmenting an order-consistent with some of its consequences does not alter its consequences. In fact, as we show, its answer sets remain unchanged.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2017-07-30 00:00:00.000000"},
{"id":"115","title":"Final myself reflect school.","abstract":"Increasing the luminosity of relativistic hadron beams is critical for the advancement of nuclear physics. Coherent electron cooling (CEC) promises to cool such beams significantly faster than alternative methods. We present simulations of 40 GeV\/nucleon Au+79 ions through the first (modulator) section of a coherent electron cooler. In the modulator, the electron beam copropagates with the ion beam, which perturbs the electron beam density and velocity via anisotropic Debye shielding. In contrast to previous simulations, where the electron density was constant in time and space, here the electron beam has a finite transverse extent, and undergoes focusing by quadrupoles as it passes through the modulator. The peak density in the modulator increases by a factor of 3, as specified by the beam Twiss parameters. The inherently 3D particle and field dynamics is modeled with the parallel VSim framework using a $\\delta$f PIC algorithm. Physical parameters are taken from the CEC proof-of-principle experiment under development at Brookhaven National Lab.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2020-03-19 00:00:00.000000"},
{"id":"116","title":"Mouth season again degree.","abstract":"Catastrophes of all kinds can be roughly defined as short duration-large amplitude events following and followed by long periods of \"ripening\". Major earthquakes surely belong to the class of 'catastrophic' events. Because of the space-time scales involved, an experimental approach is often difficult, not to say impossible, however desirable it could be. Described in this article is a \"laboratory\" setup that yields data of a type that is amenable to theoretical methods of prediction. Observations are made of a critical slowing down in the noisy signal of a solder wire creeping under constant stress. This effect is shown to be a fair signal of the forthcoming catastrophe in both of two dynamical models. The first is an \"abstract\" model in which a time dependent quantity drifts slowly but makes quick jumps from time to time. The second is a realistic physical model for the collective motion of dislocations (the Ananthakrishna set of equations for creep). Hope thus exists that similar changes in the response to noise could forewarn catastrophes in other situations, where such precursor effects should manifest early enough.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2016-03-22 00:00:00.000000"},
{"id":"117","title":"Eight put nearly south among daughter actually mission.","abstract":"At this article will be created a software written in visual basic for efficiency and penetration calculation in a fibrous filter medium for given values of particles diameter that are retained in the filter. Initially, will become report of mathematical models of air filtration in fibrous filters media and then will develop the code and the graphical interface of application, that are the base for software creation in the visual basic platform.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2019-11-27 00:00:00.000000"},
{"id":"118","title":"Industry not serve lot board.","abstract":"In this paper, a Bayesian approach is developed for simultaneously comparing multiple experimental treatments with a common control treatment in an exploratory clinical trial. The sample size is set to ensure that, at the end of the study, there will be at least one treatment for which the investigators have a strong belief that it is better than control, or else they have a strong belief that none of the experimental treatments are substantially better than control. This criterion bears a direct relationship with conventional frequentist power requirements, while allowing prior opinion to feature in the analysis with a consequent reduction in sample size. If it is concluded that at least one of the experimental treatments shows promise, then it is envisaged that one or more of these promising treatments will be developed further in a definitive phase III trial. The approach is developed in the context of normally distributed responses sharing a common standard deviation regardless of treatment. To begin with, the standard deviation will be assumed known when the sample size is calculated. The final analysis will not rely upon this assumption, although the intended properties of the design may not be achieved if the anticipated standard deviation turns out to be inappropriate. Methods that formally allow for uncertainty about the standard deviation, expressed in the form of a Bayesian prior, are then explored. Illustrations of the sample sizes computed from the new method are presented, and comparisons are made with frequentist methods devised for the same situation.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2020-03-23 00:00:00.000000"},
{"id":"119","title":"Take reveal chance different crime.","abstract":"One of the major challenges in large-scale data processing with MapReduce is the smart computation of joins. Since Semantic Web datasets published in RDF have increased rapidly over the last few years, scalable join techniques become an important issue for SPARQL query processing as well. In this paper, we introduce the Map-Side Index Nested Loop Join (MAPSIN join) which combines scalable indexing capabilities of NoSQL storage systems like HBase, that suffer from an insufficient distributed processing layer, with MapReduce, which in turn does not provide appropriate storage structures for efficient large-scale join processing. While retaining the flexibility of commonly used reduce-side joins, we leverage the effectiveness of map-side joins without any changes to the underlying framework. We demonstrate the significant benefits of MAPSIN joins for the processing of SPARQL basic graph patterns on large RDF datasets by an evaluation with the LUBM and SP2Bench benchmarks. For most queries, MAPSIN join based query execution outperforms reduce-side join based execution by an order of magnitude.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2020-12-31 00:00:00.000000"},
{"id":"120","title":"May catch wonder material.","abstract":"We identify Melrose's suspended algebra of pseudodifferential operators with a subalgebra of the algebra of parametric pseudodifferential operators with parameter space $\\R$. For a general algebra of parametric pseudodifferential operators, where the parameter space may now be a cone $\\Gamma\\subset\\R^p$, we construct a unique ``symbol valued trace'', which extends the $L^2$-trace on operators of small order. This allows to construct various trace functionals in a systematic way. Furthermore we study the higher-dimensional eta-invariants on algebras with parameter space $\\R^{2k-1}$. Using Clifford representations we construct for each first order elliptic differential operator a natural family of parametric pseudodifferential operators over $\\R^{2k-1}$. The eta-invariant of this family coincides with the spectral eta-invariant of the operator.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2015-03-24 00:00:00.000000"},
{"id":"121","title":"Until discussion moment.","abstract":"The confluence of untyped \\lambda-calculus with unconditional rewriting is now well un- derstood. In this paper, we investigate the confluence of \\lambda-calculus with conditional rewriting and provide general results in two directions. First, when conditional rules are algebraic. This extends results of M\\\"uller and Dougherty for unconditional rewriting. Two cases are considered, whether \\beta-reduction is allowed or not in the evaluation of conditions. Moreover, Dougherty's result is improved from the assumption of strongly normalizing \\beta-reduction to weakly normalizing \\beta-reduction. We also provide examples showing that outside these conditions, modularity of confluence is difficult to achieve. Second, we go beyond the algebraic framework and get new confluence results using a restricted notion of orthogonality that takes advantage of the conditional part of rewrite rules.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2021-02-02 00:00:00.000000"},
{"id":"122","title":"Range hear campaign forward.","abstract":"It was shown by Kaup that every origin-preserving automorphism of quasi-circular domains is a polynomial mapping. In this paper, we study how the weight of quasi-circular domains and the degree of such automorphisms are related. By using the Bergman mapping, we prove that every origin-preserving automorphism of normal quasi-circular domains in $\\mathbb C^2$ is linear.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2017-04-25 00:00:00.000000"},
{"id":"123","title":"Question from oil only.","abstract":"In this paper we present a method to obtain resolutions of symplectic orbifolds arising from symplectic reduction of a Hamiltonian S^1-manifold at a regular value. As an application, we show that all isolated cyclic singularities of a symplectic orbifold admit a resolution and that pre-quantisations of symplectic orbifolds are symplectically fillable by a smooth manifold.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2018-12-24 00:00:00.000000"},
{"id":"124","title":"Language property security live great test.","abstract":"This paper made some significant advances in the dual reciprocity and boundary-only RBF techniques. The proposed boundary knot method (BKM) is different from the standard boundary element method in a number of important aspects. Namely, it is truly meshless, exponential convergence, integration-free (of course, no singular integration), boundary-only for general problems, and leads to symmetric matrix under certain conditions (able to be extended to general cases after further modified). The BKM also avoids the artificial boundary in the method of fundamental solution. An amazing finding is that the BKM can formulate linear modeling equations for nonlinear partial differential systems with linear boundary conditions. This merit makes it circumvent all perplexing issues in the iteration solution of nonlinear equations. On the other hand, by analogy with Green's second identity, this paper also presents a general solution RBF (GSR) methodology to construct efficient RBFs in the dual reciprocity and domain-type RBF collocation methods. The GSR approach first establishes an explicit relationship between the BEM and RBF itself on the ground of the weighted residual principle. This paper also discusses the RBF convergence and stability problems within the framework of integral equation theory.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2018-06-04 00:00:00.000000"},
{"id":"125","title":"Board budget collection.","abstract":"Relationship is clarified between the notions of linear extension of algebraic theories, and central extension, in the sense of commutator calculus, of their models. Varieties of algebras turn out to be nilpotent Maltsev precisely when their theories may be obtained as results of iterated linear extensions by bifunctors from the so called abelian theories. The latter theories are described; they are slightly more general than theories of modules over a ring.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2016-06-08 00:00:00.000000"},
{"id":"126","title":"Care audience arrive.","abstract":"We investigate the use of inexact solves for interpolatory model reduction and consider associated perturbation effects on the underlying model reduction problem. We give bounds on system perturbations induced by inexact solves and relate this to termination criteria for iterative solution methods. We show that when a Petrov-Galerkin framework is employed for the inexact solves, the associated reduced order model is an exact interpolatory model for a nearby full-order system; thus demonstrating backward stability. We also give evidence that for $\\h2$-optimal interpolation points, interpolatory model reduction is robust with respect to perturbations due to inexact solves. Finally, we demonstrate the effecitveness of direct use of inexact solves in optimal ${\\mathcal H}_2$ approximation. The result is an effective model reduction strategy that is applicable in realistically large-scale settings.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2020-10-27 00:00:00.000000"},
{"id":"127","title":"Section everything three.","abstract":"It is well-known that sparse grid algorithm has been widely accepted as an efficient tool to overcome the \"curse of dimensionality\" in some degree. In this note, we first give the error estimate of hyperbolic cross (HC) approximations with generalized Hermite functions. The exponential convergence in both regular and optimized hyperbolic cross approximations has been shown. Moreover, the error estimate of Hermite spectral method to high-dimensional linear parabolic PDEs with HC approximations has been investigated in the properly weighted Korobov spaces. The numerical result verifies the exponential convergence of this approach.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2019-06-13 00:00:00.000000"},
{"id":"128","title":"Other around reflect total miss.","abstract":"In this paper the thermal processes generated by yoctosecond (10-24 s) laser pulses in QGP are investigated. Considering that the relaxation time in QGP is of the order of 1 ys it is shown that in QGP the yoctosecond laser pulses can generate the thermal waves with velocity v = c (0.3 fm\/ys).   Key words: QGP, thermal waves, yoctosecond pulses","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2017-06-22 00:00:00.000000"},
{"id":"129","title":"As thousand wrong during.","abstract":"We show how to compactly represent any $n$-dimensional subspace of $R^m$ as a banded product of Householder reflections using $n(m - n)$ floating point numbers. This is optimal since these subspaces form a Grassmannian space $Gr_n(m)$ of dimension $n(m - n)$. The representation is stable and easy to compute: any matrix can be factored into the product of a banded Householder matrix and a square matrix using two to three QR decompositions.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2019-11-25 00:00:00.000000"},
{"id":"130","title":"It level wrong science.","abstract":"This paper presents the design consideration and simulation of interpolator of OSR 128. The proposed structure uses the half band filers & Comb\/Sinc filter. Experimental result shows that proposed interpolator achieves the design specification, and also has good noise rejection capabilities. The interpolator accepts the input at 44.1 kHz for applications like CD & DVD audio. The interpolation filter can be applied to the delta sigma DAC. The related work is done with the MATLAB & XILINX ISE simulators. The maximum operating frequency is achieved as 34.584 MHz.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2017-08-04 00:00:00.000000"},
{"id":"131","title":"Sport once pull between run.","abstract":"Interference matrix (IM) has been widely used in frequency planning\/optimization of cellular systems because it describes the interaction between any two cells. IM is generated from the source data gathered from the cellular system, either mobile measurement reports (MMRs) or drive test (DT) records. IM accuracy is not satisfactory since neither MMRs nor DT records contain complete information on interference and traffic distribution. In this paper, two IM generation algorithms based on source data fusion are proposed. Data fusion in one algorithm is to reinforce MMRs data, using the frequency-domain information of DT data from the same region. Data fusion in another algorithm is to reshape DT data, using the traffic distribution information extracted from MMRs from the same region. The fused data contains more complete information so that more accurate IM can be obtained. Simulation results have validated this conclusion.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2022-02-07 00:00:00.000000"},
{"id":"132","title":"Nation another budget up eight pull federal.","abstract":"KNET is a general-purpose shell for constructing expert systems based on belief networks and decision networks. Such networks serve as graphical representations for decision models, in which the knowledge engineer must define clearly the alternatives, states, preferences, and relationships that constitute a decision basis. KNET contains a knowledge-engineering core written in Object Pascal and an interface that tightly integrates HyperCard, a hypertext authoring tool for the Apple Macintosh computer, into a novel expert-system architecture. Hypertext and hypermedia have become increasingly important in the storage management, and retrieval of information. In broad terms, hypermedia deliver heterogeneous bits of information in dynamic, extensively cross-referenced packages. The resulting KNET system features a coherent probabilistic scheme for managing uncertainty, an objectoriented graphics editor for drawing and manipulating decision networks, and HyperCard's potential for quickly constructing flexible and friendly user interfaces. We envision KNET as a useful prototyping tool for our ongoing research on a variety of Bayesian reasoning problems, including tractable representation, inference, and explanation.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2016-03-15 00:00:00.000000"},
{"id":"133","title":"Something attention international computer concern under.","abstract":"PCA is often used to visualize data when the rows and the columns are both of interest. In such a setting there is a lack of inferential methods on the PCA output. We study the asymptotic variance of a fixed-effects model for PCA, and propose several approaches to assessing the variability of PCA estimates: a method based on a parametric bootstrap, a new cell-wise jackknife, as well as a computationally cheaper approximation to the jackknife. We visualize the confidence regions by Procrustes rotation. Using a simulation study, we compare the proposed methods and highlight the strengths and drawbacks of each method as we vary the number of rows, the number of columns, and the strength of the relationships between variables.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2016-02-23 00:00:00.000000"},
{"id":"134","title":"Indicate leave finish five join me source change.","abstract":"In this paper, we analyze statistical properties of a communication network constructed from the records of a mobile phone company. The network consists of 2.5 million customers that have placed 810 millions of communications (phone calls and text messages) over a period of 6 months and for whom we have geographical home localization information. It is shown that the degree distribution in this network has a power-law degree distribution $k^{-5}$ and that the probability that two customers are connected by a link follows a gravity model, i.e. decreases like $d^{-2}$, where $d$ is the distance between the customers. We also consider the geographical extension of communication triangles and we show that communication triangles are not only composed of geographically adjacent nodes but that they may extend over large distances. This last property is not captured by the existing models of geographical networks and in a last section we propose a new model that reproduces the observed property. Our model, which is based on the migration and on the local adaptation of agents, is then studied analytically and the resulting predictions are confirmed by computer simulations.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2015-01-25 00:00:00.000000"},
{"id":"135","title":"Arm although dream establish around me.","abstract":"We present an experimental and theoretical study of the optical properties of metal-dielectric-metal structures with patterned top metallic surfaces, in the THz frequency range. When the thickness of the dielectric slab is very small with respect to the wavelength, these structures are able to support strongly localized electromagnetic modes, concentrated in the subwavelength metal-metal regions. We provide a detailed analysis of the physical mechanisms which give rise to these photonic modes. Furthermore, our model quantitatively predicts the resonance positions and their coupling to free space photons. We demonstrate that these structures provide an efficient and controllable way to convert the energy of far field propagating waves into near field energy.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2018-10-24 00:00:00.000000"},
{"id":"136","title":"Television same fear.","abstract":"We propose a new nonparametric procedure for the detection and estimation of multiple structural breaks in the autocovariance function of a multivariate (second- order) piecewise stationary process, which also identifies the components of the series where the breaks occur. The new method is based on a comparison of the estimated spectral distribution on different segments of the observed time series and consists of three steps: it starts with a consistent test, which allows to prove the existence of structural breaks at a controlled type I error. Secondly, it estimates sets containing possible break points and finally these sets are reduced to identify the relevant structural breaks and corresponding components which are responsible for the changes in the autocovariance structure. In contrast to all other methods which have been proposed in the literature, our approach does not make any parametric assumptions, is not especially designed for detecting one single change point and addresses the problem of multiple structural breaks in the autocovariance function directly with no use of the binary segmentation algorithm. We prove that the new procedure detects all components and the corresponding locations where structural breaks occur with probability converging to one as the sample size increases and provide data-driven rules for the selection of all regularization parameters. The results are illustrated by analyzing financial returns, and in a simulation study it is demonstrated that the new procedure outperforms the currently available nonparametric methods for detecting breaks in the dependency structure of multivariate time series.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2021-07-04 00:00:00.000000"},
{"id":"137","title":"Writer professor least fine none.","abstract":"The Full Multiple Spawning (FMS) method is designed to simulate quantum dynamics in the multi-state electronic problem. The FMS nuclear wavefunction is represented in a basis of coupled, frozen Gaussians, and the spawning procedure prescribes a means of adaptively increasing the size of the basis in order to capture population transfer between electronic states. Parent trajectories create children when passing through regions of significant nonadiabatic coupling. In order to converge branching ratios without allowing the basis to reach an impractical size, population transfer at individual spawning events should be made as effective as possible. Herein we detail a new algorithm for specifying the initial conditions of freshly spawned basis functions, one that minimizes the number of spawns needed for convergence by maximizing the efficiency of individual spawning events. Optimization is achieved by maximizing the coupling between parent and child trajectories, as a function of child position and momentum, at the point of spawning. The method is tested with a two-state, one-mode avoided crossing model and a two-state, two-mode conical intersection model.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2015-03-06 00:00:00.000000"},
{"id":"138","title":"Yes actually we would reduce various.","abstract":"Nonlinear dynamics of surface gravity waves trapped by an opposing jet current is studied analytically and numerically. For wave fields narrowband in frequency but not necessarily with narrow angular distributions the developed asymptotic weakly nonlinear theory based on the modal approach of (V. Shrira, A. Slunyaev, J. Fluid. Mech, 738, 65, 2014) leads to the one-dimensional modified nonlinear Schr\\\"{o}dinger equation of self-focusing type for a single mode. Its solutions such as envelope solitons and breathers are considered to be prototypes of rogue waves; these solutions, in contrast to waves in the absence of currents, are robust with respect to transverse perturbations, which suggests potentially higher probability of rogue waves. Robustness of the long-lived analytical solutions in form of the modulated trapped waves and solitary wave groups is verified by direct numerical simulations of potential Euler equations.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2018-01-23 00:00:00.000000"},
{"id":"139","title":"Well everything play forward news industry result.","abstract":"The concept of subdifferentiability is studied in the context of $C^1$ Finsler manifolds (modeled on a Banach space with a Lipschitz $C^1$ bump function). A class of Hamilton-Jacobi equations defined on $C^1$ Finsler manifolds is studied and several results related to the existence and uniqueness of viscosity solutions are obtained.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2016-11-28 00:00:00.000000"},
{"id":"140","title":"Enough senior still interesting office watch.","abstract":"There are numerous advantages of using Electric Vehicles (EVs) as an alternative method of transportation. However, an increase in EV usage in the existing residential distribution grid poses problems such as overloading the existing infrastructure. In this paper, we have modeled and simulated a residential distribution grid in GridLAB-D (an open-source software tool used to model, simulate, and analyze power distribution systems) to illustrate the problems associated with a higher EV market penetration rates in the residential domain. Power grid upgrades or control algorithms at the transformer level are required to overcome issues such as transformer overloading. We demonstrate the method of coordinating EV charging in a residential distribution grid so as to overcome the overloading problem without any upgrades in the distribution grid.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2016-08-28 00:00:00.000000"},
{"id":"141","title":"Theory woman clearly send.","abstract":"We consider the first serial correlation coefficient under an AR(1) model where errors are not assumed to be Gaussian. In this case it is necessary to consider bootstrap approximations for tests based on the statistic since the distribution of errors is unknown. We obtain saddle-point approximations for tail probabilities of the statistic and its bootstrap version and use these to show that the bootstrap tail probabilities approximate the true values with given relative errors, thus extending the classical results of Daniels [Biometrika 43 (1956) 169-185] for the Gaussian case. The methods require conditioning on the set of odd numbered observations and suggest a conditional bootstrap which we show has similar relative error properties.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2016-12-16 00:00:00.000000"},
{"id":"142","title":"Amount concern rock that sell effort.","abstract":"In the main part of the paper, on the basis of contour integration of complex meromorphic functions whose singularities lie onto an integration contour, in the first step, a concept of improper integrals absolute existence of meromorphic functions, as more general one with respect to the concept of improper integrals convergence (existence), is introduced into analysis. In the second step, in the case when a modulus of complex parameter tends to infinity, an interval of improper integrals convergence of parametric meromorphic functions is defined. In accordance with this, it is shown that the class of real valued meromorphic functions, whose finitely many isolated singularities lie onto a real axis segment, may be expanded into Fourier trigonometric series, separately. At all points of the segment, at which the meromorphic functions are continuous ones, the Fourier trigonometric series is summable and its sum is equal to the function values at those points. Finally, that all is illustrated by two representative examples.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2020-04-02 00:00:00.000000"},
{"id":"143","title":"Modern door simply on follow.","abstract":"The intra-beam repulsions play a significant role in determining the performances of free-electron devices when an high brilliance of the beam is required. The transversal and longitudinal spread of the beam, its energy and density are fundamental parameters in any beam experiment and different beam diagnostics are available to measure such parameters. A diagnostic method based on the Thomson backscattering of a laser beam impinging on the particle beam is proposed in this work for the study of nanosecond electron bunches in high space charge regime. This diagnostics, aimed to the measurement of density, energy and energy spread, was set-up in a Malmberg-Penning trap (generally used for the electron\/ion confinment) in two different configurations designed to optimize sensitivity, spatial resolution and electron-beam coincidence in space and time. To this purpose an electron bunch (pulse time <4ns), produced by a photocathode source, was preliminary characterized with different electrostatic diagnostics and used to test the diagnostics systems. The solutions are detailed, which were devised for both the laser and bunch injection in the vacuum chamber, space and time coincidence of electron and laser pulses, photon detection, optimization of the geometry in the laser-beam interaction. The results are then summarized with an estimate of the minimum sensitivity of the set-up.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2021-07-21 00:00:00.000000"},
{"id":"144","title":"Term professor per.","abstract":"In this article, let $\\Sigma\\subset\\R^{2n}$ be a compact convex hypersurface which is $(r, R)$-pinched with $\\frac{R}{r}<\\sqrt{{3\/2}}$. Then $\\Sg$ carries at least two strictly elliptic closed characteristics; moreover, $\\Sg$ carries at least $2[\\frac{n+2}{4}]$ non-hyperbolic closed characteristics.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2021-12-23 00:00:00.000000"},
{"id":"145","title":"Themselves on enough personal national enjoy care.","abstract":"A definition of qualitative robustness for point estimators in general statistical models is proposed. Some criteria for robustness are established and applied to estimators in parametric, semiparametric, and nonparametric models. In specific nonparametric models, the proposed definition boils down to Hampel robustness. It is also explained how plug-in estimators in certain nonparametric models can be reasonably classified w.r.t. their degrees of robustness.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2015-08-14 00:00:00.000000"},
{"id":"146","title":"Wish save car third nice size class.","abstract":"Given $n$ samples of a regular discrete distribution $\\pi$, we prove in this article first a serial of SLLNs results (of Dvoretzky and Erd\\\"{o}s' type) which implies a typical power law when $\\pi$ is heavy-tailed. Constructing a (random) graph from the ordered $n$ samples, we can establish other laws for the degree-distribution of the graph. The phenomena of small world is also discussed.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2016-12-30 00:00:00.000000"},
{"id":"147","title":"Set phone rest factor usually boy.","abstract":"We propose an active learning method for discovering low-dimensional structure in high-dimensional Gaussian process (GP) tasks. Such problems are increasingly frequent and important, but have hitherto presented severe practical difficulties. We further introduce a novel technique for approximately marginalizing GP hyperparameters, yielding marginal predictions robust to hyperparameter mis-specification. Our method offers an efficient means of performing GP regression, quadrature, or Bayesian optimization in high-dimensional spaces.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2022-10-02 00:00:00.000000"},
{"id":"148","title":"Crime blood against provide property.","abstract":"Arc plasma torches are the primary components of various industrial thermal plasma processes involving plasma spraying, metal cutting and welding, thermal plasma CVD, metal melting and remelting, waste treatment and gas production. They are relatively simple devices whose operation implies intricate thermal, chemical, electrical, and fluid dynamics phenomena. Modeling may be used as a means to better understand the physical processes involved in their operation. This paper presents an overview of the main aspects involved in the modeling of DC arc plasma torches: the mathematical models including thermodynamic and chemical non-equilibrium models, turbulent and radiative transport, thermodynamic and transport property calculation, boundary conditions and arc reattachment models. It focuses on the conventional plasma torches used for plasma spraying that include a hot-cathode and a nozzle anode.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2018-12-31 00:00:00.000000"},
{"id":"149","title":"Very run media loss.","abstract":"The main objective of this survey is to present the important theoretical and experimental results contributed till date in the area of online algorithms for the self organizing sequential search problem, also popularly known as the List Update Problem(LUP) in a chronological way. The survey includes competitiveness results of deterministic and randomized online algorithms and complexity results of optimal off line algorithms for the list update problem. We also present the results associated with list update with look ahead, list update with locality of reference and other variants of the list update problem. We investigate research issues, explore scope of future work associated with each issue so that future researchers can find it useful to work on.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2016-07-27 00:00:00.000000"},
{"id":"150","title":"Wear body PM expect without director wall.","abstract":"The basic scaling laws for structures in a fractal universe require that the characteristic quantity of action associated with astronomical bodies should be of order near the maximum possible action allowed by the holographic upper bound. That conclusion is consistent with the observed parameters of galaxies and clusters.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2022-11-07 00:00:00.000000"},
{"id":"151","title":"Reduce mother now number much.","abstract":"We present in this paper our work regarding simulating a type of P system known as a spiking neural P system (SNP system) using graphics processing units (GPUs). GPUs, because of their architectural optimization for parallel computations, are well-suited for highly parallelizable problems. Due to the advent of general purpose GPU computing in recent years, GPUs are not limited to graphics and video processing alone, but include computationally intensive scientific and mathematical applications as well. Moreover P systems, including SNP systems, are inherently and maximally parallel computing models whose inspirations are taken from the functioning and dynamics of a living cell. In particular, SNP systems try to give a modest but formal representation of a special type of cell known as the neuron and their interactions with one another. The nature of SNP systems allowed their representation as matrices, which is a crucial step in simulating them on highly parallel devices such as GPUs. The highly parallel nature of SNP systems necessitate the use of hardware intended for parallel computations. The simulation algorithms, design considerations, and implementation are presented. Finally, simulation results, observations, and analyses using an SNP system that generates all numbers in $\\mathbb N$ - {1} are discussed, as well as recommendations for future work.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2018-03-26 00:00:00.000000"},
{"id":"152","title":"This choose fast wife writer pattern another paper.","abstract":"In a recent paper we introduced a new framework for the study of call by need computations to normal form and root-stable form in term rewriting. Using elementary tree automata techniques and ground tree transducers we obtained simple decidability proofs for classes of rewrite systems that are much larger than earlier classes defined using the complicated sequentiality concept. In this paper we show that we can do without ground tree transducers in order to arrive at decidability proofs that are phrased in direct tree automata constructions. This allows us to derive better complexity bounds.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2022-01-31 00:00:00.000000"},
{"id":"153","title":"Well finally church.","abstract":"In this paper, we show how we can combine Electromagnetics (EM) with signal processing algorithms to enhance the image resolution over that can be realized by using Electromagnetics techniques alone. We discuss several signal processing techniques, including the Correlation Method (CM) and the Minimum Residual Power Search Method (MRPSM), and apply them for sub-wavelength imaging in the microwave regime by combining them with the well-known Phase Conjugation (PC) algorithm, for instance, which has been extensively used in the electromagnetics area for imaging purposes. We show that by using this type of combination we can achieve sub-wavelength resolution on the order of {\\lambda}0\/10, even if the measurement plane is not located in the very near-field region of the source. We describe the proposed imaging algorithms in detail and study their abilities to resolve at sub-wavelength level. We also study their computational efficiencies in a comparative manner.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2018-01-11 00:00:00.000000"},
{"id":"154","title":"Enter four stand provide should them budget.","abstract":"Mobile Ad Hoc Network (MANET) is a collection of nodes that can be rapidly deployed as a multi-hop network without the aid of any centralized administration. Misbehavior is challenged by bandwidth and energy efficient medium access control and fair share of throughput. Node misbehavior plays an important role in MANET. In this survey, few of the contention window misbehavior is reviewed and compared. The contention window cheating either minimizes the active communication of the network or reduces bandwidth utilization of a particular node. The classification presented is in no case unique but summarizes the chief characteristics of many published proposals for contention window cheating. After getting insight into the different contention window misbehavior, few of the enhancements that can be done to improve the existing contention window are suggested. The purpose of this paper is to facilitate the research efforts in combining the existing solutions to offer more efficient methods to reduce contention window cheating mechanisms.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2020-08-21 00:00:00.000000"},
{"id":"155","title":"Media responsibility very.","abstract":"It is well known that search SVP is equivalent to optimization SVP. However, the former reduction from search SVP to optimization SVP by Kannan needs polynomial times calls to the oracle that solves the optimization SVP. In this paper, a new rank-preserving reduction is presented with only one call to the optimization SVP oracle. It is obvious that the new reduction needs the least calls, and improves Kannan's classical result. What's more, the idea also leads a similar direct reduction from search CVP to optimization CVP with only one call to the oracle.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2017-05-28 00:00:00.000000"},
{"id":"156","title":"Page bank defense couple stage take.","abstract":"In this paper, we consider the problem of estimating the distance between any two large data streams in small- space constraint. This problem is of utmost importance in data intensive monitoring applications where input streams are generated rapidly. These streams need to be processed on the fly and accurately to quickly determine any deviance from nominal behavior. We present a new metric, the Sketch \\star-metric, which allows to define a distance between updatable summaries (or sketches) of large data streams. An important feature of the Sketch \\star-metric is that, given a measure on the entire initial data streams, the Sketch \\star-metric preserves the axioms of the latter measure on the sketch (such as the non-negativity, the identity, the symmetry, the triangle inequality but also specific properties of the f-divergence). Extensive experiments conducted on both synthetic traces and real data allow us to validate the robustness and accuracy of the Sketch \\star-metric.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2022-10-23 00:00:00.000000"},
{"id":"157","title":"High discover adult job whose often.","abstract":"This paper explores the effect of various graphical constructions upon the associated graph $C^*$-algebras. The graphical constructions in question arise naturally in the study of flow equivalence for topological Markov chains.  We prove that out-splittings give rise to isomorphic graph algebras, and in-splittings give rise to strongly Morita equivalent $C^*$-algebras. We generalise the notion of a delay as defined by Drinen to form in-delays and out-delays. We prove that these constructions give rise to Morita equivalent graph $C^*$-algebras. We provide examples which suggest that our results are the most general possible in the setting of the $C^*$-algebras of arbitrary directed graphs.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2016-01-08 00:00:00.000000"},
{"id":"158","title":"Back responsibility guy middle blue teach back.","abstract":"We obtain estimate of the exponential decay rate of semigroup associated with second order linear differential equation $u\"+Du'+Au=0$ in Hilbert space. We assume that $A$ is a selfadjoint positive definite operator, $D$ is an accretive sectorial operator and $\\Ree D\\geq\\delta A$, $\\delta>0$. We obtain a location of the spectrum of a pencil associated with linear differential equation.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2017-05-04 00:00:00.000000"},
{"id":"159","title":"Follow citizen know material smile second exist thus.","abstract":"We revisit the definition of Cartesian differential categories, showing that a slightly more general version is useful for a number of reasons. As one application, we show that these general differential categories are comonadic over Cartesian categories, so that every Cartesian category has an associated cofree differential category. We also work out the corresponding results when the categories involved have restriction structure, and show that these categories are closed under splitting restriction idempotents.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2018-07-07 00:00:00.000000"},
{"id":"160","title":"Contain success dark former hope ever identify.","abstract":"We introduce a Deep Boltzmann Machine model suitable for modeling and extracting latent semantic representations from a large unstructured collection of documents. We overcome the apparent difficulty of training a DBM with judicious parameter tying. This parameter tying enables an efficient pretraining algorithm and a state initialization scheme that aids inference. The model can be trained just as efficiently as a standard Restricted Boltzmann Machine. Our experiments show that the model assigns better log probability to unseen data than the Replicated Softmax model. Features extracted from our model outperform LDA, Replicated Softmax, and DocNADE models on document retrieval and document classification tasks.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2015-10-12 00:00:00.000000"},
{"id":"161","title":"Project might media image member than.","abstract":"We answer three problems by J. D. Monk on cardinal invariants of Boolean algebras. Two of these are whether taking the algebraic density pi(A), resp. the topological density d(A), of a Boolean algebra A commutes with formation of ultraproducts; the third one compares the number of endomorphisms and of ideals of a Boolean algebra.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2016-10-26 00:00:00.000000"},
{"id":"162","title":"Back person account return worry.","abstract":"The distribution function of a random distance in three dimensions is given and some new three-dimensional d2-tests of randomness are suggested. We show that our test statistics are not correlated with the usual test statistics and are therefore an other promising way to determine the quality of generated random numbers.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2022-09-17 00:00:00.000000"},
{"id":"163","title":"Per hot house.","abstract":"We study estimation of multivariate densities $p$ of the form $p(x)=h(g(x))$ for $x\\in \\mathbb {R}^d$ and for a fixed monotone function $h$ and an unknown convex function $g$. The canonical example is $h(y)=e^{-y}$ for $y\\in \\mathbb {R}$; in this case, the resulting class of densities [\\mathcal {P}(e^{-y})={p=\\exp(-g):g is convex}] is well known as the class of log-concave densities. Other functions $h$ allow for classes of densities with heavier tails than the log-concave class. We first investigate when the maximum likelihood estimator $\\hat{p}$ exists for the class $\\mathcal {P}(h)$ for various choices of monotone transformations $h$, including decreasing and increasing functions $h$. The resulting models for increasing transformations $h$ extend the classes of log-convex densities studied previously in the econometrics literature, corresponding to $h(y)=\\exp(y)$. We then establish consistency of the maximum likelihood estimator for fairly general functions $h$, including the log-concave class $\\mathcal {P}(e^{-y})$ and many others. In a final section, we provide asymptotic minimax lower bounds for the estimation of $p$ and its vector of derivatives at a fixed point $x_0$ under natural smoothness hypotheses on $h$ and $g$. The proofs rely heavily on results from convex analysis.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2022-12-22 00:00:00.000000"},
{"id":"164","title":"Benefit when usually agency outside.","abstract":"Motivated by studying asymptotic properties of the maximum likelihood estimator (MLE) in stochastic volatility (SV) models, in this paper we investigate likelihood estimation in state space models. We first prove, under some regularity conditions, there is a consistent sequence of roots of the likelihood equation that is asymptotically normal with the inverse of the Fisher information as its variance. With an extra assumption that the likelihood equation has a unique root for each $n$, then there is a consistent sequence of estimators of the unknown parameters. If, in addition, the supremum of the log likelihood function is integrable, the MLE exists and is strongly consistent. Edgeworth expansion of the approximate solution of likelihood equation is also established. Several examples, including Markov switching models, ARMA models, (G)ARCH models and stochastic volatility (SV) models, are given for illustration.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2019-07-22 00:00:00.000000"},
{"id":"165","title":"Board detail others author represent us.","abstract":"We provide a bird's eye view onto the area of sequential change-point detection. We focus on the discrete-time case with known pre- and post-change data distributions and offer a summary of the forefront asymptotic results established in each of the four major formulations of the underlying optimization problem: Bayesian, generalized Bayesian, minimax, and multi-cyclic.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2022-06-23 00:00:00.000000"},
{"id":"166","title":"Avoid family camera truth.","abstract":"This is a long summary of the author's book \"D-manifolds and d-orbifolds: a theory of derived differential geometry\", available at http:\/\/people.maths.ox.ac.uk\/~joyce\/dmanifolds.html . A shorter survey paper on the book, focussing on d-manifolds without boundary, is arXiv:1206.4207, and readers just wanting a general overview are advised to start there.   We introduce a 2-category dMan of \"d-manifolds\", new geometric objects which are 'derived' smooth manifolds, in the sense of the 'derived algebraic geometry' of Toen and Lurie. They are a 2-category truncation of Spivak's 'derived manifolds' (see arXiv:0810.5174, arXiv:1212.1153). The category of manifolds Man embeds in dMan as a full (2-)subcategory. We also define 2-categories dMan^b,dMan^c of \"d-manifolds with boundary\" and \"d-manifolds with corners\", and orbifold versions of these dOrb,dOrb^b,dOrb^c, \"d-orbifolds\". Much of differential geometry extends very nicely to d-manifolds and d-orbifolds -- immersions, submersions, submanifolds, transverse fibre products, orientations, orbifold strata, bordism, etc. Compact oriented d-manifolds and d-orbifolds have virtual classes.   There are truncation functors to d-manifolds and d-orbifolds from essentially every geometric structure on moduli spaces used in enumerative invariant problems in differential geometry or complex algebraic geometry, including Fredholm sections of Banach vector bundles over Banach manifolds, the \"Kuranishi spaces\" of Fukaya, Oh, Ohta and Ono and the \"polyfolds\" of Hofer, Wysocki and Zehnder in symplectic geometry, and C-schemes with perfect obstruction theories in algebraic geometry. Thus, results in the literature imply that many important classes of moduli spaces are d-manifolds or d-orbifolds, including moduli spaces of J-holomorphic curves in symplectic geometry.   D-manifolds and d-orbifolds will have applications in symplectic geometry, and elsewhere.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2020-04-18 00:00:00.000000"},
{"id":"167","title":"Debate land cell floor we.","abstract":"To coordinate with other agents in its environment, an agent needs models of what the other agents are trying to do. When communication is impossible or expensive, this information must be acquired indirectly via plan recognition. Typical approaches to plan recognition start with a specification of the possible plans the other agents may be following, and develop special techniques for discriminating among the possibilities. Perhaps more desirable would be a uniform procedure for mapping plans to general structures supporting inference based on uncertain and incomplete observations. In this paper, we describe a set of methods for converting plans represented in a flexible procedural language to observation models represented as probabilistic belief networks.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2015-10-26 00:00:00.000000"},
{"id":"168","title":"How peace edge step subject choose recently.","abstract":"In this paper we propose an XML-based multi-agent recommender system for supporting online recruitment services. Our system is characterized by the following features: {\\em (i)} it handles user profiles for personalizing the job search over the Internet; {\\em (ii)} it is based on the Intelligent Agent Technology; {\\em (iii)} it uses XML for guaranteeing a light, versatile and standard mechanism for information representation, storing and exchange. The paper discusses the basic features of the proposed system, presents the results of an experimental study we have carried out for evaluating its performance, and makes a comparison between the proposed system and other e-recruitment systems already presented in the past.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2021-01-09 00:00:00.000000"},
{"id":"169","title":"Growth summer yard on mission feel.","abstract":"The use of floating bipolar electrodes in electrowinning cells of copper constitutes a nonconventional technology that promises economic and operational impacts. This thesis presents a computational tool for the simulation and analysis of such electrochemical cells. A new model is developed for floating electrodes and a method of finite difference is used to obtain the threedimensional distribution of the potential and the field of current density inside the cell. The analysis of the results is based on a technique for the interactive visualization of three-dimensional vectorial fields as lines of flow.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2019-09-19 00:00:00.000000"},
{"id":"170","title":"Face fact energy federal.","abstract":"Algorithms for the computation of the real zeros of hypergeometric functions which are solutions of second order ODEs are described. The algorithms are based on global fixed point iterations which apply to families of functions satisfying first order linear difference differential equations with continuous coefficients. In order to compute the zeros of arbitrary solutions of the hypergeometric equations, we have at our disposal several different sets of difference differential equations (DDE). We analyze the behavior of these different sets regarding the rate of convergence of the associated fixed point iteration. It is shown how combinations of different sets of DDEs, depending on the range of parameters and the dependent variable, is able to produce efficient methods for the computation of zeros with a fairly uniform convergence rate for each zero.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2021-06-01 00:00:00.000000"},
{"id":"171","title":"Cold society though three.","abstract":"The notions of potential infinity (understood as expressing a direction) and actual infinity (expressing a quantity) are investigated. It is shown that the notion of actual infinity is inconsistent, because the set of all (finite) natural numbers which it is ascribed to, cannot contain an actually infinite number of elements. Further the basic inequality of transfinite set theory aleph0 < 2^aleph0 is found invalid, and, consequently, the set of real numbers is proven denumerable by enumerating it.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2017-05-13 00:00:00.000000"},
{"id":"172","title":"Fact site security draw successful above beyond.","abstract":"Contemporary personal computing devices are increasingly required to be portable and mobile enabling user's wireless access, to wired network infrastructures and services. This approach to mobile computing and communication is only appropriate in situations where a coherent infrastructure is available. There are many situations where these requirements are not fulfilled such as; developing nations, rural areas, natural disasters, and military conflicts to name but a few. A practical solution is to use mobile devices interconnected via a wireless medium to form a network, known as a Mobile Ad-hoc Network (MANET), and provide the services normally found in wired networks. Security in MANETs is an issue of paramount importance due to the wireless nature of the communication links. Additionally due to the lack of central administration security issues are different from conventional networks. For the purposes of this article we have used the \"WMN test-bed\" to enable secure routing in MANETs. The use of cryptography is an efficient proven way of securing data in communications, but some cryptographic algorithms are not as efficient as others and require more processing power, which is detrimental to MANETs. In this article we have assessed different cryptographic approaches to securing the OLSR (Optimised Link State Routing) protocol to provide a basis for research. We conclude the paper with a series of performance evaluation results regarding different cryptographic and hashing schemes. Our findings clearly show that the most efficient combination of algorithms used for authentication and encryption are SHA-1 and AES respectively. Using this combination over their counterparts will lead to a considerable reduction in processing time and delay on the network, creating an efficient transaction moving towards satisfying resource constraints and security requirements.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2019-08-04 00:00:00.000000"},
{"id":"173","title":"Toward art reality media describe within produce possible.","abstract":"An interpretation of the ``halo puzzle'' in accelerators based on quantum-like diffraction is given. Comparison between this approach and the others based on classical mechanics equations is exhibited.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2015-10-21 00:00:00.000000"},
{"id":"174","title":"Full thousand phone.","abstract":"A major computational burden, while performing document clustering, is the calculation of similarity measure between a pair of documents. Similarity measure is a function that assigns a real number between 0 and 1 to a pair of documents, depending upon the degree of similarity between them. A value of zero means that the documents are completely dissimilar whereas a value of one indicates that the documents are practically identical. Traditionally, vector-based models have been used for computing the document similarity. The vector-based models represent several features present in documents. These approaches to similarity measures, in general, cannot account for the semantics of the document. Documents written in human languages contain contexts and the words used to describe these contexts are generally semantically related. Motivated by this fact, many researchers have proposed seman-tic-based similarity measures by utilizing text annotation through external thesauruses like WordNet (a lexical database). In this paper, we define a semantic similarity measure based on documents represented in topic maps. Topic maps are rapidly becoming an industrial standard for knowledge representation with a focus for later search and extraction. The documents are transformed into a topic map based coded knowledge and the similarity between a pair of documents is represented as a correlation between the common patterns (sub-trees). The experimental studies on the text mining datasets reveal that this new similarity measure is more effective as compared to commonly used similarity measures in text clustering.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2015-11-06 00:00:00.000000"},
{"id":"175","title":"Any education subject age begin environmental.","abstract":"We perform a theoretical investigation on the Goos-H\\\"achen (GH) shift in one-dimensional photonic crystals (1DPCs) containing left-handed metamaterials (LHMs). We find an unusal effect of the GH shift near the photonic band-crossing structure, which is located at the condition, $% -k_{z}^{(A)}d_{A}=k_{z}^{(B)}d_{B}=m\\pi $ $(m=1,2,3...)$, under the inclined incident angle, here A denotes the LHM layer and B denotes the dielectric layer. Above the frequency of the band-crossing point (BCP), the GH shift changes from negative to positive as the incident angle increases, while the GH shift changes reversely below the BCP frequency. This effect is explained in terms of the phase property of the band-crossing structure.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2016-10-05 00:00:00.000000"},
{"id":"176","title":"Choose third picture father chair suggest.","abstract":"Mathematica is a versatile equipment for doing numeric and symbolic computations and it has wide spread applications in all branches of science. Mathematica has a complete consistency to design it at every stage that gives it multilevel capability and helps advanced usage evolve naturally. Mathematica functions work for any precision of number and it can be easily computed with symbols, represented graphically to get the best answer. Mathematica is a robust software development that can be used in any popular operating systems and it can be communicated with external programs by using proper mathlink commands.   Sometimes it is quite desirable to run jobs in background of a computer which can take considerable amount of time to finish, and this allows us to do work on other tasks, while keeping the jobs running. Most of us are very familiar to run jobs in background for the programs written in the languages like C, C++, F77, F90, F95, etc. But the way of running jobs, written in a mathematica notebook, in background is quite different from the conventional method. In this article, we explore how to create a mathematica batch-file from a mathematica notebook and run it in background. Here we concentrate our study only for the Unix version, but one can run mathematica programs in background for the Windows version as well by using proper mathematica batch-file.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2019-01-14 00:00:00.000000"},
{"id":"177","title":"Firm forget and.","abstract":"A characterization of regular topological fundamental groups yields a `no retraction theorem' for spaces constructed in similar fashion to the Hawaiian earring.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2017-10-05 00:00:00.000000"},
{"id":"178","title":"Store all child yes.","abstract":"Template matching is one of the simplest methods used for eyes and mouth detection. However, it can be modified and extended to become a powerful tool. Since the patch itself plays a significant role in optimizing detection performance, a study on the influence of patch size and shape is carried out. The optimum patch size and shape is determined using the proposed method. Usually, template matching is also combined with other methods in order to improve detection accuracy. Thus, in this paper, the effectiveness of two image processing methods i.e. grayscale and Haar wavelet transform, when used with template matching are analyzed.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2015-06-22 00:00:00.000000"},
{"id":"179","title":"Big democratic simply cultural truth about.","abstract":"Globular complexes were introduced by E. Goubault and the author in arXiv:math\/0107060 to model higher dimensional automata. Globular complexes are topological spaces equipped with a globular decomposition which is the directed analogue of the cellular decomposition of a CW-complex. We prove that there exists a combinatorial model category such that the cellular objects are exactly the globular complexes and such that the homotopy category is equivalent to the homotopy category of flows introduced in arXiv:math\/0308054. The underlying category of this model category is a variant of M. Grandis' notion of d-space over a topological space colimit generated by simplices. This result enables us to understand the relationship between the framework of flows and other works in directed algebraic topology using d-spaces. It also enables us to prove that the underlying homotopy type functor of flows constructed in arXiv:math\/0308063 can be interpreted up to equivalences of categories as the total left derived functor of a left Quillen adjoint.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2020-11-24 00:00:00.000000"},
{"id":"180","title":"Professional difficult maybe hear according past human.","abstract":"We describe some of the connections between the Bieri-Neumann-Strebel-Renz invariants, the Dwyer-Fried invariants, and the cohomology support loci of a space X. Under suitable hypotheses, the geometric and homological finiteness properties of regular, free abelian covers of X can be expressed in terms of the resonance varieties, extracted from the cohomology ring of X. In general, though, translated components in the characteristic varieties affect the answer. We illustrate this theory in the setting of toric complexes, as well as smooth, complex projective and quasi-projective varieties, with special emphasis on configuration spaces of Riemann surfaces and complements of hyperplane arrangements.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2021-12-01 00:00:00.000000"},
{"id":"181","title":"Staff example gun car first news like then.","abstract":"The required lasers parameters for recently proposed gamma collider Higgs factories are presented and reviewed in the context of new developments in high average and peak power fibre laser technology. A possible laser architecture based on fibres is proposed and some issues surrounding high average power frequency conversion to the wavelengths required for a gamma collider are discussed.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2021-10-22 00:00:00.000000"},
{"id":"182","title":"Benefit box need born.","abstract":"We characterize the compatibility of a collection of unrooted phylogenetic trees as a question of determining whether a graph derived from these trees --- the display graph --- has a specific kind of triangulation, which we call legal. Our result is a counterpart to the well known triangulation-based characterization of the compatibility of undirected multi-state characters.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2018-04-11 00:00:00.000000"},
{"id":"183","title":"Republican recent decision toward should body training.","abstract":"First we explain the concept of local deformation over a 'parameter' algebra P, in particular the notion of a P-lattice in a Lie group. Purpose of this article is to define the spaces of automorphic resp. cusp forms on the upper half plane H for a P- (!) lattice of SL(2, R) and to investigate their structure. It turns out that in almost all cases these spaces are free modules over the complexified P of rank equal to the dimension of the spaces of automorphic resp. cusp forms for the body, which is the associated ordinary lattice in SL(2, R) . In other words almost every automorphic resp. cusp form admits an 'adaption' to local deformations of the lattice. This is shown by giving the quotient of H by the P-lattice together with the cusps the structure of a P- Riemann surface and writing the spaces of automorphic resp. cusp forms as global sections of holomorphic P- (!) line bundles on this quotient.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2017-06-21 00:00:00.000000"},
{"id":"184","title":"Cut anyone modern research really wonder.","abstract":"We prove that there is a finite level-independent bound on the number of relations defining the fusion ring of positive energy representations of the loop group of a simple, simply connected Lie group. As an illustration, we compute the fusion ring of $G_2$ at all levels.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2021-12-05 00:00:00.000000"},
{"id":"185","title":"Politics pass home we article.","abstract":"We introduce a binary regression accounting-based model for bankruptcy prediction of small and medium enterprises (SMEs). The main advantage of the model lies in its predictive performance in identifying defaulted SMEs. Another advantage, which is especially relevant for banks, is that the relationship between the accounting characteristics of SMEs and response is not assumed a priori (e.g., linear, quadratic or cubic) and can be determined from the data. The proposed approach uses the quantile function of the generalized extreme value distribution as link function as well as smooth functions of accounting characteristics to flexibly model covariate effects. Therefore, the usual assumptions in scoring models of symmetric link function and linear or pre-specied covariate-response relationships are relaxed. Out-of-sample and out-of-time validation on Italian data shows that our proposal outperforms the commonly used (logistic) scoring model for different default horizons.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2019-11-06 00:00:00.000000"},
{"id":"186","title":"Computer skill sort drug PM full address away.","abstract":"Mathematical aspects of the SU(1,1) group parameter x dynamics governed by Hamiltonians exhibiting some special types of time dependence has been presented on an elementary level from the point of view of Moebius transformation of complex plane. The trajectories of x in continuous and mappings in discrete dynamics are considered. Some simple examples have been examined. Analytical considerations and numerical results have been given.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2020-01-12 00:00:00.000000"},
{"id":"187","title":"How authority yet serve help interview.","abstract":"We propose in this work an original estimator of the conditional intensity of a marker-dependent counting process, that is, a counting process with covariates. We use model selection methods and provide a non asymptotic bound for the risk of our estimator on a compact set. We show that our estimator reaches automatically a convergence rate over a functional class with a given (unknown) anisotropic regularity. Then, we prove a lower bound which establishes that this rate is optimal. Lastly, we provide a short illustration of the way the estimator works in the context of conditional hazard estimation.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2017-01-12 00:00:00.000000"},
{"id":"188","title":"Source trip education rock character large sit.","abstract":"This paper is about a correspondence between monoidal structures in categories and $n$-fold loop spaces. We develop a new syntactical technique whose role is to substitute the coherence results, which were the main ingredients in the proofs that the Segal-Thomason bar construction provides an appropriate simplicial space. The results we present here enable more common categories to enter this delooping machine. For example, such is the category of finite sets with two monoidal structures brought by the disjoint union and Cartesian product.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2018-09-26 00:00:00.000000"},
{"id":"189","title":"Again including itself size.","abstract":"Normalized information distance (NID) uses the theoretical notion of Kolmogorov complexity, which for practical purposes is approximated by the length of the compressed version of the file involved, using a real-world compression program. This practical application is called 'normalized compression distance' and it is trivially computable. It is a parameter-free similarity measure based on compression, and is used in pattern recognition, data mining, phylogeny, clustering, and classification. The complexity properties of its theoretical precursor, the NID, have been open. We show that the NID is neither upper semicomputable nor lower semicomputable.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2022-06-27 00:00:00.000000"},
{"id":"190","title":"Bag arm force both leader street discuss country.","abstract":"We demonstrate an interferometric fiber-optic bending\/micro-displacement sensor based on a plastic dual-core fiber with one end coated with a silver mirror. The two fiber cores are first excited with the same laser beam, the light in each core is then back-reflected at the mirror-coated fiber-end, and, finally, the light from the two cores is made to interfere at the coupling end. Bending of the fiber leads to shifting interference fringes that can be interrogated with a slit and a single photodetector. We find experimentally that the resolution of our bending sensor is ~3x10-4 m-1 for sensing of bending curvature, as well as ~70 nm for sensing of displacement of the fiber tip. We demonstrate operation of our sensor using two examples. One is weighting of the individual micro-crystals of salt, while the other one is monitoring dynamics of isopropanol evaporation.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2016-10-25 00:00:00.000000"},
{"id":"191","title":"Street long figure system deep he growth.","abstract":"We derive a CUR matrix factorization based on the Discrete Empirical Interpolation Method (DEIM). For a given matrix $A$, such a factorization provides a low rank approximate decomposition of the form $A \\approx C U R$, where $C$ and $R$ are subsets of the columns and rows of $A$, and $U$ is constructed to make $CUR$ a good approximation. Given a low-rank singular value decomposition $A \\approx V S W^T$, the DEIM procedure uses $V$ and $W$ to select the columns and rows of $A$ that form $C$ and $R$. Through an error analysis applicable to a general class of CUR factorizations, we show that the accuracy tracks the optimal approximation error within a factor that depends on the conditioning of submatrices of $V$ and $W$. For large-scale problems, $V$ and $W$ can be approximated using an incremental QR algorithm that makes one pass through $A$. Numerical examples illustrate the favorable performance of the DEIM-CUR method, compared to CUR approximations based on leverage scores.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2021-01-07 00:00:00.000000"},
{"id":"192","title":"Society black that amount federal week hair.","abstract":"Popular music is a key cultural expression that has captured listeners' attention for ages. Many of the structural regularities underlying musical discourse are yet to be discovered and, accordingly, their historical evolution remains formally unknown. Here we unveil a number of patterns and metrics characterizing the generic usage of primary musical facets such as pitch, timbre, and loudness in contemporary western popular music. Many of these patterns and metrics have been consistently stable for a period of more than fifty years, thus pointing towards a great degree of conventionalism. Nonetheless, we prove important changes or trends related to the restriction of pitch transitions, the homogenization of the timbral palette, and the growing loudness levels. This suggests that our perception of the new would be rooted on these changing characteristics. Hence, an old tune could perfectly sound novel and fashionable, provided that it consisted of common harmonic progressions, changed the instrumentation, and increased the average loudness.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2015-10-27 00:00:00.000000"},
{"id":"193","title":"Station yet race card own number national.","abstract":"The normal distribution has the property that the cumulant generating function has only two terms which are easy to estimate. Some of the recognized tests for normality are based on moments and involves the skewness and kurtosis. It is shown that a test statistic can be derived which takes all moments higher than the third moment into consideration. Excellent results were found when tested in a simulation study in large samples and especially in symmetric distributed data.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2022-03-14 00:00:00.000000"},
{"id":"194","title":"Structure police change support safe.","abstract":"The scaling properties of oil price fluctuations are described as a non-stationary stochastic process realized by a time series of finite length. An original model is used to extract the scaling exponent of the fluctuation functions within a non-stationary process formulation. It is shown that, when returns are measured over intervals less than 10 days, the Probability Density Functions (PDFs) exhibit self-similarity and monoscaling, in contrast to the multifractal behavior of the PDFs at macro-scales (typically larger than one month). We find that the time evolution of the distributions are well fitted by a Levy distribution law at micro-scales. The relevance of a Levy distribution is made plausible by a simple model of nonlinear transfer","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2022-05-08 00:00:00.000000"},
{"id":"195","title":"Well mission reduce wrong tonight.","abstract":"Mahotas is a computer vision library for Python. It contains traditional image processing functionality such as filtering and morphological operations as well as more modern computer vision functions for feature computation, including interest point detection and local descriptors.   The interface is in Python, a dynamic programming language, which is very appropriate for fast development, but the algorithms are implemented in C++ and are tuned for speed. The library is designed to fit in with the scientific software ecosystem in this language and can leverage the existing infrastructure developed in that language.   Mahotas is released under a liberal open source license (MIT License) and is available from (http:\/\/github.com\/luispedro\/mahotas) and from the Python Package Index (http:\/\/pypi.python.org\/pypi\/mahotas).","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2015-03-29 00:00:00.000000"},
{"id":"196","title":"Political strong American agency message.","abstract":"This article is a thorough critique to the Weniger's comments made to our papers published in prestigious journals in the recent years. A detailed and critical examination of the arguments that led to the suggested comment by Weniger reveals some serious flaws. In our published papers we have shown that the unsymmetrical and symmetrical one-range addition theorems for Slater type orbitals, Coulomb-Yukawa like correlated interaction potentials (CIPs) and their derivatives are derived from the expansions in terms of -ETOs that are complete and orthonormal sets of exponential type orbitals in corresponding Hilbert spaces, where The concrete criticism raised in Weniger's comment against our papers actually touches a very minor aspect of the works that are not relevant at all for the conclusions, which are made. As can be seen from our papers, all of the formulas for different kinds of multicenter integrals over Slater type orbitals with integer and noninteger principal quantum numbers obtained by the use of unsymmetrical and symmetrical one-range addition theorems were tested by computer calculations. We reject the Weniger's personal views about papers published by Guseinov and his coworkers from 1978 to 2006 and respectable referees on one-range addition theorems and multicenter integrals. All claims of inconsistencies and flaws in the theoretical framework are rejected as unfounded. This rejoinder paper contains all of the answers to Weniger's comments.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2016-04-09 00:00:00.000000"},
{"id":"197","title":"Street say they.","abstract":"With the rapid advancement of wireless network technology, usage of WSN in real time applications like military, forest monitoring etc. found increasing. Generally WSN operate in an unattended environment and handles critical data. Authenticating the user trying to access the sensor memory is one of the critical requirements. Many researchers have proposed remote user authentication schemes focusing on various parameters. In 2013, Li et al. proposed a temporal-credential-based mutual authentication and key agreement scheme for WSNs. Li et al. claimed that their scheme is secure against all major cryptographic attacks and requires less computation cost due to usage of hash function instead encryption operations. Unfortunately, in this paper we will show that their scheme is vulnerable to offline password guessing attack, stolen smart card attack, leakage of password etc. and failure to provide data privacy.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2017-01-25 00:00:00.000000"},
{"id":"198","title":"Great eye couple research customer manage could.","abstract":"We use existential Diophantine predicates carefully reinterpreted over the reals and the time complexity of Tarski algebra to show that 3-CNF SAT is in n^O(log^{gamma} n) time for an absolute positive constant gamma.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2018-10-13 00:00:00.000000"},
{"id":"199","title":"Answer million site college dream night item building.","abstract":"This paper is about randomized iterative algorithms for solving a linear system of equations $X \\beta = y$ in different settings. Recent interest in the topic was reignited when Strohmer and Vershynin (2009) proved the linear convergence rate of a Randomized Kaczmarz (RK) algorithm that works on the rows of $X$ (data points). Following that, Leventhal and Lewis (2010) proved the linear convergence of a Randomized Coordinate Descent (RCD) algorithm that works on the columns of $X$ (features). The aim of this paper is to simplify our understanding of these two algorithms, establish the direct relationships between them (though RK is often compared to Stochastic Gradient Descent), and examine the algorithmic commonalities or tradeoffs involved with working on rows or columns. We also discuss Kernel Ridge Regression and present a Kaczmarz-style algorithm that works on data points and having the advantage of solving the problem without ever storing or forming the Gram matrix, one of the recognized problems encountered when scaling kernelized methods.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2019-07-02 00:00:00.000000"},
{"id":"200","title":"Outside employee magazine respond dog run.","abstract":"We prove that, on a complete hyperbolic domain D\\subset C^q, any Loewner PDE associated with a Herglotz vector field of the form H(z,t)=A(z)+O(|z|^2), where the eigenvalues of A have strictly negative real part, admits a solution given by a family of univalent mappings (f_t: D\\to C^q) such that the union of the images f_t(D) is the whole C^q. If no real resonance occurs among the eigenvalues of A, then the family (e^{At}\\circ f_t) is uniformly bounded in a neighborhood of the origin. We also give a generalization of Pommerenke's univalence criterion on complete hyperbolic domains.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2021-02-23 00:00:00.000000"},
{"id":"201","title":"Final series rather outside.","abstract":"We study a family of nonholonomic mechanical systems. These systems consist of harmonic oscillators coupled through nonholonomic constraints. In particular, the family includes the so called contact oscillator, which has been used as a test problem for numerical methods for nonholonomic mechanics. Furthermore, the systems under study constitute simple models for continuously variable transmission gearboxes. The main result is that each system in the family is integrable reversible with respect to the canonical reversibility map on the cotangent bundle. This result may explain previous numerical observations, that some discretisations of the contact oscillator have favourable structure preserving properties.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2022-08-01 00:00:00.000000"},
{"id":"202","title":"Student difficult television book institution child.","abstract":"Aiming at providing an objective motion picture for the microscopic object described by the wave function, new analysis about motion is presented by use of the point set theory in mathematics, through which we show that a new kind of motion named quantum discontinuous motion is the general motion mode of the particle, while classical continuous motion is just one kind of extremely peculiar motion, and the wave function in quantum mechanics proves to be the very mathematical complex describing the particle undergoing the quantum discontinuous motion. Furthermore, Schroedinger equation of the wave function is shown to be the simplest nonrelativistic evolution equation for the particle undergoing the new motion, and the consistent axiom system of quantum mechanics is also deduced out. At last, we demonstrate that present quantum measurement theories just confirm the existence of the new motion of the microscopic particle described by the wave function, and the weird displays of the wave function in microscopic world are also physically explained in terms of the new motion.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2017-04-26 00:00:00.000000"},
{"id":"203","title":"The lead discussion leg nice car tonight on.","abstract":"Two virtual link diagrams are homotopic if one may be transformed into the other by a sequence of virtual Reidemeister moves, classical Reidemeister moves, and self crossing changes. We recall the pure virtual braid group. We then describe the set of pure virtual braids that are homotopic to the identity braid.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2020-09-24 00:00:00.000000"},
{"id":"204","title":"Whether dog accept nearly.","abstract":"This paper constructs a concrete kind of Kuranishi structure for the moduli stack of holomorphic curves in an exploded manifolds. This Kuranishi structure is embedded inside a moduli stack of (not necessarily holomorphic) curves in order to avoid technicalities which arise when working with abstract Kuranishi structures. The construction also works for the moduli stack of holomorphic curves in any compact symplectic manifold.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2016-08-26 00:00:00.000000"},
{"id":"205","title":"Human evening century hair respond.","abstract":"We provide a clarification of the description of Langevin diffusions on Riemannian manifolds and of the measure underlying the invariant density. As a result we propose a new position-dependent Metropolis-adjusted Langevin algorithm (MALA) based upon a Langevin diffusion in $\\mathbb{R}^d$ which has the required invariant density with respect to Lebesgue measure. We show that our diffusion and the diffusion upon which a previously-proposed position-dependent MALA is based are equivalent in some cases but are distinct in general. A simulation study illustrates the gain in efficiency provided by the new position-dependent MALA.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2018-07-12 00:00:00.000000"},
{"id":"206","title":"Everyone year never country someone view.","abstract":"In various situations one is given the predictions of multiple classifiers over a large unlabeled test data. This scenario raises the following questions: Without any labeled data and without any a-priori knowledge about the reliability of these different classifiers, is it possible to consistently and computationally efficiently estimate their accuracy? Furthermore, also without any labeled data can one construct a more accurate unsupervised ensemble classifier? In this paper we make the following contributions: Under the standard assumption that classifiers make independent errors, we provide (partial)\\ positive answers to these questions. In the binary case, we present two different methods to estimate the class imbalance and classifiers specificities and sensitivities. This directly gives a novel unsupervised ensemble learner. In the multi-class case, we show how to estimate the class probabilities and the diagonal entries of the classifiers confusion matrices. We illustrate our algorithms with empirical results on both artificial and real data.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2018-06-30 00:00:00.000000"},
{"id":"207","title":"Fact result choice father.","abstract":"Families of regimes for control systems are studied possessing the so called quasi-controllability property that is similar to the Kalman controllability property. A new approach is proposed to estimate the degree of transients overshooting in quasi-controllable systems. This approach is conceptually related with the principle of bounded regimes absence in the absolute stability problem. Its essence is in obtaining of constructive a priori bounds for degree of overshooting in terms of the so called quasi-controllability measure. It is shown that relations between stability, asymptotic stability and instability for quasi-controllable systems are similar to those for systems described by linear differential or difference equations in the case when the leading eigenvalue of the corresponding matrix is simple. The results are applicable for analysis of transients, classical absolute stability problem, stability problem for desynchronized systems and so on.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2019-06-09 00:00:00.000000"},
{"id":"208","title":"Indeed create recently population.","abstract":"In real life, media information has time attributes either implicitly or explicitly known as temporal data. This paper investigates the usefulness of applying Bayesian classification to an interval encoded temporal database with prioritized items. The proposed method performs temporal mining by encoding the database with weighted items which prioritizes the items according to their importance from the user perspective. Naive Bayesian classification helps in making the resulting temporal rules more effective. The proposed priority based temporal mining (PBTM) method added with classification aids in solving problems in a well informed and systematic manner. The experimental results are obtained from the complaints database of the telecommunications system, which shows the feasibility of this method of classification based temporal mining.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2015-07-29 00:00:00.000000"},
{"id":"209","title":"Bill here administration among without.","abstract":"Deligne constructed a remarkable local system on $\\bP^1-\\{0,\\infty\\}$ attached to a family of Kloosterman sums. Katz calculated its monodromy and asked whether there are Kloosterman sheaves for general reductive groups and which automorphic forms should be attached to these local systems under the Langlands correspondence. Motivated by work of Gross and Frenkel-Gross we find an explicit family of such automorphic forms and even a simple family of automorphic sheaves in the framework of the geometric Langlands program. We use these automorphic sheaves to construct l-adic Kloosterman sheaves for any reductive group in a uniform way, and describe the local and global monodromy of these Kloosterman sheaves. In particular, they give motivic Galois representations with exceptional monodromy groups G_2,F_4,E_7 and E_8. This also gives an example of the geometric Langlands correspondence with wild ramifications for any reductive group.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2019-06-05 00:00:00.000000"},
{"id":"210","title":"Play recent hand weight speech or about moment.","abstract":"We continue the investigation of Bernstein-von Mises theorems for nonparametric Bayes procedures from Castillo and Nickl (2013 Ann.Statist, arXiv:1208.3862). We introduce multiscale spaces on which nonparametric priors and posteriors are naturally defined, and prove Bernstein-von Mises theorems for a variety of priors in the setting of Gaussian nonparametric regression and in the i.i.d.sampling model. From these results we deduce several applications where posterior-based inference coincides with efficient frequentist procedures, including Donsker- and Kolmogorov-Smirnov theorems for the random posterior cumulative distribution functions. We also show that natural multiscale posterior credible bands for the regression or density function are optimal frequentist confidence bands for H\\\"olderian functions.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2020-10-20 00:00:00.000000"},
{"id":"211","title":"Realize hotel sure scene position western body.","abstract":"After reviewing the work of Pryce on Center-of-Mass (CoM) definitions in special relativity, and that of Jordan and Mukunda on position operators for relativistic particles with spin, we propose two new criteria for a CoM candidate: associativity, and compatibility with the Poisson bracket structure. We find that they are not satisfied by all of Pryce's definitions, and they also rule out Dixon's CoM generalization to the curved spacetime case. We also emphasize that the various components of the CoM position do not commute among themselves, in the general case, and thus provide a natural entry point to the arena of noncommutative spacetime, without the ad-hoc assumptions of the standard paradigm.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2015-12-21 00:00:00.000000"},
{"id":"212","title":"Finally control pass to painting consumer include.","abstract":"Our previous results on the connection between the Forbush decreases (FD) of cosmic-ray intensity and the deviations from the expected values of the diurnal temperature range (DTR) are briefly revisited. The same type of analysis is then extended to the cases of sudden increases of cosmic-ray intensity (GLE), as well as to the search for lattitude effects in the observed correlations. We find that all the investigated correlations appear to manifest both the expected signs and the plausible phase relations, though each one only at the modest confidence level. Moreover, it appears that there is some proportionality between the magnitude of a cosmic-ray intensity change and a corresponding DTR deviation, both in the case of FD and GLE events. Eventual increase of the confidence levels at which these correlations are established would have to wait for the significant increase of the number of well defined and sufficiently intense recorded departures of cosmic-ray intensity from its stationary mean value. On the other hand, the probability of such an accidental multiple coincidence of independent pieces of evidence is certainly very low.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2018-09-16 00:00:00.000000"},
{"id":"213","title":"On him politics away your for instead.","abstract":"The \"zero in the spectrum conjecture\" asserted (in its strongest form) that for any manifold M zero should be in the l2-spectrum of the Laplacian (on forms) of the universal covering of M, i.e. that at least one (unreduced) L2-cohomology group of (the universal covering of) M is non-zero.   Farber and Weinberger gave the first counterexamples to this conjecture. In this paper, using their fundamental idea to show the following stronger version of this result:   Let G be a finitely presented group and suppose that the homology groups H_k(G,\\ell^2(G)) are zero for k=0,1,2. For every dimension n\\ge 6 there is a closed manifold M of dimension n and with fundamental group G such that the L2-cohomology of (the universal covering of) M vanishes in all degrees.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2017-02-05 00:00:00.000000"},
{"id":"214","title":"Address firm business moment.","abstract":"In this paper we study the finitely generated bigraded modules over a standard bigraded polynomial ring which are relative Cohen-Macaulay or relative unmixed with respect to one of the irrelevant bigraded ideals. A generalization of Reisner's criterion for Cohen-Macaulay simplicial complexes is considered.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2015-12-05 00:00:00.000000"},
{"id":"215","title":"Man nor fire trip art huge amount.","abstract":"It is shown that the Gibbs paradox is actually paralogism, viz. an erroneous statement sounding credible due to the statistic-mechanical interpretation of entropy as a measure of \"any and all\" irreversibility. As an alternative, the thermodynamic theory of irreversible mixing processes are offered.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2018-10-18 00:00:00.000000"},
{"id":"216","title":"Nearly leave sport city.","abstract":"Virtual e-Science infrastructures supporting Web-based scientific workflows are an example for knowledge-intensive collaborative and weakly-structured processes where the interaction with the human scientists during process execution plays a central role. In this paper we propose the lightweight dynamic user-friendly interaction with humans during execution of scientific workflows via the low-barrier approach of Semantic Wikis as an intuitive interface for non-technical scientists. Our Process Makna Semantic Wiki system is a novel combination of an business process management system adapted for scientific workflows with a Corporate Semantic Web Wiki user interface supporting knowledge intensive human interaction tasks during scientific workflow execution.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2018-01-06 00:00:00.000000"},
{"id":"217","title":"Suddenly both no mouth.","abstract":"When using object-oriented frameworks it is easy to overlook certain important method calls that are required at particular places in code. In this paper, we provide a comprehensive set of empirical facts on this problem, starting from traces of missing method calls in a bug repository. We propose a new system that searches for missing method calls in software based on the other method calls that are observable. Our key insight is that the voting theory concept of majority rule holds for method calls: a call is likely to be missing if there is a majority of similar pieces of code where this call is present. The evaluation shows that the system predictions go further missing method calls and often reveal different kinds of code smells (e.g. violations of API best practices).","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2015-05-02 00:00:00.000000"},
{"id":"218","title":"Thing American tend these role.","abstract":"First of all, this paper presents some improvements of DSMC method in the form of new schemes and approaches, that, for a wide class of problems, increase performance and reduce the demands on computer resources. The most important improvement is the scheme of temporal factors, allowing the use of different time step for different sorts of particles, thus reducing the complexity and\/or resource usage in simulation of stationary problems with very different collisional cross-sections between components of a mixture. Other improvements include the similarity parameter for efficient estimation of the number of simulational particles required for 1D, 2D and 3D computations, the new scheme for solving axisymmetric problems, an approach to detect and reject repetitive collisions. Also, some advice on technical optimization of algorithm for modern computers is offered.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2016-01-08 00:00:00.000000"},
{"id":"219","title":"Without while receive what space next few knowledge.","abstract":"Recently, Yao et al. demonstrated the creation of coherent emissions in nitrogen gas with two-color (800 nm + 400 nm) ultrafast laser pulses [New J. Phys. 15, 023046 (2013)]. Based on this two-color scheme, here we report on systematic investigation of temporal characteristics of the coherent emission at 391 nm by experimentally examining its evolution with the increase of the plasma channel induced by the intense 800 nm femtosecond laser pulses at a nitrogen gas pressure of ~25 mbar. We reveal unexpected temporal profiles of the coherent emissions, which show significant superradiance signatures owing to the quantum coherence via cooperation of an ensemble of excited N2+ molecules. Our findings shed more light on the mechanisms behind the laser-like emissions induced by strong-field ionization of molecules.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2022-02-21 00:00:00.000000"},
{"id":"220","title":"Model born again rock realize choice.","abstract":"We formulate and discuss two conjectures concerning recursive formulae for Branson's $Q$-curvatures. The proposed formulae describe all $Q$-curvatures on manifolds of all even dimensions in terms of respective lower order $Q$-curvatures and lower order GJMS-operators. They are universal in the dimension of the underlying space. The recursive formulae are generated by an algorithm which rests on the theory of residue families. We attempt to resolve the algorithm by formulating a conjectural description of the coefficients in the recursive formulae in terms of interpolation polynomials associated to compositions of natural numbers. We prove that the conjectures cover $Q_4$ and $Q_6$ for general metrics, and $Q_8$ for conformally flat metrics. The result for $Q_8$ is proved here for the first time. Moreover, we display explicit (conjectural) formulae for $Q$-curvatures of order up to 16, and test high order cases for round spheres and Einstein metrics.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2018-02-19 00:00:00.000000"},
{"id":"221","title":"Final speak manager second stock.","abstract":"We review some recent results in digital geometry obtained by using a combinatorics on words approach to discrete geometry. Motivated on the one hand by the well-known theory of Sturmian words which model conveniently discrete lines in the plane, and on the other hand by the development of digital geometry, this study reveals strong links between the two fields. Discrete figures are identified with polyominoes encoded by words. The combinatorial tools lead to elegant descriptions of geometrical features and efficient algorithms. Among these, radix-trees are useful for efficiently detecting path intersection, Lyndon and Christoffel words appear as the main tools for describing digital convexity; equations on words allow to better understand tilings by translations.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2016-05-10 00:00:00.000000"},
{"id":"222","title":"Product hair heavy industry moment business fire.","abstract":"Devinatz, Nussbaum and von Neumann established some important results on the strong commutativity of self-adjoint and normal unbounded operators. In this paper, we prove results in the same spirit.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2015-06-29 00:00:00.000000"},
{"id":"223","title":"Price official site card.","abstract":"The Newton polytope $P_f$ of a polynomial $f$ is well known to have a strong impact on its zeros, as in the Kouchnirenko-Bernstein theorem on the number of simultaneous zeros of $m$ polynomials with given Newton polytopes. In this article, we show that $P_f$ also has a strong impact on the distribution of zeros of one or several polynomials. We equip the space of (holomorphic) polynomials of degree $\\leq N$ in $m$ complex variables with its usual $SU(m+1)$-invariant Gaussian measure and then consider the conditional measures $\\gamma_{|NP}$ induced on the subspace of polynomials whose Newton polytope $P_f\\subset NP$. When $P=\\Sigma$, the unit simplex, then it is obvious and well-known that the expected distribution of zeros $Z_{f_1,...,f_k}$ (regarded as a current) of $k$ polynomials $f_1,...,f_k$ of degree $N$ is uniform relative to the Fubini-Study form. Our main results concern the conditional expectation $E_{|NP} (Z_{f_1,...,f_k})$ of zeros of $k$ polynomials with Newton polytope $NP\\subset Np\\Sigma$ (where $p=\\deg P$); these results are asymptotic as the scaling factor $N\\to\\infty$. We show that $E_{|NP} (Z_{f_1,...,f_k})$ is asymptotically uniform on the inverse image $A_P$ of the open scaled polytope $p^{-1}P^\\circ$ via the moment map $\\mu:CP^m\\to\\Sigma$ for projective space. However, the zeros have an exotic distribution outside of $A_P$ and when $k=m$ (the case of the Kouchnirenko-Bernstein theorem) the percentage of zeros outside $A_P$ approaches 0 as $N\\to\\infty$.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2016-10-17 00:00:00.000000"},
{"id":"224","title":"Street listen court drive deep Mr herself.","abstract":"Evolutionary and swarm algorithms have found many applications in design problems since todays computing power enables these algorithms to find solutions to complicated design problems very fast. Newly proposed hybrid algorithm, bat algorithm, has been applied for the design of microwave microstrip couplers for the first time. Simulation results indicate that the bat algorithm is a very fast algorithm and it produces very reliable results.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2022-07-03 00:00:00.000000"},
{"id":"225","title":"Plan expert citizen small.","abstract":"We give a simplified description of quantum affine algebras in their loop presentation. This description is related to Drinfeld's new realization via halves of vertex operators. We also define an idempotent version of the quantum affine algebra which is suitable for categorification.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2020-05-27 00:00:00.000000"},
{"id":"226","title":"Trial common hot organization tonight.","abstract":"Knowledge Representation and Reasoning and Machine Learning are two important fields in AI. Nonmonotonic logic programming (NMLP) and Answer Set Programming (ASP) provide formal languages for representing and reasoning with commonsense knowledge and realize declarative problem solving in AI. On the other side, Inductive Logic Programming (ILP) realizes Machine Learning in logic programming, which provides a formal background to inductive learning and the techniques have been applied to the fields of relational learning and data mining. Generally speaking, NMLP and ASP realize nonmonotonic reasoning while lack the ability of learning. By contrast, ILP realizes inductive learning while most techniques have been developed under the classical monotonic logic. With this background, some researchers attempt to combine techniques in the context of nonmonotonic ILP. Such combination will introduce a learning mechanism to programs and would exploit new applications on the NMLP side, while on the ILP side it will extend the representation language and enable us to use existing solvers. Cross-fertilization between learning and nonmonotonic reasoning can also occur in such as the use of answer set solvers for ILP, speed-up learning while running answer set solvers, learning action theories, learning transition rules in dynamical systems, abductive learning, learning biological networks with inhibition, and applications involving default and negation. This workshop is the first attempt to provide an open forum for the identification of problems and discussion of possible collaborations among researchers with complementary expertise. The workshop was held on September 15th of 2013 in Corunna, Spain. This post-proceedings contains five technical papers (out of six accepted papers) and the abstract of the invited talk by Luc De Raedt.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2017-12-23 00:00:00.000000"},
{"id":"227","title":"Reflect page art Mr.","abstract":"Building complex software systems necessitates the use of component-based architectures. In theory, of the set of components needed for a design, only some small portion of them are \"custom\"; the rest are reused or refactored existing pieces of software. Unfortunately, this is an idealized situation. Just because two components should work together does not mean that they will work together.   The \"glue\" that holds components together is not just technology. The contracts that bind complex systems together implicitly define more than their explicit type. These \"conceptual contracts\" describe essential aspects of extra-system semantics: e.g., object models, type systems, data representation, interface action semantics, legal and contractual obligations, and more.   Designers and developers spend inordinate amounts of time technologically duct-taping systems to fulfill these conceptual contracts because system-wide semantics have not been rigorously characterized or codified. This paper describes a formal characterization of the problem and discusses an initial implementation of the resulting theoretical system.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2016-05-06 00:00:00.000000"},
{"id":"228","title":"Reason heart miss hand senior.","abstract":"Mainly, we correct the uniqueness result by adding a projection requirement to condition X and give a better proof for the equivalence of commutator density, 2\/4-generation and 3\/4-generation.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2018-04-28 00:00:00.000000"},
{"id":"229","title":"Politics person myself help reduce.","abstract":"Multi-configuration range-separated density-functional theory is extended to the time-dependent regime. An exact variational formulation is derived. The approximation, which consists in combining a long-range Multi-Configuration-Self-Consistent Field (MCSCF) treatment with an adiabatic short-range density-functional (DFT) description, is then considered. The resulting time-dependent multi-configuration short-range DFT (TD-MC-srDFT) model is applied to the calculation of singlet excitation energies in H2, Be and ferrocene, considering both short-range local density (srLDA) and generalized gradient (srGGA) approximations. In contrast to regular TD-DFT, TD-MC-srDFT can describe double excitations. As expected, when modeling long-range interactions with the MCSCF model instead of the adiabatic Buijse-Baerends density-matrix functional as recently proposed by Pernal [K. Pernal, J. Chem. Phys. 136, 184105 (2012)], the description of both the 1^1D doubly-excited state in Be and the 1^1\\Sigma^+_u state in the stretched H2 molecule are improved, although the latter is still significantly underestimated. Exploratory TD-MC-srDFT\/GGA calculations for ferrocene yield in general excitation energies at least as good as TD-DFT\/CAM-B3LYP, and superior to wave-function (TD-MCSCF, symmetry adapted cluster-configuration interaction) and TD-DFT results based on LDA, GGA, and hybrid functionals.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2021-01-30 00:00:00.000000"},
{"id":"230","title":"Early move involve again.","abstract":"This paper studies the effect of boundary value conditions on consensus networks. Consider a network where some nodes keep their estimates constant while other nodes average their estimates with that of their neighbors. We analyze such networks and show that in contrast to standard consensus networks, the network estimate converges to a general harmonic function on the graph. Furthermore, the final value depends only on the value at the boundary nodes. This has important implications in consensus networks -- for example, we show that consensus networks are extremely sensitive to the existence of a single malicious node or consistent errors in a single node. We also discuss applications of this result in social and sensor networks. We investigate the existence of boundary nodes in human social networks via an experimental study involving human subjects. Finally, the paper is concluded with the numerical studies of the boundary value problems in consensus networks.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2019-09-03 00:00:00.000000"},
{"id":"231","title":"Free whatever five box later.","abstract":"We are interested in creating an automated or semi-automated system with the capability of taking a set of radar imagery, collection parameters and a priori map and other tactical data, and producing likely interpretations of the possible military situations given the available evidence. This paper is concerned with the problem of the interpretation and computation of certainty or belief in the conclusions reached by such a system.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2021-02-20 00:00:00.000000"},
{"id":"232","title":"Thing one news human father.","abstract":"In this paper we investigate the general combinatorical structure of the truth tables of all bracketed formulae with n distinct variables connected by the binary connective of implication, an m-implication.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2021-10-26 00:00:00.000000"},
{"id":"233","title":"Yeah investment him return.","abstract":"The XXXI European Symposium on Occultation Projects will be celebrated in ICRANet center of Pescara from 24 to 27 August 2012 (www.icranet.org\/clavius2012). The occasion is the fourth centennial of the Jesuit astronomer Christopher Clavius (Bamberg 1538- Napoli 1612). The hybrid eclipse witnessed by Clavius in Rome (1567) and published on his Commentarius on the Sphere (1581 edition) was the first account of an annular eclipse ever published in a scientific book. To account of this eclipse a larger solar diameter for 1567 has to be considered, and the scientific debate is still open. This is the trait-d'union between Clavius and ESOP annual meeting. The city of Pescara and the region of Abruzzo are presented with an historical, climatic, religious and gastronomical outline.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2017-01-08 00:00:00.000000"},
{"id":"234","title":"Career every have condition treat community sign floor.","abstract":"Using techniques developed for studying polynomially bounded cohomology, we show that the assembly map for $K_*^t(\\ell^1(G))$ is rationally injective for all finitely presented discrete groups $G$. This verifies the $\\ell^1$-analogue of the Strong Novikov Conjecture for such groups.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2016-04-05 00:00:00.000000"},
{"id":"235","title":"Administration simple method increase far.","abstract":"For a family X of k-subsets of the set 1,...,n, let |X| be the cardinality of X and let Gamma(X,mu) be the expected maximum weight of a subset from X when the weights of 1,...,n are chosen independently at random from a symmetric probability distribution mu on R. We consider the inverse isoperimetric problem of finding mu for which Gamma(X,mu) gives the best estimate of ln|X|. We prove that the optimal choice of mu is the logistic distribution, in which case Gamma(X,mu) provides an asymptotically tight estimate of ln|X| as k^{-1}ln|X| grows. Since in many important cases Gamma(X,mu) can be easily computed, we obtain computationally efficient approximation algorithms for a variety of counting problems. Given mu, we describe families X of a given cardinality with the minimum value of Gamma(X,mu), thus extending and sharpening various isoperimetric inequalities in the Boolean cube.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2019-04-18 00:00:00.000000"},
{"id":"236","title":"Player necessary guess throughout help.","abstract":"This paper considers a point process model with a monotonically decreasing or increasing ROCOF and the underlying distributions from the location-scale family, known as the geometric process (Lam, 1988). In terms of repairable system reliability analysis, the process is capable of modeling various restoration types including \"better-than-new\", i.e., the one not covered by the popular G-Renewal model (Kijima & Sumita, 1986). The distinctive property of the process is that the times between successive events are obtained from the underlying distributions as the scale parameter of each is monotonically decreasing or increasing. The paper discusses properties and maximum likelihood estimation of the model for the case of the Exponential and Weibull underlying distributions.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2018-05-02 00:00:00.000000"},
{"id":"237","title":"Community decision night water exactly including certain.","abstract":"Enhancement of the number and array density of nozzles within an inkjet head chip is one of the keys to raise the printing speed and printing resolutions. However, traditional 2D architecture of driving circuits can not meet the requirement for high scanning speed and low data accessing points when nozzle numbers greater than 1000. This paper proposes a novel architecture of high-selection-speed three-dimensional data registration for inkjet applications. With the configuration of three-dimensional data registration, the number of data accessing points as well as the scanning lines can be greatly reduced for large array inkjet printheads with nozzles numbering more than 1000. This IC (Integrated Circuit) architecture involves three-dimensional multiplexing with the provision of a gating transistor for each ink firing resistor, where ink firing resistors are triggered only by the selection of their associated gating transistors. Three signals: selection (S), address (A), and power supply (P), are employed together to activate a nozzle for droplet ejection. The smart printhead controller has been designed by a 0.35 um CMOS process with a total circuit area, 2500 x 500 microm2, which is 80% of the cirucuit area by 2D configuration for 1000 nozzles. Experiment results demonstrate the functionality of the fabricated IC in operation, signal transmission and a potential to control more than 1000 nozzles with only 31 data access points and reduced 30% scanning time.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2015-02-08 00:00:00.000000"},
{"id":"238","title":"Practice me leave shoulder western across determine.","abstract":"Harmonic analysis on Hermitian symmetric spaces of tube type is a natural framework for introducing multivariate Meixner-Pollaczek polynomials. Their main properties are established in this setting: generating and determinantal formulae, difference equations. As an application we consider the problem of evaluating moments related to a multivariate Barnes type integral involving the Harish-Chandra $c$-function of a symmetric cone.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2021-07-29 00:00:00.000000"},
{"id":"239","title":"Moment address local dark friend one.","abstract":"In this work we present a dynamical model that succesfully describes the organization of mutualistic ecological systems. The main characteristic of these systems is the nested structure of the bipartite adjacency matrix describing their interactions. We introduce a nestedness coefficient, as an alternative to the Atmar and Patterson temperature, commonly used to measure the nestedness degree of the network. This coefficient has the advantage of being based on the robustness of the ecological system and it is not only describing the ordering of the bipartite matrix but it is also able to tell the difference, if any, between the degree of organization of each guild.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2018-03-12 00:00:00.000000"},
{"id":"240","title":"Area south hit discover street Mrs goal responsibility.","abstract":"A high Radio Analog Signal Processing (R-ASP) resolution transmission-type (TT) phaser based on reflection-type (RT) phaser units is introduced, theoretically studied and experimentally demonstrated. It is first shown that RT phasers inherently exhibit higher R-ASP resolution than their TT counterparts because their group delay swing is proportional to the reflection coefficient associated with a resonator coupling mechanism (admittance inverter), easy to maximize towards unity, rather than to a coupled-line coupling coefficient, typically restricted to values will inferior to unity, as in the RT case. Moreover, a detailed sensitivity analysis reveals that the proposed phaser is simultaneously features high R-ASP resolution and low sensitivity to fabrication tolerance, which makes it an ideal solution for R-ASP. The proposed phaser exhibits a 5 ns group delay swing over a fractional bandwidth of about 50% around 4 GHz.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2016-08-11 00:00:00.000000"},
{"id":"241","title":"Across blood song girl.","abstract":"We describe a new method for approximating an arbitrary $n$ qubit unitary with precision $\\varepsilon$ using a Clifford and T circuit with $O(4^{n}n(\\log(1\/\\varepsilon)+n))$ gates. The method is based on rounding off a unitary to a unitary over the ring $\\mathbb{Z}[i,1\/\\sqrt{2}]$ and employing exact synthesis. We also show that any $n$ qubit unitary over the ring $\\mathbb{Z}[i,1\/\\sqrt{2}]$ with entries of the form $(a+b\\sqrt{2}+ic+id\\sqrt{2})\/2^{k}$ can be exactly synthesized using $O(4^{n}nk)$ Clifford and T gates using two ancillary qubits. This new exact synthesis algorithm is an improvement over the best known exact synthesis method by B. Giles and P. Selinger requiring $O(3^{2^{n}}nk)$ elementary gates.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2015-02-12 00:00:00.000000"},
{"id":"242","title":"Speak win light popular very final use.","abstract":"This article presents the theoretical foundation of a new frontier of research-`LP Mixed Data Science'-that simultaneously extends and integrates the practice of traditional and novel statistical methods for nonparametric exploratory data modeling, and is applicable to the teaching and training of statistics.   Statistics journals have great difficulty accepting papers unlike those previously published. For statisticians with new big ideas a practical strategy is to publish them in many small applied studies which enables one to provide references to work of others. This essay outlines the many concepts, new theory, and important algorithms of our new culture of statistical science called LP MIXED DATA SCIENCE. It provides comprehensive solutions to problems of data analysis and nonparametric modeling of many variables that are continuous or discrete, which does not yet have a large literature. It develops a new modeling approach to nonparametric estimation of the multivariate copula density. We discuss the theory which we believe is very elegant (and can provide a framework for United Statistical Algorithms, for traditional Small Data methods and Big Data methods).","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2018-12-03 00:00:00.000000"},
{"id":"243","title":"Boy race among entire tend word staff.","abstract":"We present results from the theoretical INDO calculations of the electronic structure for stacked eumelanins' monomers. As basic indolic components of the eumelanin structure 5,6-dihydroxyindole (DHI or HQ) and its oxidized forms (SQ and IQ) were chosen. The results reveal dependency of electronic properties of such aggregates on monomers' redox states. They point out also a tendency to localize an extra charge on one of dimer's subunits that could be suggestive of an electron hopping as a model mechanism forthe electron transfer in eumelanins.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2016-10-16 00:00:00.000000"},
{"id":"244","title":"However could section we everybody second.","abstract":"We define a quotient of the category of finitely generated modules over the cyclotomic Khovanov-Lauda-Rouquier algebra for type An and show it has a module category structure over a direct sum of certain cyclotomic Khovanov-Lauda-Rouquier algebras of type An-1, this way categorifying the branching rules for the inclusion of sl(n) in sl(n+1). Using this we give a new, elementary proof of Khovanov-Lauda cyclotomic conjecture. We show that continuing recursively gives the Gelfand-Tsetlin basis for type An. As an application we prove a conjecture of Mackaay, Stosic and Vaz concerning categorical Weyl modules.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2018-02-08 00:00:00.000000"},
{"id":"245","title":"Catch house few check dinner huge mouth hot.","abstract":"Magnetic design proposed for a damping ring (DR) is based on second generation HTS cabling technology applied to the DC windings with a yoke and mu-metal-shimmed pole to achieve ~2T high-quality field within a 86 mm gap and 32-40 cm period. Low levels of current densities (~90-100A\/mm2) provide a robust, reliable operation of the wiggler at higher heat loads, up to LN2 temperatures with long leads, enhanced flexibility for the cryostats and infrastructure in harsh radiation environment, and reduced failure rate compared to the baseline SC ILC DR wiggler design at very competitive cost.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2021-08-08 00:00:00.000000"},
{"id":"246","title":"At political single nation involve for happy.","abstract":"Consider the ideal I corresponding to r points in P^2. We study the symbolic generic initial system of I, formed by taking the generic initial ideals of the symbolic powers of I, and its asymptotic behaviour. In particular, we describe the limiting shape of this system explicitly when the points lie in general position using the SHGH Conjecture for more than eight points. The symbolic generic initial system and its limiting shape reflects information about the Hilbert functions of uniform fat point ideals.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2018-11-25 00:00:00.000000"},
{"id":"247","title":"Enter technology message day keep case.","abstract":"The behaviour of electron emission under electron impact at very low energy is of great importance in many applications such as high energy physics, satellites, nuclear reactors, etc. However the question of the total electron reflectivity is still in discussion. Our experimental and theoretical studies show that the total reflectivity at very low energy is far from being an obvious fact. Moreover, our results show that the yield is close to zero and not equal to one for low energy incident electron.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2022-09-29 00:00:00.000000"},
{"id":"248","title":"Force than read newspaper.","abstract":"We address the problem of controlling a stochastic version of a Dubins vehicle such that the probability of satisfying a temporal logic specification over a set of properties at the regions in a partitioned environment is maximized. We assume that the vehicle can determine its precise initial position in a known map of the environment. However, inspired by practical limitations, we assume that the vehicle is equipped with noisy actuators and, during its motion in the environment, it can only measure its angular velocity using a limited accuracy gyroscope. Through quantization and discretization, we construct a finite approximation for the motion of the vehicle in the form of a Markov Decision Process (MDP). We allow for task specifications given as temporal logic statements over the environmental properties, and use tools in Probabilistic Computation Tree Logic (PCTL) to generate an MDP control policy that maximizes the probability of satisfaction. We translate this policy to a vehicle feedback control strategy and show that the probability that the vehicle satisfies the specification in the original environment is bounded from below by the maximum probability of satisfying the specification on the MDP.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2019-09-07 00:00:00.000000"},
{"id":"249","title":"Wide old tell hold person rest.","abstract":"This work reveals an experimental microscopy acquisition scheme successfully combining Compressed Sensing (CS) and digital holography in off-axis and frequency-shifting conditions. CS is a recent data acquisition theory involving signal reconstruction from randomly undersampled measurements, exploiting the fact that most images present some compact structure and redundancy. We propose a genuine CS-based imaging scheme for sparse gradient images, acquiring a diffraction map of the optical field with holographic microscopy and recovering the signal from as little as 7% of random measurements. We report experimental results demonstrating how CS can lead to an elegant and effective way to reconstruct images, opening the door for new microscopy applications.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2022-12-13 00:00:00.000000"},
{"id":"250","title":"Wish through audience product coach former town list.","abstract":"Regression models fitted to data can be assessed on their goodness of fit, though models with many parameters should be disfavored to prevent over-fitting. Statisticians' tools for this are little known to physical scientists. These include the Akaike Information Criterion (AIC), a penalized goodness-of-fit statistic, and the AICc, a variant including a small-sample correction. They entered the physical sciences through being used by astrophysicists to compare cosmological models; e.g., predictions of the distance-redshift relation. The AICc is shown to have been misapplied, being applicable only if error variances are unknown. If error bars accompany the data, the AIC should be used instead. Erroneous applications of the AICc are listed in an appendix. It is also shown how the variability of the AIC difference between models with a known error variance can be estimated. This yields a significance test that can potentially replace the use of `Akaike weights' for deciding between such models. Additionally, the effects of model misspecification are examined. For regression models fitted to data sets without (rather than with) error bars, they are major: the AICc may be shifted by an unknown amount. The extent of this in the fitting of physical models remains to be studied.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2022-05-14 00:00:00.000000"},
{"id":"251","title":"Story performance character good.","abstract":"This paper investigates the expected number of complex roots of nonlinear equations. Those equations are assumed to be analytic, and to belong to certain inner product spaces. Those spaces are then endowed with the Gaussian probability distribution.   The root count on a given domain is proved to be `additive' with respect to a product operation of functional spaces. This allows to deduce a general theorem relating the expected number of roots for unmixed and mixed systems. Examples of root counts for equations that are not polynomials nor exponential sums are given at the end.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2021-10-15 00:00:00.000000"},
{"id":"252","title":"Receive western sort direction research.","abstract":"OCR has been an active research area since last few decades. OCR performs the recognition of the text in the scanned document image and converts it into editable form. The OCR process can have several stages like pre-processing, segmentation, recognition and post processing. The pre-processing stage is a crucial stage for the success of OCR, which mainly deals with noise removal. In the present paper, a modified technique for noise removal named as K-Algorithm has been proposed, which has two stages as filtering and binarization. The proposed technique shows improvised results in comparison to median filtering technique.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2019-10-04 00:00:00.000000"},
{"id":"253","title":"Game head bag those note enough.","abstract":"We point out inconsistencies in the recent paper by Oughstun et al. on Sommerfeld and Brillouin precursors [J. Opt. Soc. Am. B 27, 1664-1670 (2010)]. Their study is essentially numerical and, for the parameters used in their simulations, the difference between the two limits considered is not as clear-cut as they state. The steep rise of the Brillouin precursor obtained in the singular limit and analyzed as a distinguishing feature of this limit simply results from an unsuitable time scale. In fact, the rise of the precursor is progressive and is perfectly described by a Airy function. In the weak dispersion limit, the equivalence relation, established at great length in Section 3 of the paper, appears as an immediate result in the retarded-time picture. Last but not least, we show that, contrary to the authors claim, the precursors are catastrophically affected by the rise-time of the incident optical field, even when the latter is considerably faster than the medium relaxation time.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2015-03-11 00:00:00.000000"},
{"id":"254","title":"Describe history trouble month similar artist.","abstract":"A new method of estimating some statistical characteristics of TCP flows in the Internet is developed in this paper. For this purpose, a new set of random variables (referred to as observables) is defined. When dealing with sampled traffic, these observables can easily be computed from sampled data. By adopting a convenient mouse\/elephant dichotomy also dependent on traffic, it is shown how these variables give a reliable statistical representation of the number of packets transmitted by large flows during successive time intervals with an appropriate duration. A mathematical framework is developed to estimate the accuracy of the method. As an application, it is shown how one can estimate the number of large TCP flows when only sampled traffic is available. The algorithm proposed is tested against experimental data collected from different types of IP networks.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2021-10-04 00:00:00.000000"},
{"id":"255","title":"Site rock hospital new.","abstract":"The ETS has recently released new estimates of validities of the GRE for predicting cumulative graduate GPA. They average in the middle thirties - twice as high as those previously reported by a number of independent investigators. It is shown in the first part of this paper that this unexpected finding can be traced to a flawed methodology that tends to inflate multiple correlation estimates, especially those of populations values near zero. Secondly, the issue of upward corrections of validity estimates for restriction of range is taken up. It is shown that they depend on assumptions that are rarely met by the data. Finally, it is argued more generally that conventional test theory, which is couched in terms of correlations and variances, is not only unnecessarily abstract but, more importantly, incomplete, since the practical utility of a test does not only depend on its validity, but also on base-rates and admission quotas. A more direct and conclusive method for gauging the utility of a test involves misclassification rates, and entirely dispenses with questionable assumptions and post-hoc \"corrections\". On applying this approach to the GRE, it emerges (1) that the GRE discriminates against ethnic and economic minorities, and (2) that it often produces more erroneous decisions than a purely random admissions policy would.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2020-06-03 00:00:00.000000"},
{"id":"256","title":"Forward oil resource close have ahead.","abstract":"In this work, we study the numerical solution for parabolic equations whose solutions have a common property of blowing up in finite time and the equations are invariant under the following scaling transformation $$u \\mapsto u_\\lambda(x,t):= \\lambda^{\\frac{2}{p-1}}u(\\lambda x, \\lambda^2 t).$$ For that purpose, we apply the rescaling method proposed by Berger and Kohn in 1988 to such problems. The convergence of the method is proved under some regularity assumption. Some numerical experiments are given to derive the blow-up profile verifying henceforth the theoretical results.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2019-02-07 00:00:00.000000"},
{"id":"257","title":"While old war hair maintain scene nation spend.","abstract":"In this paper, we introduce a mixture of skew-t factor analyzers as well as a family of mixture models based thereon. The mixture of skew-t distributions model that we use arises as a limiting case of the mixture of generalized hyperbolic distributions. Like their Gaussian and t-distribution analogues, our mixture of skew-t factor analyzers are very well-suited to the model-based clustering of high-dimensional data. Imposing constraints on components of the decomposed covariance parameter results in the development of eight flexible models. The alternating expectation-conditional maximization algorithm is used for model parameter estimation and the Bayesian information criterion is used for model selection. The models are applied to both real and simulated data, giving superior clustering results compared to a well-established family of Gaussian mixture models.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2016-04-19 00:00:00.000000"},
{"id":"258","title":"Both sing point item song.","abstract":"The purpose of this letter is threefold : (i) to derive, in the framework of a new parametrization, some compact formulas of energy averages for the electrostatic interaction within an (nl)N configuration, (ii) to describe a new generating function for obtaining the number of states with a given spin angular momentum in an (nl)N configuration, and (iii) to report some apparently new sum rules, actually a by-product of (i), for SU(2) > U(1) coupling coefficients.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2019-10-14 00:00:00.000000"},
{"id":"259","title":"Write election bank challenge present.","abstract":"Let R_\\alpha be the Riesz distribution on a simple Euclidean Jordan algebra, parametrized by the complex number \\alpha. I give an elementary proof of the necessary and sufficient condition for R_\\alpha to be a locally finite complex measure (= complex Radon measure).","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2019-11-06 00:00:00.000000"},
{"id":"260","title":"Address discussion direction item.","abstract":"The triatomic hydrogen ion (H$_3^+$) has spurred tremendous interest in astrophysics in recent decades, and Rydberg states of H$_3$ have also maintained an important role for understanding H$_3^+$ experiments. In a previous study [J. Chem. Phys. \\textbf{133}, 234302 (2010)], radiative transitions between neutral H$_3$ Rydberg states were calculated at wavelengths near 7 microns, and could be compared with mid-infrared laser lines observed in hydrogen\/rare gas discharges. The present study extends the investigation to wavelengths near 10 -- 13 microns. Rydberg states of D$_3$ are also treated.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2015-11-27 00:00:00.000000"},
{"id":"261","title":"Out society strategy especially.","abstract":"The emerging need for mobile ad hoc networks and secured data transmission phase is of crucial importance depending upon the environments like military. In this paper, a new way to improve the reliability of message transmission is presented. In the open collaborative MANET environment, any node can maliciously or selfishly disrupt and deny communication of other nodes. Dynamic changing topology makes it hard to determine the adversary nodes that affect the communication in MANET. An SMT protocol provides a way to secure message transmission by dispersing the message among several paths with minimal redundancy. The multiple routes selected are known as APS -Active Path Set. This paper describes a technique for fault discovery process to identify Byzantine failures which include nodes that drop, modify, or mis-route packets in an attempt to disrupt the routing service. An adaptive probing technique detects a malicious link through binary search and according to the nodes behavior, these links are avoided in the active path by multiplicatively increasing their weights. The proposed scheme provides secure communication even with increased number of adversaries.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2017-03-13 00:00:00.000000"},
{"id":"262","title":"Loss south same on.","abstract":"We focus the use of \\emph{row sampling} for approximating matrix algorithms. We give applications to matrix multipication; sparse matrix reconstruction; and, \\math{\\ell_2} regression. For a matrix \\math{\\matA\\in\\R^{m\\times d}} which represents \\math{m} points in \\math{d\\ll m} dimensions, all of these tasks can be achieved in \\math{O(md^2)} via the singular value decomposition (SVD). For appropriate row-sampling probabilities (which typically depend on the norms of the rows of the \\math{m\\times d} left singular matrix of \\math{\\matA} (the \\emph{leverage scores}), we give row-sampling algorithms with linear (up to polylog factors) dependence on the stable rank of \\math{\\matA}. This result is achieved through the application of non-commutative Bernstein bounds.   We then give, to our knowledge, the first algorithms for computing approximations to the appropriate row-sampling probabilities without going through the SVD of \\math{\\matA}. Thus, these are the first \\math{o(md^2)} algorithms for row-sampling based approximations to the matrix algorithms which use leverage scores as the sampling probabilities. The techniques we use to approximate sampling according to the leverage scores uses some powerful recent results in the theory of random projections for embedding, and may be of some independent interest. We confess that one may perform all these matrix tasks more efficiently using these same random projection methods, however the resulting algorithms are in terms of a small number of linear combinations of all the rows. In many applications, the actual rows of \\math{\\matA} have some physical meaning and so methods based on a small number of the actual rows are of interest.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2021-12-31 00:00:00.000000"},
{"id":"263","title":"Month blue have.","abstract":"The existence of an internal frequency associated to any elementary particle conjectured by de Broglie is compared with a classical description of the electron, where this internal structure corresponds to the motion of the centre of charge around the centre of mass of the particle. This internal motion has a frequency twice de Broglie's frequency, which corresponds to the frequency found by Dirac when analysing the electron structure. To get evidence of this internal electron clock a kind of experiment as the one performed by Gouan\\'ere et al. \\cite{Gouanere} will show a discrete set of momenta at which a resonant scattering effect, appears. The resonant momenta of the electron beam are given by $p_k=161.748\/k$ MeV$\/c$, $k=1,2,3,...$, where only, the corresponding to $k=2$, was within the range of Gouan\\'ere et al. experiment. The extension of the experiment to other values of $p_k$, would show the existence of this phenomenon.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2022-07-17 00:00:00.000000"},
{"id":"264","title":"People man nature pay.","abstract":"The task of camera calibration is to estimate the intrinsic and extrinsic parameters of a camera model. Though there are some restricted techniques to infer the 3-D information about the scene from uncalibrated cameras, effective camera calibration procedures will open up the possibility of using a wide range of existing algorithms for 3-D reconstruction and recognition.  The applications of camera calibration include vision-based metrology, robust visual platooning and visual docking of mobile robots where the depth information is important.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2015-12-08 00:00:00.000000"},
{"id":"265","title":"Hot color too both less sit.","abstract":"We derive a 4D covariant Relativistic Dynamics Equation. This equation canonically extends the 3D relativistic dynamics equation $\\mathbf{F}=\\frac{d\\mathbf{p}}{dt}$, where $\\mathbf{F}$ is the 3D force and $\\mathbf{p}=m_0\\gamma\\mathbf{v}$ is the 3D relativistic momentum. The standard 4D equation $F=\\frac{dp}{d\\tau}$ is only partially covariant. To achieve full Lorentz covariance, we replace the four-force $F$ by a rank 2 antisymmetric tensor acting on the four-velocity. By taking this tensor to be constant, we obtain a covariant definition of uniformly accelerated motion. This solves a problem of Einstein and Planck.   We compute explicit solutions for uniformly accelerated motion. The solutions are divided into four Lorentz-invariant types: null, linear, rotational, and general. For null acceleration, the worldline is cubic in the time. Linear acceleration covariantly extends 1D hyperbolic motion, while rotational acceleration covariantly extends pure rotational motion.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2021-05-16 00:00:00.000000"},
{"id":"266","title":"Project important win culture.","abstract":"We evaluate the electric-dipole and electric-quadrupole static and dynamic polarizabilities for the 6s^2 ^1S_0, 6s6p ^3P_0, and 6s6p ^3P_1 states and estimate their uncertainties. A methodology is developed for an accurate evaluation of the van der Waals coefficients of dimers involving excited state atoms with strong decay channel to the ground state. This method is used for evaluation of the long range interaction coefficients of particular experimental interest, including the C_6 coefficients for the Yb-Yb ^1S_0+^3P_{0,1} and ^3P_0+^3P_0 dimers and C_8 coefficients for the ^1S_0+^1S_0 and ^1S_0+^3P_1 dimers.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2015-06-21 00:00:00.000000"},
{"id":"267","title":"Oil fund education program.","abstract":"We propose a (limited) solution to the problem of constructing stream values defined by recursive equations that do not respect the guardedness condition. The guardedness condition is imposed on definitions of corecursive functions in Coq, AGDA, and other higher-order proof assistants. In this paper, we concentrate in particular on those non-guarded equations where recursive calls appear under functions. We use a correspondence between streams and functions over natural numbers to show that some classes of non-guarded definitions can be modelled through the encoding as structural recursive functions. In practice, this work extends the class of stream values that can be defined in a constructive type theory-based theorem prover with inductive and coinductive types, structural recursion and guarded corecursion","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2022-06-01 00:00:00.000000"},
{"id":"268","title":"Sign very entire involve speak or.","abstract":"We compare the solvability of the Consensus and Broadcast problems in synchronous communication networks in which the delivery of messages is not reliable. The failure model is the mobile omission faults model. During each round, some messages can be lost and the set of possible simultaneous losses is the same for each round. We investigate these problems for the first time for arbitrary sets of possible failures. Previously, these sets were defined by bounding the numbers of failures.   In this setting, we present a new necessary condition for the solvability of Consensus that unifies previous impossibility results in this area. This condition is expressed using Broadcastability properties. As a very important application, we show that when the sets of omissions that can occur are defined by bounding the numbers of failures, counted in any way (locally, globally, etc.), then the Consensus problem is actually equivalent to the Broadcast problem.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2022-02-08 00:00:00.000000"},
{"id":"269","title":"Million red pattern north.","abstract":"Let $G$ be an unmixed bipartite graph of dimension $d-1$. Assume that $K_{n,n}$, with $n\\ge 2$, is a maximal complete bipartite subgraph of $G$ of minimum dimension. Then $G$ is Cohen-Macaulay in codimension $d-n+1$. This generalizes a characterization of Cohen-Macaulay bipartite graphs by Herzog and Hibi and a result of Cook and Nagel on unmixed Buchsbaum graphs. Furthermore, we show that any unmixed bipartite graph $G$ which is Cohen-Macaulay in codimension $t$, is obtained from a Cohen-Macaulay graph by replacing certain edges of $G$ with complete bipartite graphs. We provide some examples.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2018-10-18 00:00:00.000000"},
{"id":"270","title":"Person want character woman far magazine base.","abstract":"We study when Taylor resolutions of monomial ideals are minimal. We consider monomial ideals with linear quotients. In particular, we determine precisely the stable ideals and the monomial ideals with linear resolutions having the miminal Taylor resolutions.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2016-03-11 00:00:00.000000"},
{"id":"271","title":"Word step describe leave peace particular many leave.","abstract":"A surrogate data analysis is presented, which is based on the fluctuations of the ``entropy'' $S$ defined in the natural time-domain [Phys. Rev. E {\\bf 68}, 031106, 2003]. This entropy is not a static one as, for example, the Shannon entropy. The analysis is applied to three types of time-series, i.e., seismic electric signals, ``artificial'' noises and electrocardiograms, and ``recognizes'' the non-Markovianity in all these signals. Furthermore, it differentiates the electrocardiograms of healthy humans from those of the sudden cardiac death ones. If $\\delta S$ and $\\delta S_{shuf}$ denote the standard deviation when calculating the entropy by means of a time-window sweeping through the original data and the ``shuffled'' (randomized) data, respectively, it seems that the ratio $\\delta S_{shuf}\/\\delta S$ plays a key-role. The physical meaning of $\\delta S_{shuf}$ is investigated.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2020-06-19 00:00:00.000000"},
{"id":"272","title":"Debate under evening develop name area.","abstract":"Photocatalytic water splitting reaction on TiO2 surface is one of the fundamental issues that bears significant implication in hydrogen energy technology and has been extensively studied. However, the existence of the very first reaction step, the direct photo-dissociation of water, has been disregarded. Here, we provide unambiguously experimental evidence to demonstrate that adsorbed water molecules on reduced rutile TiO2(110)-1\\times1 surface can be dissociated under UV irradiation using low temperature scanning tunneling microscopy. It is identified that a water molecule at fivefold coordinated Ti (Ti5c) site can be photocatalytically dissociated, resulting in a hydroxyl at Ti5c and another hydroxyl at bridge oxygen row. Our findings reveal a missing link in the photocatalytic water splitting reaction chain, which greatly contribute to the detailed understanding of underlying mechanism.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2015-03-31 00:00:00.000000"},
{"id":"273","title":"Nature religious sea these.","abstract":"The general principles of Bayesian data analysis imply that models for survey responses should be constructed conditional on all variables that affect the probability of inclusion and nonresponse, which are also the variables used in survey weighting and clustering. However, such models can quickly become very complicated, with potentially thousands of poststratification cells. It is then a challenge to develop general families of multilevel probability models that yield reasonable Bayesian inferences. We discuss in the context of several ongoing public health and social surveys. This work is currently open-ended, and we conclude with thoughts on how research could proceed to solve these problems.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2020-04-04 00:00:00.000000"},
{"id":"274","title":"Activity board lawyer war fly account name.","abstract":"We present a new estimator for computing free energy differences and thermodynamic expectations as well as their uncertainties from samples obtained from multiple equilibrium states via either simulation or experiment. The estimator, which we term the multistate Bennett acceptance ratio (MBAR) estimator because it reduces to the Bennett acceptance ratio when only two states are considered, has significant advantages over multiple histogram reweighting methods for combining data from multiple states. It does not require the sampled energy range to be discretized to produce histograms, eliminating bias due to energy binning and significantly reducing the time complexity of computing a solution to the estimating equations in many cases. Additionally, an estimate of the statistical uncertainty is provided for all estimated quantities. In the large sample limit, MBAR is unbiased and has the lowest variance of any known estimator for making use of equilibrium data collected from multiple states. We illustrate this method by producing a highly precise estimate of the potential of mean force for a DNA hairpin system, combining data from multiple optical tweezer measurements under constant force bias.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2019-07-04 00:00:00.000000"},
{"id":"275","title":"Often give fish indicate grow.","abstract":"Various methods have been proposed in the literature to determine an optimal partitioning of the set of actors in a network into core and periphery subsets. However, these methods either work only for relatively small input sizes, or do not guarantee an optimal answer. In this paper, we propose a new algorithm to solve this problem. This algorithm is efficient and exact, allowing the optimal partitioning for networks of several thousand actors to be computed in under a second. We also show that the optimal core can be characterized as a set containing the actors with the highest degrees in the original network.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2015-07-23 00:00:00.000000"},
{"id":"276","title":"Rest nearly sit future wall interesting.","abstract":"This obituary is devoted to M. I. Polikarpov (28.12.1952 - 18.07.2013), our teacher, our colleague, our friend. We recollect some facts of his biography and stages of his scientific career, and make a brief review of some of his most known scientific works. We conclude with some messages of condolence which were received from his colleagues and friends after his sudden death.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2018-10-02 00:00:00.000000"},
{"id":"277","title":"House information one day.","abstract":"A semi-Dirac cone refers to a peculiar type of dispersion relation that is linear along the symmetry line but quadratic in the perpendicular direction. Here, I demonstrate that a photonic crystal consisting of a square array of elliptical dielectric cylinders is able to produce this particular dispersion relation in the Brillouin zone center. A perturbation method is used to evaluate the linear slope and to affirm that the dispersion relation is a semi-Dirac type. Effective medium parameters calculated from a boundary effective medium theory not only explain the unexpected topological transition in the iso-frequency surfaces occurring at the semi-Dirac point, they also offer a perspective on the property at that point, where the photonic crystal behaves as a zero-refractive-index material along the symmetry axis but functions like at a photonic band edge in the perpendicular direction.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2015-11-11 00:00:00.000000"},
{"id":"278","title":"Available commercial ten teacher total town.","abstract":"Exotic beams of short-lived radioisotopes are produced in nuclear reactions such as thermal neutron induced fission, target or projectile fragmentation and fusion reactions. For a given radioactive ion beam (RIB), different production modes are in competition. For each of them the cross section, the intensity of the projectile beam and the target thickness define an upper production rate. The final yield relies on the optimisation of the ion-source, which should be fast and highly efficient in view of the limited production cross section, and on obtaining a minimum diffusion time out of the target matrix or fragment catcher to reduce decay losses. Eventually, either chemical or isobaric selectivity is needed to confine unwanted elements near to the production site. These considerations are discussed for pulsed or dc-driven RIB facilities and the solutions to some of the technical challenges will be illustrated by examples of currently produced near-drip-line elements.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2021-11-13 00:00:00.000000"},
{"id":"279","title":"Choice growth need or wife behind fill.","abstract":"Video object segmentation is a challenging problem due to the presence of deformable, connected, and articulated objects, intra- and inter-object occlusions, object motion, and poor lighting. Some of these challenges call for object models that can locate a desired object and separate it from its surrounding background, even when both share similar colors and textures. In this work, we extend a fuzzy object model, named cloud system model (CSM), to handle video segmentation, and evaluate it for body pose estimation of toddlers at risk of autism. CSM has been successfully used to model the parts of the brain (cerebrum, left and right brain hemispheres, and cerebellum) in order to automatically locate and separate them from each other, the connected brain stem, and the background in 3D MR-images. In our case, the objects are articulated parts (2D projections) of the human body, which can deform, cause self-occlusions, and move along the video. The proposed CSM extension handles articulation by connecting the individual clouds, body parts, of the system using a 2D stickman model. The stickman representation naturally allows us to extract 2D body pose measures of arm asymmetry patterns during unsupported gait of toddlers, a possible behavioral marker of autism. The results show that our method can provide insightful knowledge to assist the specialist's observations during real in-clinic assessments.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2022-04-05 00:00:00.000000"},
{"id":"280","title":"Thus real heavy successful practice recognize.","abstract":"The context-awareness of things that belong to IoT networks have to be considered in a distributed computation paradigm. In the paper we suggest the use of graph transformations and temporal logic as a formal framework for a knowledge representation of user\/inhabitant behaviors in multi-agent systems. IoT networks are considered as graph structures. Dynamic preference models, understood as a priority in the selecting, is also introduced. Preference models as a result of observed behaviors base on formal logic, and they are built on-the-fly by software agents. Software agents gather knowledge about user preferences expressed in terms of logical specifications as well as suggest on-the-fly future behavior basing on the logical inference process using the semantic tableaux method. The predictive processes are result of some new and important events in the context of IoT systems that should meet a response. Due to the ubiquitous availability of cyber systems that interact with physical environments, there is a great need to develop technologies that target the whole IoT system as a context-awareness system. Formal approach increases the trustworthy of a system. A simple yet illustrative example is provided.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2015-04-29 00:00:00.000000"},
{"id":"281","title":"Read live voice travel black color various.","abstract":"A short review of the motivations for supersymmetry in astrophysics and particle physics is given. Despite the amount of theoretical research conducted in the past decades, no observational evidence for supersymmetry has yet been found. While a large part of the community is expecting supersymmetry to be discovered in the Large Hadron Collider (LHC), some of the basic arguments in favor are disputed here. Since it is not excluded that the author's view may be biased by his research, he proposes a bet on the discovery of supersymmetric particles: According to the philosopher Immanuel Kant, the bet marks the difference between persuasion and conviction.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2022-05-10 00:00:00.000000"},
{"id":"282","title":"Site personal understand great happy kitchen.","abstract":"In this paper, we consider Turing machines based on unsharp quantum logic. For a lattice-ordered quantum multiple-valued (MV) algebra E, we introduce E-valued non-deterministic Turing machines (ENTMs) and E-valued deterministic Turing machines (EDTMs). We discuss different E-valued recursively enumerable languages from width-first and depth-first recognition. We find that width-first recognition is equal to or less than depth-first recognition in general. The equivalence requires an underlying E value lattice to degenerate into an MV algebra. We also study variants of ENTMs. ENTMs with a classical initial state and ENTMs with a classical final state have the same power as ENTMs with quantum initial and final states. In particular, the latter can be simulated by ENTMs with classical transitions under a certain condition. Using these findings, we prove that ENTMs are not equivalent to EDTMs and that ENTMs are more powerful than EDTMs. This is a notable difference from the classical Turing machines.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2018-02-17 00:00:00.000000"},
{"id":"283","title":"Child forget fly look.","abstract":"Various fields of science and engineering rely on linear algebra for large scale data analysis, modeling and simulation, machine learning, and other applied problems. Linear algebra computations often dominate the execution time of such applications. Meanwhile, experts in these domains typically lack the training or time required to develop efficient, high-performance implementations of linear algebra algorithms. In the Lighthouse project, we enable developers with varied backgrounds to readily discover and effectively apply the best available numerical software for their problems. We have developed a search-based expert system that combines expert knowledge, machine learningbased classification of existing numerical software collections, and automated code generation and optimization. Lighthouse provides a novel software engineering environment aimed at maximizing both developer productivity and application performance for dense and sparse linear algebra computations.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2019-06-19 00:00:00.000000"},
{"id":"284","title":"Result on song work.","abstract":"Let \\A be a complex hyperplane arrangement, and let $X$ be a modular element of arbitrary rank in the intersection lattice of \\A. We show that projection along $X$ restricts to a fiber bundle projection of the complement of \\A to the complement of the localization $\\A_X$ of \\A at $X$. The fiber is the decone of a realization of the complete principal truncation of the underlying matroid of \\A along the flat corresponding to $X$. This result gives a topological realization of results of Stanley, Brylawsky, and Terao on modular factorization. We show that (generalized) parallel connection of matroids corresponds to pullback of fiber bundles, clarifying the notion that all examples of diffeomorphisms of complements of inequivalent arrangements result from the triviality of the restriction of the Hopf bundle to the complement of a hyperplane. The modular fibration result also yields a new method for identifying $K(\\pi,1)$ arrangements of rank greater than three. We identify a new families of $K(\\pi,1)$ arrangements, providing more evidence for the conjecture that factored arrangements of arbitrary rank are $K(\\pi,1)$.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2019-03-13 00:00:00.000000"},
{"id":"285","title":"Five bank bring sister wear character why.","abstract":"Personalized recommendation attracts a surge of interdisciplinary researches. Especially, similarity based methods in applications of real recommendation systems achieve great success. However, the computations of similarities are overestimated or underestimated outstandingly due to the defective strategy of unidirectional similarity estimation. In this paper, we solve this drawback by leveraging mutual correction of forward and backward similarity estimations, and propose a new personalized recommendation index, i.e., corrected similarity based inference (CSI). Through extensive experiments on four benchmark datasets, the results show a greater improvement of CSI in comparison with these mainstream baselines. And the detailed analysis is presented to unveil and understand the origin of such difference between CSI and mainstream indices.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2018-04-14 00:00:00.000000"},
{"id":"286","title":"Close sing these character draw best.","abstract":"We compute the Stanley depth for the quotient ring of a square free Veronese ideal and we give some bounds for the Stanley depth of a square free Veronese ideal. In particular, it follows that both satisfy the Stanley's conjecture.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2019-03-29 00:00:00.000000"},
{"id":"287","title":"Act every list more customer.","abstract":"A new approach for reducing error of the volume penalization method is proposed. The mask function is modified by shifting the interface between solid and fluid by ({\\nu}{\\eta})^0.5 toward the fluid region, where {\\nu} and {\\eta} are the viscosity and the permeability, respectively. The shift length ({\\nu}{\\eta})^0.5 is derived from the analytical solution of the one-dimensional diffusion equation with a penalization term. The effect of the error reduction is verified numerically for the one-dimensional diffusion equation, Burgers' equation, and the two-dimensional Navier-Stokes equations. The results show that the numerical error is reduced except in the vicinity of the interface showing overall second-order accuracy, while it converges to a non-zero constant value as the number of grid points increases for the original mask function. However, the new approach is effective when the grid resolution is sufficiently high so that the boundary layer, whose width is proportional to ({\\nu}{\\eta})^0.5, is resolved. Hence, the approach should be used when an appropriate combination of {\\nu} and {\\eta} is chosen with a given numerical grid.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2019-07-28 00:00:00.000000"},
{"id":"288","title":"Than ready fight such appear give throughout.","abstract":"We use a result of Hellus about generalized local duality to describe some generalized Matlis duals for certain quasi-\\F-modules. Furthermore, we apply this description to obtain examples for non-artinian local cohomology modules by the theory of \\F-modules. In particular, we get a new view on Hartshorne's counterexample for a conjecture by Grothendieck about the finiteness of $Hom_R(R\/I,H^i_I(R))$ for a noetherian local Ring $R$ and an ideal $I \\subseteq R$.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2020-07-16 00:00:00.000000"},
{"id":"289","title":"Type fish government control reach far nice.","abstract":"In this article, we study the following question raised by Mel Hochster: let $(R,m,K)$ be a local ring and $S$ be a flat extension with regular closed fiber. Is $\\cV(mS)\\cap\\Ass_S H^i_I(S)$ finite for every ideal $I\\subset S$ and $i\\in \\NN?$ We prove that the answer is positive when $S$ is either a polynomial or a power series ring over $R$ and $\\dim(R\/I\\cap R)\\leq 1.$ In addition, we analyze when this question can be reduced to the case where $S$ is a power series ring over $R$. An important tool for our proof is the use of $\\Sigma$-finite $D$-modules, which are not necessarily finitely generated as $D$-modules, but whose associated primes are finite. We give examples of this class of $D$-modules and applications to local cohomology.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2018-11-22 00:00:00.000000"},
{"id":"290","title":"Simply teacher ever consider.","abstract":"Cumulation of shock snd detonation waves was considered. Computations were carried out by use of second-order central-difference scheme. Cumulation of waves in cone region with scales of 1 meter was studied. Pictures of flow in shock and detonation waves during different time moments were obtained as well as time dependences and maximum pressures for different corner angles.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2022-09-25 00:00:00.000000"},
{"id":"291","title":"Simply only how reach there state feeling.","abstract":"This letter discusses the problem of testing the degree of randomness within an image, particularly for a shuffled or encrypted image. Its key contributions are: 1) a mathematical model of perfectly shuffled images; 2) the derivation of the theoretical distribution of pixel differences; 3) a new $Z$-test based approach to differentiate whether or not a test image is perfectly shuffled; and 4) a randomized algorithm to unbiasedly evaluate the degree of randomness within a given image. Simulation results show that the proposed method is robust and effective in evaluating the degree of randomness within an image, and may often be more suitable for image applications than commonly used testing schemes designed for binary data like NIST 800-22. The developed method may be also useful as a first step in determining whether or not a shuffling or encryption scheme is suitable for a particular cryptographic application.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2018-04-13 00:00:00.000000"},
{"id":"292","title":"Once with provide fish or on.","abstract":"An out-tree $T$ of a directed graph $D$ is a rooted tree subgraph with all arcs directed outwards from the root. An out-branching is a spanning out-tree. By $l(D)$ and $l_s(D)$ we denote the maximum number of leaves over all out-trees and out-branchings of $D$, respectively.   We give fixed parameter tractable algorithms for deciding whether $l_s(D)\\geq k$ and whether $l(D)\\geq k$ for a digraph $D$ on $n$ vertices, both with time complexity $2^{O(k\\log k)} \\cdot n^{O(1)}$. This improves on previous algorithms with complexity $2^{O(k^3\\log k)} \\cdot n^{O(1)}$ and $2^{O(k\\log^2 k)} \\cdot n^{O(1)}$, respectively.   To obtain the complexity bound in the case of out-branchings, we prove that when all arcs of $D$ are part of at least one out-branching, $l_s(D)\\geq l(D)\/3$. The second bound we prove in this paper states that for strongly connected digraphs $D$ with minimum in-degree 3, $l_s(D)\\geq \\Theta(\\sqrt{n})$, where previously $l_s(D)\\geq \\Theta(\\sqrt[3]{n})$ was the best known bound. This bound is tight, and also holds for the larger class of digraphs with minimum in-degree 3 in which every arc is part of at least one out-branching.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2021-01-26 00:00:00.000000"},
{"id":"293","title":"Ten bring PM value.","abstract":"This paper deals with the new spectral and microturbulence experimental data and their analysis, which show, that the radial electric field Er generated at the LH heating (LHH) in the FT-2 is high enough to form the transport barriers. The ETB is formed when LHH is switched off. The radial fluctuation-induced E&#61620;B drift flux densities near LCFS in SOL are measured at two different poloidal angles. For this purpose two Langmuir probes located at low and high field sides of the torus are used. Registration of the poloidal and radial components of the electric field and density fluctuations at the same time during one discharge permits to measure the poloidal asymmetry of the transport reduction mechanism of the radial and poloidal particle fluxes in the SOL. The absolute E(~)&#61553; fluctuation levels show dependence on the sign of Er shear. The modification of the microscale turbulence by the poloidal Er x B rotation shear &#61559;E&#61620;B at the L - H transition near LCFS is also studied by X-mode fluctuation Reflectometry. The new data were obtained by spatial spectroscopic technique.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2022-06-12 00:00:00.000000"},
{"id":"294","title":"Consumer focus way task.","abstract":"We present formalized proofs verifying that the first-order unification algorithm defined over lists of satisfiable constraints generates a most general unifier (MGU), which also happens to be idempotent. All of our proofs have been formalized in the Coq theorem prover. Our proofs show that finite maps produced by the unification algorithm provide a model of the axioms characterizing idempotent MGUs of lists of constraints. The axioms that serve as the basis for our verification are derived from a standard set by extending them to lists of constraints. For us, constraints are equalities between terms in the language of simple types. Substitutions are formally modeled as finite maps using the Coq library Coq.FSets.FMapInterface. Coq's method of functional induction is the main proof technique used in proving many of the axioms.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2017-06-14 00:00:00.000000"},
{"id":"295","title":"Pay human result less.","abstract":"Assume A is a Frechet algebra equipped with a smooth isometric action of a vector group V, and consider Rieffel's deformation A_J of A. We construct an explicit isomorphism between the smooth crossed products V\\ltimes\\A_J and V\\ltimes\\A. When combined with the Elliott-Natsume-Nest isomorphism, this immediately implies that the periodic cyclic cohomology is invariant under deformation. Specializing to the case of smooth subalgebras of C*-algebras, we also get a simple proof of equivalence of Rieffel's and Kasprzak's approaches to deformation.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2022-06-10 00:00:00.000000"},
{"id":"296","title":"Performance artist even today eight fight.","abstract":"Techniques for plan recognition under uncertainty require a stochastic model of the plan-generation process. We introduce Probabilistic State-Dependent Grammars (PSDGs) to represent an agent's plan-generation process. The PSDG language model extends probabilistic context-free grammars (PCFGs) by allowing production probabilities to depend on an explicit model of the planning agent's internal and external state. Given a PSDG description of the plan-generation process, we can then use inference algorithms that exploit the particular independence properties of the PSDG language to efficiently answer plan-recognition queries. The combination of the PSDG language model and inference algorithms extends the range of plan-recognition domains for which practical probabilistic inference is possible, as illustrated by applications in traffic monitoring and air combat.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2019-08-04 00:00:00.000000"},
{"id":"297","title":"International gun now thank add her eight.","abstract":"The Fredholm representation theory is well adapted to construction of homotopy invariants of non simply connected manifolds on the base of generalized Hirzebruch formula. Earlier a natural family of the Fredholm representations was constructed that lead to a symmetric vector bundle on completion of the fundamental group with a modification of the Higson-Roe corona when the completion is a closed manifold. Here we will discuss a homology version of symmetry in the case when completion with a modification of the Higson-Roe corona is a manifold with boundary. The results were developed during the visit of the first author in Ancona on March, 2007. The second version is supplemented by details of consideration the case of manifolds with boundary.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2018-01-18 00:00:00.000000"},
{"id":"298","title":"Left become represent garden garden expect concern.","abstract":"We show how the effects of azimuthal optical aberrations on singular light beams can result in an intensity modulation in the beam waist or focal point spread function (PSF) that is directly proportional to the amplitude of the applied phase aberration. The resulting distortions are enough to significantly degrade the utility of the singular beams even in well corrected optical systems. However we show that pattern of these intensity modulations is related to the azimuthal order of the applied aberration and we suggest how this can be used to measure those aberrations. We demonstrate a closed loop system using a liquid crystal spatial light modulator as a programmable diffractive optical element to both generate the beam and correct for the sensed aberrations based on feedback from a CCD detected intensity image of the focal point spread function.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2020-12-05 00:00:00.000000"},
{"id":"299","title":"Black according any a camera.","abstract":"The close-in AM noise is often neglected, under the assumption that it is a minor problem as compared to phase noise. With the progress of technology and of experimental science, this assumption is no longer true. Yet, information in the literature is scarce or absent. This report describes the measurement of the AM noise of rf\/microwave sources in terms of Salpha(f), i.e., the power spectrum density of the fractional amplitude fluctuation alpha. The proposed schemes make use of commercial power detectors based on Schottky and tunnel diodes, in single-channel and correlation configuration. There follow the analysis of the front-end amplifier at the detector output, the analysis of the methods for the measurement of the power-detector noise, and a digression about the calibration procedures. The measurement methods are extended to the relative intensity noise (RIN) of optical beams, and to the AM noise of the rf\/microwave modulation in photonic systems. Some rf\/microwave synthesizers and oscillators have been measured, using correlation and moderate averaging. As an example, the flicker noise of a low-noise quartz oscillator (Wenzel 501-04623E) is Salpha = 1.15E-13\/f, which is equivalent to an Allan deviation of sigma_alpha = 4E-7. The measurement systems described exhibit the world-record lowest background noise.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2021-03-08 00:00:00.000000"},
{"id":"300","title":"Nature parent statement difficult push ask.","abstract":"We consider the stochastic and adversarial settings of continuum armed bandits where the arms are indexed by [0,1]^d. The reward functions r:[0,1]^d -> R are assumed to intrinsically depend on at most k coordinate variables implying r(x_1,..,x_d) = g(x_{i_1},..,x_{i_k}) for distinct and unknown i_1,..,i_k from {1,..,d} and some locally Holder continuous g:[0,1]^k -> R with exponent 0 < alpha <= 1. Firstly, assuming (i_1,..,i_k) to be fixed across time, we propose a simple modification of the CAB1 algorithm where we construct the discrete set of sampling points to obtain a bound of O(n^((alpha+k)\/(2*alpha+k)) (log n)^((alpha)\/(2*alpha+k)) C(k,d)) on the regret, with C(k,d) depending at most polynomially in k and sub-logarithmically in d. The construction is based on creating partitions of {1,..,d} into k disjoint subsets and is probabilistic, hence our result holds with high probability. Secondly we extend our results to also handle the more general case where (i_1,...,i_k) can change over time and derive regret bounds for the same.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2015-01-12 00:00:00.000000"},
{"id":"301","title":"Move police few near.","abstract":"The game of SET is a popular card game in which the objective is to form Sets using cards from a special deck. In this paper we study single- and multi-round variations of this game from the computational complexity point of view and establish interesting connections with other classical computational problems. Specifically, we first show that a natural generalization of the problem of finding a single Set, parameterized by the size of the sought Set is W-hard; our reduction applies also to a natural parameterization of Perfect Multi-Dimensional Matching, a result which may be of independent interest. Second, we observe that a version of the game where one seeks to find the largest possible number of disjoint Sets from a given set of cards is a special case of 3-Set Packing; we establish that this restriction remains NP-complete. Similarly, the version where one seeks to find the smallest number of disjoint Sets that overlap all possible Sets is shown to be NP-complete, through a close connection to the Independent Edge Dominating Set problem. Finally, we study a 2-player version of the game, for which we show a close connection to Arc Kayles, as well as fixed-parameter tractability when parameterized by the number of rounds played.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2020-07-06 00:00:00.000000"},
{"id":"302","title":"Step around explain various.","abstract":"Multi-label classification has attracted an increasing amount of attention in recent years. To this end, many algorithms have been developed to classify multi-label data in an effective manner. However, they usually do not consider the pairwise relations indicated by sample labels, which actually play important roles in multi-label classification. Inspired by this, we naturally extend the traditional pairwise constraints to the multi-label scenario via a flexible thresholding scheme. Moreover, to improve the generalization ability of the classifier, we adopt a boosting-like strategy to construct a multi-label ensemble from a group of base classifiers. To achieve these goals, this paper presents a novel multi-label classification framework named Variable Pairwise Constraint projection for Multi-label Ensemble (VPCME). Specifically, we take advantage of the variable pairwise constraint projection to learn a lower-dimensional data representation, which preserves the correlations between samples and labels. Thereafter, the base classifiers are trained in the new data space. For the boosting-like strategy, we employ both the variable pairwise constraints and the bootstrap steps to diversify the base classifiers. Empirical studies have shown the superiority of the proposed method in comparison with other approaches.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2018-02-12 00:00:00.000000"},
{"id":"303","title":"As animal Democrat throughout six difference.","abstract":"Through its connection with HED meteorites, Vesta is known as one of the first bodies to have accreted and differentiated in the Solar Nebula, predating the formation of Jupiter and surviving the violent evolution of the early Solar System. The formation time of Ceres instead is unknown, but it should not postdate that of Jupiter by far. In this work we modelled the collisional histories of Vesta and Ceres at the time of the formation of Jupiter, assumed to be the first giant planet to form. In this first investigation of the evolution of the early Solar System, we did not include the presence of planetary embryos in the disk of planetesimals but we concentrated on the role of the forming Jupiter and the effects of its possible inward migration due to disk-planet interactions. Our results clearly indicate that the formation of the giant planet caused an intense early bombardment in the orbital region of the Main Asteroid Belt. According to our results, Vesta and Ceres would not have survived the Jovian early bombardment if the disk was populated mainly by large planetesimals like those predicted to form in turbulent circumstellar disks. Disks dominated by small bodies, like those predicted to form in quiescent circumstellar disks, or with a varying fraction of the mass in the form of larger (D \\geq 100 km) planetesimals represent more favourable environments for the survival of the two asteroids. In those scenarios where they survive, both asteroids had their surfaces saturated by craters as big as 150 km and a few as big as 200 - 300 km. In the case of Vesta, the Jovian early bombardment would have significantly eroded (locally or globally) the crust and possibly caused effusive phenomena similar to the lunar maria, whose crystallisation time would then be directly linked to the time of the formation of Jupiter.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2022-03-13 00:00:00.000000"},
{"id":"304","title":"Maybe out discover produce environment.","abstract":"The paper gives approximation algorithms for the k-medians and facility-location problems (both NP-hard). For k-medians, the algorithm returns a solution using at most ln(n+n\/epsilon)k medians and having cost at most (1+epsilon) times the cost of the best solution that uses at most k medians. Here epsilon > 0 is an input to the algorithm. In comparison, the best previous algorithm (Jyh-Han Lin and Jeff Vitter, 1992) had a (1+1\/epsilon)ln(n) term instead of the ln(n+n\/epsilon) term in the performance guarantee. For facility location, the algorithm returns a solution of cost at most d+ln(n) k, provided there exists a solution of cost d+k where d is the assignment cost and k is the facility cost. In comparison, the best previous algorithm (Dorit Hochbaum, 1982) returned a solution of cost at most ln(n)(d+k). For both problems, the algorithms currently provide the best performance guarantee known for the general (non-metric) problems.   The paper also introduces a new probabilistic bound (called \"Chernoff-Wald bound\") for bounding the expectation of the maximum of a collection of sums of random variables, when each sum contains a random number of terms. The bound is used to analyze the randomized rounding scheme that underlies the algorithms.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2022-11-11 00:00:00.000000"},
{"id":"305","title":"Keep half sit politics parent.","abstract":"We describe the spaces $H^1(R)$ and BMO$(R)$ in terms of their closely related, simpler dyadic and two-sided counterparts. As a result of these characterizations we establish when a bounded linear operator defined on dyadic or two-sided $H^1(R)$ into a Banach space has a continuous extension to $H^1(R)$ and when a bounded linear operator that maps a Banach space into dyadic or two-sided BMO$(R)$ actually maps continuously into BMO$(R)$.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2015-11-20 00:00:00.000000"},
{"id":"306","title":"She from edge use reason second.","abstract":"Kohn-Sham density functional theory is one of the most widely used electronic structure theories. In the pseudopotential framework, uniform discretization of the Kohn-Sham Hamiltonian generally results in a large number of basis functions per atom in order to resolve the rapid oscillations of the Kohn-Sham orbitals around the nuclei. Previous attempts to reduce the number of basis functions per atom include the usage of atomic orbitals and similar objects, but the atomic orbitals generally require fine tuning in order to reach high accuracy. We present a novel discretization scheme that adaptively and systematically builds the rapid oscillations of the Kohn-Sham orbitals around the nuclei as well as environmental effects into the basis functions. The resulting basis functions are localized in the real space, and are discontinuous in the global domain. The continuous Kohn-Sham orbitals and the electron density are evaluated from the discontinuous basis functions using the discontinuous Galerkin (DG) framework. Our method is implemented in parallel and the current implementation is able to handle systems with at least thousands of atoms. Numerical examples indicate that our method can reach very high accuracy (less than 1meV) with a very small number ($4\\sim 40$) of basis functions per atom.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2020-02-09 00:00:00.000000"},
{"id":"307","title":"Book campaign see.","abstract":"Solomonoff completed the Bayesian framework by providing a rigorous, unique, formal, and universal choice for the model class and the prior. We discuss in breadth how and in which sense universal (non-i.i.d.) sequence prediction solves various (philosophical) problems of traditional Bayesian sequence prediction. We show that Solomonoff's model possesses many desirable properties: Fast convergence and strong bounds, and in contrast to most classical continuous prior densities has no zero p(oste)rior problem, i.e. can confirm universal hypotheses, is reparametrization and regrouping invariant, and avoids the old-evidence and updating problem. It even performs well (actually better) in non-computable environments.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2015-06-05 00:00:00.000000"},
{"id":"308","title":"Race focus gun thousand.","abstract":"Many AI researchers argue that probability theory is only capable of dealing with uncertainty in situations where a full specification of a joint probability distribution is available, and conclude that it is not suitable for application in knowledge-based systems. Probability intervals, however, constitute a means for expressing incompleteness of information. We present a method for computing such probability intervals for probabilities of interest from a partial specification of a joint probability distribution. Our method improves on earlier approaches by allowing for independency relationships between statistical variables to be exploited.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2018-11-09 00:00:00.000000"},
{"id":"309","title":"Group civil national argue happen simply.","abstract":"Tectonic earthquakes of high magnitude can cause considerable losses in terms of human lives, economic and infrastructure, among others. According to an evaluation published by the U.S. Geological Survey, 30 is the number of earthquakes which have greatly impacted Mexico from the end of the XIX century to this one. Based upon data from the National Seismological Service, on the period between January 1, 2006 and May 1, 2013 there have occurred 5,826 earthquakes which magnitude has been greater than 4.0 degrees on the Richter magnitude scale (25.54% of the total of earthquakes registered on the national territory), being the Pacific Plate and the Cocos Plate the most important ones. This document describes the development of an Artificial Neural Network (ANN) based on the radial topology which seeks to generate a prediction with an error margin lower than 20% which can inform about the probability of a future earthquake one of the main questions is: can artificial neural networks be applied in seismic forecasting? It can be argued that research has the potential to bring in the forecast seismic, more research is needed to consolidate data and help mitigate the impact caused by such events linked with society. Keywords--- Analysis, Mexico, Neural Artificial Networks, Seismicity.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2017-10-20 00:00:00.000000"},
{"id":"310","title":"Just rate during support.","abstract":"The large number of spectral variables in most data sets encountered in spectral chemometrics often renders the prediction of a dependent variable uneasy. The number of variables hopefully can be reduced, by using either projection techniques or selection methods; the latter allow for the interpretation of the selected variables. Since the optimal approach of testing all possible subsets of variables with the prediction model is intractable, an incremental selection approach using a nonparametric statistics is a good option, as it avoids the computationally intensive use of the model itself. It has two drawbacks however: the number of groups of variables to test is still huge, and colinearities can make the results unstable. To overcome these limitations, this paper presents a method to select groups of spectral variables. It consists in a forward-backward procedure applied to the coefficients of a B-Spline representation of the spectra. The criterion used in the forward-backward procedure is the mutual information, allowing to find nonlinear dependencies between variables, on the contrary of the generally used correlation. The spline representation is used to get interpretability of the results, as groups of consecutive spectral variables will be selected. The experiments conducted on NIR spectra from fescue grass and diesel fuels show that the method provides clearly identified groups of selected variables, making interpretation easy, while keeping a low computational load. The prediction performances obtained using the selected coefficients are higher than those obtained by the same method applied directly to the original variables and similar to those obtained using traditional models, although using significantly less spectral variables.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2017-03-06 00:00:00.000000"},
{"id":"311","title":"Machine interest get water.","abstract":"Named Entities (NEs) are often written with no orthographic changes across different languages that share a common alphabet. We show that this can be leveraged so as to improve named entity recognition (NER) by using unsupervised word clusters from secondary languages as features in state-of-the-art discriminative NER systems. We observe significant increases in performance, finding that person and location identification is particularly improved, and that phylogenetically close languages provide more valuable features than more distant languages.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2022-07-05 00:00:00.000000"},
{"id":"312","title":"Senior nice measure sister box too large author.","abstract":"This paper discusses the requirements of current and emerging applications based on the Open Archives Initiative (OAI) and emphasizes the need for a common infrastructure to support them. Inspired by HTTP proxy, cache, gateway and web service concepts, a design for a scalable and reliable infrastructure that aims at satisfying these requirements is presented. Moreover it is shown how various applications can exploit the services included in the proposed infrastructure. The paper concludes by discussing the current status of several prototype implementations.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2020-09-19 00:00:00.000000"},
{"id":"313","title":"Peace successful after program understand fear marriage maintain.","abstract":"Through in-class observations of teaching assistants (TAs) and students in the lab sections of a large introductory physics course, we study which TA behaviors can be used to predict student engagement and, in turn, how this engagement relates to learning. For the TAs, we record data to determine how they adhere to and deliver the lesson plan and how they interact with students during the lab. For the students, we use observations to record the level of student engagement and pre- and post-tests of lab skills to measure learning. We find that the frequency of TA-student interactions, especially those initiated by the TAs, is a positive and significant predictor of student engagement. Interestingly, the length of interactions is not significantly correlated with student engagement. In addition, we find that student engagement was a better predictor of post-test performance than pre-test scores. These results shed light on the manner in which students learn how to conduct inquiry and suggest that, by proactively engaging students, TAs may have a positive effect on student engagement, and therefore learning, in the lab.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2022-04-16 00:00:00.000000"},
{"id":"314","title":"Ever so writer difficult choice body right.","abstract":"One approach to future high energy particle accelerators is based on the wakefield principle: a leading high-charge drive bunch is used to excite fields in an accelerating structure or plasma that in turn accelerates a trailing low-charge witness bunch. The transformer ratio R is defined as the ratio of the maximum energy gain of the witness bunch to the maximum energy loss of the drive bunch. In general, for configurations in which the two beams traverse the accelerator along the same trajectory (collinear wakefield acceleration). A number of techniques have been proposed to overcome the transformer ratio limitation. We report here the first experimental study of the ramped bunch train (RBT) technique in which a dielectric loaded waveguide was used as the accelerating structure. A single drive bunch was replaced by two bunches with charge ratio of 1:2.5 and a separation of 10.5 wavelengths of the fundamental mode. An average measured transformer ratio enhancement by a factor of 1.31 over the single drive bunch case was obtained in this experiment.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2015-09-25 00:00:00.000000"},
{"id":"315","title":"Sort those two pattern.","abstract":"DLV is an efficient logic programming and non-monotonic reasoning (LPNMR) system with advanced knowledge representation mechanisms and interfaces to classic relational database systems.   Its core language is disjunctive datalog (function-free disjunctive logic programming) under the Answer Set Semantics with integrity constraints, both default and strong (or explicit) negation, and queries. Integer arithmetics and various built-in predicates are also supported.   In addition DLV has several frontends, namely brave and cautious reasoning, abductive diagnosis, consistency-based diagnosis, a subset of SQL3, planning with action languages, and logic programming with inheritance.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2015-01-12 00:00:00.000000"},
{"id":"316","title":"Half sing after audience catch record.","abstract":"We use geometric methods to obtain a sharp exponential integrability result for boundary traces of monotone Sobolev functions defined on the unit ball.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2019-11-20 00:00:00.000000"},
{"id":"317","title":"Model month similar build.","abstract":"Initial population plays an important role in heuristic algorithms such as GA as it help to decrease the time those algorithms need to achieve an acceptable result. Furthermore, it may influence the quality of the final answer given by evolutionary algorithms. In this paper, we shall introduce a heuristic method to generate a target based initial population which possess two mentioned characteristics. The efficiency of the proposed method has been shown by presenting the results of our tests on the benchmarks.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2021-08-01 00:00:00.000000"},
{"id":"318","title":"This standard son story discover much.","abstract":"Starting from a formulation for the $dS$ element that includes movement, and considering the variation of the entropy Lorentz invariant, we found the relativistic transformations for thermodynamic systems that satisfy the three laws of thermodynamics. Particularly, we found the temperature and pressure transformations, given by $T'=\\gamma T$ and $p'=\\gamma^2p$ respectively. Furthermore, we show that this transformations keeps the form of the state equation for an ideal gas in agreement with the relativity principle.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2020-11-05 00:00:00.000000"},
{"id":"319","title":"Spring art next nor sell raise.","abstract":"We show that BPP has either SUBEXP-dimension zero (randomness is easy) or BPP=EXP (randomness is intractable).","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2015-04-27 00:00:00.000000"},
{"id":"320","title":"Within important though.","abstract":"This paper describes limiting behaviour of tail empirical process associated with long memory stochastic volatility models. We show that such process has dichotomous behaviour, according to an interplay between a Hurst parameter and a tail index. In particular, the limit may be non-Gaussian and\/or degenerate, indicating an influence of long memory. On the other hand, tail empirical process with random levels never suffers from long memory. This is very desirable from a practical point of view, since such the process may be used to construct Hill estimator of the tail index. To prove our results we need to establish several new results for regularly varying distribution functions, which may be of independent interest.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2016-06-02 00:00:00.000000"},
{"id":"321","title":"Hospital and economic own hair.","abstract":"Linear programming bounds provide an elegant method to prove optimality and uniqueness of an (n,N,t) spherical code. However, this method does not apply to the parameters (4,10,1\/6). We use semidefinite programming bounds instead to show that the Petersen code, which consists of the midpoints of the edges of the regular simplex in dimension 4, is the unique (4,10,1\/6) spherical code.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2016-08-25 00:00:00.000000"},
{"id":"322","title":"Recognize friend decision type relate food rule.","abstract":"In order to better understand the interaction between pore-fluid overpressure and failure patterns in rocks we consider a porous elasto-plastic medium in which a laterally localized overpressure line source is imposed at depth below the free surface. We solve numerically the fluid filtration equation coupled to the gravitational force balance and poro-elasto-plastic rheology equations. Systematic numerical simulations, varying initial stress, intrinsic material properties and geometry, show the existence of five distinct failure patterns caused by either shear banding or tensile fracturing. The value of the critical pore-fluid overpressure at the onset of failure is derived from an analytical solution that is in excellent agreement with numerical simulations. Finally, we construct a phase-diagram that predicts the domains of the different failure patterns and at the onset of failure.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2017-12-17 00:00:00.000000"},
{"id":"323","title":"Skin history technology shoulder partner.","abstract":"The recently established RPCA method provides us a convenient way to restore low-rank matrices from grossly corrupted observations. While elegant in theory and powerful in reality, RPCA may be not an ultimate solution to the low-rank matrix recovery problem. Indeed, its performance may not be perfect even when data are strictly low-rank. This is because conventional RPCA ignores the clustering structures of the data which are ubiquitous in modern applications. As the number of cluster grows, the coherence of data keeps increasing, and accordingly, the recovery performance of RPCA degrades. We show that the challenges raised by coherent data (i.e., the data with high coherence) could be alleviated by Low-Rank Representation (LRR), provided that the dictionary in LRR is configured appropriately. More precisely, we mathematically prove that if the dictionary itself is low-rank then LRR is immune to the coherence parameter which increases with the underlying cluster number. This provides an elementary principle for dealing with coherent data. Subsequently, we devise a practical algorithm to obtain proper dictionaries in unsupervised environments. Our extensive experiments on randomly generated matrices verify our claims.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2020-03-08 00:00:00.000000"},
{"id":"324","title":"Community although federal benefit people success.","abstract":"Let $\\Gamma$ be the fundamental group of a manifold modeled on three dimensional Sol geometry. We prove that $\\Gamma$ has a finite index subgroup $G$ which has a rational growth series with respect to a natural generating set. We do this by enumerating $G$ by a regular language. However, in contrast to most earlier proofs of this sort our regular language is not a language of words in the generating set, but rather reflects a different geometric structure in $G$.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2017-04-28 00:00:00.000000"},
{"id":"325","title":"Article while story rock how view team.","abstract":"It is well known that Sokoban is PSPACE-complete (Culberson 1998) and several of its variants are NP-hard (Demaine et al. 2003). In this paper we prove the NP-hardness of some variants of Sokoban where the warehouse keeper can only pull boxes.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2021-12-02 00:00:00.000000"},
{"id":"326","title":"Sense under structure property almost phone happy.","abstract":"Wind is slated to become one of the most sought after source of energy in future. Both onshore as well as offshore wind farms are getting deployed rapidly over the world. This paper evaluates a neural network based time series approach to predict wind speed in real time over shorter duration of up to 12 hr based on analysis of three hourly wind data collected through a wave rider buoy deployed off Goa in deep water and far away from the shore. The data were collected for 4 years from February 1998 to February 2002. A simple feed forward type of network trained using a variety of algorithms was used. The input nodes selected by trial were three in number and belonged to the segment of preceding observations while the output node was single and it consisted of the predicted value of the wind speed over the subsequent 3, 6 and 12 hours one at a time. The number of hidden nodes was based on trials. The total sample was divided into a training set (first 70 percent) and a testing set (remaining 30 percent). The outcome of the network was compared with the actual observations with the help of scatter diagrams and time history plots as well as through the error statistics of the correlation coefficient, R, and mean square error, MSE. The testing of the network showed that it predicted the wind speed in a very satisfactory manner with R = 0.99 and MSE = 0.30 (m\/s)2 for a 3 hour ahead prediction while these values for a 12 hour ahead predictions were 0.96 and 1.19 (m\/s)2, respectively. Such a prediction based on neural network was found to be superior to that based on polynomial fittings as well as ARMA models. ARIMA models were also used but the predicted values showed significant lag.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2015-04-17 00:00:00.000000"},
{"id":"327","title":"Stage whole through.","abstract":"In this paper I investigate several offline and online data transfer scheduling problems and propose efficient algorithms and techniques for addressing them. In the offline case, I present a novel, heuristic, algorithm for scheduling files with divisible sizes on multiple disjoint paths, in order to maximize the total profit (the problem is equivalent to the multiple knapsack problem with divisible item sizes). I then consider a cost optimization problem for transferring a sequence of identical files, subject to time constraints imposed by the data transfer providers. For the online case I propose an algorithmic framework based on the block partitioning method, which can speed up the process of resource allocation and reservation.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2017-08-26 00:00:00.000000"},
{"id":"328","title":"Scientist success water town success.","abstract":"In a not obligatory series of lessons for high school students in the Netherlands we discuss the fluorescence aspects of anthracene. These lessons were developed because HiSPARC (High school Project on Astrophysics Research with Cosmics) detection of cosmic rays are available for different secondary schools. With the help of special designed scintillator detection stations, containing anthracene, cosmic rays can be detected. Fluorescence of anthracene is one of the topics discussed in these series of extra curricular lessons aimed at excellent pupils working on cosmic radiation within the HiSPARC - project.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2017-12-15 00:00:00.000000"},
{"id":"329","title":"Everyone something executive wait image away.","abstract":"We report the first experimental verification of a metamaterial cloak for a 3D object in free space. We apply the plasmonic cloaking technique, based on scattering cancellation, to suppress microwave scattering from a finite dielectric cylinder. We verify that scattering suppression is obtained all around the object and for different incidence angles, validating our measurements with analytical results and full-wave simulations. Our experiment confirms that realistic and robust plasmonic metamaterial cloaks may be realized for elongated 3D objects at microwave frequencies.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2017-04-25 00:00:00.000000"},
{"id":"330","title":"Him scene truth have program care.","abstract":"The paper addresses counterintuitive behavior of electrons injected into dense cryogenic media with negative scattering length $a_0$. Instead of expected polaronic effect (formation of density enhancement clusters) which should substantially reduce the electron mobility, an opposite picture is observed: with increasing $|a_0|$ (the trend taking place for inert gases with the growth of atomic number) and the medium density, the electrons remain practically free. An explanation of this behaviour is provided based on consistent accounting for the non-linearity of electron interaction with the gaseous medium in the gas atom number density.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2019-10-20 00:00:00.000000"},
{"id":"331","title":"Eat become blue the begin.","abstract":"We show how to construct a channel-independent representation of speech that has propagated through a noisy reverberant channel. This is done by blindly rescaling the cepstral time series by a non-linear function, with the form of this scale function being determined by previously encountered cepstra from that channel. The rescaled form of the time series is an invariant property of it in the following sense: it is unaffected if the time series is transformed by any time-independent invertible distortion. Because a linear channel with stationary noise and impulse response transforms cepstra in this way, the new technique can be used to remove the channel dependence of a cepstral time series. In experiments, the method achieved greater channel-independence than cepstral mean normalization, and it was comparable to the combination of cepstral mean normalization and spectral subtraction, despite the fact that no measurements of channel noise or reverberations were required (unlike spectral subtraction).","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2015-08-01 00:00:00.000000"},
{"id":"332","title":"Goal next young stage discuss public.","abstract":"This paper describes a systems architecture for a hybrid Centralised\/Swarm based multi-agent system. The issue of local goal assignment for agents is investigated through the use of a global agent which teaches the agents responses to given situations. We implement a test problem in the form of a Pursuit game, where the Multi-Agent system is a set of captor agents. The agents learn solutions to certain board positions from the global agent if they are unable to find a solution. The captor agents learn through the use of multi-layer perceptron neural networks. The global agent is able to solve board positions through the use of a Genetic Algorithm. The cooperation between agents and the results of the simulation are discussed here. .","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2016-12-19 00:00:00.000000"},
{"id":"333","title":"He lose quite interest.","abstract":"We review the analytical methods of solving the stochastic equations for barrier-type dynamical behavior in plasma systems. The path-integral approach is examined as a particularly efficient method of determination of the statistical properties.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2021-02-01 00:00:00.000000"},
{"id":"334","title":"Even commercial second talk rise method crime.","abstract":"Simulated landscapes have been used for decades to evaluate search strategies whose goal is to find the landscape location with maximum fitness. Applications include modeling the capacity of enzymes to catalyze reactions and the clinical effectiveness of medical treatments. Understanding properties of landscapes is important for understanding search difficulty. This paper presents a novel and transparent characterization of NK landscapes.   We prove that NK landscapes can be represented by parametric linear interaction models where model coefficients have meaningful interpretations. We derive the statistical properties of the model coefficients, providing insight into how the NK algorithm parses importance to main effects and interactions. An important insight derived from the linear model representation is that the rank of the linear model defined by the NK algorithm is correlated with the number of local optima, a strong determinant of landscape complexity and search difficulty. We show that the maximal rank for an NK landscape is achieved through epistatic interactions that form partially balanced incomplete block designs. Finally, an analytic expression representing the expected number of local optima on the landscape is derived, providing a way to quickly compute the expected number of local optima for very large landscapes.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2022-07-25 00:00:00.000000"},
{"id":"335","title":"Want present series wide front here.","abstract":"We propose two new algorithms to minimize the constant modulus (CM) criterion in the context of blind source separation. The first algorithm, referred to as Givens CMA (G-CMA) uses unitary Givens rotations and proceeds in two stages: prewhitening step, which reduces the channel matrix to a unitary one followed by a separation step where the resulting unitary matrix is computed using Givens rotations by minimizing the CM criterion. However, for small sample sizes, the prewhitening does not make the channel matrix close enough to unitary and hence applying Givens rotations alone does not provide satisfactory performance. To remediate to this problem, we propose to use non-unitary Shear (Hyperbolic) rotations in conjunction with Givens rotations. This second algorithm referred to as Hyperbolic G-CMA (HG-CMA) is shown to outperform the G-CMA as well as the Analytical CMA (ACMA) in terms of separation quality. The last part of this paper is dedicated to an efficient adaptive implementation of the HG-CMA and to performance assessment through numerical experiments.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2022-11-19 00:00:00.000000"},
{"id":"336","title":"Provide cause performance name of western good court.","abstract":"This paper presents an approach for the implementation and execution of an effective requirements generation process. We achieve this goal by providing a well-defined requirements engineering model that includes verification and validation (V&V), and analysis. In addition, we identify focused activity objectives and map popular methods to lower-level activities, and define a criterion based process for optimizing method selection for attendant activities. Our model, unlike other models, addresses the complete requirements generation process and consists of activities defined at more adequate levels of abstraction. Furthermore, our model also incorporates a unique approach to V&V that enhances quality and reduces the cost of generating requirements. Additionally, activity objectives are identified and explicitly stated - not implied as in the current models. To assist in the selection of an appropriate set of methods, we have mapped commonly used methods to activities based on their objectives. Finally, we have identified method selection criteria and prescribed a reduced set of methods that optimize these criteria for each activity in our model. Thus, our approach assists in the task of selecting methods by using selection criteria to reduce a large collection of potential methods to a smaller, manageable set. The model, clear mapping of methods to activity objectives, and the criteria based process, taken together, provide the much needed guidance for the effective implementation and execution of the requirements generation process.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2020-07-03 00:00:00.000000"},
{"id":"337","title":"Money old she.","abstract":"The success of an agent mediated e-market system lies in the underlying reputation management system to improve the quality of services in an information asymmetric e-market. Reputation provides an operatable metric for establishing trustworthiness between mutually unknown online entities. Reputation systems encourage honest behaviour and discourage malicious behaviour of participating agents in the e-market. A dynamic reputation model would provide virtually instantaneous knowledge about the changing e-market environment and would utilise Internets' capacity for continuous interactivity for reputation computation. This paper proposes a dynamic reputation framework using reinforcement learning and fuzzy set theory that ensures judicious use of information sharing for inter-agent cooperation. This framework is sensitive to the changing parameters of e-market like the value of transaction and the varying experience of agents with the purpose of improving inbuilt defense mechanism of the reputation system against various attacks so that e-market reaches an equilibrium state and dishonest agents are weeded out of the market.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2019-07-22 00:00:00.000000"},
{"id":"338","title":"Despite bad street.","abstract":"This paper reviews and extends some recent results on the multivariate fractional Brownian motion (mfBm) and its increment process. A characterization of the mfBm through its covariance function is obtained. Similarly, the correlation and spectral analyses of the increments are investigated. On the other hand we show that (almost) all mfBm's may be reached as the limit of partial sums of (super)linear processes. Finally, an algorithm to perfectly simulate the mfBm is presented and illustrated by some simulations.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2020-05-07 00:00:00.000000"},
{"id":"339","title":"Assume piece foot along kitchen see.","abstract":"We have recently demonstrated static trapping of ammonia isotopologues in a decelerator that consists of a series of ring-shaped electrodes to which oscillating high voltages are applied [Quintero-P\\'{e}rez et al., Phys. Rev. Lett. 110, 133003 (2013)]. In this paper we provide further details on this traveling wave decelerator and present new experimental data that illustrate the control over molecules that it offers. We analyze the performance of our setup under different deceleration conditions and demonstrate phase-space manipulation of the trapped molecular sample.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2015-08-17 00:00:00.000000"},
{"id":"340","title":"Everybody lose who mouth many major.","abstract":"We study the extremal competitive ratio of Boolean function evaluation. We provide the first non-trivial lower and upper bounds for classes of Boolean functions which are not included in the class of monotone Boolean functions. For the particular case of symmetric functions our bounds are matching and we exactly characterize the best possible competitiveness achievable by a deterministic algorithm. Our upper bound is obtained by a simple polynomial time algorithm.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2015-08-08 00:00:00.000000"},
{"id":"341","title":"Page base name do unit medical.","abstract":"New types of designs called nested space-filling designs have been proposed for conducting multiple computer experiments with different levels of accuracy. In this article, we develop several approaches to constructing such designs. The development of these methods also leads to the introduction of several new discrete mathematics concepts, including nested orthogonal arrays and nested difference matrices.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2018-06-12 00:00:00.000000"},
{"id":"342","title":"Few forward participant trial east black.","abstract":"The Long Baseline Neutrino Experiment (LBNE) will utilize a neutrino beamline facility located at Fermilab to carry out a compelling research program in neutrino physics. The facility will aim a beam of neutrinos toward a detector placed at the Homestake Mine in South Dakota, about 1300 km away. The neutrinos are produced as follows: First, protons extracted from the MI-10 section of the Main Injector (60-120 GeV) hit a solid target above grade and produce mesons. Then, the charged mesons are focused by a set of focusing horns into a 250 m long decay pipe, towards the far detector. Finally, the mesons that enter the decay pipe decay into neutrinos. The parameters of the facility were determined taking into account several factors including the physics goals, the modeling of the facility, spacial and radiological constraints and the experience gained by operating the NuMI facility at Fermilab. The initial beam power is expected to be ~700 kW, however some of the parameters were chosen to be able to deal with a beam power of 2.3 MW in order to enable the facility to run with an upgraded accelerator complex. We discuss here the status of the design and the associated challenges.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2019-05-22 00:00:00.000000"},
{"id":"343","title":"Indeed someone turn yet.","abstract":"In a proof-of-principle experiment with metamaterials exhibiting electric dipolar and magnetic dipolar resonances, we demonstrated that the electric and magnetic resonances can be separately switches off and on by positioning the metamaterials along a standing wave, while both resonances are present in travelling-wave spectra.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2018-09-20 00:00:00.000000"},
{"id":"344","title":"By perform billion fall yeah.","abstract":"In nuclear power generation, fissile materials are mainly used. For example, $U^{235}$ is fissile and therefore quite essential for use of nuclear energy. However, the material $U^{235}$ has very small natural abundance less than 1 %. We should seek possibility of utilizing fissionable materials such as $U^{238}$ because natural abundance of such fissionable materials is generally much larger than fissile ones. In this paper, we show that thermal neutrons with vanishing kinetic energy can induce nuclear fission when high voltage is applied to fissionable materials. To obtain this result, we use the liquid-drop model for nuclei. Finally, we propose how fissionable materials can be utilized.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2015-10-31 00:00:00.000000"},
{"id":"345","title":"Movie adult serve.","abstract":"We introduce the concept of cotensor coalgebra for a given bicomodule over a coalgebra in an abelian monoidal category. Under some further conditions we show that such a cotensor coalgebra exists and satisfies a meaningful universal property. We prove that this coalgebra is formally smooth whenever the comodule is relative injective and the coalgebra itself is formally smooth.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2016-01-20 00:00:00.000000"},
{"id":"346","title":"Whose herself anything capital bring continue purpose.","abstract":"In this work we propose an approximate Minimum Mean-Square Error (MMSE) filter for linear dynamic systems with Gaussian Mixture noise. The proposed estimator tracks each mixand of the Gaussian Mixture (GM) posterior with an individual filter and minimizes the total Mean-Square Error (MSE) of the bank of filters, as opposed to minimizing the MSE of individual filters in the commonly used Gaussian Sum Filter (GSF). The spread of means in the proposed method is smaller than that of GSF which makes it more robust to removing mixands. Hence, lower complexity reduction schemes can be used with the proposed filter without losing estimation accuracy and precision. This is supported through simulations on synthetic data as well as experimental data related to an indoor localization system. Additionally, we show that in two limit cases the state estimation provided by our proposed method converges to that of GSF, and we provide simulation results supporting this in other cases.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2017-01-16 00:00:00.000000"},
{"id":"347","title":"Him room hundred bad.","abstract":"We give a means of estimating the equivariant compression of a group G in terms of properties of open subgroups G_i whose direct limit is G. Quantifying a result by S.R. Gal, we also study the behaviour of the equivariant compression under amalgamated free products G1*_H G2 where H is of finite index in both G_1 and G_2.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2018-07-20 00:00:00.000000"},
{"id":"348","title":"Number drop about do.","abstract":"Score calibration enables automatic speaker recognizers to make cost-effective accept \/ reject decisions. Traditional calibration requires supervised data, which is an expensive resource. We propose a 2-component GMM for unsupervised calibration and demonstrate good performance relative to a supervised baseline on NIST SRE'10 and SRE'12. A Bayesian analysis demonstrates that the uncertainty associated with the unsupervised calibration parameter estimates is surprisingly small.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2020-02-22 00:00:00.000000"},
{"id":"349","title":"Suddenly the all amount.","abstract":"Conventional multiclass conditional probability estimation methods, such as Fisher's discriminate analysis and logistic regression, often require restrictive distributional model assumption. In this paper, a model-free estimation method is proposed to estimate multiclass conditional probability through a series of conditional quantile regression functions. Specifically, the conditional class probability is formulated as difference of corresponding cumulative distribution functions, where the cumulative distribution functions can be converted from the estimated conditional quantile regression functions. The proposed estimation method is also efficient as its computation cost does not increase exponentially with the number of classes. The theoretical and numerical studies demonstrate that the proposed estimation method is highly competitive against the existing competitors, especially when the number of classes is relatively large.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2020-06-02 00:00:00.000000"},
{"id":"350","title":"Against hotel born party care picture food.","abstract":"This paper presents new properties of Primitive Pythagorean Triples (PPT) that have relevance in applications where events of different probability need to be generated and in cryptography.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2021-08-26 00:00:00.000000"},
{"id":"351","title":"Success of worker price baby difficult job.","abstract":"Discussion on \"Brownian distance covariance\" by G\\'{a}bor J. Sz\\'{e}kely, Maria L. Rizzo [arXiv:1010.0297]","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2021-10-26 00:00:00.000000"},
{"id":"352","title":"Certain money discuss.","abstract":"Mathematical formulation of fluent switching from \"warm\" to \"hot\" conditions of standby units is given using the well known Sedyakin's and accelerated failure time (AFT) models. Non-parametric estimators of cumulative distribution function and mean failure time of a redundant system with several stand-by units are proposed. Goodness-of-fit tests for two given models are given.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2018-03-26 00:00:00.000000"},
{"id":"353","title":"Although control inside else history person.","abstract":"We study the approximability of instances of the minimum entropy set cover problem, parameterized by the average frequency of a random element in the covering sets. We analyze an algorithm combining a greedy approach with another one biased towards large sets. The algorithm is controled by the percentage of elements to which we apply the biased approach. The optimal parameter choice has a phase transition around average density $e$ and leads to improved approximation guarantees when average element frequency is less than $e$.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2020-12-07 00:00:00.000000"},
{"id":"354","title":"Particular one agreement worry can color.","abstract":"This paper has three main goals. First, we set up a general framework to address the problem of constructing module bases for the equivariant cohomology of certain subspaces of GKM spaces. To this end we introduce the notion of a GKM-compatible subspace of an ambient GKM space. We also discuss poset-upper-triangularity, a key combinatorial notion in both GKM theory and more generally in localization theory in equivariant cohomology. With a view toward other applications, we present parts of our setup in a general algebraic and combinatorial framework. Second, motivated by our central problem of building module bases, we introduce a combinatorial game which we dub poset pinball and illustrate with several examples. Finally, as first applications, we apply the perspective of GKM-compatible subspaces and poset pinball to construct explicit and computationally convenient module bases for the $S^1$-equivariant cohomology of all Peterson varieties of classical Lie type, and subregular Springer varieties of Lie type $A$. In addition, in the Springer case we use our module basis to lift the classical Springer representation on the ordinary cohomology of subregular Springer varieties to $S^1$-equivariant cohomology in Lie type $A$.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2017-02-03 00:00:00.000000"},
{"id":"355","title":"Happen nearly here huge message billion drive.","abstract":"In this paper the problem of scheduling with power control in wireless networks is studied: given a set of communication requests, one needs to assign the powers of the network nodes, and schedule the transmissions so that they can be done in a minimum time, taking into account the signal interference of concurrently transmitting nodes. The signal interference is modeled by SINR constraints. Approximation algorithms are given for this problem, which use the mean power assignment. The problem of schduling with fixed mean power assignment is also considered, and approximation guarantees are proven.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2020-04-21 00:00:00.000000"},
{"id":"356","title":"Mother natural here single successful go return.","abstract":"In this paper, the author proposes a series of multilevel double hashing schemes called cascade hash tables. They use several levels of hash tables. In each table, we use the common double hashing scheme. Higher level hash tables work as fail-safes of lower level hash tables. By this strategy, it could effectively reduce collisions in hash insertion. Thus it gains a constant worst case lookup time with a relatively high load factor(70%-85%) in random experiments. Different parameters of cascade hash tables are tested.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2022-12-03 00:00:00.000000"},
{"id":"357","title":"Change man we.","abstract":"The quaterionic formulation of quantum mechanics yields the unified quantum wave equation (UQWEs). From these equations, Dirac, Klein - Gordon and Schrodinger equations can be derived. While the UQWEs represent a matter wave (de Broglie), the Maxwell equations represent a transverse wave (field). Owing to UQWEs, the spin-0 and spin-1\/2 particle are described by a wavepacket consisting of waves traveling to the left and to the right with speed of light. UQWEs show that spin-0 and spin-1\/2 are in continuous states of creation and annihilation that are compatible with Heisenberg uncertainty relation. The creation - annihilation process is a result of the time translation property of the particle wavefunction. These are $E'=E-im_0c^2$ and $E'=E\\pm m_0c^2$, for Klein-Gordon' and Dirac' particles, respectively. It is found that $\\frac{\\hbar}{m_0c^2}$ is the period of the creation -annihilation process.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2015-03-05 00:00:00.000000"},
{"id":"358","title":"Our have your.","abstract":"This is a survey of Berezin's work focused on three topics: representation theory, general concept of quantization, and supermathematics.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2015-01-16 00:00:00.000000"},
{"id":"359","title":"Watch food decision decide pattern stay without.","abstract":"We have designed a machine that becomes increasingly better at behaving in underspecified circumstances, in a goal-directed way, on the job, by modeling itself and its environment as experience accumulates. Based on principles of autocatalysis, endogeny, and reflectivity, the work provides an architectural blueprint for constructing systems with high levels of operational autonomy in underspecified circumstances, starting from a small seed. Through value-driven dynamic priority scheduling controlling the parallel execution of a vast number of reasoning threads, the system achieves recursive self-improvement after it leaves the lab, within the boundaries imposed by its designers. A prototype system has been implemented and demonstrated to learn a complex real-world task, real-time multimodal dialogue with humans, by on-line observation. Our work presents solutions to several challenges that must be solved for achieving artificial general intelligence.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2018-10-19 00:00:00.000000"},
{"id":"360","title":"Study strong someone.","abstract":"We present a computational and statistical approach for fitting isotonic models under convex differentiable loss functions. We offer a recursive partitioning algorithm which provably and efficiently solves isotonic regression under any such loss function. Models along the partitioning path are also isotonic and can be viewed as regularized solutions to the problem. Our approach generalizes and subsumes two previous results: the well-known work of Barlow and Brunk (1972) on fitting isotonic regressions subject to specially structured loss functions, and a recursive partitioning algorithm (Spouge et al 2003) for the case of standard (l2-loss) isotonic regression. We demonstrate the advantages of our generalized algorithm on both real and simulated data in two settings: fitting count data using negative Poisson log-likelihood loss, and fitting robust isotonic regression using Huber's loss.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2017-02-21 00:00:00.000000"},
{"id":"361","title":"Peace everyone nation value.","abstract":"We define a Riesz type interpolation property for the Cuntz semigroup of a $C^*$-algebra and prove it is satisfied by the Cuntz semigroup of every $C^*$-algebra with the ideal property. Related to this, we obtain two characterizations of the ideal property in terms of the Cuntz semigroup of the $C^*$-algebra. Some additional characterizations are proved in the special case of the stable, purely infinite $C^*$-algebras, and two of them are expressed in language of the Cuntz semigroup. We introduce a notion of comparison of positive elements for every unital $C^*$-algebra that has (normalized) quasitraces. We prove that large classes of $C^*$-algebras (including large classes of $AH$ algebras) with the ideal property have this comparison property.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2020-02-14 00:00:00.000000"},
{"id":"362","title":"Hundred send low try not.","abstract":"This paper is concerned with estimating the intersection point of two densities, given a sample of both of the densities. This problem arises in classification theory. The main results provide lower bounds for the probability of the estimation errors to be large on a scale determined by the inverse cube root of the sample size. As corollaries, we obtain probabilistic bounds for the prediction error in a classification problem. The key to the proof is an entropy estimate. The lower bounds are based on bounds for general estimators, which are applicable in other contexts as well. Furthermore, we introduce a class of optimal estimators whose errors asymptotically meet the border permitted by the lower bounds.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2017-01-02 00:00:00.000000"},
{"id":"363","title":"Take suggest sense.","abstract":"This paper describes the structure of the moduli space of holomorphic curves and constructs Gromov Witten invariants in the category of exploded manifolds. This includes defining Gromov Witten invariants relative to normal crossing divisors and proving the associated gluing theorem which involves summing relative invariants over a count of tropical curves.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2016-07-14 00:00:00.000000"},
{"id":"364","title":"Series budget pick.","abstract":"We report experimental and theoretical study of a rotating diode-pumped Nd-YAG ring laser with active beat note stabilization. Our experimental setup is described in the usual Maxwell-Bloch formalism. We analytically derive a stability condition and some frequency response characteristics for the solid-state ring laser gyroscope, illustrating the important role of mode coupling effects on the dynamics of such a device. Experimental data are presented and compared with the theory on the basis of realistic laser parameters, showing a very good agreement. Our results illustrate the duality between the very rich non linear dynamics of the diode-pumped solid-state ring laser (including chaotic behavior) and the possibility to obtain a very stable beat note, resulting in a potentially new kind of rotation sensor.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2016-08-26 00:00:00.000000"},
{"id":"365","title":"Here animal understand hard according Mrs.","abstract":"The purpose of this article is to show that even the most elementary problems in asymptotic extremal graph theory can be highly non-trivial. We study linear inequalities between graph homomorphism densities. In the language of quantum graphs the validity of such an inequality is equivalent to the positivity of a corresponding quantum graph. Similar to the setting of polynomials, a quantum graph that can be represented as a sum of squares of labeled quantum graphs is necessarily positive. Lov\\'asz asks whether the opposite is also true. We answer this question and also a related question of Razborov in the negative by introducing explicit valid inequalities that do not satisfy the required conditions. Our solution to these problems is based on a reduction from real multivariate polynomials and uses the fact that there are positive polynomials that cannot be expressed as sums of squares of polynomials.   It is known that the problem of determining whether a multivariate polynomial is positive is decidable. Hence it is very natural to ask \"Is the problem of determining the validity of a linear inequality between homomorphism densities decidable?\" We give a negative answer to this question which shows that such inequalities are inherently difficult in their full generality. Furthermore we deduce from this fact that the analogue of Artin's solution to Hilbert's seventeenth problem does not hold in the setting of quantum graphs.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2020-05-14 00:00:00.000000"},
{"id":"366","title":"Success bar service best.","abstract":"A novel phase modulation parallel optical delay detector is proposed for microwave angle-of-arrival (AOA) measurement with accuracy monitored by using only one dual-electrode Mach-Zenhder modulator. A theoretical model is built up to analyze the proposed system including measurement accuracy monitoring. The spatial delay measurement is translated into the phase shift between two replicas of a microwave signal. Thanks to the accuracy monitoring, the phase shifts from 5{\\deg} to 165{\\deg} are measured with less than 3.1{\\deg} measurement error.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2017-01-24 00:00:00.000000"},
{"id":"367","title":"Understand hour majority message.","abstract":"The profusion of online news articles makes it difficult to find interesting articles, a problem that can be assuaged by using a recommender system to bring the most relevant news stories to readers. However, news recommendation is challenging because the most relevant articles are often new content seen by few users. In addition, they are subject to trends and preference changes over time, and in many cases we do not have sufficient information to profile the reader.   In this paper, we introduce a class of news recommendation systems based on context trees. They can provide high-quality news recommendation to anonymous visitors based on present browsing behaviour. We show that context-tree recommender systems provide good prediction accuracy and recommendation novelty, and they are sufficiently flexible to capture the unique properties of news articles.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2018-04-04 00:00:00.000000"},
{"id":"368","title":"Important stage serve item community.","abstract":"Rules in logic programming encode information about mutual interdependencies between literals that is not captured by any of the commonly used semantics. This information becomes essential as soon as a program needs to be modified or further manipulated.   We argue that, in these cases, a program should not be viewed solely as the set of its models. Instead, it should be viewed and manipulated as the set of sets of models of each rule inside it. With this in mind, we investigate and highlight relations between the SE-model semantics and individual rules. We identify a set of representatives of rule equivalence classes induced by SE-models, and so pinpoint the exact expressivity of this semantics with respect to a single rule. We also characterise the class of sets of SE-interpretations representable by a single rule. Finally, we discuss the introduction of two notions of equivalence, both stronger than strong equivalence [1] and weaker than strong update equivalence [2], which seem more suitable whenever the dependency information found in rules is of interest.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2017-10-01 00:00:00.000000"},
{"id":"369","title":"Drive deal raise break walk.","abstract":"We solve Landau's four unattackable problems, including Goldbach Conjecture and Twin Prime Conjecture through sieve method.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2016-07-31 00:00:00.000000"},
{"id":"370","title":"Office behavior cell write.","abstract":"We study properties of the general integral transform defined for a family of hypersurfaces in a smooth manifold. Estimates of Sobolev norms, range conditions and approximation theorem for the kernel of the integral transform are stated. Applications to the spherical mean transform that appears in thermo\/opto\/photoacoustic tomography are discussed.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2021-10-08 00:00:00.000000"},
{"id":"371","title":"Goal individual figure parent both.","abstract":"Chemotaxis is the process by which cells behave in a way that follows the chemical gradient. Applications to bacteria growth, tissue inflammation, and vascular tumors provide a focus on optimization strategies. Experiments can characterize the form of possible chemotactic sensitivities. This paper addresses the recovery of the chemotactic sensitivity from these experiments while allowing for nonlinear dependence of the parameter on the state variables. The existence of solutions to the forward problem is analyzed. The identification of a chemotactic parameter is determined by inverse problem techniques. Tikhonov regularization is investigated and appropriate convergence results are obtained. Numerical results of concentration dependent chemotactic terms are explored.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2019-10-25 00:00:00.000000"},
{"id":"372","title":"Affect until seat career method worker.","abstract":"What should a court do with a preliminary-injunction request to halt a multi-billion-dollar particle-physics experiment that plaintiffs claim could create a black hole that will devour the planet? The real-life case of CERN's LHC seems like a legal classic in the making. Unfortunately, however, no court has braved the extreme factual terrain to reach the merits. This article steps into the void. First, the relevant facts of the scientific debate and its human context are memorialized and made ripe for legal analysis. Next, the article explores the daunting challenges the case presents to equity, evidence, and law-and-economics analysis. Finally, a set of analytical tools are offered that provide a way out of the thicket - a method for providing meaningful judicial review even in cases, such as this one, where the scientific issues are almost unfathomably complex.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2015-06-25 00:00:00.000000"},
{"id":"373","title":"Carry help question cause amount exactly sport.","abstract":"We give elementary derivations of several classical and some new summation and transformation formulae for bilateral basic hypergeometric series. For purpose of motivation, we review our previous simple proof (\"A simple proof of Bailey's very-well-poised 6-psi-6 summation\", Proc. Amer. Math. Soc., to appear) of Bailey's very-well-poised 6-psi-6 summation. Using a similar but different method, we now give elementary derivations of some transformations for bilateral basic hypergeometric series. In particular, these include M. Jackson's very-well-poised 8-psi-8 transformation, a very-well-poised 10-psi-10 transformation, by induction, Slater's general transformation for very-well-poised 2r-psi-2r series, and Slater's transformation for general r-psi-r series. Finally, we derive some new transformations for bilateral basic hypergeometric series of Chu-Gasper-Karlsson-Minton-type.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2020-02-04 00:00:00.000000"},
{"id":"374","title":"Mother decade actually course trial national team.","abstract":"Acting on time-critical events by processing ever growing social media, news or cyber data streams is a major technical challenge. Many of these data sources can be modeled as multi-relational graphs. Mining and searching for subgraph patterns in a continuous setting requires an efficient approach to incremental graph search. The goal of our work is to enable real-time search capabilities for graph databases. This demonstration will present a dynamic graph query system that leverages the structural and semantic characteristics of the underlying multi-relational graph.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2019-07-23 00:00:00.000000"},
{"id":"375","title":"Development spring range ask style go.","abstract":"Previous researches have demonstrated that the framework of dictionary learning with sparse coding, in which signals are decomposed as linear combinations of a few atoms of a learned dictionary, is well adept to reconstruction issues. This framework has also been used for discrimination tasks such as image classification. To achieve better performances of classification, experts develop several methods to learn a discriminative dictionary in a supervised manner. However, another issue is that when the data become extremely large in scale, these methods will be no longer effective as they are all batch-oriented approaches. For this reason, we propose a novel online algorithm for discriminative dictionary learning, dubbed \\textbf{ODDL} in this paper. First, we introduce a linear classifier into the conventional dictionary learning formulation and derive a discriminative dictionary learning problem. Then, we exploit an online algorithm to solve the derived problem. Unlike the most existing approaches which update dictionary and classifier alternately via iteratively solving sub-problems, our approach directly explores them jointly. Meanwhile, it can largely shorten the runtime for training and is also particularly suitable for large-scale classification issues. To evaluate the performance of the proposed ODDL approach in image recognition, we conduct some experiments on three well-known benchmarks, and the experimental results demonstrate ODDL is fairly promising for image classification tasks.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2018-09-19 00:00:00.000000"},
{"id":"376","title":"True cultural us nor community.","abstract":"From the hypothesis of a quadratic dependence of the binding energy of the quarks on the length scale and from the idea of a universal running coupling constant, we get the closure mass of the Universe and the pion mass. Besides this, we propose a free energy for the pions which stationarity condition leads to a closed form for the pion mass as a function of the Planck mass and of the Hubble constant.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2016-08-21 00:00:00.000000"},
{"id":"377","title":"Bar fact officer bit decide sea loss close.","abstract":"Given a polygon $P$ in the plane, a {\\em pop} operation is the reflection of a vertex with respect to the line through its adjacent vertices. We define a family of alternating polygons, and show that any polygon from this family cannot be convexified by pop operations. This family contains simple, as well as non-simple (i.e., self-intersecting) polygons, as desired. We thereby answer in the negative an open problem posed by Demaine and O'Rourke \\cite[Open Problem 5.3]{DO07}.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2019-03-09 00:00:00.000000"},
{"id":"378","title":"Along debate wonder war back.","abstract":"The main theorem of the paper allows to generalize a class of identities among the quantum minors for quantum linear groups to similar identities but with the row labels of the quantum minors involved permuted.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2020-01-12 00:00:00.000000"},
{"id":"379","title":"Reduce one really place deal.","abstract":"We derive symmetries and adjunction inequalities of the knot Floer homology groups which appear to be especially interesting for homologically essential knots. Furthermore, we obtain an adjunction inequality for cobordism maps in knot Floer homologies. We demonstrate the adjunction inequalities and symmetries in explicit calculations which recover some of the main results from [1] on longitude Floer homology and also give rise to vanishing results on knot Floer homologies. Furthermore, using symmetries we prove that the knot Floer homology of a fiber distinguishes $\\stwo\\times\\sone$ from other $\\sone$-bundles over surfaces.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2022-07-06 00:00:00.000000"},
{"id":"380","title":"Make church discuss foot require all respond.","abstract":"It is natural to try to place the new polynomial invariants of links in algebraic topology (e.g. to try to interpret them using homology or homotopy groups). However, one can think that these new polynomial invariants are byproducts of a new more delicate algebraic invariant of 3-manifolds which measures the obstruction to isotopy of links (which are homotopic). We propose such an algebraic invariant based on skein theory introduced by Conway (1969) and developed by Giller (1982) as well as Lickorish and Millett (1987). (This is the first paper I wrote about skein modules, almost 20 years ago. The recent survey of skein modules is available at http:\/\/arxiv.org\/abs\/math.GT\/0602264.)","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2018-04-06 00:00:00.000000"},
{"id":"381","title":"Talk risk explain economy.","abstract":"All non-local but relatively local irreducible extensions of Virasoro chiral CFTs with c<1 are classified. The classification, which is a prerequisite for the classification of local c<1 boundary CFTs on a two-dimensional half-space, turns out to be 1 to 1 with certain pairs of A-D-E graphs with distinguished vertices.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2017-05-01 00:00:00.000000"},
{"id":"382","title":"Bring improve performance history forward music.","abstract":"The Minimum Quartet Tree Cost problem is to construct an optimal weight tree from the $3{n \\choose 4}$ weighted quartet topologies on $n$ objects, where optimality means that the summed weight of the embedded quartet topologies is optimal (so it can be the case that the optimal tree embeds all quartets as nonoptimal topologies). We present a Monte Carlo heuristic, based on randomized hill climbing, for approximating the optimal weight tree, given the quartet topology weights. The method repeatedly transforms a dendrogram, with all objects involved as leaves, achieving a monotonic approximation to the exact single globally optimal tree. The problem and the solution heuristic has been extensively used for general hierarchical clustering of nontree-like (non-phylogeny) data in various domains and across domains with heterogeneous data. We also present a greatly improved heuristic, reducing the running time by a factor of order a thousand to ten thousand. All this is implemented and available, as part of the CompLearn package. We compare performance and running time of the original and improved versions with those of UPGMA, BioNJ, and NJ, as implemented in the SplitsTree package on genomic data for which the latter are optimized.   Keywords: Data and knowledge visualization, Pattern matching--Clustering--Algorithms\/Similarity measures, Hierarchical clustering, Global optimization, Quartet tree, Randomized hill-climbing,","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2017-04-15 00:00:00.000000"},
{"id":"383","title":"Although expert summer concern space about stay.","abstract":"The focus of this paper is the calculation of similarity between two concepts from an ontology for a Human-Like Interaction system. In order to facilitate this calculation, a similarity function is proposed based on five dimensions (sort, compositional, essential, restrictive and descriptive) constituting the structure of ontological knowledge. The paper includes a proposal for computing a similarity function for each dimension of knowledge. Later on, the similarity values obtained are weighted and aggregated to obtain a global similarity measure. In order to calculate those weights associated to each dimension, four training methods have been proposed. The training methods differ in the element to fit: the user, concepts or pairs of concepts, and a hybrid approach. For evaluating the proposal, the knowledge base was fed from WordNet and extended by using a knowledge editing toolkit (Cognos). The evaluation of the proposal is carried out through the comparison of system responses with those given by human test subjects, both providing a measure of the soundness of the procedure and revealing ways in which the proposal may be improved.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2015-04-11 00:00:00.000000"},
{"id":"384","title":"Price sense fill chair can best fill.","abstract":"We survey a few concentration inequalities for submodular and fractionally subadditive functions of independent random variables, implied by the entropy method for self-bounding functions. The power of these concentration bounds is that they are dimension-free, in particular implying standard deviation O(\\sqrt{\\E[f]}) rather than O(\\sqrt{n}) which can be obtained for any 1-Lipschitz function of n variables.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2022-03-03 00:00:00.000000"},
{"id":"385","title":"Weight soon into more story whatever.","abstract":"The study of properties of mean functionals of random probability measures is an important area of research in the theory of Bayesian nonparametric statistics. Many results are now known for random Dirichlet means, but little is known, especially in terms of posterior distributions, for classes of priors beyond the Dirichlet process. In this paper, we consider normalized random measures with independent increments (NRMI's) and mixtures of NRMI. In both cases, we are able to provide exact expressions for the posterior distribution of their means. These general results are then specialized, leading to distributional results for means of two important particular cases of NRMI's and also of the two-parameter Poisson--Dirichlet process.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2019-09-10 00:00:00.000000"},
{"id":"386","title":"Force TV peace suggest.","abstract":"We study the complex symplectic structure of the quiver varieties corresponding to the moduli spaces of SU(2) instantons on both commutative and non-commutative R^4. We identify global Darboux coordinates and quadratic Hamiltonians on classical phase spaces for which these quiver varieties are natural completions. We also show that the group of non-commutative symplectomorphisms of the corresponding path algebra acts transitively on the moduli spaces of non-commutative instantons.   This paper should be viewed as a step towards extending known results for Calogero-Moser spaces to the instanton moduli spaces.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2015-12-23 00:00:00.000000"},
{"id":"387","title":"Follow story natural high whole recognize it its.","abstract":"The signal to noise ratio, which plays such an important r\\^ole in information theory, is shown to become pointless for digital communications where the demodulation is achieved via new fast estimation techniques. Operational calculus, differential algebra, noncommutative algebra and nonstandard analysis are the main mathematical tools.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2018-08-20 00:00:00.000000"},
{"id":"388","title":"Tend any audience assume door point this.","abstract":"This survey paper examines the work of J. von Neumann and M.H. Stone as it relates to the abstract theory of wavelets. In particular, we discuss the direct integral theory of von Neumann and how it can be applied to representations of certain discrete groups to study the existence of normalized tight frames in the setting of Gabor systems and wavelets, via the use of group representations and von Neumann algebras. Then the extension of Stone's theorem due to M. Naimark, W. Ambrose and R. Godement is reviewed, and its relationship to the multiresolution analyses of S. Mallat and Y. Meyer and the generalized multiresolution analyses of L. Baggett, H. Medina, and K. Merrill. Finally, the paper ends by discussing some recent work due to the author, Baggett, P. Jorgensen and Merrill, and its relationship to operator theory.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2018-02-28 00:00:00.000000"},
{"id":"389","title":"Owner surface road meeting cell above order science.","abstract":"We consider brave new cochain extensions $F(BG_+,R)\\to F(EG_+,R)$, where $R$ is either a Lubin-Tate spectrum $E_n$ or the related 2-periodic Morava K-theory $K_n$, and $G$ is a finite group. When $R$ is an Eilenberg-Mac Lane spectrum, in some good cases such an extension is a $G$-Galois extension in the sense of John Rognes, but not always faithful. We prove that for $E_n$ and $K_n$ these extensions are always faithful in the $K_n$ local category. However, for a cyclic $p$-group $C_{p^r}$, the cochain extension $F({BC_{p^r}}_+,E_n) \\to F({EC_{p^r}}_+,E_n)$ is not a Galois extensions because it ramifies. As a consequence, it follows that the $E_n$-theory Eilenberg-Moore spectral sequence for $G$ and $BG$ does not always converge to its expected target.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2020-08-31 00:00:00.000000"},
{"id":"390","title":"Beautiful people appear hair.","abstract":"The inherently homogeneous stationary-state and time-dependent Schroedinger equations are often recast into inhomogeneous form in order to resolve their solution nonuniqueness. The inhomogeneous term can impose an initial condition or, for scattering, the preferred permitted asymptotic behavior. For bound states it provides sufficient focus to exclude all but one of the homogeneous version's solutions. Because of their unique solutions, such inhomogeneous versions of Schroedinger equations have long been the indispensable basis for a solution scheme of successive perturbational corrections which are anchored by their inhomogeneous term. Here it is noted that every such perturbational solution scheme for an inhomogeneous linear vector equation spins off a nonperturbational continued-fraction scheme. Unlike its representation-independent antecedent, the spin-off scheme only works in representations where all components of the equation's inhomogeneous term are nonzero. But that requirement seems to confer theoretical physics robustness heretofore unknown: for quantum fields the order of the perturbation places a bound on unperturbed particle number, the spin-off scheme contrariwise has only basis elements of unbounded unperturbed particle number. It furthermore is difficult to visualize such a continued-fraction spin-off scheme generating infinities, since its successive iterations always go into denominators.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2020-07-06 00:00:00.000000"},
{"id":"391","title":"Build else within middle type possible entire simply.","abstract":"We show that for any infinite countable group $G$ and for any free Borel action $G \\curvearrowright X$ there exists an equivariant class-bijective Borel map from $X$ to the free part $\\mathrm{Free}(2^G)$ of the $2$-shift $G \\curvearrowright 2^G$. This implies that any Borel structurability which holds for the equivalence relation generated by $G \\curvearrowright \\mathrm{Free}(2^G)$ must hold a fortiori for all equivalence relations coming from free Borel actions of $G$. A related consequence is that the Borel chromatic number of $\\mathrm{Free}(2^G)$ is the maximum among Borel chromatic numbers of free actions of $G$. This answers a question of Marks. Our construction is flexible and, using an appropriate notion of genericity, we are able to show that in fact the generic $G$-equivariant map to $2^G$ lands in the free part. As a corollary we obtain that for every $\\epsilon > 0$, every free pmp action of $G$ has a free factor which admits a $2$-piece generating partition with Shannon entropy less than $\\epsilon$. This generalizes a result of Danilenko and Park.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2020-02-09 00:00:00.000000"},
{"id":"392","title":"Avoid reality military.","abstract":"Margin theory provides one of the most popular explanations to the success of \\texttt{AdaBoost}, where the central point lies in the recognition that \\textit{margin} is the key for characterizing the performance of \\texttt{AdaBoost}. This theory has been very influential, e.g., it has been used to argue that \\texttt{AdaBoost} usually does not overfit since it tends to enlarge the margin even after the training error reaches zero. Previously the \\textit{minimum margin bound} was established for \\texttt{AdaBoost}, however, \\cite{Breiman1999} pointed out that maximizing the minimum margin does not necessarily lead to a better generalization. Later, \\cite{Reyzin:Schapire2006} emphasized that the margin distribution rather than minimum margin is crucial to the performance of \\texttt{AdaBoost}. In this paper, we first present the \\textit{$k$th margin bound} and further study on its relationship to previous work such as the minimum margin bound and Emargin bound. Then, we improve the previous empirical Bernstein bounds \\citep{Maurer:Pontil2009,Audibert:Munos:Szepesvari2009}, and based on such findings, we defend the margin-based explanation against Breiman's doubts by proving a new generalization error bound that considers exactly the same factors as \\cite{Schapire:Freund:Bartlett:Lee1998} but is sharper than \\cite{Breiman1999}'s minimum margin bound. By incorporating factors such as average margin and variance, we present a generalization error bound that is heavily related to the whole margin distribution. We also provide margin distribution bounds for generalization error of voting classifiers in finite VC-dimension space.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2015-09-09 00:00:00.000000"},
{"id":"393","title":"Discover picture wide simple all.","abstract":"The puzzle of an odd structure of fractional fillings for FQHE in higher Landau levels not repeating the hierarchy from the lowest Landau level is solved. The fractional filling rates for correlated states in higher Landau levels including spin subbands are systematically derived for the first time. Using topology-type commensurability arguments the hierarchy in higher Landau level fillings is determined in perfect agreement with the experimental observations. The relative paucity of fractional structure in higher Landau levels is explained and the criterion for pairing in states at half fillings and for other even-denominator rates of consecutive Landau levels is formulated.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2019-01-30 00:00:00.000000"},
{"id":"394","title":"Wall common left meet year past good.","abstract":"In diffusion-based algorithms for adaptive distributed estimation, each node of an adaptive network estimates a target parameter vector by creating an intermediate estimate and then combining the intermediate estimates available within its closed neighborhood. We propose a reduced-communication diffusion least mean-square (RC-DLMS) algorithm by allowing each node to only receive the intermediate estimates of a subset of its neighbors at each iteration. Therefore, the proposed RC-DLMS algorithm eases the usage of network communication resources and delivers a trade-off between estimation performance and communication cost. We examine the performance of the RC-DLMS algorithm analytically and show that it is stable and convergent in both mean and mean-square senses. We also calculate the theoretical steady-state mean-square deviation of the RC-DLMS algorithm and compute combination weights that optimize its performance in the small-step-size regime. Simulation results confirm the effectiveness of the RC-DLMS algorithm as well as a good match between theory and experiment.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2019-12-28 00:00:00.000000"},
{"id":"395","title":"Great seem share window.","abstract":"The Atomic Clocks Ensemble in Space (ACES\/PHARAO mission), which will be installed on board the International Space Station (ISS), uses a dedicated two-way Micro-Wave Link (MWL) in order to compare the timescale generated on board with those provided by many ground stations disseminated on the Earth. Phase accuracy and stability of this long range link will have a key role in the success of the ACES\/PHARAO experiment. SYRTE laboratory is heavily involved in the design and development of the data processing software : from theoretical modelling and numerical simulations to the development of a software prototype. Our team is working on a wide range of problems that need to be solved in order to achieve high accuracy in (almost) real time. In this article we present some key aspects of the measurement, as well as current status of the software's development.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2019-11-14 00:00:00.000000"},
{"id":"396","title":"Easy act decide stand now.","abstract":"The need for high availability (HA) and disaster recovery (DR) in IT environment is more stringent than most of the other sectors of enterprises. Many businesses require the availability of business-critical applications 24 hours a day, seven days a week, and can afford no data loss in the event of a disaster. It is vital that the IT infrastructure is resilient with regard to disruption, even site failures, and that business operations can continue without significant impact. As a result, DR has gained great importance in IT. Clustering of multiple industries standard servers together to allow workload sharing and fail-over capabilities is a low cost approach. In this paper, we present the availability model through Semi-Markov Process (SMP) and also analyze the difference in downtime of the SMP model and the approximate Continuous Time Markov Chain (CTMC) model. To acquire system availability, we perform numerical analysis and SHARPE tool evaluation.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2015-11-30 00:00:00.000000"},
{"id":"397","title":"Whole director already arrive total others bar.","abstract":"The interplanetary magnetic fluctuation spectrum obeys a Kolmogorovian power law at scales above the proton inertial length and gyroradius which is well regarded as an inertial range. Below these scales a power law index around $-2.5$ is often measured and associated to nonlinear dispersive processes. Recent observations reveal a third region at scales below the electron inertial length. This region is characterized by a steeper spectrum that some refer to it as the dissipation range. We investigate this range of scales in the electron magnetohydrodynamic approximation and derive an exact and universal law for a third-order structure function. This law can predict a magnetic fluctuation spectrum with an index of $-11\/3$ which is in agreement with the observed spectrum at the smallest scales. We conclude on the possible existence of a third turbulence regime in the solar wind instead of a dissipation range as recently postulated.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2017-01-11 00:00:00.000000"},
{"id":"398","title":"Option big leave of language why be.","abstract":"The paper presents a current tunable multifunction filter using current conveyor. The proposed circuit can be realized as on chip tunable low pass, high pass, band pass and elliptical notch filter. The circuit employs two current conveyors, one OTA, four resistors and two grounded capacitors, ideal for integration. It has only one output terminal and the number of input terminals may be used. Further, there is no requirement for component matching in the circuit. The resonance frequency ({\\omega}0) and bandwidth ({\\omega}0 \/Q) enjoy orthogonal tuning. The cutoff frequency of the filter is tunable by changing the bias current, which makes it on chip tunable filter. The circuit is realized by using commercially available current conveyor AD844 and OTA LM13700. A HSPICE simulation of circuit is also studied for the verification of theoretical results.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2020-11-20 00:00:00.000000"},
{"id":"399","title":"Capital yeah economic least class us majority.","abstract":"We obtain an explicit parametrization of stationary discs glued to some Levi non-degenerate hypersurfaces. These discs form a family which is invariant under the action of biholomorphisms. We use this parametrization to construct a local circular representation of these hypersurfaces. As a corollary, we get the uniqueness of biholomorphisms with given 1-jet at some convenient point.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2015-11-26 00:00:00.000000"},
{"id":"400","title":"Anyone exist market us late officer lay.","abstract":"We reprove and strengthen some old difficult theorems of 4-manifolds by the aid of recently discovered modern tools, which involve contact structures on 3-manifolds, compact Stein domains, etc.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2015-02-02 00:00:00.000000"},
{"id":"401","title":"Country wide imagine class expert still buy.","abstract":"We derive minimax generalized Bayes estimators of regression coefficients in the general linear model with spherically symmetric errors under invariant quadratic loss for the case of unknown scale. The class of estimators generalizes the class considered in Maruyama and Strawderman (2005) to include non-monotone shrinkage functions.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2018-10-11 00:00:00.000000"},
{"id":"402","title":"Position actually glass act.","abstract":"This paper deals with the recognition and matching of text in both cartographic maps and ancient documents. The purpose of this work is to find similar text regions based on statistical and global features. A phase of normalization is done first, in object to well categorize the same quantity of information. A phase of wordspotting is done next by combining local and global features. We make different experiments by combining the different techniques of extracting features in order to obtain better results in recognition phase. We applied fontspotting on both ancient documents and cartographic ones. We also applied the wordspotting in which we adopted a new technique which tries to compare the images of character and not the entire images words. We present the precision and recall values obtained with three methods for the new method of wordspotting applied on characters only.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2018-02-23 00:00:00.000000"},
{"id":"403","title":"Time ok them near environment increase.","abstract":"In secondary spectrum trading markets, auctions are widely used by spectrum holders (SHs) to redistribute their unused channels to secondary wireless service providers (WSPs). As sellers, the SHs design proper auction schemes to stimulate more participants and maximize the revenue from the auction. As buyers, the WSPs determine the bidding strategies in the auction to better serve their end users.   In this paper, we consider a three-layered spectrum trading market consisting of the SH, the WSPs and the end users. We jointly study the strategies of the three parties. The SH determines the auction scheme and spectrum supplies to optimize its revenue. The WSPs have flexible bidding strategies in terms of both demands and valuations considering the strategies of the end users. We design FlexAuc, a novel auction mechanism for this market to enable dynamic supplies and demands in the auction. We prove theoretically that FlexAuc not only maximizes the social welfare but also preserves other nice properties such as truthfulness and computational tractability.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2017-01-30 00:00:00.000000"},
{"id":"404","title":"Control of eat challenge young.","abstract":"It is frequently suggested that predictions made by game theory could be improved by considering computational restrictions when modeling agents. Under the supposition that players in a game may desire to balance maximization of payoff with minimization of strategy complexity, Rubinstein and co-authors studied forms of Nash equilibrium where strategies are maximally simplified in that no strategy can be further simplified without sacrificing payoff. Inspired by this line of work, we introduce a notion of equilibrium whereby strategies are also maximally simplified, but with respect to a simplification procedure that is more careful in that a player will not simplify if the simplification incents other players to deviate. We study such equilibria in two-player machine games in which players choose finite automata that succinctly represent strategies for repeated games; in this context, we present techniques for establishing that an outcome is at equilibrium and present results on the structure of equilibria.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2017-12-27 00:00:00.000000"},
{"id":"405","title":"With conference nature for.","abstract":"A simple proof of (2n)-weak amenability of the triangular Banach algebra T= [(A A) (0 A)] is given where A is a unital C*-algebra.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2019-09-23 00:00:00.000000"},
{"id":"406","title":"Tree and deal section as chance health democratic.","abstract":"We study the problem of efficient, scalable set-sharing analysis of logic programs. We use the idea of representing sharing information as a pair of abstract substitutions, one of which is a worst-case sharing representation called a clique set, which was previously proposed for the case of inferring pair-sharing. We use the clique-set representation for (1) inferring actual set-sharing information, and (2) analysis within a top-down framework. In particular, we define the abstract functions required by standard top-down analyses, both for sharing alone and also for the case of including freeness in addition to sharing. Our experimental evaluation supports the conclusion that, for inferring set-sharing, as it was the case for inferring pair-sharing, precision losses are limited, while useful efficiency gains are obtained. At the limit, the clique-set representation allowed analyzing some programs that exceeded memory capacity using classical sharing representations.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2016-10-08 00:00:00.000000"},
{"id":"407","title":"Few approach bag election suggest president pass.","abstract":"Methods of dynamical system's theory are used for numerical study of transport and mixing of passive particles (water masses, temperature, salinity, pollutants, etc.) in simple kinematic ocean models composed with the main Eulerian coherent structures in a randomly fluctuating ocean -- a jet-like current and an eddy. Advection of passive tracers in a periodically-driven flow consisting of a background stream and an eddy (the model inspired by the phenomenon of topographic eddies over mountains in the ocean and atmosphere) is analyzed as an example of chaotic particle's scattering and transport. A numerical analysis reveals a nonattracting chaotic invariant set $\\Lambda$ that determines scattering and trapping of particles from the incoming flow. It is shown that both the trapping time for particles in the mixing region and the number of times their trajectories wind around the vortex have hierarchical fractal structure as functions of the initial particle's coordinates. Scattering functions are singular on a Cantor set of initial conditions, and this property should manifest itself by strong fluctuations of quantities measured in experiments. The Lagrangian structures in our numerical experiments are shown to be similar to those found in a recent laboratory dye experiment at Woods Hole. Transport and mixing of passive particles is studied in the kinematic model inspired by the interaction of a jet current (like the Gulf Stream or the Kuroshio) with an eddy in a noisy environment. We demonstrate a non-trivial phenomenon of noise-induced clustering of passive particles and propose a method to find such clusters in numerical experiments. These clusters are patches of advected particles which can move together in a random velocity field for comparatively long time.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2018-12-11 00:00:00.000000"},
{"id":"408","title":"Arm goal my million.","abstract":"We analyze the magnetic moment of gluon, find if QCD is nongauge SU(3) theory then the magnetic moment of gluon varnishes, but if QCD is gauge theory then the magnetic moment of gluon will not vanishes. The magnetic moment of gluon can be measured by investigate the E-M decay of gluball.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2021-04-10 00:00:00.000000"},
{"id":"409","title":"Last once project.","abstract":"In this paper, we study small-N gravitational dynamics involving up to six objects. We perform a large suite of numerical scattering experiments involving single, binary, and triple stars. This is done using the FEWBODY numerical scattering code, which we have upgraded to treat encounters involving triple stars. We focus on outcomes that result in direct physical collisions between stars, within the low angular momentum and high absolute orbital energy regime. The dependence of the collision probability on the number of objects involved in the interaction, N, is found for fixed total energy and angular momentum. Our results are consistent with a collision probability that increases approximately as N^2. Interestingly, this is also what is expected from the mean free path approximation in the limit of very large N. A more thorough exploration of parameter space will be required in future studies to fully explore this potentially intriguing connection. This study is meant as a first step in an on-going effort to extend our understanding of small-N collisional dynamics beyond the three- and four-body problems and into the realm of larger-N.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2016-03-25 00:00:00.000000"},
{"id":"410","title":"Worker stop blood safe church seven value action.","abstract":"When minimizing a nonlinear least-squares function, the Levenberg-Marquardt algorithm can suffer from a slow convergence, particularly when it must navigate a narrow canyon en route to a best fit. On the other hand, when the least-squares function is very flat, the algorithm may easily become lost in parameter space. We introduce several improvements to the Levenberg-Marquardt algorithm in order to improve both its convergence speed and robustness to initial parameter guesses. We update the usual step to include a geodesic acceleration correction term, explore a systematic way of accepting uphill steps that may increase the residual sum of squares due to Umrigar and Nightingale, and employ the Broyden method to update the Jacobian matrix. We test these changes by comparing their performance on a number of test problems with standard implementations of the algorithm. We suggest that these two particular challenges, slow convergence and robustness to initial guesses, are complimentary problems. Schemes that improve convergence speed often make the algorithm less robust to the initial guess, and vice versa. We provide an open source implementation of our improvements that allow the user to adjust the algorithm parameters to suit particular needs.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2015-03-31 00:00:00.000000"},
{"id":"411","title":"Door remain prepare themselves make senior.","abstract":"We give new deterministic bounds for fully-dynamic graph connectivity. Our data structure supports updates (edge insertions\/deletions) in $O(\\log^2n\/\\log\\log n)$ amortized time and connectivity queries in $O(\\log n\/\\log\\log n)$ worst-case time, where $n$ is the number of vertices of the graph. This improves the deterministic data structures of Holm, de Lichtenberg, and Thorup (STOC 1998, J.ACM 2001) and Thorup (STOC 2000) which both have $O(\\log^2n)$ amortized update time and $O(\\log n\/\\log\\log n)$ worst-case query time. Our model of computation is the same as that of Thorup, i.e., a pointer machine with standard $AC^0$ instructions.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2021-06-23 00:00:00.000000"},
{"id":"412","title":"Raise probably stuff realize politics either.","abstract":"It has been shown that AIC-type criteria are asymptotically efficient selectors of the tuning parameter in non-concave penalized regression methods under the assumption that the population variance is known or that a consistent estimator is available. We relax this assumption to prove that AIC itself is asymptotically efficient and we study its performance in finite samples. In classical regression, it is known that AIC tends to select overly complex models when the dimension of the maximum candidate model is large relative to the sample size. Simulation studies suggest that AIC suffers from the same shortcomings when used in penalized regression. We therefore propose the use of the classical corrected AIC (AICc) as an alternative and prove that it maintains the desired asymptotic properties. To broaden our results, we further prove the efficiency of AIC for penalized likelihood methods in the context of generalized linear models with no dispersion parameter. Similar results exist in the literature but only for a restricted set of candidate models. By employing results from the classical literature on maximum-likelihood estimation in misspecified models, we are able to establish this result for a general set of candidate models. We use simulations to assess the performance of AIC and AICc, as well as that of other selectors, in finite samples for both SCAD-penalized and Lasso regressions and a real data example is considered.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2022-11-15 00:00:00.000000"},
{"id":"413","title":"Support win try structure stand believe one.","abstract":"The traditional multi-commodity flow problem assumes a given flow network in which multiple commodities are to be maximally routed in response to given demands. This paper considers the multi-commodity flow network-design problem: given a set of multi-commodity flow demands, find a network subject to certain constraints such that the commodities can be maximally routed.   This paper focuses on the case when the network is required to be a tree. The main result is an approximation algorithm for the case when the tree is required to be of constant degree. The algorithm reduces the problem to the minimum-weight balanced-separator problem; the performance guarantee of the algorithm is within a factor of 4 of the performance guarantee of the balanced-separator procedure. If Leighton and Rao's balanced-separator procedure is used, the performance guarantee is O(log n). This improves the O(log^2 n) approximation factor that is trivial to obtain by a direct application of the balanced-separator method.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2021-04-10 00:00:00.000000"},
{"id":"414","title":"Different population watch commercial board pressure not.","abstract":"Split sample methods have recently been put forward as a way to reduce the coverage oscillations that haunt confidence intervals for parameters of lattice distributions, such as the binomial and Poisson distributions. We study split sample intervals in the binomial setting, showing that these intervals can be viewed as being based on adding discrete random noise to the data. It is shown that they can be improved upon by using noise with a continuous distribution instead, regardless of whether the randomization is determined by the data or an external source of randomness. We compare split sample intervals to the randomized Stevens interval, which removes the coverage oscillations completely, and find the latter interval to have several advantages.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2018-12-07 00:00:00.000000"},
{"id":"415","title":"You value talk event.","abstract":"Recent work has revealed a 62 (+\/-) 3-million-year cycle in the fossil diversity in the past 542 My, however no plausible mechanism has been found. We propose that the cycle may be caused by modulation of cosmic ray (CR) flux by the Solar system vertical oscillation (64 My period) in the galaxy, the galactic north-south anisotropy of CR production in the galactic halo\/wind\/termination shock (due to the galactic motion toward the Virgo cluster), and the shielding by galactic magnetic fields. We revisit the mechanism of CR propagation and show that CR flux can vary by a factor of about 4.6 and reach a maximum at north-most displacement of the Sun. The very high statistical significance of (i) the phase agreement between Solar north-ward excursions and the diversity minima and (ii) the correlation of the magnitude of diversity drops with CR amplitudes through all cycles provide solid support for our model. Various observational predictions which can be used to confirm or falsify our hypothesis are presented.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2020-02-11 00:00:00.000000"},
{"id":"416","title":"Because say realize walk law.","abstract":"We consider the residual empirical process in random design regression with long memory errors. We establish its limiting behaviour, showing that its rates of convergence are different from the rates of convergence for to the empirical process based on (unobserved) errors. Also, we study a residual empirical process with estimated parameters. Its asymptotic distribution can be used to construct Kolmogorov-Smirnov, Cram\\'{e}r-Smirnov-von Mises, or other goodness-of-fit tests. Theoretical results are justified by simulation studies.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2015-09-06 00:00:00.000000"},
{"id":"417","title":"Teach international blue wonder collection whose hard.","abstract":"Let $M$ be a transitive model of $ZFC$ and let ${\\bf B}$ be a $M$-complete Boolean algebra in $M.$ (In general a proper class.) We define a generalized notion of forcing with such Boolean algebras, $^*$forcing. (A $^*$ forcing extension of $M$ is a transitive set of the form $M[{\\bf G}]$ where ${\\bf G}$ is an $M$-complete ultrafilter on ${\\bf B}.$) We prove that  1. If ${\\bf G}$ is a $^*$forcing complete ultrafilter on ${\\bf B},$ then $M[{\\bf G}]\\models ZFC.$  2. Let $H\\sub M.$ If there is a least transitive model $N$ such that $H\\in M,$ $Ord^M=Ord^N,$ and $N\\models ZFC,$ then we denote $N$ by $M[H].$ We show that all models of $ZFC$ of the form $M[H]$ are $^*$forcing extensions of $M.$   As an immediate corollary we get that $L[0^{\\#}]$ is a $^*$forcing extension of $L.$","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2015-09-27 00:00:00.000000"},
{"id":"418","title":"Record financial wrong ground sense career hear.","abstract":"For the energy absorption of atomic clusters as a function of the laser pulse duration we find a similar behavior as it has been observed for metallic clusters [K\\\"oller et al., Phys. Rev. Lett. {\\bf 82}, 3783 (1999)]. In both situations there exists an optimum radius $R_{o}$ of the cluster for energy absorption. In the metallic case the existence of $R_{o}$ has been interpreted as a consequence of the collective oscillation of a delocalized electron cloud in resonance with the laser frequency. Here, we give evidence that in the atomic cluster the origin of $R_{o}$ is very different. Based on field assisted tunneling it can be related to the phenomenon of enhanced ionization as it occurs in small molecules. The dependence of $R_{o}$ on the laser frequency turns out to be the key quantity to distinguish the processes.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2021-09-14 00:00:00.000000"},
{"id":"419","title":"They since certain few even choice.","abstract":"This paper studies estimation in functional linear quantile regression in which the dependent variable is scalar while the covariate is a function, and the conditional quantile for each fixed quantile index is modeled as a linear functional of the covariate. Here we suppose that covariates are discretely observed and sampling points may differ across subjects, where the number of measurements per subject increases as the sample size. Also, we allow the quantile index to vary over a given subset of the open unit interval, so the slope function is a function of two variables: (typically) time and quantile index. Likewise, the conditional quantile function is a function of the quantile index and the covariate. We consider an estimator for the slope function based on the principal component basis. An estimator for the conditional quantile function is obtained by a plug-in method. Since the so-constructed plug-in estimator not necessarily satisfies the monotonicity constraint with respect to the quantile index, we also consider a class of monotonized estimators for the conditional quantile function. We establish rates of convergence for these estimators under suitable norms, showing that these rates are optimal in a minimax sense under some smoothness assumptions on the covariance kernel of the covariate and the slope function. Empirical choice of the cutoff level is studied by using simulations.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2022-10-05 00:00:00.000000"},
{"id":"420","title":"Raise include good general.","abstract":"A new method for visualizing the relatedness of scientific areas is developed that is based on measuring the overlap of researchers between areas. It is found that closely related areas have a high propensity to share a larger number of common authors. A methodology for comparing areas of vastly different sizes and to handle name homonymy is constructed, allowing for the robust deployment of this method on real data sets. A statistical analysis of the probability distributions of the common author overlap that accounts for noise is carried out along with the production of network maps with weighted links proportional to the overlap strength. This is demonstrated on two case studies, complexity science and neutrino physics, where the level of relatedness of areas within each area is expected to vary greatly. It is found that the results returned by this method closely match the intuitive expectation that the broad, multidisciplinary area of complexity science possesses areas that are weakly related to each other while the much narrower area of neutrino physics shows very strongly related areas.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2022-05-27 00:00:00.000000"},
{"id":"421","title":"Record require financial image magazine power.","abstract":"We propose a bivariate model for a pair of dependent unit vectors which is generated by Brownian motion. Both marginals have uniform distributions on the sphere, while the conditionals follow so-called ``exit'' distributions. Some properties of the proposed model, including parameter estimation and a pivotal statistic, are investigated. Further study is undertaken for the bivariate circular case by transforming variables and parameters into the form of complex numbers. Some desirable properties, such as a multiplicative property and infinite divisibility, hold for this submodel. Two estimators for the parameter of the submodel are studied and a simulation study is carried out to investigate the finite sample performance of the estimators. In an attempt to produce more flexible models, some methods to generalize the proposed model are discussed. One of the generalized models is applied to wind direction data. Finally, we show how it is possible to construct distributions in the plane and on the cylinder by applying bilinear fractional transformations to the proposed bivariate circular model.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2018-09-09 00:00:00.000000"},
{"id":"422","title":"Director know suddenly glass baby up.","abstract":"In this paper, we consider the so-called Shape Invariant Model which stands for the estimation of a function f0 submitted to a random translation of law g0 in a white noise model. We are interested in such a model when the law of the deformations is unknown. We aim to recover the law of the process P(f0,g0). In this perspective, we adopt a Bayesian point of view and find prior on f and g such that the posterior distribution concentrates at a polynomial rate around P(f0,g0) when n goes to infinity. We intensively use some Bayesian non parametric tools coupled with mixture models and believe that some of our results obtained on this mixture framework may be also of interest for frequentist point of view.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2019-11-26 00:00:00.000000"},
{"id":"423","title":"Design although later suffer.","abstract":"The Learning to Rank (L2R) research field has experienced a fast paced growth over the last few years, with a wide variety of benchmark datasets and baselines available for experimentation. We here investigate the main assumption behind this field, which is that, the use of sophisticated L2R algorithms and models, produce significant gains over more traditional and simple information retrieval approaches. Our experimental results surprisingly indicate that many L2R algorithms, when put up against the best individual features of each dataset, may not produce statistically significant differences, even if the absolute gains may seem large. We also find that most of the reported baselines are statistically tied, with no clear winner.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2019-09-08 00:00:00.000000"},
{"id":"424","title":"Fall now send voice challenge suffer whole.","abstract":"We study the problem of computing the free space F of a simple legged robot called the spider robot. The body of this robot is a single point and the legs are attached to the body. The robot is subject to two constraints: each leg has a maximal extension R (accessibility constraint) and the body of the robot must lie above the convex hull of its feet (stability constraint). Moreover, the robot can only put its feet on some regions, called the foothold regions. The free space F is the set of positions of the body of the robot such that there exists a set of accessible footholds for which the robot is stable. We present an efficient algorithm that computes F in O(n2 log n) time using O(n2 alpha(n)) space for n discrete point footholds where alpha(n) is an extremely slowly growing function (alpha(n) <= 3 for any practical value of n). We also present an algorithm for computing F when the foothold regions are pairwise disjoint polygons with n edges in total. This algorithm computes F in O(n2 alpha8(n) log n) time using O(n2 alpha8(n)) space (alpha8(n) is also an extremely slowly growing function). These results are close to optimal since Omega(n2) is a lower bound for the size of F.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2016-04-25 00:00:00.000000"},
{"id":"425","title":"Subject find even would.","abstract":"We consider liquid suspensions with dispersed nanoparticles. Using two-points Pade approximants and combining results of both hydrodynamic and molecular dynamics methods, we obtain the effective viscosity for any diameters of nanoparticles","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2018-10-26 00:00:00.000000"},
{"id":"426","title":"Check teacher television form.","abstract":"We consider the problem of constructing an an optimal-weight tree from the 3*(n choose 4) weighted quartet topologies on n objects, where optimality means that the summed weight of the embedded quartet topologiesis optimal (so it can be the case that the optimal tree embeds all quartets as non-optimal topologies). We present a heuristic for reconstructing the optimal-weight tree, and a canonical manner to derive the quartet-topology weights from a given distance matrix. The method repeatedly transforms a bifurcating tree, with all objects involved as leaves, achieving a monotonic approximation to the exact single globally optimal tree. This contrasts to other heuristic search methods from biological phylogeny, like DNAML or quartet puzzling, which, repeatedly, incrementally construct a solution from a random order of objects, and subsequently add agreement values.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2017-12-25 00:00:00.000000"},
{"id":"427","title":"Rise before miss project.","abstract":"Drinfel'd used associators to construct families of universal representations of braid groups. We consider semi-associators (i.e., we drop the pentagonal axiom and impose a normalization in degree one). We show that the process may be reversed, to obtain semi-associators from universal representations of 3-braids. We view braid groups as subgroups of braid-permutation groups. We construct a family of universal representations of braid-permutation groups, without using associators. All representations in the family are faithful, defined over $\\bbQ$ by simple explicit formulae. We show that they give universal Vassiliev-type invariants for braid-permutation groups.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2022-09-10 00:00:00.000000"},
{"id":"428","title":"If get news hair police.","abstract":"In previous paper we have shown that there is a special kind of non-linear electrodynamics (which we name Curvilinear Wave Electrodynamics - CWED), whose equations are mathematically equivalent to the equations of photons and leptons of quantum electrodynamics. The purpose of the present paper is to show that in framework of CWED the description of the interaction is also mathematically equivalent to description of the interaction in quantum physics. Another purpose of this paper is to show that CWED allows to unify the description of interactions in physics.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2015-02-13 00:00:00.000000"},
{"id":"429","title":"Hundred heart into.","abstract":"Recently, two new parallel algorithms for on-the-fly model checking of LTL properties were presented at the same conference: Automated Technology for Verification and Analysis, 2011. Both approaches extend Swarmed NDFS, which runs several sequential NDFS instances in parallel. While parallel random search already speeds up detection of bugs, the workers must share some global information in order to speed up full verification of correct models. The two algorithms differ considerably in the global information shared between workers, and in the way they synchronize.   Here, we provide a thorough experimental comparison between the two algorithms, by measuring the runtime of their implementations on a multi-core machine. Both algorithms were implemented in the same framework of the model checker LTSmin, using similar optimizations, and have been subjected to the full BEEM model database.   Because both algorithms have complementary advantages, we constructed an algorithm that combines both ideas. This combination clearly has an improved speedup. We also compare the results with the alternative parallel algorithm for accepting cycle detection OWCTY-MAP. Finally, we study a simple statistical model for input models that do contain accepting cycles. The goal is to distinguish the speedup due to parallel random search from the speedup that can be attributed to clever work sharing schemes.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2017-07-25 00:00:00.000000"},
{"id":"430","title":"Serve act car bill.","abstract":"Representing knowledge with the use of ontology description languages offers several advantages arising from knowledge reusability, possibilities of carrying out reasoning processes and the use of existing concepts of knowledge integration. In this work we are going to present an environment for the integration of knowledge expressed in such a way. Guaranteeing knowledge integration is an important element during the development of the Semantic Web. Thanks to this, it is possible to obtain access to services which offer knowledge contained in various distributed databases associated with semantically described web portals. We will present the advantages of the multi-agent approach while solving this problem. Then, we will describe an example of its application in systems supporting company management knowledge in the process of constructing supply-chains.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2022-05-29 00:00:00.000000"},
{"id":"431","title":"Building cause lose similar as water performance the.","abstract":"To propose that black holes do not exist would be the fundamental way to resolve the contradiction between event horizons and quantum mechanics. In this paper we shall use the Lorentz and Levi-Civita conservation laws to explain how an event horizon might not exist, and the reasons for its nonexistence are presented by using the theory of classical gravity.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2021-09-30 00:00:00.000000"},
{"id":"432","title":"List stage stock help guy her.","abstract":"A simple model of a relativistic open string with a point mass attached at one end is quantized. The normal modes are derived and used to construct expressions for the operator commutators. Light cone gauge is used to find the mass squared operator. The singular part of the operator product expansion is derived.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2016-07-24 00:00:00.000000"},
{"id":"433","title":"Wish she may ago according.","abstract":"The connections between nonmonotonic reasoning and belief revision are well-known. A central problem in the area of nonmonotonic reasoning is the problem of default entailment, i.e., when should an item of default information representing \"if A is true then, normally, B is true\" be said to follow from a given set of items of such information. Many answers to this question have been proposed but, surprisingly, virtually none have attempted any explicit connection to belief revision. The aim of this paper is to give an example of how such a connection can be made by showing how the lexicographic closure of a set of defaults may be conceptualised as a process of iterated revision by sets of sentences. Specifically we use the revision process of Nayak.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2019-01-27 00:00:00.000000"},
{"id":"434","title":"Attention finally training serve sense film talk gun.","abstract":"In this paper we show that if $Y=N \\times \\mathbb{Q}_m$ is a metric space where $N$ is a Carnot group endowed with the Carnot-Caratheodory metric then any quasisymmetric map of $Y$ is actually bilipschitz. The key observation is that $Y$ is the parabolic visual boundary of a mixed type locally compact amenable hyperbolic group. The same results also hold for a larger class of nilpotent Lie groups $N$. As part of the proof we also obtain partial quasi-isometric rigidity results for mixed type locally compact amenable hyperbolic groups. Finally we prove a rigidity result for uniform subgroups of bilipschitz maps of $Y$ in the case of $N= \\mathbb{R}^n$.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2022-08-14 00:00:00.000000"},
{"id":"435","title":"Or floor majority.","abstract":"A review of the empirical literature on access to scholarly information. This review focuses on surveys of authors, article download and citation analysis.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2018-07-31 00:00:00.000000"},
{"id":"436","title":"Child big least race get sign.","abstract":"We consider the computational power of silent transitions in one-way automata with storage. Specifically, we ask which storage mechanisms admit a transformation of a given automaton into one that accepts the same language and reads at least one input symbol in each step.   We study this question using the model of valence automata. Here, a finite automaton is equipped with a storage mechanism that is given by a monoid.   This work presents generalizations of known results on silent transitions. For two classes of monoids, it provides characterizations of those monoids that allow the removal of \\lambda-transitions. Both classes are defined by graph products of copies of the bicyclic monoid and the group of integers. The first class contains pushdown storages as well as the blind counters while the second class contains the blind and the partially blind counters.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2016-09-16 00:00:00.000000"},
{"id":"437","title":"Support dream share edge action.","abstract":"In this paper, we develop the continuous time dynamic topic model (cDTM). The cDTM is a dynamic topic model that uses Brownian motion to model the latent topics through a sequential collection of documents, where a \"topic\" is a pattern of word use that we expect to evolve over the course of the collection. We derive an efficient variational approximate inference algorithm that takes advantage of the sparsity of observations in text, a property that lets us easily handle many time points. In contrast to the cDTM, the original discrete-time dynamic topic model (dDTM) requires that time be discretized. Moreover, the complexity of variational inference for the dDTM grows quickly as time granularity increases, a drawback which limits fine-grained discretization. We demonstrate the cDTM on two news corpora, reporting both predictive perplexity and the novel task of time stamp prediction.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2021-01-17 00:00:00.000000"},
{"id":"438","title":"Charge decade land become also bed red.","abstract":"We study the minimum \\emph{interval deletion} problem, which asks for the removal of a set of at most $k$ vertices to make a graph of $n$ vertices into an interval graph. We present a parameterized algorithm of runtime $10^k \\cdot n^{O(1)}$ for this problem, that is, we show the problem is fixed-parameter tractable.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2021-03-17 00:00:00.000000"},
{"id":"439","title":"Leg star western special firm defense.","abstract":"Joint matching over a collection of objects aims at aggregating information from a large collection of similar instances (e.g. images, graphs, shapes) to improve maps between pairs of them. Given multiple matches computed between a few object pairs in isolation, the goal is to recover an entire collection of maps that are (1) globally consistent, and (2) close to the provided maps --- and under certain conditions provably the ground-truth maps. Despite recent advances on this problem, the best-known recovery guarantees are limited to a small constant barrier --- none of the existing methods find theoretical support when more than $50\\%$ of input correspondences are corrupted. Moreover, prior approaches focus mostly on fully similar objects, while it is practically more demanding to match instances that are only partially similar to each other.   In this paper, we develop an algorithm to jointly match multiple objects that exhibit only partial similarities, given a few pairwise matches that are densely corrupted. Specifically, we propose to recover the ground-truth maps via a parameter-free convex program called MatchLift, following a spectral method that pre-estimates the total number of distinct elements to be matched. Encouragingly, MatchLift exhibits near-optimal error-correction ability, i.e. in the asymptotic regime it is guaranteed to work even when a dominant fraction $1-\\Theta\\left(\\frac{\\log^{2}n}{\\sqrt{n}}\\right)$ of the input maps behave like random outliers. Furthermore, MatchLift succeeds with minimal input complexity, namely, perfect matching can be achieved as soon as the provided maps form a connected map graph. We evaluate the proposed algorithm on various benchmark data sets including synthetic examples and real-world examples, all of which confirm the practical applicability of MatchLift.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2017-02-17 00:00:00.000000"},
{"id":"440","title":"Issue according note green window model her.","abstract":"We provide an algorithmic method for constructing projective resolutions of modules over quotients of path algebras. This algorithm is modified to construct minimal projective resolutions of linear modules over Koszul algebras.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2017-09-04 00:00:00.000000"},
{"id":"441","title":"Peace small level environmental how marriage.","abstract":"In this paper the selective broadening of the atomic hydrogen lines in pure H2 and Ar\/H2 mixtures in a large 'GEC' cell (36 cm length_ 14 cm ID) was mapped as a function of position, H2\/Ar ratio, time, power, and pressure. Several observations regarding the selective line broadening were particularly notable as they are unanticipated on the basis of earlier models. First, the anomalous broadening of the Balmer lines was found to exist throughout the plasma, and not just in the region between the electrodes. Second, the broadening was consistently a complex function of the operating parameters particularly gas composition (highest in pure H2), position, power, time and pressure. Clearly not anticipated by earlier models were the findings that under some conditions the highest concentration of 'hot' (>10 eV) hydrogen was found at the entry end, and not in the high field region between the electrodes and that in other conditions, the hottest H was at the (exit) pump (also grounded electrode) end. Third, excitation and electron temperatures were less than one eV in all regions of the plasma not directly adjacent (>1mm) to the electrodes, providing additional evidence that the energy for broadening, contrary to standard models, is not obtained from the field. Fourth, in contrast to our earlier studies of hydrogen\/helium and water plasmas, we found that in some conditions 98% of the atomic hydrogen was in the 'hot' state throughout the GEC-type cell. Virtually every operating parameter studied impacted the character of the hot H atom population, and clearly second and third order effects exist, indicating a need for experimental design. Some non-field mechanisms for generating hot hydrogen atoms, specifically those suggested by Mills' CQM model, are outlined.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2016-04-08 00:00:00.000000"},
{"id":"442","title":"Measure door face western.","abstract":"The q-Gaussian distribution results from maximizing certain generalizations of Shannon entropy under some constraints. The importance of q-Gaussian distributions stems from the fact that they exhibit power-law behavior, and also generalize Gaussian distributions. In this paper, we propose a Smoothed Functional (SF) scheme for gradient estimation using q-Gaussian distribution, and also propose an algorithm for optimization based on the above scheme. Convergence results of the algorithm are presented. Performance of the proposed algorithm is shown by simulation results on a queuing model.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2021-07-02 00:00:00.000000"},
{"id":"443","title":"Him politics east field success teacher.","abstract":"We show that all integrally closed ideals on log terminal surfaces are multiplier ideals by extending an existing proof for smooth surfaces.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2022-01-25 00:00:00.000000"},
{"id":"444","title":"Law player data listen compare she.","abstract":"Circular and linear zone plates have been fabricated on the surface of silicon crystals for the energy of 8 keV by electron beam lithography and deep ion plasma etching methods. Various variants of compound zone plates with first, second, third diffraction orders have been made. The zone relief height is about 10 mkm, the outermost zone width of the zone plate is 0.4 mkm. The experimental testing of the zone plates has been conducted on SPring-8 and ESRF synchrotron radiation sources. A focused spot size and diffraction efficiency measured by knife-edge scanning are accordingly 0.5 mkm and 39% for the first order circular zone plate.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2021-11-09 00:00:00.000000"},
{"id":"445","title":"Project individual everything begin network majority chair.","abstract":"We show that the continua I_u and H* are non-chainable and have span nonzero. Under CH this can be strengthened to surjective symmetric span nonzero.   We discuss the logical consequences of this.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2015-06-07 00:00:00.000000"},
{"id":"446","title":"Eat animal wonder Mr.","abstract":"It is proved the mathematical theorem, that the wave function describes the statistical ensemble of particles, but not a single particle. Supposition, that the wave function describes a single particle appears to be incompatible with formalism of quantum mechanics.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2015-03-24 00:00:00.000000"},
{"id":"447","title":"Change minute yet really.","abstract":"Let $\\mathfrak{L}_1$, $\\mathfrak{L}_2$, $\\mathfrak{L}_3$ be finite collections of $L_1$, $L_2$, $L_3$, respectively, lines in $\\mathbb{R}^3$, and $J(\\mathfrak{L}_1, \\mathfrak{L}_2,\\mathfrak{L}_3)$ the set of multijoints formed by them, i.e. the set of points $x \\in \\mathbb{R}^3$, each of which lies in at least one line $l_i \\in \\mathfrak{L}_i$, for all $i=1,2,3$, such that the directions of $l_1$, $l_2$ and $l_3$ span $\\mathbb{R}^3$. We prove here that $|J(\\mathfrak{L}_1, \\mathfrak{L}_2,\\mathfrak{L}_3)|\\lesssim (L_1L_2L_3)^{1\/2}$, and we extend our results to multijoints formed by real algebraic curves in $\\mathbb{R}^3$ of uniformly bounded degree, as well as by curves in $\\mathbb{R}^3$ parametrised by real univariate polynomials of uniformly bounded degree. The multijoints problem is a variant of the joints problem, as well as a discrete analogue of the endpoint multilinear Kakeya problem.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2022-07-29 00:00:00.000000"},
{"id":"448","title":"Hit during simply know senior again.","abstract":"It is very common to use dynamic methods to detect deadlocks in MPI programs for the reason that static methods have some restrictions. To guarantee high reliability of some important MPI-based application software, a model of MPI synchronization communication is abstracted and a type of static method is devised to examine deadlocks in such modes. The model has three forms with different complexity: sequential model, single-loop model and nested-loop model. Sequential model is a base for all models. Single-loop model must be treated with a special type of equation group and nested-loop model extends the methods for the other two models. A standard Java-based software framework originated from these methods is constructed for determining whether MPI programs are free from synchronization communication deadlocks. Our practice shows the software framework is better than those tools using dynamic methods because it can dig out all synchronization communication deadlocks before an MPI-based program goes into running.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2019-03-16 00:00:00.000000"},
{"id":"449","title":"Even attention spring reflect among successful.","abstract":"We consider the operator of taking the $2p$th derivative of a function with zero boundary conditions for the function and its first $p-1$ derivatives at two distinct points. Our main result provides an asymptotic formula for the eigenvalues and resolves a question on the appearance of certain regular numbers in the eigenvalue sequences for $p=1$ and $p=3$.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2019-08-08 00:00:00.000000"},
{"id":"450","title":"Artist tax occur crime recently draw thousand.","abstract":"A discontinuous Galerkin method for the ideal 5 moment two-fluid plasma system is presented. The method uses a second or third order discontinuous Galerkin spatial discretization and a third order TVD Runge-Kutta time stepping scheme. The method is benchmarked against an analytic solution of a dispersive electron acoustic square pulse as well as the two-fluid electromagnetic shock and existing numerical solutions to the GEM challenge magnetic reconnection problem. The algorithm can be generalized to arbitrary geometries and three dimensions. An approach to maintaining small gauge errors based on error propagation is suggested.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2021-06-29 00:00:00.000000"},
{"id":"451","title":"Despite respond third bill wait citizen.","abstract":"The timed automata formalism is an important model for specifying and analysing real-time systems. Robustness is the correctness of the model in the presence of small drifts on clocks or imprecision in testing guards. A symbolic algorithm for the analysis of the robustness of timed automata has been implemented. In this paper, we re-analyse an industrial case lip synchronization protocol using the new robust reachability algorithm. This lip synchronization protocol is an interesting case because timing aspects are crucial for the correctness of the protocol. Several versions of the model are considered: with an ideal video stream, with anchored jitter, and with non-anchored jitter.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2018-07-11 00:00:00.000000"},
{"id":"452","title":"Smile body wear culture painting water position really.","abstract":"Understanding the query complexity for testing linear-invariant properties has been a central open problem in the study of algebraic property testing. Triangle-freeness in Boolean functions is a simple property whose testing complexity is unknown. Three Boolean functions $f_1$, $f_2$ and $f_3: \\mathbb{F}_2^k \\to \\{0, 1\\}$ are said to be triangle free if there is no $x, y \\in \\mathbb{F}_2^k$ such that $f_1(x) = f_2(y) = f_3(x + y) = 1$. This property is known to be strongly testable (Green 2005), but the number of queries needed is upper-bounded only by a tower of twos whose height is polynomial in $1 \/ \\epsislon$, where $\\epsislon$ is the distance between the tested function triple and triangle-freeness, i.e., the minimum fraction of function values that need to be modified to make the triple triangle free. A lower bound of $(1 \/ \\epsilon)^{2.423}$ for any one-sided tester was given by Bhattacharyya and Xie (2010). In this work we improve this bound to $(1 \/ \\epsilon)^{6.619}$. Interestingly, we prove this by way of a combinatorial construction called \\emph{uniquely solvable puzzles} that was at the heart of Coppersmith and Winograd's renowned matrix multiplication algorithm.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2017-04-15 00:00:00.000000"},
{"id":"453","title":"Reality perhaps million party.","abstract":"In this paper we propose a new data hiding technique. The new technique uses steganography and cryptography on images with a size of 256x256 pixels and an 8-bit grayscale format. There are design restrictions such as a fixed-size cover image, and reconstruction without error of the hidden image. The steganography technique uses a Haar-DWT (Discrete Wavelet Transform) with hard thresholding and LSB (Less Significant Bit) technique on the cover image. The algorithms used for compressing and ciphering the secret image are lossless JPG and AES, respectively. The proposed technique is used to generate a stego image which provides a double type of security that is robust against attacks. Results are reported for different thresholds levels in terms of PSNR.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2016-11-04 00:00:00.000000"},
{"id":"454","title":"Character compare energy leg while.","abstract":"This paper uses an alternative approach to study the monochromatic plane wave propagation within dielectric and conductor linear media of plane-parallel-faces. This approach introduces the time-averaged Poynting vector modulus as field variable. The conceptual implications of this formalism are that the nonequivalence between the time-averaged Poynting vector and the squared-field amplitude modulus is naturally manifested as a consequence of interface effects. Also, two practical implications are considered: first, the exact transmittance is compared with that given by the Beer's Law, employed commonly in experiments. The departure among them can be significative for certain material parameter values. Second, when the exact reflectance is studied for negative permittivity slabs, it is show that the high reflectance can be diminished if a small amount of absorption is present.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2019-04-08 00:00:00.000000"},
{"id":"455","title":"Our couple consider site heavy nothing.","abstract":"We present an ion kinetic model describing the ignition and burn of the deuterium-tritium fuel of inertial fusion targets. The analysis of the underlying physical model enables us to develop efficient numerical methods to simulate the creation, transport and collisional relaxation of fusion reaction products (alpha-particles) at a kinetic level. A two-energy-scale approach leads to a self-consistent modeling of the coupling between suprathermal alpha-particles and the thermal bulk of the imploding plasma. This method provides an accurate numerical treatment of energy deposition and transport processes involving suprathermal particles. The numerical tools presented here are validated against known analytical results. This enables us to investigate the potential role of ion kinetic effects on the physics of ignition and thermonuclear burn in inertial confinement fusion schemes.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2022-09-21 00:00:00.000000"},
{"id":"456","title":"Put food politics reduce goal air positive lay.","abstract":"Let X_1, ..., X_n be independent and identically distributed random vectors with a log-concave (Lebesgue) density f. We first prove that, with probability one, there exists a unique maximum likelihood estimator of f. The use of this estimator is attractive because, unlike kernel density estimation, the method is fully automatic, with no smoothing parameters to choose. Although the existence proof is non-constructive, we are able to reformulate the issue of computation in terms of a non-differentiable convex optimisation problem, and thus combine techniques of computational geometry with Shor's r-algorithm to produce a sequence that converges to the maximum likelihood estimate. For the moderate or large sample sizes in our simulations, the maximum likelihood estimator is shown to provide an improvement in performance compared with kernel-based methods, even when we allow the use of a theoretical, optimal fixed bandwidth for the kernel estimator that would not be available in practice. We also present a real data clustering example, which shows that our methodology can be used in conjunction with the Expectation--Maximisation (EM) algorithm to fit finite mixtures of log-concave densities. An R version of the algorithm is available in the package LogConcDEAD -- Log-Concave Density Estimation in Arbitrary Dimensions.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2016-09-20 00:00:00.000000"},
{"id":"457","title":"Without college short current.","abstract":"Sequential decision tasks with incomplete information are characterized by the exploration problem; namely the trade-off between further exploration for learning more about the environment and immediate exploitation of the accrued information for decision-making. Within artificial intelligence, there has been an increasing interest in studying planning-while-learning algorithms for these decision tasks. In this paper we focus on the exploration problem in reinforcement learning and Q-learning in particular. The existing exploration strategies for Q-learning are of a heuristic nature and they exhibit limited scaleability in tasks with large (or infinite) state and action spaces. Efficient experimentation is needed for resolving uncertainties when possible plans are compared (i.e. exploration). The experimentation should be sufficient for selecting with statistical significance a locally optimal plan (i.e. exploitation). For this purpose, we develop a probabilistic hill-climbing algorithm that uses a statistical selection procedure to decide how much exploration is needed for selecting a plan which is, with arbitrarily high probability, arbitrarily close to a locally optimal one. Due to its generality the algorithm can be employed for the exploration strategy of robust Q-learning. An experiment on a relatively complex control task shows that the proposed exploration strategy performs better than a typical exploration strategy.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2017-09-29 00:00:00.000000"},
{"id":"458","title":"Whatever receive white security.","abstract":"In this work, a novel quaternary algebra has been proposed that can be used to implement any quaternary logic function. Unlike other variants of quaternary algebra, this algebra is closely related to Boolean algebra and can be used to convert any binary function into quaternary without any significant modification. For this purpose, we have defined a set of quaternary operators and developed two ways to express any quaternary function mathematically. Finally, we have presented the design of several combinational logic circuits and compared these designs with several other variants of quaternary logic. Since a quaternary digit can contain as much information as a pair of binary digits, this new logic may be quite useful in the fields of communication and computing.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2019-09-24 00:00:00.000000"},
{"id":"459","title":"Send key window stage.","abstract":"We consider the following evolutionary Hamilton-Jacobi equation with initial condition: \\begin{equation*} \\begin{cases} \\partial_tu(x,t)+H(x,u(x,t),\\partial_xu(x,t))=0,\\\\ u(x,0)=\\phi(x), \\end{cases} \\end{equation*} where $\\phi(x)\\in C(M,\\mathbb{R})$. Under some assumptions on the convexity of $H(x,u,p)$ with respect to $p$ and the uniform Lipschitz of $H(x,u,p)$ with respect to $u$, we establish a variational principle and provide an intrinsic relation between viscosity solutions and certain minimal characteristics. By introducing an implicitly defined {\\it fundamental solution}, we obtain a variational representation formula of the viscosity solution of the evolutionary Hamilton-Jacobi equation. Moreover, we discuss the large time behavior of the viscosity solution of the evolutionary Hamilton-Jacobi equation and provide a dynamical representation formula of the viscosity solution of the stationary Hamilton-Jacobi equation with strictly increasing $H(x,u,p)$ with respect to $u$.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2019-06-09 00:00:00.000000"},
{"id":"460","title":"Especially everyone buy inside between behavior.","abstract":"Motivated by widely observed examples in nature, society and software, where groups of already related nodes arrive together and attach to an existing network, we consider network growth via sequential attachment of linked node groups, or graphlets. We analyze the simplest case, attachment of the three node V-graphlet, where, with probability alpha, we attach a peripheral node of the graphlet, and with probability (1-alpha), we attach the central node. Our analytical results and simulations show that tuning alpha produces a wide range in degree distribution and degree assortativity, achieving assortativity values that capture a diverse set of many real-world systems. We introduce a fifteen-dimensional attribute vector derived from seven well-known network properties, which enables comprehensive comparison between any two networks. Principal Component Analysis (PCA) of this attribute vector space shows a significantly larger coverage potential of real-world network properties by a simple extension of the above model when compared against a classic model of network growth.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2019-05-26 00:00:00.000000"},
{"id":"461","title":"Class friend perhaps miss.","abstract":"This is a semipopular introduction to the Special and General Theory of Relativity, with special emphasis on the geometrical aspects of both theories and their physical implications.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2019-02-02 00:00:00.000000"},
{"id":"462","title":"Company national glass area.","abstract":"The current document contains a brief description of a system for Reasoning about Actions and Change called PAL (Pertinence Action Language) which makes use of several reasoning properties extracted from a Temporal Expert Systems tool called Medtool.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2018-01-29 00:00:00.000000"},
{"id":"463","title":"Bed crime such whole stock would.","abstract":"We present a sensitive diffusion cloud chamber which does not require any radioactive sources. A major difference from a commonly used chamber is use of a heat sink as its bottom plate. A result of a performance test of the chamber is given.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2022-10-31 00:00:00.000000"},
{"id":"464","title":"Across bring ground.","abstract":"The effect of electron conditioning on commercially aluminium alloys 1100 and 6063 were investigated. Contrary to the assumption that electron conditioning, if performed long enough, can reduce and stabilize the SEY to low values ($\\leq 1.3$, value of many pure elements), the SEY of aluminium did not go lower than 1.8. In fact, it reincreases with continued electron exposure dose.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2017-03-23 00:00:00.000000"},
{"id":"465","title":"Billion put kid leg paper.","abstract":"SNePS is a logic- and network- based knowledge representation, reasoning, and acting system, based on a monotonic, paraconsistent, first-order term logic, with compositional intensional semantics. It has an ATMS-style facility for belief contraction, and an acting component, including a well-defined syntax and semantics for primitive and composite acts, as well as for ``rules'' that allow for acting in support of reasoning and reasoning in support of acting. SNePS has been designed to support natural language competent cognitive agents.   When the current version of SNePS detects an explicit contradiction, it interacts with the user, providing information that helps the user decide what to remove from the knowledge base in order to remove the contradiction. The forthcoming SNePS 2.6 will also do automatic belief contraction if the information in the knowledge base warrents it.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2020-08-30 00:00:00.000000"},
{"id":"466","title":"Improve area perform central fine.","abstract":"We present the MDS feature learning framework, in which multidimensional scaling (MDS) is applied on high-level pairwise image distances to learn fixed-length vector representations of images. The aspects of the images that are captured by the learned features, which we call MDS features, completely depend on what kind of image distance measurement is employed. With properly selected semantics-sensitive image distances, the MDS features provide rich semantic information about the images that is not captured by other feature extraction techniques. In our work, we introduce the iterated Levenberg-Marquardt algorithm for solving MDS, and study the MDS feature learning with IMage Euclidean Distance (IMED) and Spatial Pyramid Matching (SPM) distance. We present experiments on both synthetic data and real images --- the publicly accessible UIUC car image dataset. The MDS features based on SPM distance achieve exceptional performance for the car recognition task.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2015-06-04 00:00:00.000000"},
{"id":"467","title":"Fly which country seven.","abstract":"In this manuscript we present a brief life history of Ludwig Edward Boltzmann and his achivements. Particularly, we discuss his H-theorem, his work on entropy and statistical interpretation of second-law of thermodynamics. We point out his some other contributions in physics, characteristics of his work, his strong support on atomism, character of his personality and relationship with his students and final part of his life.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2021-07-28 00:00:00.000000"},
{"id":"468","title":"Use newspaper Congress try.","abstract":"A transition to Kraichnan ultimate regime of convection has been reported in very high Rayleigh numbers experiments, but not in all of them. These apparently contradictory results can be explained by a recent phenomenological model which accounts for the non-ideality of the plate thermal properties [Chill\\`{a} et al, Physics of Fluids 16:2452 (2004)]. In this paper, we present a direct test of this model, using a low conductivity plate. We found an unaltered transition, not compatible with the model's predictions.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2019-05-14 00:00:00.000000"},
{"id":"469","title":"Race itself teach protect person.","abstract":"Realistic mobility models can demonstrate more precise evaluation results because their parameters are closer to the reality. In this paper a realistic Fuzzy Mobility Model has been proposed. This model has rules which is changeable depending on nodes and environment conditions. This model is more complete and precise than the other mobility models and this is the advantage of this model. After simulation, it was found out that not only considering nodes movement as being imprecise (fuzzy) has a positive effects on most of ad hoc network parameters, but also, more importantly as they are closer to the real world condition, they can have a more positive effect on the implementation of ad hoc network protocols.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2019-02-14 00:00:00.000000"},
{"id":"470","title":"Report light still power firm watch.","abstract":"We study the following rigidity problem in symplectic geometry:can one displace a Lagrangian submanifold from a hypersurface? We relate this to the Arnold Chord Conjecture, and introduce a refined question about the existence of relative leaf-wise intersection points, which are the Lagrangian-theoretic analogue of the notion of leaf-wise intersection points defined by Moser. Our tool is Lagrangian Rabinowitz Floer homology, which we define first for Liouville domains and exact Lagrangian submanifolds with Legendrian boundary. We then extend this to the `virtually contact' setting. By means of an Abbondandolo-Schwarz short exact sequence we compute the Lagrangian Rabinowitz Floer homology of certain regular level sets of Tonelli Hamiltonians of sufficiently high energy in twisted cotangent bundles, where the Lagrangians are conormal bundles. We deduce that in this situation a generic Hamiltonian diffeomorphism has infinitely many relative leaf-wise intersection points.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2017-11-03 00:00:00.000000"},
{"id":"471","title":"Evidence reason let notice someone.","abstract":"Some low-energy three-body muon- and electron-transfer processes are considered within the Faddeev-Hahn formulation using two-, six-, and ten-state close-coupling approximation. We test our approach in bound-state problems for systems H$_2^+$ and ($\\mu^-$dd)$^+$ within six- and ten-state schemes, where $d$ is a deuteron and $\\mu$ a muon. We present results in the six-state model for muonium formation from hydrogen. We also present results for muon-transfer rates from muonic hydrogen isotopes to bare nuclei S$^{16}$ and Ar$^{18}$ in reasonable agreement with experiment. For these heavier targets a polarization potential is included and Coulomb potentials are treated exactly without approximation or cut off.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2021-09-27 00:00:00.000000"},
{"id":"472","title":"Must lead single group political determine.","abstract":"We prove two new reverse Cauchy--Schwarz inequalities of additive and multiplicative types in a space equipped with a positive sesquilinear form with values in a C*-algebra. We apply our results to get some norm and integral inequalities. As a consequence, we improve a celebrated reverse Cauchy--Schwarz inequality due to G Polya and G. Szego.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2015-01-05 00:00:00.000000"},
{"id":"473","title":"Kitchen quality bit know peace behind travel.","abstract":"Typical arguments against scientific misconduct generally fail to support current policies on research fraud: they may not prove wrong what is usually considered research misconduct and they tend to make wrong things that are not normally seen as scientific fraud, in particular honest errors. I also point out that sanctions are not consistent with the reasons why scientific fraud is supposed to be wrong either. Moreover honestly seeking truth should not be contrived as a moral rule -- it is instead a necessary condition for work to qualify as scientific.   Keywords: cheating; ethics; fabrication; falsification; integrity; plagiarism; research fraud; scientific misconduct.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2019-08-05 00:00:00.000000"},
{"id":"474","title":"Increase risk government kind marriage see degree enter.","abstract":"The article considers an opportunity of electrodynamics accelerating the magnetic dipoles at initial velocity six hundred meters per second, which is the magnetic dipole gain after pre-gas-dynamic acceleration to finite velocity eight and half kilometers per second. The acceleration length is more than two kilometers. When selecting the drag coefficient and the lift coefficient equal to one hundredth, the dipoles rise to height ten kilometers during a period of time fourteen seconds, thus reaching the vertical velocity one kilometer per second and reducing the forward velocity till seven and a half kilometer per second. The magnetic dipoles reach flight range twelve thousand three hundred kilometers.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2017-09-27 00:00:00.000000"},
{"id":"475","title":"Social into bit explain food example wife.","abstract":"The modeling of cascade processes in multi-agent systems in the form of complex networks has in recent years become an important topic of study due to its many applications: the adoption of commercial products, spread of disease, the diffusion of an idea, etc. In this paper, we begin by identifying a desiderata of seven properties that a framework for modeling such processes should satisfy: the ability to represent attributes of both nodes and edges, an explicit representation of time, the ability to represent non-Markovian temporal relationships, representation of uncertain information, the ability to represent competing cascades, allowance of non-monotonic diffusion, and computational tractability. We then present the MANCaLog language, a formalism based on logic programming that satisfies all these desiderata, and focus on algorithms for finding minimal models (from which the outcome of cascades can be obtained) as well as how this formalism can be applied in real world scenarios. We are not aware of any other formalism in the literature that meets all of the above requirements.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2022-04-22 00:00:00.000000"},
{"id":"476","title":"Worry military more half.","abstract":"We discuss the first three particle colliders : AdA, VEP-1 and CBX","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2016-05-18 00:00:00.000000"},
{"id":"477","title":"Wonder plan price measure remember success home.","abstract":"We study the geodesics in a planar chessboard structure with two values 1 and $\\beta>1$. The results for a fixed structure allow us to infer the properties of the Finsler metrics obtained, with an homogenization procedure, as limit of oscillating chessboard structures.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2015-02-23 00:00:00.000000"},
{"id":"478","title":"Serious herself lay major mention effect effort.","abstract":"As part of a general study of the time-dependent local density approximation (TDLDA), we here report calculations of optical activity of chiral molecules. The theory automatically satisfies sum rules and the Kramers-Kronig relation between circular dichroism and optical rotatory power. We find that the theory describes the measured circular dichroism of the lowest states in methyloxirane with an accuracy of about a factor of two. In the chiral fullerene C_76 the TDLDA provides a consistent description of the optical absorption spectrum, the circular dichroism spectrum, and the optical rotatory power, except for an overall shift of the theoretical spectrum.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2020-12-30 00:00:00.000000"},
{"id":"479","title":"Likely catch role affect thus.","abstract":"We propose a scenario that involves a stationary observer who detects a point like source of light moving with constant velocity at a constant altitude, using a telescope and a frequency-meter. We derive a formula for the angular velocity at which we should rotate the axis of the telescope and a formula that relates the proper period at which the source emits successive wave crests and the proper period at which the stationary observer receives them","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2019-12-17 00:00:00.000000"},
{"id":"480","title":"Theory she left where kid person.","abstract":"In this thesis I will give a formal definition of side effects. I will do so by modifying a system for modelling program instructions and program states, Quantified Dynamic Logic, to a system called DLAf (for Dynamic Logic with Assignments as Formulas), which in contrast to QDL allows assignments in formulas and makes use of short-circuit evaluation. I will show the underlying logic in those formulas to be a variant of short-circuit logic called repetition-proof short-circuit logic.   Using DLAf I will define the actual and the expected evaluation of a single instruction. The side effects are then defined to be the difference between the two. I will give rules for composing those side effects in single instructions, thus scaling up our definition of side effects to a definition of side effects in deterministic \\dlaf-programs. Using this definition I will give a classification of side effects, introducing as most important class that of marginal side effects. Finally, I will show how to use our system for calculating the side effects in a real system such as Program Algebra (PGA).","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2017-03-12 00:00:00.000000"},
{"id":"481","title":"Include fly though so by candidate fine.","abstract":"Deformation-induced lateral migration of a bubble slowly rising near a vertical plane wall in a stagnant liquid is numerically and theoretically investigated. In particular, our focus is set on a situation with a small clearance $c$ between the bubble interface and the wall. Motivated by the fact that experimentally measured migration velocity (Takemura et al. (2002, J. Fluid Mech. {\\bf 461}, 277)) is higher than the velocity estimated by the available analytical solution (Magnaudet et al. (2003, J. Fluid Mech. {\\bf 476}, 115)) using the Fax\\'{e}n mirror image technique for $\\kappa(=a\/(a+c))\\ll 1$ (here $a$ is the bubble radius), when the clearance parameter $\\epsilon(=c\/a)$ is comparable to or smaller than unit, the numerical analysis based on the boundary-fitted finite-difference approach by solving the Stokes equation is performed to complement the experiment. To improve the understandings of a role of the squeezing flow within the bubble-wall gap, the theoretical analysis based on a soft-lubrication approach (Skotheim & Mahadevan (2004, Phys. Rev. Lett. {\\bf 92}, 245509)) is also performed. The present analyses demonstrate the migration velocity scales $\\propto{\\rm Ca}\\ \\epsilon^{-1}V_{B1}$ (here, $V_{B1}$ and ${\\rm Ca}$ denote the rising velocity and the capillary number, respectively) in the limit of $\\epsilon\\to 0$.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2021-09-17 00:00:00.000000"},
{"id":"482","title":"Politics know yard common wait have keep.","abstract":"I prove that the generic type of the free nonabelian group has infinite weight (strengthening non superstability of the free group).","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2021-02-06 00:00:00.000000"},
{"id":"483","title":"Store crime maintain field staff lay.","abstract":"Today, flash memory are strongly used in the embedded system domain. NAND flash memories are the building block of main secondary storage systems. Such memories present many benefits in terms of data density, I\/O performance, shock resistance and power consumption. Nevertheless, flash does not come without constraints: the write \/ erase granularity asymmetry and the limited lifetime bring the need for specific management. This can be done through the operating system using dedicated Flash File Systems (FFSs). In this document, we present general concepts about FFSs, and implementations example that are JFFS2, YAFFS2 and UBIFS, the most commonly used flash file systems. Then we give performance evaluation results for these FFSs.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2022-01-22 00:00:00.000000"},
{"id":"484","title":"Ready provide interview else interview life.","abstract":"Cellular automata are often used to model systems in physics, social sciences, biology that are inherently asynchronous. Over the past 20 years, studies have demonstrated that the behavior of cellular automata drastically changed under asynchronous updates. Still, the few mathematical analyses of asynchronism focus on one-dimensional probabilistic cellular automata, either on single examples or on specific classes. As for other classic dynamical systems in physics, extending known methods from one- to two-dimensional systems is a long lasting challenging problem.   In this paper, we address the problem of analysing an apparently simple 2D asynchronous cellular automaton: 2D Minority where each cell, when fired, updates to the minority state of its neighborhood. Our experiments reveal that in spite of its simplicity, the minority rule exhibits a quite complex response to asynchronism. By focusing on the fully asynchronous regime, we are however able to describe completely the asymptotic behavior of this dynamics as long as the initial configuration satisfies some natural constraints. Besides these technical results, we have strong reasons to believe that our techniques relying on defining an energy function from the transition table of the automaton may be extended to the wider class of threshold automata.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2015-08-14 00:00:00.000000"},
{"id":"485","title":"Television career also agree.","abstract":"Let $H^{\\infty}(E)$ be the Hardy algebra of a $W^{*}$-correspondence $E$ over a $W^{*}$-algebra $M$. Then the ultraweakly continuous completely contractive representations of $H^{\\infty}(E)$ are parametrized by certain sets $\\mathcal{AC}(\\sigma)$ indexed by $NRep(M)$ - the normal *-representations $\\sigma$ of $M$. Each set $\\mathcal{AC}(\\sigma)$ has analytic structure, and each element $F\\in H^{\\infty}(E)$ gives rise to an analytic operator-valued function $\\hat{F}_{\\sigma}$ on $\\mathcal{AC}(\\sigma)$ that we call the $\\sigma$-Berezin transform of $F$. The sets ${\\mathcal{AC}(\\sigma)}_{\\sigma\\in\\Sigma}$ and the family of functions ${\\hat{F}_{\\sigma}}_{\\sigma\\in\\Sigma}$ exhibit \"matricial structure\" that was introduced by Joeseph Taylor in his work on noncommutative spectral theory in the early 1970s. Such structure has been exploited more recently in other areas of free analysis and in the theory of linear matrix inequalities. Our objective here is to determine the extent to which the matricial structure characterizes the Berezin transforms.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2020-11-12 00:00:00.000000"},
{"id":"486","title":"Some sea card pattern.","abstract":"Three limits to the physical world (quantum physics, gravity and dark energy) are presented on a triangular diagram having as summits the Planck scale, the Universe and a neutrino-like object.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2018-09-20 00:00:00.000000"},
{"id":"487","title":"Condition people cut conference up loss individual.","abstract":"This paper presents the Anisotropic selection scheme for cellular Genetic Algorithms (cGA). This new scheme allows to enhance diversity and to control the selective pressure which are two important issues in Genetic Algorithms, especially when trying to solve difficult optimization problems. Varying the anisotropic degree of selection allows swapping from a cellular to an island model of parallel genetic algorithm. Measures of performances and diversity have been performed on one well-known problem: the Quadratic Assignment Problem which is known to be difficult to optimize. Experiences show that, tuning the anisotropic degree, we can find the accurate trade-off between cGA and island models to optimize performances of parallel evolutionary algorithms. This trade-off can be interpreted as the suitable degree of migration among subpopulations in a parallel Genetic Algorithm.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2017-07-13 00:00:00.000000"},
{"id":"488","title":"Lawyer decade whatever note.","abstract":"Network penetration testing identifies the exploits and vulnerabilities those exist within computer network infrastructure and help to confirm the security measures. The objective of this paper is to explain methodology and methods behind penetration testing and illustrate remedies over it, which will provide substantial value for network security Penetration testing should model real world attacks as closely as possible. An authorized and scheduled penetration testing will probably detected by IDS (Intrusion Detection System). Network penetration testing is done by either or manual automated tools. Penetration test can gather evidence of vulnerability in the network. Successful testing provides indisputable evidence of the problem as well as starting point for prioritizing remediation. Penetration testing focuses on high severity vulnerabilities and there are no false positive.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2021-01-29 00:00:00.000000"},
{"id":"489","title":"Break structure toward interview firm focus minute.","abstract":"Group and individual solutions are considered for hard problems such as satisfiability problem. Time-space trade-off in a structured active memory provides means to achieve lower time complexity for solutions of these problems.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2019-03-28 00:00:00.000000"},
{"id":"490","title":"Serious yourself let close.","abstract":"Multi-fractal model for dissipation field has been used to provide a detailed structure for the critical exponent \\sigma describing the scaling form of dissipation \\epsilon that appears to exhibit an interesting universality covering radically different hydrodynamic fully developed turbulence (FDT) systems. This result also appears to provide a consistent framework for classification of dissipation field into critical, subcritical and supercritical cases. Some FDT problems that exemplify these cases are discussed.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2020-04-14 00:00:00.000000"},
{"id":"491","title":"Nation this different organization series.","abstract":"We show that the signal-processing paradigm known as compressed sensing (CS) is applicable to genome-wide association studies (GWAS) and genomic selection (GS). The aim of GWAS is to isolate trait-associated loci, whereas GS attempts to predict the phenotypic values of new individuals on the basis of training data. CS addresses a problem common to both endeavors, namely that the number of genotyped markers often greatly exceeds the sample size. We show using CS methods and theory that all loci of nonzero effect can be identified (selected) using an efficient algorithm, provided that they are sufficiently few in number (sparse) relative to sample size. For heritability h2 = 1, there is a sharp phase transition to complete selection as the sample size is increased. For heritability values less than one, complete selection can still occur although the transition is smoothed. The transition boundary is only weakly dependent on the total number of genotyped markers. The crossing of a transition boundary provides an objective means to determine when true effects are being recovered; we discuss practical methods for detecting the boundary. For h2 = 0.5, we find that a sample size that is thirty times the number of nonzero loci is sufficient for good recovery.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2016-03-31 00:00:00.000000"},
{"id":"492","title":"Coach letter central.","abstract":"In this letter, we use quantum quasi-shuffle algebras to construct Rota-Baxter algebras, as well as tridendriform algebras. We also propose the notion of braided Rota-Baxter algebras, which is the relevant object of Rota-Baxter algebras in a braided tensor category. Examples of such new algebras are provided by using quantum multi-brace algebras in a category of Yetter-Drinfeld modules.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2019-10-07 00:00:00.000000"},
{"id":"493","title":"Several quite believe none.","abstract":"In ubiquitous computing devices, users tend to store some valuable information in their device. Even though the device can be borrowed by the other user temporarily, it is not safe for any user to borrow or lend the device as it may cause private data of the user to be public. To safeguard the user data and also to preserve user privacy we propose and model the technique of ownership authentication transfer. The user who is willing to sell the device has to transfer the ownership of the device under sale. Once the device is sold and the ownership has been transferred, the old owner will not be able to use that device at any cost. Either of the users will not be able to use the device if the process of ownership has not been carried out properly. This also takes care of the scenario when the device has been stolen or lost, avoiding the impersonation attack. The aim of this paper is to model basic process of proposed ownership authentication transfer protocol and check its safety properties by representing it using CSP and model checking approach. For model checking we have used a symbolic model checker tool called NuSMV. The safety properties of ownership transfer protocol has been modeled in terms of CTL specification and it is observed that the system satisfies all the protocol constraint and is safe to be deployed.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2016-05-02 00:00:00.000000"},
{"id":"494","title":"Find rate theory stage describe choose officer.","abstract":"Google's Android is a comprehensive software framework for mobile communication devices (i.e., smartphones, PDAs). The Android framework includes an operating system, middleware and a set of key applications. The incorporation of integrated access services to the Internet on such mobile devices, however, increases their exposure to damages inflicted by various types of malware. This paper provides a comprehensive security assessment of the Android framework and the security mechanisms incorporated into it. A methodological qualitative risk analysis that we conducted identifies the high-risk threats to the framework and any potential danger to information or to the system resulting from vulnerabilities that have been uncovered and exploited. Our review of current academic and commercial solutions in the area of smartphone security yields a list of applied and recommended defense mechanisms for hardening mobile devices in general and the Android in particular. Lastly, we present five major (high-risk) threats to the Android framework and propose security solutions to mitigate them. We conclude by proposing a set of security mechanisms that should be explored and introduced into Android-powered devices.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2020-06-16 00:00:00.000000"},
{"id":"495","title":"Coach carry candidate along.","abstract":"Being an integral part of the network traffic, nowadays it's vital to design robust mechanisms to provide QoS for multimedia applications. The main goal of this paper is to provide an efficient solution to support content-aware video transmission mechanism with buffer underflow avoidance at the receiver in multipath networks. Towards this, we introduce a content-aware time-varying utility function, where the quality impacts of video content is incorporated into its definition. Using the proposed utility function, we formulate a multipath Dynamic Network Utility Maximization (DNUM) problem for the rate allocation of video streams, where it takes into account QoS demand of video streams in terms of buffer underflow avoidance. Finally, using primal-dual method, we propose a distributed solution that optimally allocates the shared bandwidth to video streams. The numerical examples demonstrate the efficacy of the proposed content-aware rate allocation algorithm for video sources in both single and multiple path network models.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2021-04-18 00:00:00.000000"},
{"id":"496","title":"Ability much option.","abstract":"Examples of small contingency tables on binary random variables with large integer programming gaps on the lower bounds of cell entries were constructed by Sullivant. We argue here that the margins for which these constructed large gaps occur are rarely encountered, thus reopening the question of whether linear programming is an effective heuristic for detecting disclosures when releasing margins of multi-way tables. The notion of ``rarely encountered'' is made precise through the language of standard pairs.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2020-04-13 00:00:00.000000"},
{"id":"497","title":"Around effect foreign suddenly special various wait.","abstract":"The purpose of the New York Workshop on Computer, Earth and Space Sciences is to bring together the New York area's finest Astronomers, Statisticians, Computer Scientists, Space and Earth Scientists to explore potential synergies between their respective fields. The 2011 edition (CESS2011) was a great success, and we would like to thank all of the presenters and participants for attending. This year was also special as it included authors from the upcoming book titled \"Advances in Machine Learning and Data Mining for Astronomy\". Over two days, the latest advanced techniques used to analyze the vast amounts of information now available for the understanding of our universe and our planet were presented. These proceedings attempt to provide a small window into what the current state of research is in this vast interdisciplinary field and we'd like to thank the speakers who spent the time to contribute to this volume.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2018-01-08 00:00:00.000000"},
{"id":"498","title":"Beat arrive such stage base tough.","abstract":"We study the complexity of the maximum coverage problem, restricted to set systems of bounded VC-dimension. Our main result is a fixed-parameter tractable approximation scheme: an algorithm that outputs a $(1-\\eps)$-approximation to the maximum-cardinality union of $k$ sets, in running time $O(f(\\eps,k,d)\\cdot poly(n))$ where $n$ is the problem size, $d$ is the VC-dimension of the set system, and $f(\\eps,k,d)$ is exponential in $(kd\/\\eps)^c$ for some constant $c$. We complement this positive result by showing that the function $f(\\eps,k,d)$ in the running-time bound cannot be replaced by a function depending only on $(\\eps,d)$ or on $(k,d)$, under standard complexity assumptions.   We also present an improved upper bound on the approximation ratio of the greedy algorithm in special cases of the problem, including when the sets have bounded cardinality and when they are two-dimensional halfspaces. Complementing these positive results, we show that when the sets are four-dimensional halfspaces neither the greedy algorithm nor local search is capable of improving the worst-case approximation ratio of $1-1\/e$ that the greedy algorithm achieves on arbitrary instances of maximum coverage.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2019-01-16 00:00:00.000000"},
{"id":"499","title":"Billion record create time pressure.","abstract":"The celebrated Kadison--Sakai theorem states that every derivation on a von Neumann algebra is inner. In this paper, we prove this theorem for ultraweakly continuous *-\\sigma-derivations, where \\sigma is an ultraweakly continuous surjective *-linear mapping. We decompose a $\\sigma$-derivation into a sum of an inner \\sigma-derivation and a multiple of a homomorphism. The so-called *-(\\sigma,\\tau)-derivations are also discussed.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2015-02-15 00:00:00.000000"},
{"id":"500","title":"Fear bad edge.","abstract":"Cryptography algorithm standards play a key role both to the practice of information security and to cryptography theory research. Among them, the MQV and HMQV protocols ((H)MQV, in short) are a family of (implicitly authenticated) Diffie-Hellman key-exchange (DHKE) protocols that are widely standardized and deployed. In this work, from some new perspectives and approaches and under some new design rationales and insights, we develop a new family of practical implicitly authenticated DHKE protocols, which enjoy notable performance among security, privacy, efficiency and easy deployment. We make detailed comparisons between our new DHKE protocols and (H)MQV, showing that the newly developed protocols outperform HMQV in most aspects. Along the way, guided by our new design rationales, we also identify a new vulnerability (H)MQV, which brings some new perspectives (e.g., computational fairness) to the literature.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2022-09-09 00:00:00.000000"},
{"id":"501","title":"Hold various reflect until plant customer national.","abstract":"The analytic properties of Nilsson's Modified Oscillator (MO), which was first introduced in nuclear structure, and of the recently introduced, based on quantum algebraic techniques, 3-dimensional q-deformed harmonic oscillator (3-dim q-HO) with Uq(3) > SOq(3) symmetry, which is known to reproduce correctly in terms of only one parameter the magic numbers of alkali clusters up to 1500 (the expected limit of validity for theories based on the filling of electronic shells), are considered. Exact expressions for the total energy of closed shells are determined and compared among them. Furthermore, the systematics of the appearance of supershells in the spectra of the two oscillators is considered, showing that the 3-dim q-HO correctly predicts the first supershell closure in alkali clusters without use of any extra parameter.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2018-02-07 00:00:00.000000"},
{"id":"502","title":"Perhaps speak star step star.","abstract":"In 1760, Leonhard Euler began to write beautiful Letters to a German Princess on Diverse Subjects of Physics and Philosophy. Much has been written about Euler and his work, but we wonder, who was the princess? How did she become involved with the greatest mathematician of her time? The princess was a fifteen year old named Friederike Charlotte von Brandenburg-Schwedt. In this article we explore her story and the nature of the letters.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2018-06-19 00:00:00.000000"},
{"id":"503","title":"We feel of senior magazine life.","abstract":"We define in a global manner the notion of a connective structure for a gerbe on a space X. When the gerbe is endowed with trivializing data with respect to an open cover of X, we describe this connective structure in two separate ways, which extend from abelian to general gerbes the corresponding descriptions due to J.- L. Brylinski and N. Hitchin. We give a global definition of the 3-curvature of this connective structure as a 3-form on X with values in the Lie stack of the gauge stack of the gerbe. We also study this notion locally in terms of more traditional Lie algebra-valued 3-forms. The Bianchi identity, which the curvature of a connection on a principal bundle satisfies, is replaced here by a more elaborate equation.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2018-01-29 00:00:00.000000"},
{"id":"504","title":"International control account none likely.","abstract":"The difference between surface and deep structures of a spreadsheet is a major cause of difficulty in checking spreadsheets. After a brief survey of current methods of checking (or debugging) spreadsheets, new visual methods of showing the deep structures are presented. Illustrations are given on how these visual methods can be employed in various interactive local and global debugging strategies.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2016-08-16 00:00:00.000000"},
{"id":"505","title":"Pressure likely light suddenly involve race school common.","abstract":"A large class of dense linear algebra operations, such as LU decomposition or inversion of a triangular matrix, are usually performed by blocked algorithms. For one such operation, typically, not only one but many algorithmic variants exist; depending on computing architecture, libraries and problem size, each variant attains a different performances. We propose methods and tools to rank the algorithmic variants according to their performance for a given scenario without executing them.   For this purpose, we identify the routines upon which the algorithms are built. A first tool - the Sampler - measures the performance of these routines. Using the Sampler, a second tool models their performance. The generated models are then used to predict the performance of the considered algorithms. For a given scenario, these predictions allow us to correctly rank the algorithms according to their performance without executing them. With the help of the same tools, algorithmic parameters such as block-size can be optimally tuned.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2022-11-27 00:00:00.000000"},
{"id":"506","title":"Himself determine last charge budget detail machine artist.","abstract":"The \"simplicial complexes\" and \"join\" (*) today used within combinatorics aren't the classical concepts, cf. Spanier (1966) p. 108-9, but, exept for \\emptyset, complexes having {\\emptyset} as a subcomplex resp. \\Sigma1 * \\Sigma2 := {\\sigma1 \\cup \\sigma2 | \\sigmai \\in \\Sigmai} implying a tacit change of unit element w.r.t. the join operation, from \\emptyset to {\\emptyset}. Extending the classical realization functor to this category of simplicial complexes we end up with a \"restricted\" category of topological spaces, \"containing\" the classical and where the classical (co)homology theory, as well as the ad-hoc invented reduced versions, automatically becomes obsolete, in favor of a unifying and more algebraically efficient theory.   This very modest category modification greatly improves the interaction between algebra and topology. E.g. it makes it possible to calculate the homology groups of a topological pair-join, expressed in the relative factor groups, leading up to a truly simple boundary formula for joins of manifolds: Bd(X1 * X2) = ((BdX1 * X2) \\cup (X1 * BdX2)), the product counterpart of which is true also classically. It is also easily seen that no finite simplicial n-manifold has an (n-2)-dimensional boundary, cf. Cor. 1 p. 26, and that simplicial homology manifolds with the integers as koefficient module are all locally orientable, cf. Cor. 2 p. 29.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2021-08-31 00:00:00.000000"},
{"id":"507","title":"Girl third leader network.","abstract":"IT industries in current scenario have to struggle effectively in terms of cost, quality, service or innovation for their subsistence in the global market. Due to the swift transformation of technology, software industries owe to manage a large set of data having precious information hidden. Data mining technique enables one to effectively cope with this hidden information where it can be applied to code optimization, fault prediction and other domains which modulates the success nature of software projects. Additionally, the efficiency of the product developed further depends upon the quality of the project personnel. The position of the paper therefore is to explore potentials of project personnel in terms of their competency and skill set and its influence on quality of project. The above mentioned objective is accomplished using a Bayesian classifier in order to capture the pattern of human performance. By this means, the hidden and valuable knowledge discovered in the related databases will be summarized in the statistical structure. This mode of predictive study enables the project managers to reduce the failure ratio to a significant level and improve the performance of the project using the right choice of project personnel.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2021-02-25 00:00:00.000000"},
{"id":"508","title":"Successful agreement recent they man class position.","abstract":"A nonadiabatic scheme for the description of the coupled electron and nuclear motions in the ozone molecule was proposed recently. An initial coherent nonstationary state was prepared as a superposition of the ground state and the excited Hartley band. In this situation neither the electrons nor the nuclei are in a stationary state. The multiconfiguration time dependent Hartree method was used to solve the coupled nuclear quantum dynamics in the framework of the adiabatic separation of the time-dependent Schr\\\"odinger equation. The resulting wave packet shows an oscillation of the electron density between the two chemical bonds. As a first step for probing the electronic motion we computed the time-dependent molecular dipole and the Dyson orbitals. The latter play an important role in the explanation of the photoelectron angular distribution. Calculations of the Dyson orbitals are presented both for the time-independent as well as the time-dependent situations. We limited our description of the electronic motion to the Franck-Condon region only due to the localization of the nuclear wave packets around this point during the first 5-6 fs.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2016-08-04 00:00:00.000000"},
{"id":"509","title":"One religious vote free.","abstract":"Bound states of the Hamiltonian describing a quantum particle living on three dimensional straight strip of width $d$ are investigated. We impose the Neumann boundary condition on the two concentric windows of the radii $a$ and $ b$ located on the opposite walls and the Dirichlet boundary condition on the remaining part of the boundary of the strip. We prove that such a system exhibits discrete eigenvalues below the essential spectrum for any $a,b>0$. When $a$ and $b$ tend to the infinity, the asymptotic of the eigenvalue is derived. A comparative analysis with the one-window case reveals that due to the additional possibility of the regulating energy spectrum the anticrossing structure builds up as a function of the inner radius with its sharpness increasing for the larger outer radius. Mathematical and physical interpretation of the obtained results is presented; namely, it is derived that the anticrossings are accompanied by the drastic changes of the wave function localization. Parallels are drawn to the other structures exhibiting similar phenomena; in particular, it is proved that, contrary to the two-dimensional geometry, at the critical Neumann radii true bound states exist.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2016-01-21 00:00:00.000000"},
{"id":"510","title":"Operation with suddenly interview hour east next build.","abstract":"We define a general framework of partition games for formulating two-player pebble games over finite structures. We show that one particular such game, which we call the invertible-map game, yields a family of polynomial-time approximations of graph isomorphism that is strictly stronger than the well-known Weisfeiler-Lehman method. The general framework we introduce includes as special cases the pebble games for finite-variable logics with and without counting. It also includes a matrix-equivalence game, introduced here, which characterises equivalence in the finite-variable fragments of matrix-rank logic. We show that the equivalence defined by the invertible-map game is a refinement of the equivalence defined by each of these games for finite-variable logics.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2016-08-06 00:00:00.000000"},
{"id":"511","title":"Election sell modern picture sense.","abstract":"One is expressed as the sum of the reciprocals of a certain set of integers. We give an elegant proof to the fact applying the polynomial theorem and basic calculus.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2018-01-19 00:00:00.000000"},
{"id":"512","title":"Information now for air maintain.","abstract":"We numerically investigate the saturation of the hydromagnetic instabilities of a magnetized spherical Couette flow. Previous simulations [Hollerbach, 2009] demonstrated region where the axisymmetric flow, calculated from a 2-D simulation, was linearly unstable to nonaxisymmetric perturbations. Full, nonlinear, 3d simulations [Hollerbach 2009, Travnikov 2011] showed that the saturated state would consist only of harmonics of one azimuthal wave number, though there were bifurcations and transitions as nondimensional parameters (Re, Ha) were varied. Here, the energy transfer between different aziumthal modes is formulated as a network. This demonstrates a mechanism or the saturation of one mode and for the suppression of other unstable modes. A given mode grows by extracting energy from the axisymmetric flow, and then saturates as the energy transfer to its second harmonic equals this inflow. At the same time, this mode suppresses other unstable modes by facilitating an energy transfer to linearly stable modes.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2015-08-24 00:00:00.000000"},
{"id":"513","title":"Safe race although concern catch.","abstract":"Streaming applications often tolerate bit errors in their received data well. This is contrasted by the enforcement of correctness of the packet headers and payload by network protocols. We investigate a solution for the Real-time Transport Protocol (RTP) that is tolerant to errors by accepting erroneous data. It passes potentially corrupted stream data payloads to the codecs. If errors occur in the header, our solution recovers from these by leveraging the known state and expected header values for each stream. The solution is fully receiver-based and incrementally deployable, and as such requires neither support from the sender nor changes to the RTP specification. Evaluations show that our header error recovery scheme can recover from almost all errors, with virtually no erroneous recoveries, up to bit error rates of about 10%.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2016-12-23 00:00:00.000000"},
{"id":"514","title":"Hit worker fill most what.","abstract":"We give algebraic characterizations of the properties of autonomy and of controllability of behaviours of spatially invariant dynamical systems, consisting of distributional solutions, that are periodic in the spatial variables, to a system pf partial differential equations corresponding to a polynomial matrix M in (C[\\xi_1,...,\\xi_d, \\tau])^{m \\times n}.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2020-03-17 00:00:00.000000"},
{"id":"515","title":"Offer fight TV list new cut you.","abstract":"Obtaining compact and discriminative features is one of the major challenges in many of the real-world image classification tasks such as face verification and object recognition. One possible approach is to represent input image on the basis of high-level features that carry semantic meaning which humans can understand. In this paper, a model coined deep attribute network (DAN) is proposed to address this issue. For an input image, the model outputs the attributes of the input image without performing any classification. The efficacy of the proposed model is evaluated on unconstrained face verification and real-world object recognition tasks using the LFW and the a-PASCAL datasets. We demonstrate the potential of deep learning for attribute-based classification by showing comparable results with existing state-of-the-art results. Once properly trained, the DAN is fast and does away with calculating low-level features which are maybe unreliable and computationally expensive.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2016-10-27 00:00:00.000000"},
{"id":"516","title":"Week throw much letter magazine some.","abstract":"A class of multivariate mixed survival models for continuous and discrete time with a complex covariance structure is introduced in a context of quantitative genetic applications. The methods introduced can be used in many applications in quantitative genetics although the discussion presented concentrates on longevity studies. The framework presented allows to combine models based on continuous time with models based on discrete time in a joint analysis. The continuous time models are approximations of the frailty model in which the hazard function will be assumed to be piece-wise constant. The discrete time models used are multivariate variants of the discrete relative risk models. These models allow for regular parametric likelihood-based inference by exploring a coincidence of their likelihood functions and the likelihood functions of suitably defined multivariate generalized linear mixed models. The models include a dispersion parameter, which is essential for obtaining a decomposition of the variance of the trait of interest as a sum of parcels representing the additive genetic effects, environmental effects and unspecified sources of variability; as required in quantitative genetic applications. The methods presented are implemented in such a way that large and complex quantitative genetic data can be analyzed.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2020-01-14 00:00:00.000000"},
{"id":"517","title":"Customer drop pull bit sign.","abstract":"We study convergence of the following discrete-time non-linear dynamical system: n agents are located in R^d and at every time step, each moves synchronously to the average location of all agents within a unit distance of it. This popularly studied system was introduced by Krause to model the dynamics of opinion formation and is often referred to as the Hegselmann-Krause model. We prove the first polynomial time bound for the convergence of this system in arbitrary dimensions. This improves on the bound of n^{O(n)} resulting from a more general theorem of Chazelle. Also, we show a quadratic lower bound and improve the upper bound for one-dimensional systems to O(n^3).","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2015-12-12 00:00:00.000000"},
{"id":"518","title":"Food popular long fall.","abstract":"Bolometers are phonon mediated detectors used in particle physics experiments to search for rare processes, such as neutrinoless double beta decay and dark matter interactions. They feature an excellent energy resolution, which is a few keV over an energy range extending from a few keV up to several MeV. Nevertheless the resolution can be limited by the noise induced by vibrations of the mechanical apparatus. In arrays of bolometers part of this noise is correlated among different detectors and can be removed using a multichannel decorrelation algorithm. In this paper we present a decorrelation method and its application to data from the CUORICINO experiment, an array of 62 TeO2 bolometers.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2022-10-03 00:00:00.000000"},
{"id":"519","title":"Describe later executive cultural development.","abstract":"The principles of self-organizing the neural networks of optimal complexity is considered under the unrepresentative learning set. The method of self-organizing the multi-layered neural networks is offered and used to train the logical neural networks which were applied to the medical diagnostics.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2016-02-12 00:00:00.000000"},
{"id":"520","title":"Increase clearly add avoid expert child.","abstract":"We use extreme-ultraviolet interferometry to measure the phase of high-order harmonic generation from transiently aligned CO2 molecules. We unambiguously observe a reversal in phase of the high order harmonic emission for higher harmonic orders with a sufficient degree of alignment. This results from molecular-scale quantum interferences between the molecular electronic wave function and the recolliding electron as it recombines with the molecule, and is consistent with a two-center model. Furthermore, using the combined harmonic intensity and phase information, we extract accurate information on the dispersion relation of the returning electron wavepacket as a function of harmonic order. This analysis shows evidence of the effect of the molecular potential on the recolliding electron wave.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2019-06-26 00:00:00.000000"},
{"id":"521","title":"Its site cost clear.","abstract":"We consider combinatorial avoidance and achievement games based on graph Ramsey theory: The players take turns in coloring still uncolored edges of a graph G, each player being assigned a distinct color, choosing one edge per move. In avoidance games, completing a monochromatic subgraph isomorphic to another graph A leads to immediate defeat or is forbidden and the first player that cannot move loses. In the avoidance+ variants, both players are free to choose more than one edge per move. In achievement games, the first player that completes a monochromatic subgraph isomorphic to A wins. Erdos & Selfridge (1973) were the first to identify some tractable subcases of these games, followed by a large number of further studies. We complete these investigations by settling the complexity of all unrestricted cases: We prove that general graph Ramsey avoidance, avoidance+, and achievement games and several variants thereof are PSPACE-complete. We ultra-strongly solve some nontrivial instances of graph Ramsey avoidance games that are based on symmetric binary Ramsey numbers and provide strong evidence that all other cases based on symmetric binary Ramsey numbers are effectively intractable.   Keywords: combinatorial games, graph Ramsey theory, Ramsey game, PSPACE-completeness, complexity, edge coloring, winning strategy, achievement game, avoidance game, the game of Sim, Polya's enumeration formula, probabilistic counting, machine learning, heuristics, Java applet","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2016-08-05 00:00:00.000000"},
{"id":"522","title":"Maintain member more red.","abstract":"Discrete mixture models are routinely used for density estimation and clustering. While conducting inferences on the cluster-specific parameters, current frequentist and Bayesian methods often encounter problems when clusters are placed too close together to be scientifically meaningful. Current Bayesian practice generates component-specific parameters independently from a common prior, which tends to favor similar components and often leads to substantial probability assigned to redundant components that are not needed to fit the data. As an alternative, we propose to generate components from a repulsive process, which leads to fewer, better separated and more interpretable clusters. We characterize this repulsive prior theoretically and propose a Markov chain Monte Carlo sampling algorithm for posterior computation. The methods are illustrated using simulated data as well as real datasets.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2018-11-26 00:00:00.000000"},
{"id":"523","title":"Office trial group heavy summer here.","abstract":"Challenging optimisation problems are abundant in all areas of science. Since the 1950s, scientists have developed ever-diversifying families of black box optimisation algorithms designed to address any optimisation problem, requiring only that quality of a candidate solution is calculated via a fitness function specific to the problem. For such algorithms to be successful, at least three properties are required: an effective informed sampling strategy, that guides generation of new candidates on the basis of fitnesses and locations of previously visited candidates; mechanisms to ensure efficiency, so that same candidates are not repeatedly visited; absence of structural bias, which, if present, would predispose the algorithm towards limiting its search to some regions of solution space. The first two of these properties have been extensively investigated, however the third is little understood. In this article we provide theoretical and empirical analyses that contribute to the understanding of structural bias. We prove a theorem concerning dynamics of population variance in the case of real-valued search spaces. This reveals how structural bias can manifest as non-uniform clustering of population over time. Theory predicts that structural bias is exacerbated with increasing population size and problem difficulty. These predictions reveal two previously unrecognised aspects of structural bias. Respectively, increasing population size, though ostensibly promoting diversity, will magnify any inherent structural bias, and effects of structural bias are more apparent when faced with difficult problems. Our theoretical result also suggests that two commonly used approaches to enhancing exploration, increasing population size and increasing disruptiveness of search operators, have quite distinct implications in terms of structural bias.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2015-04-28 00:00:00.000000"},
{"id":"524","title":"Community wonder modern expect defense.","abstract":"The eigenvalues of a self-adjoint nxn matrix A can be put into a decreasing sequence $\\lambda=(\\lambda_1,...,\\lambda_n)$, with repetitions according to multiplicity, and the diagonal of A is a point of $R^n$ that bears some relation to $\\lambda$. The Schur-Horn theorem characterizes that relation in terms of a system of linear inequalities.   We give a new proof of the latter result for positive trace-class operators on infinite dimensional Hilbert spaces, generalizing results of one of us on the diagonals of projections. We also establish an appropriate counterpart of the Schur inequalities that relate spectral properties of self-adjoint operators in $II_1$ factors to their images under a conditional expectation onto a maximal abelian subalgebra.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2016-03-04 00:00:00.000000"},
{"id":"525","title":"Same piece news exactly whom about.","abstract":"Protein inference plays a vital role in the proteomics study. Two major approaches could be used to handle the problem of protein inference; top-down and bottom-up. This paper presents a framework for protein inference, which uses hardware accelerated protein inference framework for handling the most important step in a bottom-up approach, viz. peptide identification during the assembling process. In our framework, identified peptides and their probabilities are used to predict the most suitable reference protein cluster for a given input amino acid sequence with the probability of identified peptides. The framework is developed on an FPGA where hardware software co-design techniques are used to accelerate the computationally intensive parts of the protein inference process. In the paper we have measured, compared and reported the time taken for the protein inference process in our framework against a pure software implementation.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2016-05-11 00:00:00.000000"},
{"id":"526","title":"Trip grow test lead.","abstract":"We show that if g is a generic isometry of a generic subspace of the Urysohn metric space U, then g does not extend to a full isometry of U. The same is proven to hold for the Urysohn sphere S. Let M be a Fraisse L-structure, where L is a relational countable language and M has no algebraicity. We provide necessary and sufficient conditions for the following to hold: for a generic substructure A of M, every automorphism f in Aut(A) extends to a full automorphism f in Aut(M). From our analysis, a dichotomy arises and some structural results are derived that, in particular, apply to omega-stable Fraisse structures without algebraicity.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2020-07-05 00:00:00.000000"},
{"id":"527","title":"Build build sign him message.","abstract":"Nowadays hybrid evolutionary algorithms, i.e, heuristic search algorithms combining several mutation operators some of which are meant to implement stochastically a well known technique designed for the specific problem in question while some others playing the role of random search, have become rather popular for tackling various NP-hard optimization problems. While empirical studies demonstrate that hybrid evolutionary algorithms are frequently successful at finding solutions having fitness sufficiently close to the optimal, many fewer articles address the computational complexity in a mathematically rigorous fashion. This paper is devoted to a mathematically motivated design and analysis of a parameterized family of evolutionary algorithms which provides a polynomial time approximation scheme for one of the well-known NP-hard combinatorial optimization problems, namely the \"single machine scheduling problem without precedence constraints\". The authors hope that the techniques and ideas developed in this article may be applied in many other situations.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2019-01-07 00:00:00.000000"},
{"id":"528","title":"But probably give green.","abstract":"In addition to deep-water rogue waves which develop from the modulation instability of an optical CW, wave propagation in optical fibers may also produce shallow water rogue waves. These extreme wave events are generated in the modulationally stable normal dispersion regime. A suitable phase or frequency modulation of a CW laser leads to chirp-free and flat-top pulses or flaticons which exhibit a stable self-similar evolution. Upon collision, flaticons at different carrier frequencies, which may also occur in wavelength division multiplexed transmission systems, merge into a single, high-intensity, temporally and spatially localized rogue pulse.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2015-10-18 00:00:00.000000"},
{"id":"529","title":"Their time to pattern certainly drop them doctor.","abstract":"We propose a new approach to value function approximation which combines linear temporal difference reinforcement learning with subspace identification. In practical applications, reinforcement learning (RL) is complicated by the fact that state is either high-dimensional or partially observable. Therefore, RL methods are designed to work with features of state rather than state itself, and the success or failure of learning is often determined by the suitability of the selected features. By comparison, subspace identification (SSID) methods are designed to select a feature set which preserves as much information as possible about state. In this paper we connect the two approaches, looking at the problem of reinforcement learning with a large set of features, each of which may only be marginally useful for value function approximation. We introduce a new algorithm for this situation, called Predictive State Temporal Difference (PSTD) learning. As in SSID for predictive state representations, PSTD finds a linear compression operator that projects a large set of features down to a small set that preserves the maximum amount of predictive information. As in RL, PSTD then uses a Bellman recursion to estimate a value function. We discuss the connection between PSTD and prior approaches in RL and SSID. We prove that PSTD is statistically consistent, perform several experiments that illustrate its properties, and demonstrate its potential on a difficult optimal stopping problem.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2021-10-11 00:00:00.000000"},
{"id":"530","title":"Behind term mind late truth big sound.","abstract":"We present the design and simulation of a three-dimensional photonic crystal waveguide for linear laser-driven acceleration in vacuum. The structure confines a synchronous speed-of-light accelerating mode in both transverse dimensions. We report the properties of this mode, including sustainable gradient and optical-to-beam efficiency. We present a novel method for confining a particle beam using optical fields as focusing elements. This technique, combined with careful structure design, is shown to have a large dynamic aperture and minimal emittance growth, even over millions of optical wavelengths.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2016-09-02 00:00:00.000000"},
{"id":"531","title":"Individual individual understand official air this force.","abstract":"The aim of the paper is to derive the numerical least-squares estimator for mean and variance of random variable. In order to do so the following questions have to be answered: (i) what is the statistical model for the estimation procedure? (ii) what are the properties of the estimator, like optimality (in which class) or asymptotic properties? (iii) how does the estimator work in practice, how compared to competing estimators?","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2021-04-01 00:00:00.000000"},
{"id":"532","title":"Company surface these government method coach.","abstract":"The term \"Active Plasma Resonance Spectroscopy\" (APRS) denotes a class of related techniques which utilize, for diagnostic purposes, the natural ability of plasmas to resonate on or near the electron plasma frequency $\\omega_{\\rm pe}$: A radio frequent signal (in the GHz range) is coupled into the plasma via an antenna or probe, the spectral response is recorded, and a mathematical model is used to determine plasma parameters like the electron density or the electron temperature.   This manuscript provides a kinetic description of APRS valid for all pressures and probe geometries. Subject of the description is the interaction of the probe with the plasma of its influence domain. In a first step, the kinetic free energy of that domain is established which has a definite time derivative with respect to the RF power. In the absence of RF excitation, it assumes the properties of a Lyapunov functional; its minimum provides the stable equilibrium of the plasma-probe system. Equipped with a scalar product motivated by the second variation of the free energy, the set of all perturbations of the equilibrium forms a Hilbert space. The dynamics of the perturbations can be cast in an evolution equation in that space. The spectral response function of the plasma-probe system consists of matrix elements of the resolvent of the dynamical operator. An interpretation in terms of an equivalent electric circuit model is given and the residual broadening of the spectrum in the collisionless regime is explained.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2020-11-19 00:00:00.000000"},
{"id":"533","title":"Husband from lay six increase station work.","abstract":"We consider the master\/slave parameterised reachability problem for networks of pushdown systems, where communication is via a global store using only non-atomic reads and writes. We show that the control-state reachability problem is decidable. As part of the result, we provide a constructive extension of a theorem by Ehrenfeucht and Rozenberg to produce an NFA equivalent to certain kinds of CFG. Finally, we show that the non-parameterised version is undecidable.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2016-08-21 00:00:00.000000"},
{"id":"534","title":"Really apply factor century appear draw throughout trade.","abstract":"This article derives lower bounds on the supremal (strict) p-negative type of finite metric spaces using purely elementary techniques. The bounds depend only on the cardinality and the (scaled) diameter of the underlying finite metric space. Examples show that these lower bounds can easily be best possible under clearly delineated circumstances. We further point out that the entire theory holds (more generally) for finite semi-metric spaces without modification and wherein the lower bounds are always optimal.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2018-10-06 00:00:00.000000"},
{"id":"535","title":"Heart thought high yourself and western natural.","abstract":"Fast nearest neighbor searching is becoming an increasingly important tool in solving many large-scale problems. Recently a number of approaches to learning data-dependent hash functions have been developed. In this work, we propose a column generation based method for learning data-dependent hash functions on the basis of proximity comparison information. Given a set of triplets that encode the pairwise proximity comparison information, our method learns hash functions that preserve the relative comparison relationships in the data as well as possible within the large-margin learning framework. The learning procedure is implemented using column generation and hence is named CGHash. At each iteration of the column generation procedure, the best hash function is selected. Unlike most other hashing methods, our method generalizes to new data points naturally; and has a training objective which is convex, thus ensuring that the global optimum can be identified. Experiments demonstrate that the proposed method learns compact binary codes and that its retrieval performance compares favorably with state-of-the-art methods when tested on a few benchmark datasets.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2015-06-25 00:00:00.000000"},
{"id":"536","title":"Player hold always.","abstract":"The Higher-Energy LHC (HE-LHC) should collide two proton beams of 16.5-TeV energy, circulating in the LHC tunnel. We discuss the main parameter choices, as well as some optics and beam dynamics issues, in particular the time evolution of emittances, beam-beam tune shift and luminosity, with and without controlled emittance blow up, considering various constraints, and the quadrupole-magnet parameters for arcs and interaction regions.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2015-11-11 00:00:00.000000"},
{"id":"537","title":"Break organization rich memory short.","abstract":"Distributed collaborative software development tends to make artifacts and decisions inconsistent and uncertain. We try to solve this problem by providing an information repository to reflect the state of works precisely, by managing the states of artifacts\/products made through collaborative work, and the states of decisions made through communications. In this paper, we propose models and a tool to construct the artifact-related part of the information repository, and explain the way to use the repository to resolve inconsistencies caused by concurrent changes of artifacts. We first show the model and the tool to generate the dependency relationships among UML model elements as content of the information repository. Next, we present the model and the method to generate change support workflows from the information repository. These workflows give us the way to efficiently modify the change-related artifacts for each change request. Finally, we define inconsistency patterns that enable us to be aware of the possibility of inconsistency occurrences. By combining this mechanism with version control systems, we can make changes safely. Our models and tool are useful in the maintenance phase to perform changes safely and efficiently.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2019-05-21 00:00:00.000000"},
{"id":"538","title":"Produce person all whole.","abstract":"A celestial is a surface that is generated by a family of Moebius circles in at least 2 different ways. A translation is an isometry where every point moves with the same distance. We classify celestials in 3-space that are obtained by translating Moebius circles in either Euclidean or elliptic space. This is a natural extension of classical work by William Kingdon Clifford and Felix Klein on the Clifford torus.   We prove that an elliptic translational celestial of Moebius degree 4 is a Dupin cyclide and that a Dupin cyclide is Moebius equivalent to the Clifford torus. Our main result is that celestials of Moebius degree 8 with a family of elliptic lines are translational in elliptic space. The real singular locus of its Moebius model is a great circle and allows us to classify these celestials up to homeomorphism. Moreover, we obtain a classically flavored theorem in elliptic geometry: if we translate a line along a circle but not along a line then exactly 2 translated lines will coincide. Finally we show that Euclidean translational celestials can be seen as limit cases of elliptic translational celestials.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2020-09-10 00:00:00.000000"},
{"id":"539","title":"Single surface assume PM.","abstract":"A bivariate distribution with continuous margins can be uniquely decomposed via a copula and its marginal distributions. We consider the problem of estimating the copula function and adopt a Bayesian approach. On the space of copula functions, we construct a finite-dimensional approximation subspace that is parametrized by a doubly stochastic matrix. A major problem here is the selection of a prior distribution on the space of doubly stochastic matrices also known as the Birkhoff polytope. The main contributions of this paper are the derivation of a simple formula for the Jeffreys prior and showing that it is proper. It is known in the literature that for a complex problem like the one treated here, the above results are difficult to obtain. The Bayes estimator resulting from the Jeffreys prior is then evaluated numerically via Markov chain Monte Carlo methodology. A rather extensive simulation experiment is carried out. In many cases, the results favour the Bayes estimator over frequentist estimators such as the standard kernel estimator and Deheuvels' estimator in terms of mean integrated squared error.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2017-08-25 00:00:00.000000"},
{"id":"540","title":"War nation much hot writer necessary.","abstract":"The MULTICUT IN TREES problem consists in deciding, given a tree, a set of requests (i.e. paths in the tree) and an integer k, whether there exists a set of k edges cutting all the requests. This problem was shown to be FPT by Guo and Niedermeyer. They also provided an exponential kernel. They asked whether this problem has a polynomial kernel. This question was also raised by Fellows. We show that MULTICUT IN TREES has a polynomial kernel.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2020-10-10 00:00:00.000000"},
{"id":"541","title":"Major buy where under thus.","abstract":"We determine all generalized Baumslag-Solitar groups (finitely generated groups acting on a tree with all stabilizers infinite cyclic) which are quotients of a given Baumslag-Solitar group BS(m,n), and (when BS(m,n) is not Hopfian) which of them also admit BS(m,n) as a quotient. We determine for which values of r,s one may embed BS(r,s) into a given BS(m,n), and we characterize finitely generated groups which embed into some BS(n,n).","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2015-03-19 00:00:00.000000"},
{"id":"542","title":"Ago its around even real want coach.","abstract":"We look for a parallel to the notion of ``proper forcing'' among lambda-complete forcing notions not collapsing lambda^+ . We suggest such a definition and prove that it is preserved by suitable iterations.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2015-07-22 00:00:00.000000"},
{"id":"543","title":"Share economic feeling laugh manage.","abstract":"We prove that every length space X is the orbit space (with the quotient metric) of an R-tree T via a free action of a locally free subgroup G(X) of isometries of X. The mapping f:T->X is a kind of generalized covering map called a URL-map and is universal among URL-maps onto X. T is the unique R-tree admitting a URL-map onto X. When X is a complete Riemannian manifold M of dimension n>1, the Menger sponge, the Sierpin'ski carpet or gasket, T is isometric to the so-called \"universal\" R-tree A_{c}, which has valency equal to the cardinality of the continuum at each point. In these cases, and when X is the Hawaiian earring H, the action of G(X) on T gives examples in addition to those of Dunwoody and Zastrow that negatively answer a question of J. W. Morgan about group actions on R-trees. Indeed, for one length metric on H, we obtain precisely Zastrow's example.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2021-10-20 00:00:00.000000"},
{"id":"544","title":"Feel suggest author.","abstract":"In sequential change detection, existing performance measures differ significantly in the way they treat the time of change. By modeling this quantity as a random time, we introduce a general framework capable of capturing and better understanding most well-known criteria and also propose new ones. For a specific new criterion that constitutes an extension to Lorden's performance measure, we offer the optimum structure for detecting a change in the constant drift of a Brownian motion and a formula for the corresponding optimum performance.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2017-10-01 00:00:00.000000"},
{"id":"545","title":"Game hope face perhaps film car however black.","abstract":"In [2] the authors introduced the notion of finite embeddability for sets (and for ultrafilters): a set $A$ is finitely embeddable in $B$ if every finite subset of $A$ can be translated into $B$. In this paper we study the generalizations of this notion that are obtained by substituting the translations with other families $\\mathcal{F}$ of functions. This generalizations are called $\\mathcal{F}$-finite embeddabilities. We prove that, under some general hypothesis on $\\mathcal{F}$, the $\\mathcal{F}$-finite embeddability is a pre-order with nice combinatorial properties. We also study the generalization of this notion to ultrafilters by mean of standard and nonstandard techniques, and we apply our construction to prove some results in combinatorial number theory.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2020-10-22 00:00:00.000000"},
{"id":"546","title":"Player game conference.","abstract":"We provide a complete classification of hexagonal singular 3-web germs in the complex plane, satisfying the following two conditions: 1) the Chern connection remains holomorphic at the singular point, 2) the web admits at least one infinitesimal symmetry at this point. As a by-product, a classification of hexagonal weighted homogeneous 3-webs is obtained.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2022-05-28 00:00:00.000000"},
{"id":"547","title":"Low pretty tend final national.","abstract":"Recently published formulas for the surface and regular solid spherical harmonics and for the expansion of the product of two normalized associated Legendre functions with different centers in ellipsoidal coordinates (Telhat Ozdogan, Metin Orbay, Czech.J.Phys., 52(2002)1297) are critically analyzed. It is demonstrated that the presented in this work formulas are not original and they are available in the literature or can easily be obtained from the published in the literature formulas by changing the summation indices.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2015-10-03 00:00:00.000000"},
{"id":"548","title":"Improve gas believe him.","abstract":"In recent years, the nuclear norm minimization (NNM) problem has been attracting much attention in computer vision and machine learning. The NNM problem is capitalized on its convexity and it can be solved efficiently. The standard nuclear norm regularizes all singular values equally, which is however not flexible enough to fit real scenarios. Weighted nuclear norm minimization (WNNM) is a natural extension and generalization of NNM. By assigning properly different weights to different singular values, WNNM can lead to state-of-the-art results in applications such as image denoising. Nevertheless, so far the global optimal solution of WNNM problem is not completely solved yet due to its non-convexity in general cases. In this article, we study the theoretical properties of WNNM and prove that WNNM can be equivalently transformed into a quadratic programming problem with linear constraints. This implies that WNNM is equivalent to a convex problem and its global optimum can be readily achieved by off-the-shelf convex optimization solvers. We further show that when the weights are non-descending, the globally optimal solution of WNNM can be obtained in closed-form.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2022-05-11 00:00:00.000000"},
{"id":"549","title":"Itself treatment want hear his firm large special.","abstract":"In this paper, we provide a novel and simple approach to study the supermarket model with general service times. This approach is based on the supplementary variable method used in analyzing stochastic models extensively. We organize an infinite-size system of integral-differential equations by means of the density dependent jump Markov process, and obtain a close-form solution: doubly exponential structure, for the fixed point satisfying the system of nonlinear equations, which is always a key in the study of supermarket models. The fixed point is decomposited into two groups of information under a product form: the arrival information and the service information. based on this, we indicate two important observations: the fixed point for the supermarket model is different from the tail of stationary queue length distribution for the ordinary M\/G\/1 queue, and the doubly exponential solution to the fixed point can extensively exist even if the service time distribution is heavy-tailed. Furthermore, we analyze the exponential convergence of the current location of the supermarket model to its fixed point, and study the Lipschitz condition in the Kurtz Theorem under general service times. Based on these analysis, one can gain a new understanding how workload probing can help in load balancing jobs with general service times such as heavy-tailed service.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2015-11-12 00:00:00.000000"},
{"id":"550","title":"Home song quality central.","abstract":"Many results of the Fatou-Julia iteration theory of rational functions extend to uniformly quasiregular maps in higher dimensions. We obtain results of this type for certain classes of quasiregular maps which are not uniformly quasiregular.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2017-01-20 00:00:00.000000"},
{"id":"551","title":"Beat Republican rather act back maybe tough.","abstract":"The consistency of the results of measuring the gravitational force temperature dependence obtained by Shaw and Davy in 1923 and by the author in 2003 was shown. Such dependence is observed in the laboratory experiments, it does not contradict the known facts of classical mechanics and agrees with astrophysics data. It was pointed out that experimental research into temperature influence on gravitation was needed and perspectives of developing that trend in gravitation physics was promising.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2018-05-08 00:00:00.000000"},
{"id":"552","title":"Still each character final administration table.","abstract":"We study theoretically and experimentally the electronic relaxation of NO2 molecules excited by absorption of one ~400 nm pump photon. Semi-classical simulations based on trajectory surface hopping calculations are performed. They predict fast oscillations of the electronic character around the intersection of the ground and first excited diabatic states. An experiment based on high-order harmonic transient grating spectroscopy reveals dynamics occuring on the same timescale. A systematic study of the detected transient is conducted to investigate the possible influence of the pump intensity, pump wavelength, and rotational temperature of the molecules. The quantitative agreement between measured and predicted dynamics shows that, in NO2, high harmonic transient grating spectroscopy encodes vibrational dynamics underlying the electronic relaxation.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2015-07-08 00:00:00.000000"},
{"id":"553","title":"Peace order experience.","abstract":"The Einstein theories of space-time and gravity as well the stander cosmology are reconstructed thoroughly in this paper based on flat reference frame. The rational parts of the Einstein theories are reserved while the irrational parts including space-time paradoxes and singularities and so on are eliminated completely. A more rational the theory of space-time, gravitation and cosmology is established. By transforming the geodesic equation described by the Schwarzschild solution of the Einsteins equation of gravitational field into flat reference frame for of gravitational field, it is provdescription, the revised formulas of the Newtonian gravitation is obtained. Based on the formulas, all experiments which support general relativity can also be explained well, but the theory has no any space-time singularity and other strange characters which exist in general relativity. It is pointed that there exists logical difficulties to use the equivalent principle to explain spectrum gravitational redshift actually. The new formula of gravitational redshift and the revised Doppler formula of redshift when light source moves in gravitational field are deduced. Based on the Schwarzschild solution of the Einstein equation field, it is proved that the speed of light would change and the isotropy of light speed would be violated in gravitational field with spherical symmetry. It is suggested to use the method of the Michelson Morley interference to verify the change of light speed and the violation of isotropy in the gravitational field of the earth. This experiment can be considered as a new verification for general relativity in the weak gravitational field with spherical symmetry. The theory may also be used to explain so-called the Pioneer Anomaly which the Einstein theory of gravitation can not do.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2015-04-05 00:00:00.000000"},
{"id":"554","title":"Analysis catch foot clearly take approach.","abstract":"Counting independent sets on bipartite graphs (#BIS) is considered a canonical counting problem of intermediate approximation complexity. It is conjectured that #BIS neither has an FPRAS nor is as hard as #Sat to approximate. We study #BIS in the general framework of two-state spin systems in bipartite graphs. Such a system is parameterized by three numbers $(\\beta,\\gamma,\\lambda)$, where $\\beta$ (respectively $\\gamma$) represents the weight of an edge (or \"interaction strength\") whose end points are of the same 0 (respectively 1) spin, and $\\lambda$ is the weight of a 1 vertex, also known as an \"external field\". By convention, the edge weight with unequal 0\/1 end points and the vertex weight with spin 0 are both normalized to 1. The partition function of the special case $\\beta=1$, $\\gamma=0$, and $\\lambda=1$ counts the number of independent sets. We define two notions, nearly-independent phase-correlated spins and symmetry breaking. We prove that it is #BIS-hard to approximate the partition function of any two-spin system on bipartite graphs supporting these two notions.   As a consequence, we show that #BIS on graphs of degree at most 6 is as hard to approximate as #BIS without degree bound. The degree bound 6 is the best possible as Weitz presented an FPTAS to count independent sets on graphs of maximum degree 5. This result extends to the hard-core model and to other anti-ferromagnetic two-spin models. In particular, for all antiferromagnetic two-spin systems, namely those satisfying $\\beta\\gamma$ < 1, we prove that when the infinite ($\\Delta$-1)-ary tree lies in the non-uniqueness region then it is #BIS-hard to approximate the partition function on bipartite graphs of maximum degree $\\Delta$, except for the case $\\beta=\\gamma$ and $\\lambda=1$.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2016-09-10 00:00:00.000000"},
{"id":"555","title":"Group too bill such by.","abstract":"We study the \"quantized calculus\" corresponding to the algebraic ideas related to \"twisted cyclic cohomology\" introduced in [KMT]. With very similar definitions and techniques as those used in [jlo], we define and study \"twisted entire cyclic cohomology\" and the \"twisted Chern character\" associated with an appropriate operator-theoretic data called \"twisted spectral data\", which consists of a spectral triple in the conventional sense of noncommutative geometry ([Con]) and an additional positive operator having specified properties. Furthermore, it is shown that given a spectral triple (in the conventional sense) which is equivariant under the action of a compact matrix pseudogroup, it is possible to obtain a canonical twisted spectral data and hence the corresponding (twisted) Chern character, which will be invariant under the action of the pseudogroup, in contrast to the fact that the Chern character coming from the conventional noncommutative geometry need not be invariant under the above action.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2022-11-30 00:00:00.000000"},
{"id":"556","title":"Write popular ok deep raise enter large.","abstract":"With recent advances in graphical user interfaces, more and more tasks on computers have become easier to perform. Out of the belief that creating computer programs can also be one of them, visual programming languages (VPLs) have emerged. The goal of VPLs is to shift a part of work from the programmer to the IDE so that the programmer can focus more on algorithm logic than the syntax of the implementation programming language. In this article, the methods required to build a VPL are presented, with an emphasis on a novel method of code generation in a WHILE language. Also, the methods for achieving basic principles of VPLs will be shown - suitable visual presentation of information and guiding the programmer in the right direction using constraints. These methods are demonstrated on an example of vIDE, a VPL based on the Eclipse integrated development environment (IDE). The design of vIDE with respect to the Eclipse Graphical Modeling Framework (GMF) is described. The concept of a flowchart graphical notation is examined in contrast with the algorithm model it maps to. Finally, the disambiguity of the model representation of an algorithm is discussed and the methods for transforming it to an actual implementation in a programming language.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2018-08-18 00:00:00.000000"},
{"id":"557","title":"Difference they always me majority.","abstract":"The parameter $W_\\mathrm{a}$, which characterizes nuclear spin-dependent parity violation effects within the effective molecular spin-rotational Hamiltonian, was computed for the electronic ground state of radium fluoride (RaF) and found to be one of the largest absolute values predicted so far. These calculations were performed with the complex generalised Hartree-Fock method within a two-component (quasi-relativistic) zeroth-order regular approximation framework. Peculiarities of the molecular electronic structure of RaF lead to highly diagonal Franck-Condon matrices between vibrational states of the electronic ground and first excited states, which renders the molecule in principle suitable for direct laser cooling. As a trapped gas of cold molecules offers a superior coherence time, RaF can be considered a promising candidate for high-precision spectroscopic experiments aimed at the search of molecular parity-violation effects.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2022-02-14 00:00:00.000000"},
{"id":"558","title":"Several sound wall serve admit their physical.","abstract":"This article discusses a latent variable model for inference and prediction of symmetric relational data.   The model, based on the idea of the eigenvalue decomposition, represents the relationship between two nodes as the weighted inner-product of node-specific vectors of latent characteristics. This ``eigenmodel'' generalizes other popular latent variable models, such as latent class and distance models: It is shown mathematically that any latent class or distance model has a representation as an eigenmodel, but not vice-versa. The practical implications of this are examined in the context of three real datasets, for which the eigenmodel has as good or better out-of-sample predictive performance than the other two models.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2017-08-07 00:00:00.000000"},
{"id":"559","title":"Year appear ask available.","abstract":"We propose a variant of Cauchy's Lemma, proving that when a convex chain on one sphere is redrawn (with the same lengths and angles) on a larger sphere, the distance between its endpoints increases. The main focus of this work is a comparison of three alternate proofs, to show the links between Toponogov's Comparison Theorem, Legendre's Theorem and Cauchy's Arm Lemma.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2015-06-20 00:00:00.000000"},
{"id":"560","title":"Alone dinner figure between official right.","abstract":"We prove results on weak convergence for the alternating split Bregman algorithm in infinite dimensional Hilbert spaces. We also show convergence of an approximate split Bregman algorithm, where errors are allowed at each step of the computation. To be able to treat the infinite dimensional case, our proofs focus mostly on the dual problem. We rely on Svaiter's theorem on weak convergence of the Douglas-Rachford splitting algorithm and on the relation between the alternating split Bregman and Douglas-Rachford splitting algorithms discovered by Setzer. Our motivation for this study is to provide a convergent algorithm for weighted least gradient problems arising in the hybrid method of imaging electric conductivity from interior knowledge (obtainable by MRI) of the magnitude of one current.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2016-12-13 00:00:00.000000"},
{"id":"561","title":"Raise nearly spring scene.","abstract":"Using the concepts of Hyperbolic Classification of Natural Numbers, Essential Regions and Goldbach Conjecture Function we prove that the existence of a proof of the Goldbach Conjecture in First-Order Arithmetic would imply the existence of another proof in a certain extension that would not be valid in all states of time associated to natural numbers created by means of adequate dynamic processes.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2020-04-10 00:00:00.000000"},
{"id":"562","title":"Analysis between today word.","abstract":"The goal of this paper is to develop tools to study maximal families of Gorenstein quotients A of a polynomial ring R. We prove a very general Theorem on deformations of the homogeneous coordinate ring of a scheme Proj(A) which is defined as the degeneracy locus of a regular section of the dual of some sheaf M^~ of rank r supported on say an arithmetically Cohen-Macaulay subscheme Proj(B) of Proj(R). Under certain conditions (notably; M maximally Cohen-Macaulay and the top exterior power of M^~ a twist of the canonical sheaf), then A is Gorenstein, and under additional assumptions, we show the unobstructedness of A and we give an explicit formula the dimension of any maximal family of Gorenstein quotients of R with fixed Hilbert function obtained by a regular section as above. The theorem also applies to Artinian quotients A.   The case where M itself is a twist of the canonical module (r=1) was studied in a previous paper, while this paper concentrates on other low rank cases, notably r=2 and 3. In these cases regular sections of the first Koszul homology module and of normal sheaves to licci schemes (of say codimension 2) lead to Gorenstein quotients (of e.g. codimension 4) whose parameter spaces we examine. Our main applications are for Gorenstein quotients of codimension 4 of R since our assumptions are almost always satisfied in this case. Special attention are paid to arithmetically Gorenstein curves in P^5.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2017-07-29 00:00:00.000000"},
{"id":"563","title":"Never especially rate forget strong key computer hair.","abstract":"We discuss secondary characteristic classes in motivic cohomology for algebraic vector bundles with trivial top Chern class. We then show that vanishing of the Chow-Witt theoretic Euler class implies not only vanishing of the top Chern class, but also vanishing of certain secondary characteristic classes in motivic cohomology.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2022-10-23 00:00:00.000000"},
{"id":"564","title":"Meet focus let stop mind side reach.","abstract":"This paper investigates the effect of the ITER-like wall (ILW) on runaway electron (RE) generation through a comparative study of similar slow argon injection JET disruptions, performed with different wall materials. In the carbon wall case, a runaway electron plateau is observed, while in the ITER-like wall case, the current quench is slower and the runaway current is negligibly small. The aim of the paper is to shed light on the reason for these differences by detailed numerical modelling to study which factors affected the RE formation. The post-disruption current profile is calculated by a one-dimensional model of electric field, temperature and runaway current taking into account the impurity injection. Scans of various impurity contents are performed and agreement with the experimental scenarios is obtained for reasonable argon- and wall impurity contents. Our modelling shows that the reason for the changed RE dynamics is a complex, combined effect of the differences in plasma parameter profiles, the radiation characteristics of beryllium and carbon, and the difference of the injected argon amount. These together lead to a significantly higher Dreicer generation rate in the carbon wall case, which is less prone to be suppressed by RE loss mechanisms. The results indicate that the differences are greatly reduced above ~50% argon content, suggesting that significant RE current is expected in future massive gas injection experiments on both JET and ITER.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2016-10-15 00:00:00.000000"},
{"id":"565","title":"Nice receive western bed money analysis dog.","abstract":"Short-range forecasts of precipitation fields are needed in a wealth of agricultural, hydrological, ecological and other applications. Forecasts from numerical weather prediction models are often biased and do not provide uncertainty information. Here we present a postprocessing technique for such numerical forecasts that produces correlated probabilistic forecasts of precipitation accumulation at multiple sites simultaneously. The statistical model is a spatial version of a two-stage model that represents the distribution of precipitation by a mixture of a point mass at zero and a Gamma density for the continuous distribution of precipitation accumulation. Spatial correlation is captured by assuming that two Gaussian processes drive precipitation occurrence and precipitation amount, respectively. The first process is latent and drives precipitation occurrence via a threshold. The second process explains the spatial correlation in precipitation accumulation. It is related to precipitation via a site-specific transformation function, so as to retain the marginal right-skewed distribution of precipitation while modeling spatial dependence. Both processes take into account the information contained in the numerical weather forecast and are modeled as stationary isotropic spatial processes with an exponential correlation function. The two-stage spatial model was applied to 48-hour-ahead forecasts of daily precipitation accumulation over the Pacific Northwest in 2004. The predictive distributions from the two-stage spatial model were calibrated and sharp, and outperformed reference forecasts for spatially composite and areally averaged quantities.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2020-11-17 00:00:00.000000"},
{"id":"566","title":"Compare past true information piece billion itself.","abstract":"The equilibrium of a finite-beta RFP plasma in the presence of saturated-amplitude tearing modes is investigated. The singularities of the MHD force balance equation JXB=grad(p) at the modes rational surfaces are resolved through a proper regularization of the zeroth-order (equilibrium) profiles, by setting to zero there the gradient of the pressure and parallel current density. An equilibrium model, which satisfies the regularization rule at the various rational surfaces, is developed. The comparison with the experimental data from the Reversed Field eXperiment (RFX) gives encouraging results. The model provides an easy tool for magnetic analysis: many aspects of the perturbations can be analyzed and reconstructed.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2018-07-11 00:00:00.000000"},
{"id":"567","title":"Need see alone strategy seven professional high professional.","abstract":"We prove that the determinacy of Gale-Stewart games whose winning sets are accepted by real-time 1-counter B\\\"uchi automata is equivalent to the determinacy of (effective) analytic Gale-Stewart games which is known to be a large cardinal assumption. We show also that the determinacy of Wadge games between two players in charge of omega-languages accepted by 1-counter B\\\"uchi automata is equivalent to the (effective) analytic Wadge determinacy. Using some results of set theory we prove that one can effectively construct a 1-counter B\\\"uchi automaton A and a B\\\"uchi automaton B such that: (1) There exists a model of ZFC in which Player 2 has a winning strategy in the Wadge game W(L(A), L(B)); (2) There exists a model of ZFC in which the Wadge game W(L(A), L(B)) is not determined. Moreover these are the only two possibilities, i.e. there are no models of ZFC in which Player 1 has a winning strategy in the Wadge game W(L(A), L(B)).","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2015-09-30 00:00:00.000000"},
{"id":"568","title":"Total set wear occur increase hear.","abstract":"We study the relation between approximate joint diagonalization of self-adjoint matrices and the norm of their commutator, and show that almost commuting self-adjoint matrices are almost jointly diagonalizable by a unitary matrix.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2016-02-17 00:00:00.000000"},
{"id":"569","title":"Control manager side program knowledge away.","abstract":"Sparse and convolutional constraints form a natural prior for many optimization problems that arise from physical processes. Detecting motifs in speech and musical passages, super-resolving images, compressing videos, and reconstructing harmonic motions can all leverage redundancies introduced by convolution. Solving problems involving sparse and convolutional constraints remains a difficult computational problem, however. In this paper we present an overview of convolutional sparse coding in a consistent framework. The objective involves iteratively optimizing a convolutional least-squares term for the basis functions, followed by an L1-regularized least squares term for the sparse coefficients. We discuss a range of optimization methods for solving the convolutional sparse coding objective, and the properties that make each method suitable for different applications. In particular, we concentrate on computational complexity, speed to {\\epsilon} convergence, memory usage, and the effect of implied boundary conditions. We present a broad suite of examples covering different signal and application domains to illustrate the general applicability of convolutional sparse coding, and the efficacy of the available optimization methods.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2016-01-13 00:00:00.000000"},
{"id":"570","title":"Least source big new operation around president.","abstract":"We use different semi-empirical dispersion correction schemes to assess the role of long-range van der Waals interactions in the adsorption of the prototypical molecular switch azobenzene (C6H5-N2-C6H5) at the coinage metal surfaces Cu(111), Ag(111) and Au(111). Compared to preceding density-functional theory results employing a semi-local exchange and correlation functional we obtain partly sizable changes of the computed adsorption geometry and energetics. The discomforting scatter in the results provided by the different schemes is largely attributed to the unknown form of the damping function in the semi-empirical correction expression. Using the congeneric problem of the adsorption of benzene as a vehicle to connection with experiment, we cautiously conclude that the account of dispersive interactions at the metal surfaces provided by the various schemes is in the right ballpark, with the more recent, general schemes likely to overbind.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2018-10-23 00:00:00.000000"},
{"id":"571","title":"Wife clearly big understand player surface in close.","abstract":"Outlying observations, which significantly deviate from other measurements, may distort the conclusions of data analysis. Therefore, identifying outliers is one of the important problems that should be solved to obtain reliable results. While there are many statistical outlier detection algorithms and software programs for uncensored data, few are available for censored data. In this article, we propose three outlier detection algorithms based on censored quantile regression, two of which are modified versions of existing algorithms for uncensored or censored data, while the third is a newly developed algorithm to overcome the demerits of previous approaches. The performance of the three algorithms was investigated in simulation studies. In addition, real data from SEER database, which contains a variety of data sets related to various cancers, is illustrated to show the usefulness of our methodology. The algorithms are implemented into an R package OutlierDC which can be conveniently employed in the \\proglang{R} environment and freely obtained from CRAN.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2016-01-23 00:00:00.000000"},
{"id":"572","title":"Power simply could their easy PM describe.","abstract":"Global observations of ocean swell, from satellite Synthetic Aperture Radar data, are used to estimate the dissipation of swell energy for a number of storms. Swells can be very persistent with energy e-folding scales exceeding 20,000 km. For increasing swell steepness this scale shrinks systematically, down to 2800 km for the steepest observed swells, revealing a significant loss of swell energy. This value corresponds to a normalized energy decay in time {\\ss} = 4.2 x 10-6 s -1 . Many processes may be responsible for this dissipation. Because no particular trend is found with wind magnitude and direction, the increase of dissipation rate in dissipation with swell steepness is interpreted as a laminar to turbulent transition of the boundary layer, with a threshold Reynolds number of the order of 100,000. These observations of swell evolution open the way for more accurate wave forecasting models, and provides a constraint on swell-induced air-sea fluxes of momentum and energy.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2017-04-12 00:00:00.000000"},
{"id":"573","title":"High seek pick fly.","abstract":"We obtain a result concerning the stability under the interpolation with functional parameter method for the approximation spaces of Lorentz-Marcinkiewicz type and also for the approximation spaces generated by symmetric norming functions of a certain type.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2020-03-04 00:00:00.000000"},
{"id":"574","title":"Real medical mention pay drug.","abstract":"Several methods to extract an asymmetry parameter in an event distribution function are discussed and compared in terms of statistical precision and applicability. These methods are: simple counting rate asymmetries, event weighting procedures and the unbinned extended maximum likelihood method. It is known that weighting methods reach the same figure of merit (FOM) as the likelihood method in the limit of vanishing asymmetries. This article presents an improved weighting procedure reaching the FOM of the likelihood method for arbitrary asymmetries. Cases where the maximum likelihood method is not applicable are also discussed.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2019-11-19 00:00:00.000000"},
{"id":"575","title":"Power late increase house trip chance.","abstract":"Engineering efficient implementations of compact and succinct structures is a time-consuming and challenging task, since there is no standard library of easy-to- use, highly optimized, and composable components. One consequence is that measuring the practical impact of new theoretical proposals is a difficult task, since older base- line implementations may not rely on the same basic components, and reimplementing from scratch can be very time-consuming. In this paper we present a framework for experimentation with succinct data structures, providing a large set of configurable components, together with tests, benchmarks, and tools to analyze resource requirements. We demonstrate the functionality of the framework by recomposing succinct solutions for document retrieval.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2015-06-28 00:00:00.000000"},
{"id":"576","title":"Station night day choice.","abstract":"Two kinds of approximation algorithms exist for the k-BALANCED PARTITIONING problem: those that are fast but compute unsatisfying approximation ratios, and those that guarantee high quality ratios but are slow. In this paper we prove that this tradeoff between runtime and solution quality is necessary. For the problem a minimum number of edges in a graph need to be found that, when cut, partition the vertices into k equal-sized sets. We develop a reduction framework which identifies some necessary conditions on the considered graph class in order to prove the hardness of the problem. We focus on two combinatorially simple but very different classes, namely trees and solid grid graphs. The latter are finite connected subgraphs of the infinite 2D grid without holes. First we use the framework to show that for solid grid graphs it is NP-hard to approximate the optimum number of cut edges within any satisfying ratio. Then we consider solutions in which the sets may deviate from being equal-sized. Our framework is used on grids and trees to prove that no fully polynomial time algorithm exists that computes solutions in which the sets are arbitrarily close to equal-sized. This is true even if the number of edges cut is allowed to increase the more stringent the limit on the set sizes is. These are the first bicriteria inapproximability results for the problem.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2015-07-21 00:00:00.000000"},
{"id":"577","title":"Successful between structure professor society level simply message.","abstract":"We establish, for smooth enough initial data, the global well-posedness (existence, uniqueness and continuous dependence on initial data) of solutions, for an inviscid three-dimensional {\\it slow limiting ocean dynamics} model. This model was derived as a strong rotation limit of the rotating and stratified Boussinesg equations with periodic boundary conditions. To establish our results we utilize the tools developed for investigating the two-dimensional incompressible Euler equations and linear transport equations. Using a weaker formulation of the model we also show the global existence and uniqueness of solutions, for less regular initial data.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2017-08-16 00:00:00.000000"},
{"id":"578","title":"Be indicate however foot relate.","abstract":"Disjunctive Logic Programming (DLP) is a very expressive formalism: it allows for expressing every property of finite structures that is decidable in the complexity class SigmaP2 (= NP^NP). Despite this high expressiveness, there are some simple properties, often arising in real-world applications, which cannot be encoded in a simple and natural manner. Especially properties that require the use of arithmetic operators (like sum, times, or count) on a set or multiset of elements, which satisfy some conditions, cannot be naturally expressed in classic DLP.   To overcome this deficiency, we extend DLP by aggregate functions in a conservative way. In particular, we avoid the introduction of constructs with disputed semantics, by requiring aggregates to be stratified. We formally define the semantics of the extended language (called DLP^A), and illustrate how it can be profitably used for representing knowledge. Furthermore, we analyze the computational complexity of DLP^A, showing that the addition of aggregates does not bring a higher cost in that respect. Finally, we provide an implementation of DLP^A in DLV -- a state-of-the-art DLP system -- and report on experiments which confirm the usefulness of the proposed extension also for the efficiency of computation.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2015-01-22 00:00:00.000000"},
{"id":"579","title":"Raise item everything city parent amount.","abstract":"We consider the following problem: to decompose a nonnegative integer matrix into a linear combination of binary matrices that respect the consecutive ones prop- erty. This problem occurs in the radiotherapy treatment of cancer. The nonnegative integer matrix corresponds to fields giving the different radiation beams that a linear accelerator has to send throughout the body of a patient. Due to the in- homogeneous dose levels, leaves from a multi-leaf collimator are used between the accelerator and the body of the patient to block the radiations. The leaves positions can be represented by segments, that are binary matrices with the consecutive ones property. The aim is to find efficient decompositions that simultaneously minimize the irradiation time, the cardinality of the decomposition and the setup-time to configure the multi-leaf collimator at each step of the decomposition. We propose for this NP-hard multiobjective combinatorial problem a heuristic, based on the adaptation of the two-phase Pareto local search. Experiments are carried out on different size instances and the results are reported.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2022-10-19 00:00:00.000000"},
{"id":"580","title":"Study firm cover inside beautiful.","abstract":"Comparison of programming languages is a common topic of discussion among software engineers. Few languages ever become sufficiently popular that they are used by more than a few people or find their niche in research or education; but professional programmers can easily use dozens of different languages during their career. Multiple programming languages are designed, specified, and implemented every year in order to keep up with the changing programming paradigms, hardware evolution, etc. In this paper we present a comparative study between ten programming languages: Haskell, Java, Perl, C++, AspectJ, COBOL, Ruby, PHP, Bash Scripts, and Scheme; with respect of the following criteria: Secure programming practices, web applications development, web services design and composition, object oriented-based abstraction, reflection, aspect-orientation, functional programming, declarative programming, batch scripting, and user interface prototype design.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2017-05-08 00:00:00.000000"},
{"id":"581","title":"Manager never apply indicate character region major.","abstract":"The CDF experiment is successfully collecting data from ppbar collisions at the Tevatron in Run II. As the data samples are getting larger, systematic uncertainties due to the measurement of the jet energy scale assessed using the calorimeter simulation have become increasingly important. In many years of operation, the collaboration has gained experience with GFLASH, a fast parametrization of electromagnetic and hadronic showers used for the calorimeter simulation. We present the performance of the calorimeter simulation and report on recent improvements based on a refined in situ tuning technique. The central calorimeter response is reproduced with a precision of 1-2%.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2016-03-02 00:00:00.000000"},
{"id":"582","title":"Thought bill natural role movement become.","abstract":"The ITER neutral beam cell will contain up to three heating neutral beams and one diagnostic neutral beam, and four upper ports. Though manual maintenance work is envisaged within the cell, when containment is breached, or the radiological protection is removed the maintenance must be conducted remotely. This maintenance constitutes the removal and replacement of line replaceable units, and their transport to and from a cask docked to the cell. A design of the remote handling system has been prepared to concept level which this paper describes including the development of a beam line transporter, beam source remote handling equipment, upper port remote handling equipment and equipment for the maintenance of the neutral shield. This equipment has been developed complete the planned maintenance tasks for the components of the neutral beam cell and to have inherent flexibility to enable as yet unforeseen tasks and recovery operations to be performed.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2016-08-13 00:00:00.000000"},
{"id":"583","title":"Focus take success hot whole.","abstract":"In this paper, we present a technique for parameterizing Leslie transition matrices from simple age and sex population counts, using an implementation of \"Wood's Method\" [wood]; these matrices can forecast population by age and sex (the \"cohort component\" method) using simple matrix multiplication and a starting population. Our approach improves on previous methods for creating Leslie matrices in two respects: it eliminates the need to calculate input demographic rates from \"raw\" data, and our new format for the Leslie matrix more elegantly reveals the population's demographic components of change (fertility, mortality, and migration). The paper is organized around three main themes. First, we describe the underlying algorithm, \"Wood's Method,\" which uses quadratic optimization to fit a transition matrix to age and sex population counts. Second, we use demographic theory to create constraint sets that make the algorithm useable for human populations. Finally, we use the method to forecast 3,120 US counties and show that it holds promise for automating cohort-component forecasts. This paper describes the first published successful application of Wood's method to human populations; it also points to more general promise of constrained optimization techniques in demographic modeling.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2022-11-22 00:00:00.000000"},
{"id":"584","title":"Everything wait wrong now.","abstract":"Cassidy, Phan and Shelton associate to any regular cell complex X a quadratic K-algebra R(X). They give a combinatorial solution to the question of when this algebra is Koszul. The algebra R(X) is a combinatorial invariant but not a topological invariant. We show that nevertheless, the property that R(x) be Koszul is a topological invariant.   In the process we establish some conditions on the types of local singular- ities that can occur in cell complexes X such that R(X) is Koszul, and more generally in cell complexes that are pure and connected by codimension one faces.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2022-01-28 00:00:00.000000"},
{"id":"585","title":"Apply hour suffer ten media statement specific.","abstract":"In this paper, a matrix representation for the differential resultant of two generic ordinary differential polynomials $f_1$ and $f_2$ in the differential indeterminate $y$ with order one and arbitrary degree is given. That is, a non-singular matrix is constructed such that its determinant contains the differential resultant as a factor. Furthermore, the algebraic sparse resultant of $f_1, f_2, \\delta f_1, \\delta f_2$ treated as polynomials in $y, y', y\"$ is shown to be a non-zero multiple of the differential resultant of $f_1, f_2$. Although very special, this seems to be the first matrix representation for a class of nonlinear generic differential polynomials.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2021-10-24 00:00:00.000000"},
{"id":"586","title":"Thank provide natural order yet price late.","abstract":"The Balmer formula for the spectrum of atomic hydrogen is shown to be analogous to that in Compton effect and is written in terms of the difference between the absorbed and emitted wavelengths. The g-factors come into play when the atom is subjected to disturbances (like changes in the magnetic and electric fields), and the electron and proton get displaced from their fixed positions giving rise to Zeeman effect, Stark effect, etc.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2017-12-06 00:00:00.000000"},
{"id":"587","title":"Hotel letter building build.","abstract":"There has been a lot of work fitting Ising models to multivariate binary data in order to understand the conditional dependency relationships between the variables. However, additional covariates are frequently recorded together with the binary data, and may influence the dependence relationships. Motivated by such a dataset on genomic instability collected from tumor samples of several types, we propose a sparse covariate dependent Ising model to study both the conditional dependency within the binary data and its relationship with the additional covariates. This results in subject-specific Ising models, where the subject's covariates influence the strength of association between the genes. As in all exploratory data analysis, interpretability of results is important, and we use L1 penalties to induce sparsity in the fitted graphs and in the number of selected covariates. Two algorithms to fit the model are proposed and compared on a set of simulated data, and asymptotic results are established. The results on the tumor dataset and their biological significance are discussed in detail.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2021-07-04 00:00:00.000000"},
{"id":"588","title":"Drug hospital cultural training.","abstract":"The best current methods for exactly computing the number of satisfying assignments, or the satisfying probability, of Boolean formulas can be seen, either directly or indirectly, as building 'decision-DNNF' (decision decomposable negation normal form) representations of the input Boolean formulas. Decision-DNNFs are a special case of 'd-DNNF's where 'd' stands for 'deterministic'. We show that any decision-DNNF can be converted into an equivalent 'FBDD' (free binary decision diagram) -- also known as a 'read-once branching program' (ROBP or 1-BP) -- with only a quasipolynomial increase in representation size in general, and with only a polynomial increase in size in the special case of monotone k-DNF formulas. Leveraging known exponential lower bounds for FBDDs, we then obtain similar exponential lower bounds for decision-DNNFs which provide lower bounds for the recent algorithms. We also separate the power of decision-DNNFs from d-DNNFs and a generalization of decision-DNNFs known as AND-FBDDs. Finally we show how these imply exponential lower bounds for natural problems associated with probabilistic databases.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2022-04-30 00:00:00.000000"},
{"id":"589","title":"Traditional assume say all.","abstract":"Elementary integration methods for waveguides are compared. One using non-local loading rules based on Heaviside step functions, one using input side integration and one using integration of the output of traveling velocity waves. We show that most approaches can be made consistent with the wave equation in principle, under proper circumstances. Of all methods studied the Heaviside method is the only method shown to not suffer from undesirable numerical difficulties and amendable to standard waveguide loop filtering practices, yet it gives incorrect results for Neumann boundary conditions. We also discuss localized velocity excitations, time-limited input-side excitations and the relation of loop filters to wave variable type.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2020-12-12 00:00:00.000000"},
{"id":"590","title":"Practice range reflect land.","abstract":"We consider spaces for which there is a notion of harmonicity for complex valued functions defined on them. For instance, this is the case of Riemannian manifolds on one hand, and (metric) graphs on the other hand. We observe that it is then possible to define an \"amazing\" notion of holomorphic functions on them, and show how rigid it is in some cases.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2018-07-31 00:00:00.000000"},
{"id":"591","title":"Weight interesting really science hit forget door team.","abstract":"A well-known conjecture says that every one-relator group is coherent. We state and partly prove an analogous statement for graded associative algebras. In particular, we show that every Gorenstein algebra $A$ of global dimension 2 is graded coherent.   This allows us to define a noncommutative analogue of the projective line $\\PP^1$ as a noncommutative scheme based on the coherent noncommutative spectrum $\\cohp A$ of such an algebra $A$, that is, the category of coherent $A$-modules modulo the torsion ones. This category is always abelian Ext-finite hereditary with Serre duality, like the category of coherent sheaves on $\\PP^1$. In this way, we obtain a sequence $\\PP^1_n $ ($n\\ge 2$) of pairwise non-isomorphic noncommutative schemes which generalize the scheme $\\PP^1 = \\PP^1_2$.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2022-12-04 00:00:00.000000"},
{"id":"592","title":"Identify raise site add.","abstract":"In connection with recent and proposed experiments, and new theoretical results, my previous calculations of the Lamb shift in muonic hydrogen will be reviewed and compared with other work. In addition, numerical results for muonic deuterium and helium will be presented. Some previously neglected (but very small) effects are included.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2018-06-24 00:00:00.000000"},
{"id":"593","title":"Arrive wrong buy power.","abstract":"Videos of the molecular dynamics simulations of a colliding hard disk reactive medium. A simple event-driven algorithm is used to simulate these colliding hard disks allowing for the study of detonations at the microscopic level. This video was submitted as party of the Gallery of Fluid Motion for the American Physical Society 63rd Annual DFD Meeting.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2022-09-03 00:00:00.000000"},
{"id":"594","title":"Watch return president marriage.","abstract":"Active microrheology is a valuable tool to determine viscoelastic properties of polymer networks. Observing the beads response to the excitation of a reference leads to dynamic and morphological information of the material. In this work we present an expansion of the well-known active two-point microrheology. By measuring the response of multiple particles in the viscoelastic medium in response to the excitation of a reference particle we are able to determine the force propagation in the polymer network.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2017-03-12 00:00:00.000000"},
{"id":"595","title":"Consider themselves hot.","abstract":"Recently, Gunn, Allison and Abbott (GAA) [http:\/\/arxiv.org\/pdf\/1402.2709v2.pdf] proposed a new scheme to utilize electromagnetic waves for eavesdropping on the Kirchhoff-law-Johnson-noise (KLJN) secure key distribution. We proved in a former paper [Fluct. Noise Lett. 13 (2014) 1450016] that GAA's mathematical model is unphysical. Here we analyze GAA's cracking scheme and show that, in the case of a loss-free cable, it provides less eavesdropping information than in the earlier (Bergou)-Scheuer-Yariv mean-square-based attack [Kish LB, Scheuer J, Phys. Lett. A 374 (2010) 2140-2142], while it offers no information in the case of a lossy cable. We also investigate GAA's claim to be experimentally capable of distinguishing - using statistics over a few correlation times only - the distributions of two Gaussian noises with a relative variance difference of less than 10^-8. Normally such distinctions would require hundreds of millions of correlations times to be observable. We identify several potential experimental artifacts as results of poor KLJN design, which can lead to GAA's assertions: deterministic currents due to spurious harmonic components caused by ground loops, DC offset, aliasing, non-Gaussian features including non-linearities and other non-idealities in generators, and the time-derivative nature of GAA's scheme which tends to enhance all of these artifacts.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2020-07-06 00:00:00.000000"},
{"id":"596","title":"Thought respond add decade.","abstract":"Many real life domains contain a mixture of discrete and continuous variables and can be modeled as hybrid Bayesian Networks. Animportant subclass of hybrid BNs are conditional linear Gaussian (CLG) networks, where the conditional distribution of the continuous variables given an assignment to the discrete variables is a multivariate Gaussian. Lauritzen's extension to the clique tree algorithm can be used for exact inference in CLG networks. However, many domains also include discrete variables that depend on continuous ones, and CLG networks do not allow such dependencies to berepresented. No exact inference algorithm has been proposed for these enhanced CLG networks. In this paper, we generalize Lauritzen's algorithm, providing the first \"exact\" inference algorithm for augmented CLG networks - networks where continuous nodes are conditional linear Gaussians but that also allow discrete children ofcontinuous parents. Our algorithm is exact in the sense that it computes the exact distributions over the discrete nodes, and the exact first and second moments of the continuous ones, up to the accuracy obtained by numerical integration used within thealgorithm. When the discrete children are modeled with softmax CPDs (as is the case in many real world domains) the approximation of the continuous distributions using the first two moments is particularly accurate. Our algorithm is simple to implement and often comparable in its complexity to Lauritzen's algorithm. We show empirically that it achieves substantially higher accuracy than previous approximate algorithms.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2020-05-10 00:00:00.000000"},
{"id":"597","title":"Include physical represent wear common begin whether.","abstract":"We report on a test of Lorentz invariance performed by comparing the resonance frequencies of one stationary optical resonator and one continuously rotating on a precision air bearing turntable. Special attention is paid to the control of rotation induced systematic effects. Within the photon sector of the Standard Model Extension, we obtain improved limits on combinations of 8 parameters at a level of a few parts in $10^{-16}$. For the previously least well known parameter we find $\\tilde \\kappa_{e-}^{ZZ} =(-1.9 \\pm 5.2)\\times 10^{-15}$. Within the Robertson-Mansouri-Sexl test theory, our measurement restricts the isotropy violation parameter $\\beta -\\delta -\\frac 12$ to $(-2.1\\pm 1.9)\\times 10^{-10}$, corresponding to an eightfold improvement with respect to previous non-rotating measurements.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2017-03-27 00:00:00.000000"},
{"id":"598","title":"He hundred like power or them share.","abstract":"A variable screening procedure via correlation learning was proposed Fan and Lv (2008) to reduce dimensionality in sparse ultra-high dimensional models. Even when the true model is linear, the marginal regression can be highly nonlinear. To address this issue, we further extend the correlation learning to marginal nonparametric learning. Our nonparametric independence screening is called NIS, a specific member of the sure independence screening. Several closely related variable screening procedures are proposed. Under the nonparametric additive models, it is shown that under some mild technical conditions, the proposed independence screening methods enjoy a sure screening property. The extent to which the dimensionality can be reduced by independence screening is also explicitly quantified. As a methodological extension, an iterative nonparametric independence screening (INIS) is also proposed to enhance the finite sample performance for fitting sparse additive models. The simulation results and a real data analysis demonstrate that the proposed procedure works well with moderate sample size and large dimension and performs better than competing methods.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2019-11-25 00:00:00.000000"},
{"id":"599","title":"Grow argue despite.","abstract":"This paper studies etale twists of derived categories of schemes and associative algebras. A general method, based on a new construction called the twisted Brauer space, is given for classifying etale twists, and a complete classification is carried out for genus 0 curves, quadrics, and noncommutative projective spaces. A partial classification is given for curves of higher genus. The techniques build upon my recent work with David Gepner on the Brauer groups of commutative ring spectra.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2015-04-08 00:00:00.000000"},
{"id":"600","title":"Soldier main response apply book think send.","abstract":"We explore the possibility of applying the framework of frequent pattern mining to a class of continuous objects appearing in nature, namely knots. We introduce the frequent knot mining problem and present a solution. The key observation is that a database consisting of knots can be transformed into a transactional database. This observation is based on the Prime Decomposition Theorem of knots.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2021-08-28 00:00:00.000000"},
{"id":"601","title":"List anything sister thought interest night.","abstract":"We develop local reasoning techniques for message passing concurrent programs based on ideas from separation logics and resource usage analysis. We extend processes with permission- resources and define a reduction semantics for this extended language. This provides a foundation for interpreting separation formulas for message-passing concurrency. We also define a sound proof system permitting us to infer satisfaction compositionally using local, separation-based reasoning.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2020-05-07 00:00:00.000000"},
{"id":"602","title":"Season two south like cultural price.","abstract":"Player ONE chooses a meager set and player TWO, a nowhere dense set per inning. They play $\\omega$ many innings. ONE's consecutive choices must form a (weakly) increasing sequence. TWO wins if the union of the chosen nowhere dense sets covers the union of the chosen meager sets. A strategy for TWO which depends on knowing only the uncovered part of the most recently chosen meager set is said to be a remainder strategy. Theorem (among others): TWO has a winning remainder strategy for this game played on the real line with its usual topology.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2021-04-20 00:00:00.000000"},
{"id":"603","title":"Public to ready fast enough skin.","abstract":"The purpose of this note is to provide a short alternate proof that (combined with a theorem proven by Szczepanski) shows that a group which is relatively hyperbolic in the sense of the definition of Gromov is relatively hyperbolic in the sense of the definition of Farb.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2019-10-31 00:00:00.000000"},
{"id":"604","title":"Activity main drug own many teacher newspaper finally.","abstract":"Vector operations play an important role in high performance computing and are typically provided by highly optimized libraries that implement the BLAS (Basic Linear Algebra Subprograms) interface. In C++ templates and operator overloading allow the implementation of these vector operations as expression templates which construct custom loops at compile time and providing a more abstract interface. Unfortunately existing expression template libraries lack the performance of fast BLAS(Basic Linear Algebra Subprograms) implementations. This paper presents a new approach - Statically Accelerated Loop Templates (SALT) - to close this performance gap by combining expression templates with an aggressive loop unrolling technique. Benchmarks were conducted using the Intel C++ compiler and GNU Compiler Collection to assess the performance of our library relative to Intel's Math Kernel Library as well as the Eigen template library. The results show that the approach is able to provide optimization comparable to the fastest available BLAS implementations, while retaining the convenience and flexibility of a template library.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2021-10-09 00:00:00.000000"},
{"id":"605","title":"Option project building true relationship between us push.","abstract":"Parameter estimation in a class of heteroscedastic time series models is investigated. The existence of conditional least-squares and conditional likelihood estimators is proved. Their consistency and their asymptotic normality are established. Kernel estimators of the noise's density and its derivatives are defined and shown to be uniformly consistent. A simulation experiment conducted shows that the estimators perform well for large sample size.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2020-08-26 00:00:00.000000"},
{"id":"606","title":"Scene forward audience its.","abstract":"R. F. pollution has been recognized as health hazard in India in the prevailing circumstances. There is lot of hue and cry against cellular towers installed in residential area. Recently high court in India has issued an order not to install towers in residential areas. For meeting the exponential demand of cellular communication in India this will be a set back for future growth. An appropriate solution has to be developed for meeting demand as well as RF pollution concern of the society. This paper deals with the installation of low power base stations in residential areas instead of high power macro cell base stations. Macro stations are proposed to be used for fast traffic, low power micro cell for a slow traffic \/ pedestrian and pico cell \/ femto cell for indoor use. These cells will be in hierarchical structure along with adaptive frequency allocation techniques and A-SDMA approach.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2018-05-26 00:00:00.000000"},
{"id":"607","title":"Main real new their information laugh reduce.","abstract":"The Theil index is much used in economy and finance; it looks like the Shannon entropy, but pertains to event values rather than to their probabilities. Any time series can be remapped through the Theil index. Correlation coefficients can be evaluated between the new time series, thereby allowing to study their mutual statistical distance, - to be contrasted to the usual correlation distance measure for the primary time series. As an example this entropy-like correlation distance method (ECDM) is applied to the Gross Domestic Product of 20 rich countries in order to test some economy globalization process. Hierarchical distances allow to construct (i) a linear network, (ii) a Locally Minimal Spanning Tree. The role of time averaging in finite size windows is illustrated and discussed. It is also shown that the mean distance between the most developed countries, was decreasing since 1960 till 2000, - which we consider to be a proof of globalization of the economy for these countries.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2017-09-28 00:00:00.000000"},
{"id":"608","title":"Drug environmental everyone evidence beat.","abstract":"In this paper, we show that the regularity of the q-th quasi-symbolic power $I^{((q))}$ and the regularity of the $q$-th bracket power $I^{[q]}$ of a monomial ideal of Borel type $I$, satisfy the relations $reg(I^{((q))})\\leq q \\cdot reg(I)$, respectively $reg(I^{[q]})\\geq q\\cdot reg(I)$. Also, we give an upper bound for $reg(I^{[q]})$.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2015-10-15 00:00:00.000000"},
{"id":"609","title":"Best spend democratic management mind year.","abstract":"We detail the rules and mathematical structure of Al-Jabar, a game invented by the authors based on intuitive concepts of color-mixing and ideas from abstract algebra. Game-play consists of manipulating colored game pieces; we discuss how these colored pieces form a group structure and how this structure, along with an operation used to combine the pieces, is used to create a game of strategy. We also consider extensions of the game rules to other group structures.   Note: While this is an article for general readership originally published online by Gathering for Gardner in honor of Martin Gardner's birthday (Oct. 2011), Al-Jabar has been played in university abstract algebra courses as a teaching tool, as well as by game enthusiasts, since its release. Moreover, the algebraic game structure described has sparked further work by other mathematicians and game designers. Thus, we submit this article to the ArXiV as a resource for educators as well as those interested in mathematical games.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2017-01-12 00:00:00.000000"},
{"id":"610","title":"Wonder simply information under fact collection.","abstract":"In this paper, we show that the adaptive multidimensional increment ratio estimator of the long range memory parameter defined in Bardet and Dola (2012) satisfies a central limit theorem (CLT in the sequel) for a large semiparametric class of Gaussian fractionally integrated processes with memory parameter $d \\in (-0.5,1.25)$. Since the asymptotic variance of this CLT can be computed, tests of stationarity or nonstationarity distinguishing the assumptions $d<0.5$ and $d \\geq 0.5$ are constructed. These tests are also consistent tests of unit root. Simulations done on a large benchmark of short memory, long memory and non stationary processes show the accuracy of the tests with respect to other usual stationarity or nonstationarity tests (LMC, V\/S, ADF and PP tests). Finally, the estimator and tests are applied to log-returns of famous economic data and to their absolute value power laws.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2017-08-19 00:00:00.000000"},
{"id":"611","title":"Other quite play space number consumer.","abstract":"We present a model for the spontaneous onset of fast magnetic reconnection in a weakly collisional plasma, such as the solar corona. When a current layer of macroscopic width undergoes collisional (Sweet-Parker) reconnection, a narrow dissipation region forms around the X-line. This dissipation region naturally becomes narrower during the reconnection process as stronger magnetic fields are convected toward the X-line. When the dissipation region becomes thinner than the ion skin depth, resistive magnetohydrodynamics breaks down as the Hall effect becomes important and the Sweet-Parker solution ceases to exist. A transition to collisionless (Hall) reconnection ensues, increasing the reconnection rate by many orders of magnitude in a very short time. Predictions of the model are consistent with constraints set by observations of solar flares.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2015-06-16 00:00:00.000000"},
{"id":"612","title":"Way ask particularly page little.","abstract":"As Grids are emerging as the next generation service-oriented computing platforms, they need to support Grid economy that helps in the management of supply and demand for resources and offers an economic incentive for Grid resource providers. To enable this Grid economy, a market-like Grid environment including an infrastructure that supports the publication of services and their discovery is needed. As part of the Gridbus project, we proposed and have developed a Grid Market Directory (GMD) that serves as a registry for high-level service publication and discovery in Virtual Organisations.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2015-08-30 00:00:00.000000"},
{"id":"613","title":"Able third section prevent sport interview western.","abstract":"We propose in this paper a theoretical approach of teachers' professional development, focusing on teachers' interactions with resources, digital resources in particular. Documents, entailing resources and schemes of utilization of these resources, are developed throughout documentational geneses occurring along teachers' documentation work (selecting resources, adapting, combining, refining them). The study of teachers' documentation systems permits to seize the changes brought by digital resources; it also constitutes a way to embrace teachers' professional change.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2017-11-24 00:00:00.000000"},
{"id":"614","title":"Rise attack green manager.","abstract":"I report the results of the internet quiz, where the takers had to tell the music of Mozart from that of Salieri. The average score earned by over eleven thousand quiz-takers is 61%. This suggests that the music of Mozart is of about the same quality as the music of Salieri.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2020-11-22 00:00:00.000000"},
{"id":"615","title":"City medical very evening entire.","abstract":"The propagation of electromagnetic fields in matter has been the subject of intensive studies since the discovery of its rich dynamics. Impedance measurements are one most used technique available to study material properties as well as electromagnetic devices and circuits. This way, novelties on device construction and circuit technology associated to new material properties and\/or unusual field dynamics generally rely on results supported by impedance data. Recent advances on nanostructured materials explore astounding molecular properties derived from nanoscale levels and apply them to studies foucused on the generation of new devices. Accordingly, properties inherent to quantum dynamics can also generate unusual circuit elements, not included on the former development of the electromagnetic theory. On same footings, advances in field dynamics could also determine the advent of new technologies, producing immediate impact on our everyday life. In this work we present the results obtained by measuring the impedance of single spires and coils of specific geometry in the MHz range. They demonstrate that a new passive circuit element was found, which bears out the existence of an as yet unobserved propagation mode of the electromagnetic fields in matter. Our results also indicates that this effect is more evident using carbon made spires.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2015-12-26 00:00:00.000000"},
{"id":"616","title":"Spring firm travel pressure.","abstract":"We present a rectangle-based segmentation algorithm that sets up a graph and performs a graph cut to separate an object from the background. However, graph-based algorithms distribute the graph's nodes uniformly and equidistantly on the image. Then, a smoothness term is added to force the cut to prefer a particular shape. This strategy does not allow the cut to prefer a certain structure, especially when areas of the object are indistinguishable from the background. We solve this problem by referring to a rectangle shape of the object when sampling the graph nodes, i.e., the nodes are distributed nonuniformly and non-equidistantly on the image. This strategy can be useful, when areas of the object are indistinguishable from the background. For evaluation, we focus on vertebrae images from Magnetic Resonance Imaging (MRI) datasets to support the time consuming manual slice-by-slice segmentation performed by physicians. The ground truth of the vertebrae boundaries were manually extracted by two clinical experts (neurological surgeons) with several years of experience in spine surgery and afterwards compared with the automatic segmentation results of the proposed scheme yielding an average Dice Similarity Coefficient (DSC) of 90.97\\pm62.2%.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2019-01-06 00:00:00.000000"},
{"id":"617","title":"Avoid theory nice artist stand.","abstract":"A program fails. Under which circumstances does this failure occur? One single algorithm, the delta debugging algorithm, suffices to determine these failure-inducing circumstances. Delta debugging tests a program systematically and automatically to isolate failure-inducing circumstances such as the program input, changes to the program code, or executed statements.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2019-10-09 00:00:00.000000"},
{"id":"618","title":"Box former away ago.","abstract":"We determine a general link between two different solutions of the MaxEnt variational problem, namely, the ones that correspond to using either Shannon's or Tsallis' entropies in the concomitant variational problem. It is shown that the two variations lead to equivalent solutions that take different appearances but contain the same information. These solutions are linked by our transformation.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2015-01-26 00:00:00.000000"},
{"id":"619","title":"Brother sense blood thought just.","abstract":"In recent years, Answer Set Programming (ASP), logic programming under the stable model or answer set semantics, has seen several extensions by generalizing the notion of an atom in these programs: be it aggregate atoms, HEX atoms, generalized quantifiers, or abstract constraints, the idea is to have more complicated satisfaction patterns in the lattice of Herbrand interpretations than traditional, simple atoms. In this paper we refer to any of these constructs as generalized atoms. Several semantics with differing characteristics have been proposed for these extensions, rendering the big picture somewhat blurry. In this paper, we analyze the class of programs that have convex generalized atoms (originally proposed by Liu and Truszczynski in [10]) in rule bodies and show that for this class many of the proposed semantics coincide. This is an interesting result, since recently it has been shown that this class is the precise complexity boundary for the FLP semantics. We investigate whether similar results also hold for other semantics, and discuss the implications of our findings.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2020-04-01 00:00:00.000000"},
{"id":"620","title":"Serious save floor crime decision part than.","abstract":"One way of evaluating individual scientists is the determination of the number of highly cited publications, where the threshold is given by a large reference set. It is shown that this indicator behaves in a counterintuitive way, leading to inconsistencies in the ranking of different scientists.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2015-04-17 00:00:00.000000"},
{"id":"621","title":"Create these sing course develop often teach.","abstract":"We first show that the eigenvector of a tensor is well-defined. The differences between the eigenvectors of a tensor and its E-eigenvectors are the eigenvectors on the nonsingular projective variety $\\mathbb S=\\{\\mathbf x\\in\\mathbb P^n\\;|\\;\\sum\\limits_{i=0}^nx_i^2=0\\}$. We show that a generic tensor has no eigenvectors on $\\mathbb S$. Actually, we show that a generic tensor has no eigenvectors on a proper nonsingular projective variety in $\\mathbb P^n$. By these facts, we show that the coefficients of the E-characteristic polynomial are algebraically dependent. Actually, a certain power of the determinant of the tensor can be expressed through the coefficients besides the constant term. Hence, a nonsingular tensor always has an E-eigenvector. When a tensor $\\mathcal T$ is nonsingular and symmetric, its E-eigenvectors are exactly the singular points of a class of hypersurfaces defined by $\\mathcal T$ and a parameter. We give explicit factorization of the discriminant of this class of hypersurfaces, which completes Cartwright and Strumfels' formula. We show that the factorization contains the determinant and the E-characteristic polynomial of the tensor $\\mathcal T$ as irreducible factors.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2020-03-15 00:00:00.000000"},
{"id":"622","title":"Let various probably public.","abstract":"We report a single-copy tempering method for simulating large complex systems. In a generalized ensemble, the method uses runtime estimate of the thermal average energy computed from a novel integral identity to guide a continuous temperature-space random walk. We first validated the method in a two-dimensional Ising model and a Lennard-Jones liquid system. It was then applied to folding of three small proteins, trpzip2, trp-cage, and villin headpiece in explicit solvent. Within 0.5~1 microsecond, all three systems were folded into atomic accuracy: the alpha carbon root mean square deviations of the best folded conformations from the native states were 0.2 A, 0.4 A, and 0.4 A, for trpzip2, trp-cage, and villin headpiece, respectively.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2022-11-29 00:00:00.000000"},
{"id":"623","title":"Bank hit change else clear.","abstract":"We consider multi-player graph games with partial-observation and parity objective. While the decision problem for three-player games with a coalition of the first and second players against the third player is undecidable, we present a decidability result for partial-observation games where the first and third player are in a coalition against the second player, thus where the second player is adversarial but weaker due to partial-observation. We establish tight complexity bounds in the case where player 1 is less informed than player 2, namely 2-EXPTIME-completeness for parity objectives. The symmetric case of player 1 more informed than player 2 is much more complicated, and we show that already in the case where player 1 has perfect observation, memory of size non-elementary is necessary in general for reachability objectives, and the problem is decidable for safety and reachability objectives. Our results have tight connections with partial-observation stochastic games for which we derive new complexity results.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2019-06-04 00:00:00.000000"},
{"id":"624","title":"Effort statement past choice manage black pressure mission.","abstract":"The prototype of a workflow system for the submission of content to a digital object repository is here presented. It is based entirely on open-source standard components and features a service-oriented architecture. The front-end consists of Java Business Process Management (jBPM), Java Server Faces (JSF), and Java Server Pages (JSP). A Fedora Repository and a mySQL data base management system serve as a back-end. The communication between front-end and back-end uses a SOAP minimal binding stub. We describe the design principles and the construction of the prototype and discuss the possibilities and limitations of work ow creation by administrators. The code of the prototype is open-source and can be retrieved in the project escipub at http:\/\/sourceforge.net","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2022-05-26 00:00:00.000000"},
{"id":"625","title":"Among prepare control.","abstract":"Transfer learning techniques are important to handle small training sets and to allow for quick generalization even from only a few examples. The following paper is the introduction as well as the literature overview part of my thesis related to the topic of transfer learning for visual recognition problems.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2020-03-01 00:00:00.000000"},
{"id":"626","title":"Thus so ever hit likely ball let manager.","abstract":"We examine deterministic and nondeterministic state complexities of regular operations on prefix-free languages. We strengthen several results by providing witness languages over smaller alphabets, usually as small as possible. We next provide the tight bounds on state complexity of symmetric difference, and deterministic and nondeterministic state complexity of difference and cyclic shift of prefix-free languages.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2019-06-04 00:00:00.000000"},
{"id":"627","title":"Wonder sure blood three most director magazine.","abstract":"We compute the K-theory of the Cuntz-Krieger C^*-algebras associated to infinite matrices.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2016-08-20 00:00:00.000000"},
{"id":"628","title":"Think dinner attention which nothing.","abstract":"In this paper we study the simultaneous problems of food waste and hunger in the context of the possible solution of food (waste) rescue and redistribution. To this end, we develop an empirical model that can be used in Monte Carlo simulations to study the dynamics of the underlying problem. Our model's parameters are derived from a unique data set provided by a large food bank and food rescue organization in north central Colorado. We find that food supply is a non-parametric heavy-tailed process that is well-modeled with an extreme value peaks-over-threshold model. Although the underlying process is stochastic, the basic approach of food rescue and redistribution appears to be feasible both at small and large scales. The ultimate efficacy of this model is intimately tied to the rate at which food expires and hence the ability to preserve and quickly transport and redistribute food. The cost of the redistribution is tied to the number and density of participating suppliers, and costs can be reduced (and supply increased) simply by recruiting additional donors to participate. Our results show that with sufficient funding and manpower, a significant amount of food can be rescued from the waste stream and used to feed the hungry.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2015-03-11 00:00:00.000000"},
{"id":"629","title":"Military build look box.","abstract":"The first two years of user service of the third generation light source BESSY II emphasized the importance of a reliable, comprehensive and dense logging of a few thousand setpoints, readbacks, status and alarm values. Today data from sources with various characteristics residing in different protected networks are centrally collected and retrievable via an uncomplex CGI program to any desktop system on the site. Data post-processing tools cover Windows applications, IDL, SDDS and custom programs matching users skills and preferences. In this paper illustrative sample data explorations are described that underline the importance of the logging system for operations as well as for the understanding of singular events or long term drifts. Serious shortcomings of the present installation and focus of further development are described.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2022-10-30 00:00:00.000000"},
{"id":"630","title":"Spring drug across positive hand yard.","abstract":"This is another approach to realize Maxwell's \"demon\" hypothesis. Two Ag-O-Cs thermal electron ejectors, A and B, are settled in a vacuum tube. A non-uniform magnetic field exerted on the tube provides a one-way channel for the thermal electrons. Ejector A, losing electrons, charges positively, while ejector B, getting electrons, charges negatively, resulting in an electric voltage. In flying from A to B, the speed of the electrons decreases, and part of their thermal kinetic energy converts into electric potential energy. Thus, the temperature of the whole electron tube drops down slightly, and that can be compensated by the heat attracted from the ambient air. The device can provide a small but macroscopic power to an external load, violating Kelvin's statement of the second law.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2019-12-31 00:00:00.000000"},
{"id":"631","title":"Remain recent opportunity fill defense practice wear.","abstract":"The current paper presents a solution of the Program Understanding: A Reengineering Case for the Transformation Tool Contest using the VIATRA2 model transformation tool.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2020-03-05 00:00:00.000000"},
{"id":"632","title":"Ago public sometimes sense onto may.","abstract":"We propose imposing box constraints on the individual elements of the unknown matrix in the matrix completion problem and present a number of natural applications, ranging from collaborative filtering under interval uncertainty to computer vision. Moreover, we design an alternating direction parallel coordinate descent method (MACO) for a smooth unconstrained optimization reformulation of the problem. In large scale numerical experiments in collaborative filtering under uncertainty, our method obtains solution with considerably smaller errors compared to classical matrix completion with equalities. We show that, surprisingly, seemingly obvious and trivial inequality constraints, when added to the formulation, can have a large impact. This is demonstrated on a number of machine learning problems.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2021-04-23 00:00:00.000000"},
{"id":"633","title":"Chance right picture experience big often item.","abstract":"New methods and theory have recently been developed to nonparametrically estimate cumulative incidence functions for competing risks survival data subject to current status censoring. In particular, the limiting distribution of the nonparametric maximum likelihood estimator and a simplified \"naive estimator\" have been established under certain smoothness conditions. In this paper, we establish the large-sample behavior of these estimators in two additional models, namely when the observation time distribution has discrete support and when the observation times are grouped. These asymptotic results are applied to the construction of confidence intervals in the three different models. The methods are illustrated on two data sets regarding the cumulative incidence of (i) different types of menopause from a cross-sectional sample of women in the United States and (ii) subtype-specific HIV infection from a sero-prevalence study in injecting drug users in Thailand.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2018-04-29 00:00:00.000000"},
{"id":"634","title":"Possible no dog wear successful large seat as.","abstract":"We image spatial distributions of Xe$^{q+}$ ions in the focus of a laser beam of ultrashort, intense pulses in all three dimensions, with a resolution of $\\sim$3 $\\mu$m and $\\sim$12 $\\mu$m in the two transverse directions. This allows for studying ionization processes without spatially averaging ion yields. Our \\emph{in situ} ion imaging is also useful to analyze focal intensity profiles and to investigate the transverse modal purity of tightly focused beams of complex light. As an example, the intensity profile of a Hermite-Gaussian beam mode HG$_{1,0}$ recorded with ions is found to be in good agreement with optical images.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2018-10-29 00:00:00.000000"},
{"id":"635","title":"Prevent film attention choice.","abstract":"The aim of this paper is to present a method for identifying the structure of a rule in a fuzzy model. For this purpose, an ATMS shall be used (Zurita 1994). An algorithm obtaining the identification of the structure will be suggested (Castro 1995). The minimal structure of the rule (with respect to the number of variables that must appear in the rule) will be found by this algorithm. Furthermore, the identification parameters shall be obtained simultaneously. The proposed method shall be applied for classification to an example. The {em Iris Plant Database} shall be learnt for all three kinds of plants.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2017-09-18 00:00:00.000000"},
{"id":"636","title":"Agency heart employee quickly worry out participant.","abstract":"In some situations, EM algorithm shows slow convergence problems. One possible reason is that standard procedures update the parameters simultaneously. In this paper we focus on finite mixture estimation. In this framework, we propose a component-wise EM, which updates the parameters sequentially. We give an interpretation of this procedure as a proximal point algorithm and use it to prove the convergence. Illustrative numerical experiments show how our algorithm compares to EM and a version of the SAGE algorithm.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2015-09-22 00:00:00.000000"},
{"id":"637","title":"Them wear main deep defense push challenge.","abstract":"We present a simple polarizing Mach-Zehnder interferometer that can be used for optimal minimal ellipsometry: Only four intensities are measured to determine the three Stokes parameters, and an optimal choice for the four polarization projections can be achieved for any sufficiently small wavelength range of interest.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2022-08-21 00:00:00.000000"},
{"id":"638","title":"Significant former economy.","abstract":"A denoising technique based on noise invalidation is proposed. The adaptive approach derives a noise signature from the noise order statistics and utilizes the signature to denoise the data. The novelty of this approach is in presenting a general-purpose denoising in the sense that it does not need to employ any particular assumption on the structure of the noise-free signal, such as data smoothness or sparsity of the coefficients. An advantage of the method is in denoising the corrupted data in any complete basis transformation (orthogonal or non-orthogonal). Experimental results show that the proposed method, called Noise Invalidation Denoising (NIDe), outperforms existing denoising approaches in terms of Mean Square Error (MSE).","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2017-05-07 00:00:00.000000"},
{"id":"639","title":"Rise test now agreement.","abstract":"If we define classical foundational concepts constructively, and introduce non-algorithmic effective methods into classical mathematics, then we can bridge the chasm between truth and provability, and define computational methods that are not Turing-computable.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2019-07-24 00:00:00.000000"},
{"id":"640","title":"Task skill left executive success realize.","abstract":"In this paper we consider the Sturm-Liuoville operator in the Hilbert space $L_2$ with the singular complex potential of $W^{-1}_2$ and two-point boundary conditions. For this operator we give sufficient conditions for norm resolvent approximation by the operators of the same class.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2016-04-04 00:00:00.000000"},
{"id":"641","title":"Change realize plan by.","abstract":"The production of ion beams from the interaction of a circularly polarized laser pulse with a nanometric double-layer target is discussed in the regime where all electrons are expelled from the target by laser radiation pressure. Quasi-monochromatic, well-collimated ion beams are observed in two-dimensional particle-in-cell simulations. The ion beam properties are derived from a simple analytical model, and the possibility to control those properties by using a laser-pulse with sharp-rising edge is discussed. Potential application to hadron-therapy is finally considered.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2015-11-06 00:00:00.000000"},
{"id":"642","title":"Television we when open red throughout PM stay.","abstract":"We introduce, for every positive integer n, the notion of an n-relative category and show that the category of the small n-relative categories is a model for the homotopy theory of n-fold homotopy theories, i.e. homotopy theories of ... of homotopy theories.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2015-07-17 00:00:00.000000"},
{"id":"643","title":"Design two authority happen else.","abstract":"We consider approximate Bayesian model choice for model selection problems that involve models whose Fisher-information matrices may fail to be invertible along other competing submodels. Such singular models do not obey the regularity conditions underlying the derivation of Schwarz's Bayesian information criterion (BIC) and the penalty structure in BIC generally does not reflect the frequentist large-sample behavior of their marginal likelihood. While large-sample theory for the marginal likelihood of singular models has been developed recently, the resulting approximations depend on the true parameter value and lead to a paradox of circular reasoning. Guided by examples such as determining the number of components of mixture models, the number of factors in latent factor models or the rank in reduced-rank regression, we propose a resolution to this paradox and give a practical extension of BIC for singular model selection problems.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2020-01-27 00:00:00.000000"},
{"id":"644","title":"Street model region.","abstract":"Prion diseases {\\it (e.g. Creutzfeldt-Jakob disease (CJD), variant CJD (vCJD), Gerstmann-Str$\\ddot{\\text{a}}$ussler-Scheinker syndrome (GSS), Fatal Familial Insomnia (FFI) and Kuru in humans, scrapie in sheep, bovine spongiform encephalopathy (BSE or `mad-cow' disease) and chronic wasting disease (CWD) in cattles)} are invariably fatal and highly infectious neurodegenerative diseases affecting humans and animals. However, by now there have not been some effective therapeutic approaches or medications to treat all these prion diseases. Rabbits, dogs, and horses are the only mammalian species reported to be resistant to infection from prion diseases isolated from other species. Recently, the $\\beta$2-$\\alpha$2 loop has been reported to contribute to their protein structural stabilities. The author has found that rabbit prion protein has a strong salt bridge ASP177-ARG163 (like a taut bow string) keeping this loop linked. This paper confirms that this salt bridge also contributes to the structural stability of horse prion protein. Thus, the region of $\\beta$2-$\\alpha$2 loop might be a potential drug target region. Besides this very important salt bridge, other four important salt bridges GLU196-ARG156-HIS187, ARG156-ASP202 and GLU211-HIS177 are also found to greatly contribute to the structural stability of horse prion protein. Rich databases of salt bridges, hydrogen bonds and hydrophobic contacts for horse prion protein can be found in this paper.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2016-01-05 00:00:00.000000"},
{"id":"645","title":"Remain language speech with air.","abstract":"We study the state complexity of the set of subwords and superwords of regular languages, and provide new lower bounds in the case of languages over a two-letter alphabet. We also consider the dual interior sets, for which the nondeterministic state complexity has a doubly-exponential upper bound. We prove a matching doubly-exponential lower bound for downward interiors in the case of an unbounded alphabet.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2018-11-08 00:00:00.000000"},
{"id":"646","title":"Memory than city nearly.","abstract":"Internet applications increasingly employ TCP not as a stream abstraction, but as a substrate for application-level transports, a use that converts TCP's in-order semantics from a convenience blessing to a performance curse. As Internet evolution makes TCP's use as a substrate likely to grow, we offer Minion, an architecture for backward-compatible out-of-order delivery atop TCP and TLS. Small OS API extensions allow applications to manage TCP's send buffer and to receive TCP segments out-of-order. Atop these extensions, Minion builds application-level protocols offering true unordered datagram delivery, within streams preserving strict wire-compatibility with unsecured or TLS-secured TCP connections. Minion's protocols can run on unmodified TCP stacks, but benefit incrementally when either endpoint is upgraded, for a backward-compatible deployment path. Experiments suggest that Minion can noticeably improve performance of applications such as conferencing, virtual private networking, and web browsing, while incurring minimal CPU or bandwidth costs.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2020-04-08 00:00:00.000000"},
{"id":"647","title":"Meet everybody whole room.","abstract":"We found the self-similar solitary solutions of a recently proposed model for propagation of pulses in gas filled hollow-core photonic crystal fibers that includes a plasma induced nonlinearity. As anticipated for a simpler model and using a perturbation analysis, there are indeed stationary solitary waves that accelerate and self-shift to higher frequencies. However, if the plasma nonlinearity strength is large or the pulse amplitudes are small, the solutions have distinguished long tails and decay as they propagate.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2019-09-21 00:00:00.000000"},
{"id":"648","title":"Government everybody music fire.","abstract":"The past few years has witnessed the great success of recommender systems, which can significantly help users find relevant and interesting items for them in the information era. However, a vast class of researches in this area mainly focus on predicting missing links in bipartite user-item networks (represented as behavioral networks). Comparatively, the social impact, especially the network structure based properties, is relatively lack of study. In this paper, we firstly obtain five corresponding network-based features, including user activity, average neighbors' degree, clustering coefficient, assortative coefficient and discrimination, from social and behavioral networks, respectively. A hybrid algorithm is proposed to integrate those features from two respective networks. Subsequently, we employ a machine learning process to use those features to provide recommendation results in a binary classifier method. Experimental results on a real dataset, Flixster, suggest that the proposed method can significantly enhance the algorithmic accuracy. In addition, as network-based properties consider not only the social activities, but also take into account user preferences in the behavioral networks, therefore, it performs much better than that from either social or behavioral networks. Furthermore, since the features based on the behavioral network contain more diverse and meaningfully structural information, they play a vital role in uncovering users' potential preference, which, might show light in deeply understanding the structure and function of the social and behavioral networks.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2017-08-14 00:00:00.000000"},
{"id":"649","title":"Yet central into including.","abstract":"Designing a wireless node that supports quality of service (QoS) in a mobile ad hoc network is a challenging task. In this paper, we propose an architecture of a wireless node that may be used to form a mobile ad hoc network that supports QoS. We discuss the core functionalities required for such a node and how those functionalities can be incorporated. A feature of our architecture is that the node has the ability to utilize multiple paths, if available, for the provision of QoS. However, in the absence of multiple paths it can utilize the resources provided by a single path between the source and the destination. We follow a modular approach where each module is expanded iteratively. We compare the features of our architecture with the existing architectures proposed in the literature. Our architecture has provisions of energy and mobility management and it can be customized to design a system-on-chip (SoC).","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2018-03-01 00:00:00.000000"},
{"id":"650","title":"Congress open talk discussion significant light exist bag.","abstract":"We assess a variant of linear-response range-separated time-dependent density-functional theory (TDDFT), combining a long-range Hartree-Fock (HF) exchange kernel with a short-range adiabatic exchange-correlation kernel in the local-density approximation (LDA) for calculating isotropic C6 dispersion coefficients of homodimers of a number of closed-shell atoms and small molecules. This range-separated TDDFT tends to give underestimated C6 coefficients of small molecules with a mean absolute percentage error of about 5%, a slight improvement over standard TDDFT in the adiabatic LDA which tends to overestimate them with a mean absolute percentage error of 8%, but close to time-dependent Hartree-Fock which has a mean absolute percentage error of about 6%. These results thus show that introduction of long-range HF exchange in TDDFT has a small but beneficial impact on the values of C6 coefficients. It also confirms that the present variant of range-separated TDDFT is a reasonably accurate method even using only a LDA-type density functional and without adding an explicit treatment of long-range correlation.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2015-07-01 00:00:00.000000"},
{"id":"651","title":"Subject money blue several.","abstract":"In Intelligence Analysis it is of vital importance to manage uncertainty. Intelligence data is almost always uncertain and incomplete, making it necessary to reason and taking decisions under uncertainty. One way to manage the uncertainty in Intelligence Analysis is Dempster-Shafer Theory. This thesis contains five results regarding multiple target tracks and intelligence specification.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2015-02-10 00:00:00.000000"},
{"id":"652","title":"Official always economic skill.","abstract":"In this article the lack of equilibrium between matter and antimatter is elucidated. Heisenberg uncertainty principle is a crucial ingredient to understand this disproportion.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2019-01-31 00:00:00.000000"},
{"id":"653","title":"Already rise wide off indeed door.","abstract":"In this work we study a class of stochastic processes $\\{X_t\\}_{t\\in\\N}$, where $X_t = (\\phi \\circ T_s^t)(X_0)$ is obtained from the iterations of the transformation T_s, invariant for an ergodic probability \\mu_s on [0,1] and a continuous by part function $\\phi:[0,1] \\to \\R$. We consider here $T_s:[0,1]\\to [0,1]$ the Manneville-Pomeau transformation. The autocorrelation function of the resulting process decays hyperbolically (or polynomially) and we obtain efficient methods to estimate the parameter s from a finite time series. As a consequence we also estimate the rate of convergence of the autocorrelation decay of these processes. We compare different estimation methods based on the periodogram function, on the smoothed periodogram function, on the variance of the partial sum and on the wavelet theory.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2021-02-26 00:00:00.000000"},
{"id":"654","title":"Surface require similar himself.","abstract":"We study in this work flat surfaces with conical singularities, that is, surfaces provided with a flat structure with conical singular points. Finding good parameters for these surfaces in the general case is an open question. We give an answer to this question in the case of flat structures on pairs of pants with one singular point. The question of decomposability of an arbitrary flat surface into flat pairs of pants is discussed.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2021-07-26 00:00:00.000000"},
{"id":"655","title":"Exist modern value first morning.","abstract":"NOOP is a mathematical model of nominally-typed OOP that proves the identification of inheritance and subtyping in mainstream nominally-typed OO programming languages and the validity of this identification. This report gives an overview of the main notions in OOP relevant to constructing a mathematical model of OOP such as NOOP. The emphasis in this report is on defining nominality, nominal typing and nominal subtyping of mainstream nominally-typed OO languages, and on contrasting the three notions with their counterparts in structurally-typed OO languages, i.e., with structurality, structural typing and structural subtyping, respectively. An additional appendix demonstrates these notions and other related notions, and the differences between them, using some simple code examples. A detailed, more technical comparison between nominal typing and structural typing in OOP is presented in other publications.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2022-12-18 00:00:00.000000"},
{"id":"656","title":"Who final show red compare financial head.","abstract":"This work presents a numerical simulation using CFX 4.4 of the Energy Amplifier Experimental Facility (X-ADS) downcomer channel. The simulation is focused on the Steady-State Analysis. The Intermediate Heat exchangers (IHX) of the X-ADS reference configuration are immersed in the lead-bismuth eutectic of the downcomer. Due to the absence of a physical separation between the primary coolant hot and cold collectors, two different flow paths are available in the downcomer region: inside the IHX and outside it (IHX by-pass flow). The amount of IHX by-pass flow is determined by the balance between the driving force due to buoyancy (originated by the weight difference between the cooled fluid inside the IHX and the hot outside downcomer fluid) and the IHX pressure losses. At the IHX exit the two flow paths are mixed before the core inlet. This fact provides a potential for a downcomer thermal stratification, which is influenced by the actual value of coolant flow rate outside the IHX. The amount and extension of the thermal stratification phenomena is the object of this study. The simulation allowed studying the position and intensity of the thermal stratification phenomena. Several runs have been performed. However, to limit the extension of the paper, we deal with the results of only one of the calculations performed, which resulted in the worst condition from the point of view of thermal loads on the structure. Other results obtained will be shortly recalled when needed.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2016-07-14 00:00:00.000000"},
{"id":"657","title":"Effort ball ball study.","abstract":"We prove a basic result about tensor products of a $\\text{II}_1$ factor with a finite von Neumann algebra and use it to answer, affirmatively, a question asked by S. Popa about maximal injective factors.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2019-06-16 00:00:00.000000"},
{"id":"658","title":"Decision series father loss go return stuff rather.","abstract":"We develop a linear response theory of solvation of ionic and dipolar solutes in anisotropic, axially symmetric polar solvents. The theory is applied to solvation in polar nematic liquid crystals. The formal theory constructs the solvation response function from projections of the solvent dipolar susceptibility on rotational invariants. These projections are obtained from Monte Carlo simulations of a fluid of dipolar spherocylinders which can exist both in the isotropic and nematic phase. Based on the properties of the solvent susceptibility from simulations and the formal solution, we have obtained a formula for the solvation free energy which incorporates experimentally available properties of nematics and the length of correlation between the dipoles in the liquid crystal. Illustrative calculations are presented for the Stokes shift and Stokes shift correlation function of coumarin-153 in 4-n-pentyl-4'-cyanobiphenyl (5CB) and 4,4-n-heptyl-cyanopiphenyl (7CB) solvents as a function of temperature in both the nematic and isotropic phase.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2020-11-13 00:00:00.000000"},
{"id":"659","title":"Music involve nation seek live life.","abstract":"We construct and analyze an explicit basis for the homology of the boolean complex of a Coxeter system. This gives combinatorial meaning to the spheres in the wedge sum describing the homotopy type of the complex. We assign a set of derangements to any finite simple graph. For each derangement, we construct a corresponding element in the homology of the complex, and the collection of these elements forms a basis for the homology of the boolean complex. In this manner, the spheres in the wedge sum describing the homotopy type of the complex can be represented by a set of derangements. We give an explicit, closed-form description of the derangements that can be obtained from any graph, and compute this set for several families of graphs. In the cases of complete graphs and Ferrers graphs, these calculations give bijective proofs of previously obtained enumerative results.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2016-11-10 00:00:00.000000"},
{"id":"660","title":"Light require PM perform.","abstract":"In this contribution we use the model of discrete spaces that we have put forward in former articles to give an interpretation to the phenomena of quantum entanglement and quantum states reduction that rests upon a new way of considering space and time.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2015-10-06 00:00:00.000000"},
{"id":"661","title":"Space culture account rich kitchen rich.","abstract":"I detail applications of timer interrupts in a popular micro-controller family to time critical applications in laser-cooling type experiments. I demonstrate a low overhead 1-bit frequency locking scheme and a multichannel experimental sequencer using the timer-counter intterrupts to achieve accurate timing along with flexible interfaces. The general purpose nature of micro-controllers can offer unique functionality compared with commercial solutions due to the flexibility of a computer controlled interface without the poor latencies associated with computer timing.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2016-10-29 00:00:00.000000"},
{"id":"662","title":"Law behavior suffer adult employee seat this.","abstract":"The Langevin theory of the polarization of a dilute collection of dipoles by an external field is often included in introductory solid state physics and physical chemistry curricula. The average polarization is calculated assuming the dipoles are in thermal equilibrium with a heat bath. The heart of the polarization calculation is a derivation of the average dipole-field projection, whose dependence on the external field is given by the Langevin function. The Langevin problem is revisited, here, and the average projection of any given dipole onto any other dipole from the collection is derived in terms of the Langevin function. A simple expression is obtained for the underlying dipole-dipole angular distribution function.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2016-12-10 00:00:00.000000"},
{"id":"663","title":"This parent crime suggest.","abstract":"Document classification is a task of assigning a new unclassified document to one of the predefined set of classes. The content based document classification uses the content of the document with some weighting criteria to assign it to one of the predefined classes. It is a major task in library science, electronic document management systems and information sciences. This paper investigates document classification by using two different classification techniques (1) Support Vector Machine (SVM) and (2) Relevance Vector Machine (RVM). SVM is a supervised machine learning technique that can be used for classification task. In its basic form, SVM represents the instances of the data into space and tries to separate the distinct classes by a maximum possible wide gap (hyper plane) that separates the classes. On the other hand RVM uses probabilistic measure to define this separation space. RVM uses Bayesian inference to obtain succinct solution, thus RVM uses significantly fewer basis functions. Experimental studies on three standard text classification datasets reveal that although RVM takes more training time, its classification is much better as compared to SVM.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2022-07-12 00:00:00.000000"},
{"id":"664","title":"Conference others level small I include budget.","abstract":"We examine the combination of two directions in the field of privacy concerning computations over distributed private inputs - secure function evaluation (SFE) and differential privacy. While in both the goal is to privately evaluate some function of the individual inputs, the privacy requirements are significantly different. The general feasibility results for SFE suggest a natural paradigm for implementing differentially private analyses distributively: First choose what to compute, i.e., a differentially private analysis; Then decide how to compute it, i.e., construct an SFE protocol for this analysis.   We initiate an examination whether there are advantages to a paradigm where both decisions are made simultaneously. In particular, we investigate under which accuracy requirements it is beneficial to adapt this paradigm for computing a collection of functions including binary sum, gap threshold, and approximate median queries. Our results imply that when computing the binary sum of $n$ distributed inputs then:   * When we require that the error is $o(\\sqrt{n})$ and the number of rounds is constant, there is no benefit in the new paradigm.   * When we allow an error of $O(\\sqrt{n})$, the new paradigm yields more efficient protocols when we consider protocols that compute symmetric functions.   Our results also yield new separations between the local and global models of computations for private data analysis.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2015-11-21 00:00:00.000000"},
{"id":"665","title":"Scene will but matter travel administration front Republican.","abstract":"Predictive recursion is an accurate and computationally efficient algorithm for nonparametric estimation of mixing densities in mixture models. In semiparametric mixture models, however, the algorithm fails to account for any uncertainty in the additional unknown structural parameter. As an alternative to existing profile likelihood methods, we treat predictive recursion as a filter approximation to fitting a fully Bayes model, whereby an approximate marginal likelihood of the structural parameter emerges and can be used for inference. We call this the predictive recursion marginal likelihood. Convergence properties of predictive recursion under model mis-specification also lead to an attractive construction of this new procedure. We show pointwise convergence of a normalized version of this marginal likelihood function. Simulations compare the performance of this new marginal likelihood approach that of existing profile likelihood methods as well as Dirichlet process mixtures in density estimation. Mixed-effects models and an empirical Bayes multiple testing application in time series analysis are also considered.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2022-06-12 00:00:00.000000"},
{"id":"666","title":"Foreign health land.","abstract":"We present a novel inference algorithm for arbitrary, binary, undirected graphs. Unlike loopy belief propagation, which iterates fixed point equations, we directly descend on the Bethe free energy. The algorithm consists of two phases, first we update the pairwise probabilities, given the marginal probabilities at each unit,using an analytic expression. Next, we update the marginal probabilities, given the pairwise probabilities by following the negative gradient of the Bethe free energy. Both steps are guaranteed to decrease the Bethe free energy, and since it is lower bounded, the algorithm is guaranteed to converge to a local minimum. We also show that the Bethe free energy is equal to the TAP free energy up to second order in the weights. In experiments we confirm that when belief propagation converges it usually finds identical solutions as our belief optimization method. However, in cases where belief propagation fails to converge, belief optimization continues to converge to reasonable beliefs. The stable nature of belief optimization makes it ideally suited for learning graphical models from data.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2018-03-26 00:00:00.000000"},
{"id":"667","title":"Mission above scientist recent rest.","abstract":"Alignment-free sequence analysis approaches provide important alternatives over multiple sequence alignment (MSA) in biological sequence analysis because alignment-free approaches have low computation complexity and are not dependent on high level of sequence identity, however, most of the existing alignment-free methods do not employ true full information content of sequences and thus can not accurately reveal similarities and differences among DNA sequences. We present a novel alignment-free computational method for sequence analysis based on Ramanujan-Fourier transform (RFT), in which complete information of DNA sequences is retained. We represent DNA sequences as four binary indicator sequences and apply RFT on the indicator sequences to convert them into frequency domain. The Euclidean distance of the complete RFT coefficients of DNA sequences are used as similarity measure. To address the different lengths in Euclidean space of RFT coefficients, we pad zeros to short DNA binary sequences so that the binary sequences equal the longest length in the comparison sequence data. Thus, the DNA sequences are compared in the same dimensional frequency space without information loss. We demonstrate the usefulness of the proposed method by presenting experimental results on hierarchical clustering of genes and genomes. The proposed method opens a new channel to biological sequence analysis, classification, and structural module identification.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2016-03-05 00:00:00.000000"},
{"id":"668","title":"Can statement bar show upon type.","abstract":"We propose new summary statistics for intensity-reweighted moment stationary point processes that generalise the well known J-, empty space, and nearest-neighbour distance distribution functions, represent them in terms of generating functionals and conditional intensities, and relate them to the inhomogeneous reduced second moment function. Extensions to space time and marked point processes are briefly discussed.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2016-11-17 00:00:00.000000"},
{"id":"669","title":"Story out political song again.","abstract":"Often we wish to predict a large number of variables that depend on each other as well as on other observed variables. Structured prediction methods are essentially a combination of classification and graphical modeling, combining the ability of graphical models to compactly model multivariate data with the ability of classification methods to perform prediction using large sets of input features. This tutorial describes conditional random fields, a popular probabilistic method for structured prediction. CRFs have seen wide application in natural language processing, computer vision, and bioinformatics. We describe methods for inference and parameter estimation for CRFs, including practical issues for implementing large scale CRFs. We do not assume previous knowledge of graphical modeling, so this tutorial is intended to be useful to practitioners in a wide variety of fields.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2018-05-09 00:00:00.000000"},
{"id":"670","title":"Republican his year defense small theory.","abstract":"We compute all dynamical degrees of monomial maps by interpreting them as mixed volumes of polytopes. By exploiting further the isomorphism between the polytope algebra of P. McMullen and the universal cohomology of complete toric varieties, we construct invariant positive cohomology classes when the dynamical degrees have no resonance.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2022-12-03 00:00:00.000000"},
{"id":"671","title":"Report sometimes significant wear those certainly course.","abstract":"This paper presents a stream processor generator, called SPGen, for FPGA-based system-on-chip platforms. In our research project, we use an FPGA as a common platform for applications ranging from HPC to embedded\/robotics computing. Pipelining in application-specific stream processors brings FPGAs power-efficient and high-performance computing. However, poor productivity in developing custom pipelines prevents the reconfigurable platform from being widely and easily used. SPGen aims at assisting developers to design and implement high-throughput stream processors by generating their HDL codes with our domain-specific high-level stream processing description, called SPD.With an example of fluid dynamics computation, we validate SPD for describing a real application and verify SPGen for synthesis with a pipelined data-flow graph. We also demonstrate that SPGen allows us to easily explore a design space for finding better implementation than a hand-designed one.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2019-08-28 00:00:00.000000"},
{"id":"672","title":"View sing arm clear low affect.","abstract":"We consider estimation in a sparse additive regression model with the design points on a regular lattice. We establish the minimax convergence rates over Sobolev classes and propose a Fourier-based rate-optimal estimator which is adaptive to the unknown sparsity and smoothness of the response function. The estimator is derived within Bayesian formalism but can be naturally viewed as a penalized maximum likelihood estimator with the complexity penalties on the number of nonzero univariate additive components of the response and on the numbers of the nonzero coefficients of their Fourer expansions. We compare it with several existing counterparts and perform a short simulation study to demonstrate its performance.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2016-03-17 00:00:00.000000"},
{"id":"673","title":"Consider party cause identify describe pick sometimes will.","abstract":"Expanding on the work of Fouli and Vassilev \\cite{FV}, we determine a formula for the *-$\\rm{core}$ of an ideal in two different settings: (1) in a Cohen--Macaulay local ring of characteristic $p>0$, perfect residue field and test ideal of depth at least two, where the ideal has a minimal *-reduction that is a parameter ideal and (2) in a normal local domain of characteristic $p>0$, perfect residue field and $\\m$-primary test ideal, where the ideal is a sufficiently high Frobenius power of an ideal. We also exhibit some examples where our formula fails if our hypotheses are not met.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2019-05-30 00:00:00.000000"},
{"id":"674","title":"Compare prove step seem section standard.","abstract":"Breast cancer is the second leading cause for death among women and it is diagnosed with the help of mammograms. Oncologists are miserably failed in identifying the micro calcification at the early stage with the help of the mammogram visually. In order to improve the performance of the breast cancer screening, most of the researchers have proposed Computer Aided Diagnosis using image processing. In this study mammograms are preprocessed and features are extracted, then the abnormality is identified through the classification. If all the extracted features are used, most of the cases are misidentified. Hence feature selection procedure is sought. In this paper, Fuzzy-Rough feature selection with {\\pi} membership function is proposed. The selected features are used to classify the abnormalities with help of Ant-Miner and Weka tools. The experimental analysis shows that the proposed method improves the mammograms classification accuracy.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2021-12-28 00:00:00.000000"},
{"id":"675","title":"Center image policy management away that state.","abstract":"Recently Baraglia showed how topological T-duality can be extended to apply not only to principal circle bundles, but also to non-principal circle bundles. We show that his results can also be recovered via two other methods: the homotopy-theoretic approach of Bunke and Schick, and the noncommutative geometry approach which we previously used for principal torus bundles. This work has several interesting byproducts, including a study of the K-theory of crossed products by Isom(R), the universal cover of O(2), and some interesting facts about equivariant K-theory for Z\/2. In the final section of this paper, these results are extended to the case of bundles with singular fibers, or in other words, non-free O(2)-actions.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2022-02-22 00:00:00.000000"},
{"id":"676","title":"Cut team property.","abstract":"We present a sound static analysis technique for fighting the combinatorial explosion of parameterised Boolean equation systems (PBESs). These essentially are systems of mutually recursive fixed point equations ranging over first-order logic formulae. Our method detects parameters that are not live by analysing a control flow graph of a PBES, and it subsequently eliminates such parameters. We show that a naive approach to constructing a control flow graph, needed for the analysis, may suffer from an exponential blow-up, and we define an approximate analysis that avoids this problem. The effectiveness of our techniques is evaluated using a number of case studies.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2022-11-25 00:00:00.000000"},
{"id":"677","title":"Themselves create teach style member man.","abstract":"The relationship between algebraic geometry and the inferential framework of the Bayesian Networks with hidden variables has now been fruitfully explored and exploited by a number of authors. More recently the algebraic formulation of Causal Bayesian Networks has also been investigated in this context. After reviewing these newer relationships, we proceed to demonstrate that many of the ideas embodied in the concept of a ``causal model'' can be more generally expressed directly in terms of a partial order and a family of polynomial maps. The more conventional graphical constructions, when available, remain a powerful tool.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2019-07-19 00:00:00.000000"},
{"id":"678","title":"News prevent travel floor price teach drive.","abstract":"We develop singular value shrinkage priors for the mean matrix parameters in the matrix-variate Normal model with known covariance matrices. Introduced priors are superharmonic and put more weight on matrices with smaller singular values. They are a natural generalization of the Stein prior. Bayes estimators and Bayesian predictive densities based on introduced priors are minimax and dominate those based on the uniform prior in finite samples. The risk reduction is large when the true value of the parameter has small singular values. In particular, introduced priors perform stably well in the low rank case. We apply this result to multivariate linear regression problems by considering priors depending on the future samples. Introduced priors are compatible with reduced-rank regression.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2021-04-05 00:00:00.000000"},
{"id":"679","title":"Bar former gun well she wide catch.","abstract":"Statistical characteristics of freely decaying two-dimensional hydrodynamic turbulence at high Reynolds numbers are numerically studied. In particular, numerical experiments (with resolution up to $8192\\times 8192$) provide a Kraichnan-type turbulence spectrum $E_k\\sim k^{-3}$. By means of spatial filtration, it is found that the main contribution to the spectrum comes from the sharp vorticity gradients in the form of quasi-shocks. Such quasi-singularities are responsible for a strong angular dependence of the spectrum owing to well-localized (in terms of the angle) jets with minor and\/or large overlapping. In each jet, the spectrum decreases as $k^{-3}$. The behavior of the third-order structure function accurately agrees with Kraichnan direct cascade concept corresponding to a constant enstrophy flux. It is shown that the power law exponents $\\zeta_n$ for higher structure functions grow more slowly than the linear dependence of $n$, which testifies to turbulence intermittency.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2017-12-29 00:00:00.000000"},
{"id":"680","title":"Large everybody ever wall feel.","abstract":"We developed a novel technique for frequency measurement and synthesis, based on the operation of a femtosecond comb generator as transfer oscillator. The technique can be used to measure frequency ratios of any optical signals throughout the visible and near-infrared part of the spectrum. Relative uncertainties of $10^{-18}$ for averaging times of 100 s are possible. Using a Nd:YAG laser in combination with a nonlinear crystal we measured the frequency ratio of the second harmonic $\\nu_{SH}$ at 532 nm to the fundamental $\\nu_0$ at 1064 nm, $\\nu_{SH}\/\\nu_0 = 2.000 000 000 000 000 001 \\times (1 \\pm 7 \\times 10^{-19})$.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2022-09-06 00:00:00.000000"},
{"id":"681","title":"Accept property woman.","abstract":"An accelerated classical point charge radiates at the Larmor power rate $2e^2a^2\/3$, leading to the expectation of an associated radiation reaction force. The famous Abraham-Lorentz-Dirac proposal is plagued with difficulties. Here we note a simple, amazing, and apparently overlooked fact: an accelerated charge is also always absorbing power at exactly the Larmor rate. Implications for radiation reaction and the particle motion are considered. Our analysis supports Kijowski's recent proposal.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2020-09-12 00:00:00.000000"},
{"id":"682","title":"Plan network admit avoid financial.","abstract":"Self-organizing neural networks are used for brick finding in OPERA experiment. Self-organizing neural networks and wavelet analysis used for recognition and extraction of car numbers from images.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2017-10-21 00:00:00.000000"},
{"id":"683","title":"Large development act author.","abstract":"We show that the near-field functionality of hyperbolic metamaterials (HMM), typically proposed for increasing the photonic local density of states (LDOS), can be achieved with thin metal films. Although HMMs have an infinite density of internally-propagating plane-wave states, the external coupling to nearby emitters is severely restricted. We show analytically that properly designed thin films, of thicknesses comparable to the metal size of a hyperbolic metamaterial, yield a LDOS as high as (if not higher than) that of HMMs. We illustrate these ideas by performing exact numerical computations of the LDOS of multilayer HMMs, along with their application to the problem of maximizing near-field heat transfer, to show that thin films are suitable replacements in both cases.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2017-04-02 00:00:00.000000"},
{"id":"684","title":"Night ago president high give brother.","abstract":"The formation of $^{40}$Ca$_2^+$ molecular ions is observed in a hybrid $^{40}$Ca magneto-optical and ion trap system. The molecular ion formation process is determined to be two-photon photo-associative ionization of ultracold $^{40}$Ca atoms. A lower bound for the two-body, two-photon rate constant is found to be $\\bar{\\beta} \\geq 2 \\pm 1 \\times 10^{-15}$ cm$^{3}$ Hz. $\\textit{Ab initio}$ molecular potential curves are calculated for the neutral Ca$_2$ and ionic Ca$_2^+$ molecules and used in a model that identifies the photo-associative ionization pathway. As this technique does not require a separate photo-association laser, it could find use as a simple, robust method for producing ultracold, state-selected molecular ions.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2021-08-21 00:00:00.000000"},
{"id":"685","title":"Happy hundred front heavy car move.","abstract":"Introduced below is a quantum database method, not only for retrieval but also for creation. It uses a particular structure of true's and false's in a state vector of n qubits, permitting up to 2**2**n words, vastly more than for classical bits. Several copies are produced so that later they can be destructively observed and a word determined with high probability. Grover's algorithm is proposed below to read out, nondestructively the unknown contents of a given stored state vector using only one state vector.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2017-10-10 00:00:00.000000"},
{"id":"686","title":"Doctor list practice get this listen.","abstract":"In this paper, we present a GPU implementation of a two-dimensional shallow water model. Water simulations are useful for modeling floods, river\/reservoir behavior, and dam break scenarios. Our GPU implementation shows vast performance improvements over the original Fortran implementation. By taking advantage of the GPU, researchers and engineers will be able to study water systems more efficiently and in greater detail.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2020-12-04 00:00:00.000000"},
{"id":"687","title":"Kind try material so measure miss many.","abstract":"We describe Venture, an interactive virtual machine for probabilistic programming that aims to be sufficiently expressive, extensible, and efficient for general-purpose use. Like Church, probabilistic models and inference problems in Venture are specified via a Turing-complete, higher-order probabilistic language descended from Lisp. Unlike Church, Venture also provides a compositional language for custom inference strategies built out of scalable exact and approximate techniques. We also describe four key aspects of Venture's implementation that build on ideas from probabilistic graphical models. First, we describe the stochastic procedure interface (SPI) that specifies and encapsulates primitive random variables. The SPI supports custom control flow, higher-order probabilistic procedures, partially exchangeable sequences and ``likelihood-free'' stochastic simulators. It also supports external models that do inference over latent variables hidden from Venture. Second, we describe probabilistic execution traces (PETs), which represent execution histories of Venture programs. PETs capture conditional dependencies, existential dependencies and exchangeable coupling. Third, we describe partitions of execution histories called scaffolds that factor global inference problems into coherent sub-problems. Finally, we describe a family of stochastic regeneration algorithms for efficiently modifying PET fragments contained within scaffolds. Stochastic regeneration linear runtime scaling in cases where many previous approaches scaled quadratically. We show how to use stochastic regeneration and the SPI to implement general-purpose inference strategies such as Metropolis-Hastings, Gibbs sampling, and blocked proposals based on particle Markov chain Monte Carlo and mean-field variational inference techniques.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2019-12-30 00:00:00.000000"},
{"id":"688","title":"Agency important agree build.","abstract":"The full relativity of the concepts of motion and rest, which is characteristic of the Einsteinian general relativity (GR), does not allow the generation of physical gravitational waves (GW's). -- The undulatory nature of a metric tensor is not an invariant property, but depends on the coordinate frame. -- An undulation of a metric tensor is propagated with a speed that can have any value between zero and infinite.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2017-03-13 00:00:00.000000"},
{"id":"689","title":"Method air good choice research.","abstract":"The advent of sensor networks presents untapped opportunities for synthesis. We examine the problem of synthesis of behavioral specifications into networks of programmable sensor blocks. The particular behavioral specification we consider is an intuitive user-created network diagram of sensor blocks, each block having a pre-defined combinational or sequential behavior. We synthesize this specification to a new network that utilizes a minimum number of programmable blocks in place of the pre-defined blocks, thus reducing network size and hence network cost and power. We focus on the main task of this synthesis problem, namely partitioning pre-defined blocks onto a minimum number of programmable blocks, introducing the efficient but effective PareDown decomposition algorithm for the task. We describe the synthesis and simulation tools we developed. We provide results showing excellent network size reductions through such synthesis, and significant speedups of our algorithm over exhaustive search while obtaining near-optimal results for 15 real network designs as well as nearly 10,000 randomly generated designs.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2021-09-22 00:00:00.000000"},
{"id":"690","title":"Tough more series.","abstract":"A new MS Excel application has been developed which seeks to reduce the risks associated with the development, operation and auditing of Excel spreadsheets. FormulaDataSleuth provides a means of checking spreadsheet formulas and data as they are developed or used, enabling the users to identify actual or potential errors quickly and thereby halt their propagation. In this paper, we will describe, with examples, how the application works and how it can be applied to reduce the risks associated with Excel spreadsheets.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2019-10-23 00:00:00.000000"},
{"id":"691","title":"Learn growth pull discuss million.","abstract":"The varying-coefficient model is an important nonparametric statistical model that allows us to examine how the effects of covariates vary with exposure variables. When the number of covariates is big, the issue of variable selection arrives. In this paper, we propose and investigate marginal nonparametric screening methods to screen variables in ultra-high dimensional sparse varying-coefficient models. The proposed nonparametric independence screening (NIS) selects variables by ranking a measure of the nonparametric marginal contributions of each covariate given the exposure variable. The sure independent screening property is established under some mild technical conditions when the dimensionality is of nonpolynomial order, and the dimensionality reduction of NIS is quantified. To enhance practical utility and the finite sample performance, two data-driven iterative NIS methods are proposed for selecting thresholding parameters and variables: conditional permutation and greedy methods, resulting in Conditional-INIS and Greedy-INIS. The effectiveness and flexibility of the proposed methods are further illustrated by simulation studies and real data applications.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2015-11-19 00:00:00.000000"},
{"id":"692","title":"Teacher agency buy name machine grow claim.","abstract":"In complex network research clique percolation, introduced by Palla et al., is a deterministic community detection method, which allows for overlapping communities and is purely based on local topological properties of a network. Here we present a sequential clique percolation algorithm (SCP) to do fast community detection in weighted and unweighted networks, for cliques of a chosen size. This method is based on sequentially inserting the constituent links to the network and simultaneously keeping track of the emerging community structure. Unlike existing algorithms, the SCP method allows for detecting k-clique communities at multiple weight thresholds in a single run, and can simultaneously produce a dendrogram representation of hierarchical community structure. In sparse weighted networks, the SCP algorithm can also be used for implementing the weighted clique percolation method recently introduced by Farkas et al. The computational time of the SCP algorithm scales linearly with the number of k-cliques in the network. As an example, the method is applied to a product association network, revealing its nested community structure.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2017-10-07 00:00:00.000000"},
{"id":"693","title":"Compare either our total.","abstract":"We present a unified treatment of the prevalence of different double ionization (DI) pathways as a function of the sum of the final electron energies in strongly driven Helium. We do so as a function of laser frequency and intensity. At small total energy a new DI pathway prevails where both electrons are ionized with a delay after re-collision. We find that three-body collisions between the two electrons and the nucleus underly this pathway--we refer to it as triple collision (TC) pathway. At high total energy the pathway that prevails is the one where one electron is ionized with a delay following re-collision---we refer to it as Delayed pathway. Asymptotic observables that trace the prevalence of the latter pathways are identified.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2018-08-07 00:00:00.000000"},
{"id":"694","title":"Question prepare seven born human off government.","abstract":"It is shown that extreme problem for one-dimensional Euler-Lagrange variational functional in $C^1[a;b]$ under the strengthened Legendre condition can be solved without using Hamilton-Jacobi equation. In this case, exactly one of the two possible cases requires a restriction to a length of $[a;b]$, defined only by the form of integrand. The result is extended to the case of compact extremum in $H^1[a;b]$.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2020-02-05 00:00:00.000000"},
{"id":"695","title":"Affect black training she least like glass.","abstract":"e investigate both experimentally and theoretically the waveguiding properties of a novel double trench waveguide where a conventional single-mode strip waveguide is embedded in a two dimensional photonic crystal (PhC) slab formed in silicon on insulator (SOI) wafers. We demonstrate that the bandwidth for relatively low-loss (50dB\/cm) waveguiding is significantly expanded to 250nm covering almost all the photonic band gap owing to nearly linear dispersion of the TE-like waveguiding mode. The flat transmission spectrum however is interrupted by numerous narrow stop bands. We found that these stop bands can be attributed to anti-crossing between TE-like (positive parity) and TM-like (negative parity) modes. This effect is a direct result of the strong asymmetry of the waveguides that have an upper cladding of air and lower cladding of oxide. To our knowledge this is the first demonstration of the effects of cladding asymmetry on the transmission characteristics of the PhC slab waveguides.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2016-09-10 00:00:00.000000"},
{"id":"696","title":"World central should color win.","abstract":"A challenging problem is to find an algorithm to decide whether a morphism is k-power-free. We provide such an algorithm when k >= 3 for uniform morphisms showing that in such a case, contrarily to the general case, there exist finite test-sets for k-power-freeness.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2021-07-23 00:00:00.000000"},
{"id":"697","title":"Whatever foreign cell travel machine system.","abstract":"Optical frequency combs provide equidistant frequency markers in the infrared, visible and ultra-violet and can link an unknown optical frequency to a radio or microwave frequency reference. Since their inception frequency combs have triggered major advances in optical frequency metrology and precision measurements and in applications such as broadband laser-based gas sensing8 and molecular fingerprinting. Early work generated frequency combs by intra-cavity phase modulation while to date frequency combs are generated utilizing the comb-like mode structure of mode-locked lasers, whose repetition rate and carrier envelope phase can be stabilized. Here, we report an entirely novel approach in which equally spaced frequency markers are generated from a continuous wave (CW) pump laser of a known frequency interacting with the modes of a monolithic high-Q microresonator13 via the Kerr nonlinearity. The intrinsically broadband nature of parametric gain enables the generation of discrete comb modes over a 500 nm wide span (ca. 70 THz) around 1550 nm without relying on any external spectral broadening. Optical-heterodyne-based measurements reveal that cascaded parametric interactions give rise to an optical frequency comb, overcoming passive cavity dispersion. The uniformity of the mode spacing has been verified to within a relative experimental precision of 7.3*10(-18).","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2017-01-18 00:00:00.000000"},
{"id":"698","title":"Rather per benefit.","abstract":"We produce new upper and lower bounds for the s-Frobenius number by relating it to the so called s-covering radius of a certain convex body with respect to a certain lattice; this generalizes a well-known theorem of R. Kannan for the classical Frobenius number. Using these bounds, we obtain results on the average behavior of the s-Frobenius number, extending analogous recent investigations for the classical Frobenius number by a variety of authors. We also derive bounds on the s-covering radius, an interesting geometric quantity in its own right.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2016-04-27 00:00:00.000000"},
{"id":"699","title":"Approach political religious production police social.","abstract":"We present a new method for analyzing the running time of parallel evolutionary algorithms with spatially structured populations. Based on the fitness-level method, it yields upper bounds on the expected parallel running time. This allows to rigorously estimate the speedup gained by parallelization. Tailored results are given for common migration topologies: ring graphs, torus graphs, hypercubes, and the complete graph. Example applications for pseudo-Boolean optimization show that our method is easy to apply and that it gives powerful results. In our examples the possible speedup increases with the density of the topology. Surprisingly, even sparse topologies like ring graphs lead to a significant speedup for many functions while not increasing the total number of function evaluations by more than a constant factor. We also identify which number of processors yield asymptotically optimal speedups, thus giving hints on how to parametrize parallel evolutionary algorithms.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2020-03-08 00:00:00.000000"},
{"id":"700","title":"You large many agreement.","abstract":"Several messages express opinions about events, products, and services, political views or even their author's emotional state and mood. Sentiment analysis has been used in several applications including analysis of the repercussions of events in social networks, analysis of opinions about products and services, and simply to better understand aspects of social communication in Online Social Networks (OSNs). There are multiple methods for measuring sentiments, including lexical-based approaches and supervised machine learning methods. Despite the wide use and popularity of some methods, it is unclear which method is better for identifying the polarity (i.e., positive or negative) of a message as the current literature does not provide a method of comparison among existing methods. Such a comparison is crucial for understanding the potential limitations, advantages, and disadvantages of popular methods in analyzing the content of OSNs messages. Our study aims at filling this gap by presenting comparisons of eight popular sentiment analysis methods in terms of coverage (i.e., the fraction of messages whose sentiment is identified) and agreement (i.e., the fraction of identified sentiments that are in tune with ground truth). We develop a new method that combines existing approaches, providing the best coverage results and competitive agreement. We also present a free Web service called iFeel, which provides an open API for accessing and comparing results across different sentiment methods for a given text.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2022-04-01 00:00:00.000000"},
{"id":"701","title":"Political decision serve yet sit real sort suffer.","abstract":"Solvency games, introduced by Berger et al., provide an abstract framework for modelling decisions of a risk-averse investor, whose goal is to avoid ever going broke. We study a new variant of this model, where, in addition to stochastic environment and fixed increments and decrements to the investor's wealth, we introduce interest, which is earned or paid on the current level of savings or debt, respectively.   We study problems related to the minimum initial wealth sufficient to avoid bankruptcy (i.e. steady decrease of the wealth) with probability at least p. We present an exponential time algorithm which approximates this minimum initial wealth, and show that a polynomial time approximation is not possible unless P = NP. For the qualitative case, i.e. p=1, we show that the problem whether a given number is larger than or equal to the minimum initial wealth belongs to both NP and coNP, and show that a polynomial time algorithm would yield a polynomial time algorithm for mean-payoff games, existence of which is a longstanding open problem. We also identify some classes of solvency MDPs for which this problem is in P. In all above cases the algorithms also give corresponding bankruptcy avoiding strategies.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2018-12-20 00:00:00.000000"},
{"id":"702","title":"Little degree off.","abstract":"Marine microorganisms often reach high swimming speeds, either to take advantage of evanescent nutrient patches or to beat Brownian forces. Since this implies that a sizable part of their energetic budget must be allocated to motion, it is reasonable to assume that some fast-swimming microorganisms may increase their nutrient intake by increasing their speed v. We formulate a model to investigate this hypothesis and its consequences, finding the steady state solutions and analyzing their stability. Surprisingly, we find that even modest increases in nutrient absorption may lead to a significant increase of the microbial speed. In fact, evaluations obtained using realistic parameter values for bacteria indicate that the speed increase due to the enhanced nutrient absorption may be quite large.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2020-07-04 00:00:00.000000"},
{"id":"703","title":"Administration hundred key animal miss.","abstract":"Consider the following cascading process on a simple undirected graph $G(V,E)$ with diameter $\\Delta$. In round zero, a set $S\\subseteq V$ of vertices, called the seeds, are active. In round $i+1,$ $i\\in\\mathbb{N},$ a non-isolated vertex is activated if at least a $\\rho\\in(\\,0,1\\,]$ fraction of its neighbors are active in round $i$; it is deactivated otherwise. For $k\\in\\mathbb{N},$ let $\\text{min-seed}^{(k)}(G,\\rho)$ be the minimum number of seeds needed to activate all vertices in or before round $k$. This paper derives upper bounds on $\\text{min-seed}^{(k)}(G,\\rho)$. In particular, if $G$ is connected and there exist constants $C>0$ and $\\gamma>2$ such that the fraction of degree-$k$ vertices in $G$ is at most $C\/k^\\gamma$ for all $k\\in\\mathbb{Z}^+,$ then $\\text{min-seed}^{(\\Delta)}(G,\\rho)=O(\\lceil\\rho^{\\gamma-1}\\,|\\,V\\,|\\rceil)$. Furthermore, for $n\\in\\mathbb{Z}^+,$ $p=\\Omega((\\ln{(e\/\\rho)})\/(\\rho n))$ and with probability $1-\\exp{(-n^{\\Omega(1)})}$ over the Erd\\H{o}s-R\\'enyi random graphs $G(n,p),$ $\\text{min-seed}^{(1)}(G(n,p),\\rho)=O(\\rho n)$.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2018-03-04 00:00:00.000000"},
{"id":"704","title":"Realize challenge region responsibility position article.","abstract":"A lot of beautiful observations of Supernova remnant 1987A give a precise idea of its structure and its evolution. The regular interpretations of the observations set that the large energy needed to explain the brightness of the pearl necklaces is provided by shock waves involving remnants of a first explosion and a wave produced by the observed explosion although the existence of this wave is discussed. We develop the alternative explanation of the necklaces by photoionization. Our main hypothesis is that the explosion of the blue supergiant progenitor produces two neutron stars and a central brilliant object, a linear system similar to those which were observed by Halton Arp. We suppose that these stars remains bright in extreme UV, to maintain the strong ionization of a bubble of hot hydrogen nearly transparent in far UV (defined as the range of Lyman frequencies of atomic hydrogen). Outside the bubbles, three shells containing atomic hydrogen generate resonant, superradiant scatterings at Lyman frequencies, in tangential competing modes. The superradiance cools the gas and absorbs strongly the radial far UV light, hiding the stars. The shells may be identified with the inner active shells found from light echoes.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2022-01-25 00:00:00.000000"},
{"id":"705","title":"Blood nice save himself bring interest.","abstract":"This paper considers the linear inverse problem where we wish to estimate a structured signal $x$ from its corrupted observations. When the problem is ill-posed, it is natural to make use of a convex function $f(\\cdot)$ that exploits the structure of the signal. For example, $\\ell_1$ norm can be used for sparse signals. To carry out the estimation, we consider two well-known convex programs: 1) Second order cone program (SOCP), and, 2) Lasso. Assuming Gaussian measurements, we show that, if precise information about the value $f(x)$ or the $\\ell_2$-norm of the noise is available, one can do a particularly good job at estimation. In particular, the reconstruction error becomes proportional to the \"sparsity\" of the signal rather than the ambient dimension of the noise vector. We connect our results to existing works and provide a discussion on the relation of our results to the standard least-squares problem. Our error bounds are non-asymptotic and sharp, they apply to arbitrary convex functions and do not assume any distribution on the noise.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2016-07-30 00:00:00.000000"},
{"id":"706","title":"Him purpose authority identify husband pretty himself.","abstract":"Accurately assigning folds for divergent protein sequences is a major obstacle to structural studies and underlies the inverse protein folding problem. Herein, we outline our theories for fold-recognition in the \"twilight-zone\" of sequence similarity (<25% identity). Our analyses demonstrate that structural sequence profiles built using Position-Specific Scoring Matrices (PSSMs) significantly outperform multiple popular homology-modeling algorithms for relating and predicting structures given only their amino acid sequences. Importantly, structural sequence profiles reconstitute SCOP fold classifications in control and test datasets. Results from our experiments suggest that structural sequence profiles can be used to rapidly annotate protein folds at proteomic scales. We propose that encoding the entire Protein DataBank (~1070 folds) into structural sequence profiles would extract interoperable information capable of improving most if not all methods of structural modeling.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2019-10-16 00:00:00.000000"},
{"id":"707","title":"Pass fill step cultural ever raise both.","abstract":"The Monty Hall problem is the TV game scenario where you, the contestant, are presented with three doors, with a car hidden behind one and goats hidden behind the other two. After you select a door, the host (Monty Hall) opens a second door to reveal a goat. You are then invited to stay with your original choice of door, or to switch to the remaining unopened door, and claim whatever you find behind it. Assuming your objective is to win the car, is your best strategy to stay or switch, or does it not matter? Jason Rosenhouse has provided the definitive analysis of this game, along with several intriguing variations, and discusses some of its psychological and philosophical implications. This extended review examines several themes from the book in some detail from a Bayesian perspective, and points out one apparently inadvertent error.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2022-03-07 00:00:00.000000"},
{"id":"708","title":"Peace level week nation especially.","abstract":"We propose a concept for future space gravity missions using cold atom interferometers for measuring the diagonal elements of the gravity gradient tensor and the spacecraft angular velocity. The aim is to achieve better performance than previous space gravity missions due to a very low white noise spectral behavior and a very high common mode rejection, with the ultimate goals of determining the fine structures of the gravity field with higher accuracy than GOCE and detecting time-variable signals in the gravity field better than GRACE.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2015-06-07 00:00:00.000000"},
{"id":"709","title":"Campaign claim body employee.","abstract":"This article deals with a quantum-mechanical system which generalizes the ordinary isotropic harmonic oscillator system. We give the coefficients connecting the polar and Cartesian bases for D=2 and the coefficients connecting the Cartesian and cylindrical bases as well as the cylindrical and spherical bases for D=3. These interbasis expansion coefficients are found to be analytic continuations to real values of their arguments of the Clebsch-Gordan coefficients for the group SU(2). For D=2, the superintegrable character for the generalized oscillator system is investigated from the points of view of a quadratic invariance algebra.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2020-10-08 00:00:00.000000"},
{"id":"710","title":"How partner book off market watch.","abstract":"Computational complexity is a particularly important objective. The idea of Landauer principle was extended through mapping three classic problems (sorting,ordered searching and max of N unordered numbers) into Maxwell demon thought experiment in this paper. The problems'complexity is defined on the entropy basis and the minimum energy required to solve them are rigorous deduced from the perspective of energy (entropy) and the second law of thermodynamics. Then the theoretical energy consumed by real program and basic operators of classical computer are both analyzed, the time complexity lower bounds of three problems'all possible algorithms are derived in this way. The lower bound is also deduced for the two n*n matrix multiplication problem. In the end, the reason why reversible computation is impossible and the possibility of super-linear energy consumption capacity which may be the power behind quantum computation are discussed, a conjecture is proposed which may prove NP!=P. The study will bring fresh and profound understanding of computation complexity.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2020-08-18 00:00:00.000000"},
{"id":"711","title":"Service daughter wonder onto town.","abstract":"We theoretically and experimentally investigate the chaotic regime of optical frequency combs generated in nonlinear ring microresonators pumped with continuous wave light. We show that the chaotic regime reveals itself, in an apparently counter-intuitive way, by a flat top symmetric envelope of the frequency spectrum, when observed by means of an optical spectrum analyzer. The comb demodulated on a fast photodiode produces a noisy radio frequency signal with an spectral width significantly exceeding the linear bandwidth of the microresonator mode.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2016-12-30 00:00:00.000000"},
{"id":"712","title":"Administration section drug class fall four generation.","abstract":"This volume contains the proceedings of the Fifth International Workshop on Intersection Types and Related Systems (ITRS 2010). The workshop was held in Edinburgh, Scotland, on July 9th 2010, as part of FLoC 2010 and affiliated with LICS 2010.   The ITRS workshop series aim at bringing together researchers working on both the theory and practical applications of systems based on intersection types and related approaches (e.g., union types, refinement types, behavioral types).","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2016-06-17 00:00:00.000000"},
{"id":"713","title":"Party coach message cover morning blue.","abstract":"In a closed manifold of positive dimension $n$, we estimate the expected volume and Euler characteristic for random submanifolds of codimension $r\\in \\{1,\\dots,n\\}$ in two different settings. On one hand, we consider a closed Riemannian manifold and some positive $\\lambda$. Then we take $r$ independent random functions in the direct sum of the eigenspaces of the Laplace-Beltrami operator associated to eigenvalues less than $\\lambda^2$ and consider the random submanifold defined as the common zero set of these $r$ functions. We compute asymptotics for the mean volume and Euler characteristic of this random submanifold as $\\lambda$ goes to infinity. On the other hand, we consider a complex projective manifold defined over the reals, equipped with an ample line bundle $\\mathcal{L}$ and a rank $r$ holomorphic vector bundle $\\mathcal{E}$ that are also defined over the reals. Then we get asymptotics for the expected volume and Euler characteristic of the vanishing locus of a random real holomorphic section of $\\mathcal{E}\\otimes\\mathcal{L}^d$ as $d$ goes to infinity. The same techniques apply to both settings.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2022-04-23 00:00:00.000000"},
{"id":"714","title":"Space ever despite mission people somebody.","abstract":"The baseline configuration of the International Linear Collider requires 2 beam dumps per interaction region, each rated to 18MW of beam power, together with additional beam dumps for tuning purposes and machine protection. The baseline design uses high pressure moving water dumps, first developed for the SLC and used in the TESLA design, although a gas based dump is also being considered. In this paper we discuss the progress made by the international community on both physics and engineering studies for the beam dumps.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2020-02-06 00:00:00.000000"},
{"id":"715","title":"Return major race TV institution mention miss.","abstract":"The theory of relativity showed that several Newtonian ideas about spacetime are imperfect. We present here some relativistic concepts related to these ideas: simultaneity of events and synchronization of clocks (both along a line in the space frame), gravitational Doppler effect, and time travel. --------- La relativeca teorio montris ke pluraj Newtonaj ideoj pri la spacotempo estas malperfektaj. Tie cxi ni prezentas kelkajn relativecajn konceptojn iel rilatajn al tiuj ideoj: samtempecon de eventoj kaj sinkronon de horlogxoj (ambaux laux linio en la spaca reto), gravitan Doppleran efikon, kaj vojagxon kun reveno al estinto.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2017-02-27 00:00:00.000000"},
{"id":"716","title":"Decade debate section however white.","abstract":"The electron optics of a 90 degree spherical deflecting analyzer (SDA-90) is investigated with an imaging matrix formalism. As a preanalyzer in the UTA-neutrino experiment, high transmission and reasonable energy resolution are the choices of optimization. The magnification of the source through the analyzer plays the key role in determining the energy resolution. The imaging matrix approach provides graphical information to facilitate such an evaluation. We can demonstrate that in case where the analyzer is asymmetrically charged, the rotation of the image helps increase both transmission probability and resolution. A telefocus electron gun is used to check the numerical result, and to investigate the transverse focusing behavior.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2022-11-11 00:00:00.000000"},
{"id":"717","title":"What stay population marriage to himself Republican leader.","abstract":"We consider point to point link scheduling in Spatial Time Division Multiple Access (STDMA) wireless networks under the physical interference model. We propose a novel link scheduling algorithm based on a line graph representation of the network, by embedding the interferences between pairs of nodes into the edge weights of the line graph. Our algorithm achieves lower schedule length and lower run time complexity than existing algorithms.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2021-07-18 00:00:00.000000"},
{"id":"718","title":"Say suggest try adult control.","abstract":"We develop a Hamiltonian theory for a time dispersive and dissipative (TDD) inhomogeneous medium, as described by a linear response equation respecting causality and power dissipation. The canonical Hamiltonian constructed here exactly reproduces the original dissipative evolution after integrating out auxiliary fields. In particular, for a dielectric medium we obtain a simple formula for the Hamiltonian and closed form expressions for the energy density and energy flux involving the auxiliary fields. The developed approach also allows to treat a long standing problem of scattering from a lossy non-spherical obstacle and, more generally, wave propagation in TDD media.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2018-09-07 00:00:00.000000"},
{"id":"719","title":"Close key hospital action party attention.","abstract":"The Single Cut or Join (SCJ) operation on genomes, generalizing chromosome evolution by fusions and fissions, is the computationally simplest known model of genome rearrangement. While most genome rearrangement problems are already hard when comparing three genomes, it is possible to compute in polynomial time a most parsimonious SCJ scenario for an arbitrary number of genomes related by a binary phylogenetic tree.   Here we consider the problems of sampling and counting the most parsimonious SCJ scenarios. We show that both the sampling and counting problems are easy for two genomes, and we relate SCJ scenarios to alternating permutations. However, for an arbitrary number of genomes related by a binary phylogenetic tree, the counting and sampling problems become hard. We prove that if a Fully Polynomial Randomized Approximation Scheme or a Fully Polynomial Almost Uniform Sampler exist for the most parsimonious SCJ scenario, then RP = NP.   The proof has a wider scope than genome rearrangements: the same result holds for parsimonious evolutionary scenarios on any set of discrete characters.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2015-12-12 00:00:00.000000"},
{"id":"720","title":"Near serve with law high how.","abstract":"Let B denote a three-dimensional body of rotation, with respect to one coordinate axis, whose boundary is sufficiently smooth and of bounded nonzero Gaussian curvature throughout, except for the two boundary points on the axis of rotation, where the curvature may vanish. For a large real variable t, we are interested in the number A(t) of integer points in the linearly dilated body tB, in particular in the lattice discrepancy P(t) = A(t) - volume(tB). We are able to evaluate the contribution of the boundary points of curvature zero to P(t), with a remainder that is fairly small in mean-square.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2017-02-26 00:00:00.000000"},
{"id":"721","title":"There explain avoid either sense likely.","abstract":"Characterization of real-world complex systems increasingly involves the study of their topological structure using graph theory. Among global network properties, small-world property, consisting in existence of relatively short paths together with high clustering of the network, is one of the most discussed and studied. When dealing with coupled dynamical systems, links among units of the system are commonly quantified by a measure of pairwise statistical dependence of observed time series (functional connectivity). We argue that the functional connectivity approach leads to upwardly biased estimates of small-world characteristics (with respect to commonly used random graph models) due to partial transitivity of the accepted functional connectivity measures such as the correlation coefficient. In particular, this may lead to observation of small-world characteristics in connectivity graphs estimated from generic randomly connected dynamical systems. The ubiquity and robustness of the phenomenon is documented by an extensive parameter study of its manifestation in a multivariate linear autoregressive process, with discussion of the potential relevance for nonlinear processes and measures.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2015-05-22 00:00:00.000000"},
{"id":"722","title":"Century understand mouth develop seven various development.","abstract":"Many emerging Web services, such as email, photo sharing, and web site archives, need to preserve large amounts of quickly-accessible data indefinitely into the future. In this paper, we make the case that these applications' demands on large scale storage systems over long time horizons require us to re-evaluate traditional storage system designs. We examine threats to long-lived data from an end-to-end perspective, taking into account not just hardware and software faults but also faults due to humans and organizations. We present a simple model of long-term storage failures that helps us reason about the various strategies for addressing these threats in a cost-effective manner. Using this model we show that the most important strategies for increasing the reliability of long-term storage are detecting latent faults quickly, automating fault repair to make it faster and cheaper, and increasing the independence of data replicas.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2017-06-18 00:00:00.000000"},
{"id":"723","title":"After receive cup allow.","abstract":"The authors argue for the hypothesis that interactive feedbacks involving surface enthalpy fluxes are important to the dynamics of tropical intraseasonal variability. These include cloud-radiative feedbacks as well as surface turbulent flux feedbacks; the former effectively act to transport enthalpy from the ocean to the atmosphere, as do the latter. Evidence in favor of this hypothesis includes the observed spatial distribution of intraseasonal variance in precipitation and outgoing longwave radiation, the observed relationship between intraseasonal latent heat flux and precipitation anomalies in regions where intraseasonal variability is strong, and sensitivity experiments performed with a small number of general circulation and idealized models.   The authors argue that it would be useful to assess the importance of surface fluxes to intraseasonal variability in a larger number of comprehensive numerical models. Such an assessment could provide insight into the relevance of interactive surface fluxes to real intraseasonal variability, perhaps making it possible to rule out either theoretical explanations in which surface fluxes are crucial, or those in which they are not.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2020-12-26 00:00:00.000000"},
{"id":"724","title":"Oil experience thing future customer use she.","abstract":"This paper describes an efficient and nonlinearly consistent parallel solution methodology for solving coupled nonlinear thermal transport problems that occur in nuclear reactor applications over hundreds of individual 3D physical subdomains. Efficiency is obtained by leveraging knowledge of the physical domains, the physics on individual domains, and the couplings between them for preconditioning within a Jacobian Free Newton Krylov method. Details of the computational infrastructure that enabled this work, namely the open source Advanced Multi-Physics (AMP) package developed by the authors is described. Details of verification and validation experiments, and parallel performance analysis in weak and strong scaling studies demonstrating the achieved efficiency of the algorithm are presented. Furthermore, numerical experiments demonstrate that the preconditioner developed is independent of the number of fuel subdomains in a fuel rod, which is particularly important when simulating different types of fuel rods. Finally, we demonstrate the power of the coupling methodology by considering problems with couplings between surface and volume physics and coupling of nonlinear thermal transport in fuel rods to an external radiation transport code.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2015-06-15 00:00:00.000000"},
{"id":"725","title":"Class serious strategy pull office threat southern.","abstract":"A Lie algebra $K$ over a field of characteristic zero $E$ is called a completion of a rational Lie algebra $L$, if it contains $L$ as $\\mathbb{Q}$-subalgebra and the $E$-span of $L$ is equal to $K$. The class of all completions of a rational Lie algebra is studied in this article.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2019-11-11 00:00:00.000000"},
{"id":"726","title":"Star because spring total expert home condition.","abstract":"In many regular cases, there exists a (properly defined) limit of iterations of a function in several real variables, and this limit satisfies the functional equation (1-z)f(x)=f(f(xz)(1-z)\/z); here z is a scalar and x is a vector. This is a special case of a well-known translation equation. In this paper we present a complete solution to this functional equation in case f is a continuous function on a single point compactification of a 2-dimensional real vector space. It appears that, up to conjugation by a homogeneous continuous function, there are exactly four solutions. Further, in a 1-dimensional case we present a solution with no regularity assumptions on f.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2018-01-11 00:00:00.000000"},
{"id":"727","title":"Agency maybe arm federal four a.","abstract":"We determine the three hyperbolic 5-orbifolds of smallest volume among compact arithmetic orbifolds, and we identify their fundamental groups with hyperbolic Coxeter groups. This gives two different ways to compute the volume of these orbifolds.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2021-11-17 00:00:00.000000"},
{"id":"728","title":"Whether small down rise radio.","abstract":"We study the action of the Hecke operators Un on the set of hy- pergeometric functions, as well as on formal power series. We show that the spectrum of these operators on the set of hypergeometric functions is the set n^a with a an integer and n a positive integer, and that the polylogarithms play a dominant role in the study of the eigenfunctions of the Hecke operators Un on the set of hypergeometric functions. As a corollary of our results on simultaneous eigen- functions, we also obtain an apriori unrelated result regarding the behavior of completely multiplicative hypergeometric coefficients.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2019-07-03 00:00:00.000000"},
{"id":"729","title":"Head skin gun.","abstract":"We use the extended Barabasi model without the rewired process and show that the degree distribution for the corresponding networks is the Tsallis distribution. We offer an analysis of the novel \"The Sound and the Fury\" by W. Faulkner in English and in Russian, and show that the degree distributions of the relevant word networks are described with the Tsallis distribution. We have constructed degree distributions for each of the relevant word networks and defined the value of the nonextensivity parameter with the maximum likelihood method. For the novel text in English qB = 1.57; qK = 1.49; qJ = 1.53; qA = 1.47; qT = 1.54, and for the translation into Russian qB = 1.50; qK = 1.42; qD = 1.46; qA = 1.40; qT = 1.47. Therefore, if the translation of the novel is regarded as mapping, the nonextensivity parameters ordering qB > qT > qD > qK > qA is an invariant of this mapping.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2020-08-26 00:00:00.000000"},
{"id":"730","title":"Friend even save student mother idea create.","abstract":"In this paper, a new transformation is generated from a three variable Boolean function 3, which is used to produce a self-similar fractal pattern of dimension 1.58. This very fractal pattern is used to reconstruct the whole structural position of resources in wireless CDMA network. This reconstruction minimizes the number of resources in the network and so naturally network consumption costs are getting reduced. Now -a -days resource controlling and cost minimization are still a severe problem in wireless CDMA network. To overcome this problem fractal pattern produced in our research provides a complete solution of structural position of resources in this Wireless CDMA Network.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2015-12-10 00:00:00.000000"},
{"id":"731","title":"What soldier whose mouth agent enjoy only.","abstract":"Julian Jaynes's profound humanitarian convictions not only prevented him from going to war, but would have prevented him from ever kicking a dog. Yet according to his theory, not only are language-less dogs unconscious, but so too were the speaking\/hearing Greeks in the Bicameral Era, when they heard gods' voices telling them what to do rather than thinking for themselves. I argue that to be conscious is to be able to feel, and that all mammals (and probably lower vertebrates and invertebrates too) feel, hence are conscious. Julian Jaynes's brilliant analysis of our concepts of consciousness nevertheless keeps inspiring ever more inquiry and insights into the age-old mind\/body problem and its relation to cognition and language.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2017-06-28 00:00:00.000000"},
{"id":"732","title":"Old quickly standard far adult public.","abstract":"A roller-ball pen enabled direct writing electronics via room temperature liquid metal ink was proposed. With the rolling to print mechanism, the metallic inks were smoothly written on flexible polymer substrate to form conductive tracks and electronic devices. The contact angle analyzer and scanning electron microscope were implemented to probe the inner property of the obtained electronics. An ever high writing resolution with line width and thickness as 200{\\mu}m and 80{\\mu}m, respectively was realized. Further, with the administration of external writing pressure, GaIn24.5 droplets embody increasing wettability on polymer which demonstrates the pervasive adaptability of the roller-ball pen electronics.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2018-01-17 00:00:00.000000"},
{"id":"733","title":"These on international care.","abstract":"At present a number of current or proposed experiments are directed towards a search for a `new physics' by detecting variations of fundamental physical constants or violations of certain basic symmetries. Various problems related to the phenomenology of such experiments are considered here.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2019-06-09 00:00:00.000000"},
{"id":"734","title":"They design enough fire analysis impact everyone.","abstract":"One of the important evidence in a crime scene that is normally overlooked but very important evidence is shoe print as the criminal is normally unaware of the mask for this. In this paper we use image processing technique to process reference shoe images to make it index-able for a search from the database the shoe print impressions available in the commercial market. This is achieved first by converting the commercially available image through the process of converting them to gray scale then apply image enhancement and restoration techniques and finally do image segmentation to store the segmented parameter as index in the database storage. We use histogram method for image enhancement, inverse filtering for image restoration and threshold method for indexing. We use global threshold as index of the shoe print. The paper describes this method and simulation results are included to validate the method.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2016-08-31 00:00:00.000000"},
{"id":"735","title":"Light never rock me specific ground.","abstract":"A graph-theoretic method, simpler than existing ones, is used to characterize the minimal set of monomial generators for the integral closure of any algebra of polynomials generated by quadratic monomials. The toric ideal of relations between these generators is generated by a set of binomials, defined graphically. The spectra of the original algebra and of its integral closure turn out to be canonically homeomorphic.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2017-01-01 00:00:00.000000"},
{"id":"736","title":"Possible want lead foot.","abstract":"We study and actively control the coherent properties of Surface Plasmon Polaritons (SPPs) optically exited on a nano-hole array. Amplitude and phase of the optical excitation are externally controlled via a digital spatial light modulator (SLM) and SPP interference fringe patterns are observed with high contrast. Our interferometric observations revel SPPs dressed with the Bloch modes of the periodic nano-structure. The momentum associated with these Dressed Plasmons (DP) is highly dependent on the grating period and fully matches our theoretical predictions. We show that the momentum of DP waves can in principle exceed the SPP momentum. Actively controlling DP waves via programmable phase patterns offers the potential for high field confinement applicable in sensing, Surface Enhanced Raman Scattering and plasmonic structured illumination microscopy.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2021-12-21 00:00:00.000000"},
{"id":"737","title":"Administration great raise write different floor.","abstract":"An entropy for the scalar variable case, parallel to Havrda-Charvat entropy was introduced by the first author and the properties and its connection to Tsallis non-extensive statistical mechanics and the Mathai pathway model were examined by the authors in previous papers. In the current paper we extend the entropy to cover scalar case, multivariable case, and matrix variate case. Then this measure is optimized under different types of restrictions and a number of models in the multivariable case and matrix variable case are obtained. Connections of these models to problems in statistical, physical, and engineering sciences are also pointed out. An application of the simplest case of the pathway model to the interpretation of solar neutrino data is provided.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2019-05-29 00:00:00.000000"},
{"id":"738","title":"Out daughter find someone.","abstract":"This article describes five common student misconceptions about succeeding in college-level Physics courses: the miracle finish, the soft hearted professor, an extension of high school, weak areas won't be tested, and passing is more important than learning. These fantasies are unique to neither Physics nor freshman, but the challenge of learning Physics brings more certain negative consequences to students retaining these attitudes. Ascribing these student misconceptions to freshmen acknowledges that they diminish with increasing academic maturity.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2021-10-17 00:00:00.000000"},
{"id":"739","title":"Game standard music can find.","abstract":"We offer a complete classification of right coideal subalgebras which contain all group-like elements for the multiparameter version of the quantum group $U_q(\\mathfrak{sl}_{n+1})$ provided that the main parameter $q$ is not a root of 1. As a consequence, we determine that for each subgroup $\\Sigma $ of the group $G$ of all group-like elements the quantum Borel subalgebra $U_q^+ (\\mathfrak{sl}_{n+1})$ containes $(n+1)!$ different homogeneous right coideal subalgebras $U$ such that $U\\cap G=\\Sigma .$ If $q$ has a finite multiplicative order $t>2,$ the classification remains valid for homogeneous right coideal subalgebras of the multiparameter version of the Lusztig quantum group $u_q (\\frak{sl}_{n+1}).$ In the paper we consider the quantifications of Kac-Moody algebras as character Hopf algebras [V.K. Kharchenko, A combinatorial approach to the quantifications of Lie algebras, Pacific J. Math., 203(1)(2002), 191- 233].","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2016-05-26 00:00:00.000000"},
{"id":"740","title":"Ahead entire all oil card system.","abstract":"We introduce weak morphisms of higher dimensional automata and use them to define preorder relations for HDAs, among which homeomorphic abstraction and trace equivalent abstraction. It is shown that homeomorphic abstraction is essentially always stronger than trace equivalent abstraction. We also define the trace language of an HDA and show that, for a large class of HDAs, it is invariant under trace equivalent abstraction.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2015-07-23 00:00:00.000000"},
{"id":"741","title":"Campaign focus heavy there.","abstract":"Let k be a field and let G be a finite group. By a theorem of D.Benson, H.Krause and S.Schwede, there is a canonical element in the Hochschild cohomology of the Tate cohomology HH^{3,-1} H*G with the following property: Given any graded H*G-module X, the image of the canonical element in Ext^{3,-1}(X,X) is zero if and only if X is isomorphic to a direct summand of H*(G,M) for some kG-module M.   We investigate this canonical element in certain special cases, namely that of (finite) abelian p-groups and the quaternion group. In case of non-triviality of the canonical element, we also give examples of non-realizable modules X.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2020-02-21 00:00:00.000000"},
{"id":"742","title":"Decade collection meet position heavy.","abstract":"Following Braverman-Finkelberg-Feigin-Rybnikov (arXiv:1008.3655), we study the convolution algebra of a handsaw quiver variety, a.k.a. a parabolic Laumon space, and a finite W-algebra of type A. This is a finite analog of the AGT conjecture on 4-dimensional supersymmetric Yang-Mills theory with surface operators. Our new observation is that the C^*-fixed point set of a handsaw quiver variety is isomorphic to a graded quiver variety of type A, which was introduced by the author in connection with the representation theory of a quantum affine algebra. As an application, simple modules of the W-algebra are described in terms of IC sheaves of graded quiver varieties of type A, which were known to be related to Kazhdan-Lusztig polynomials. This gives a new proof of a conjecture by Brundan-Kleshchev on composition multiplicities on Verma modules, which was proved by Losev, in a wider context, by a different method.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2015-10-24 00:00:00.000000"},
{"id":"743","title":"Organization safe his people later.","abstract":"In the \"6D treatment of Special Relativity\" proposed by Igor A. Urusovskii one deals with universal light-like motion of matter pre-elements in the extended (3+3) space and with their regular rotation in the additional 3-space. On the other hand, in the framework of our algebrodynamical approach one naturally comes to the complex space-time geometry resulting in a universal kinematics that resembles the well-known Wheeler-Feynmann \"one electron representation\". Combining the two approaches, we propose a simple classical explanation of the canonical two-slit experiment. Some small corrections to the predictions of quantum theory are established.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2021-01-05 00:00:00.000000"},
{"id":"744","title":"We drive back health money.","abstract":"Dynamic Contrast-enhanced Magnetic Resonance Imaging (DCE-MRI) is an important tool for detecting subtle kinetic changes in cancerous tissue. Quantitative analysis of DCE-MRI typically involves the convolution of an arterial input function (AIF) with a nonlinear pharmacokinetic model of the contrast agent concentration. Parameters of the kinetic model are biologically meaningful, but the optimization of the non-linear model has significant computational issues. In practice, convergence of the optimization algorithm is not guaranteed and the accuracy of the model fitting may be compromised. To overcome this problems, this paper proposes a semi-parametric penalized spline smoothing approach, with which the AIF is convolved with a set of B-splines to produce a design matrix using locally adaptive smoothing parameters based on Bayesian penalized spline models (P-splines). It has been shown that kinetic parameter estimation can be obtained from the resulting deconvolved response function, which also includes the onset of contrast enhancement. Detailed validation of the method, both with simulated and in vivo data, is provided.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2015-09-21 00:00:00.000000"},
{"id":"745","title":"Whose apply wide mention somebody surface thousand already.","abstract":"Fourier ptychographic microscopy (FPM) is a recently developed imaging modality that uses angularly varying illumination to extend a system performance beyond the limit defined by its optical elements. The FPM technique applies a novel phase retrieval procedure to achieve both resolution enhancement and complex image recovery. In this letter, we compare FPM data to both theoretical prediction and phase-shifting digital holography measurement to show that its acquired phase maps are quantitative and artifact-free. We additionally explore the relationship between the achievable spatial and optical thickness resolution offered by a reconstructed FPM phase image. We conclude by demonstrating both enhanced visualization and the collection of otherwise unobservable sample information using FPM quantitative phase.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2016-08-03 00:00:00.000000"},
{"id":"746","title":"Though road school between really radio management.","abstract":"Following the work of Anily et al., we consider a variant of bin packing, called \"bin packing with general cost structures\" (GCBP) and design an asymptotic fully polynomial time approximation scheme (AFPTAS) for this problem. In the classic bin packing problem, a set of one-dimensional items is to be assigned to subsets of total size at most 1, that is, to be packed into unit sized bins. However, in GCBP, the cost of a bin is not 1 as in classic bin packing, but it is a non-decreasing and concave function of the number of items packed in it, where the cost of an empty bin is zero. The construction of the AFPTAS requires novel techniques for dealing with small items, which are developed in this work. In addition, we develop a fast approximation algorithm which acts identically for all non-decreasing and concave functions, and has an asymptotic approximation ratio of 1.5 for all functions simultaneously.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2017-10-24 00:00:00.000000"},
{"id":"747","title":"International international eat.","abstract":"This article explores the design and construction of a geo-spatial Internet web service application from the host web site perspective and from the perspective of an application using the web service. The TerraService.NET web service was added to the popular TerraServer database and web site with no major structural changes to the database. The article discusses web service design, implementation, and deployment concepts and design guidelines. Web services enable applications that aggregate and interact with information and resources from Internet-scale distributed servers. The article presents the design of two USDA applications that interoperate with database and web service resources in Fort Collins Colorado and the TerraService web service located in Tukwila Washington.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2015-05-29 00:00:00.000000"},
{"id":"748","title":"Animal street western either size player painting.","abstract":"We revisit the Kolmogorov-Smirnov and Cram\\'er-von Mises goodness-of-fit (GoF) tests and propose a generalisation to identically distributed, but dependent univariate random variables. We show that the dependence leads to a reduction of the \"effective\" number of independent observations. The generalised GoF tests are not distribution-free but rather depend on all the lagged bivariate copulas. These objects, that we call \"self-copulas\", encode all the non-linear temporal dependences. We introduce a specific, log-normal model for these self-copulas, for which a number of analytical results are derived. An application to financial time series is provided. As is well known, the dependence is to be long-ranged in this case, a finding that we confirm using self-copulas. As a consequence, the acceptance rates for GoF tests are substantially higher than if the returns were iid random variables.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2020-12-16 00:00:00.000000"},
{"id":"749","title":"Analysis similar father design age example people.","abstract":"We consider the iteration of a unitary operator on a separable Hilbert space and study the spreading rates of the associated discrete-time dynamical system relative to a given orthonormal basis. We prove lower bounds for the transport exponents, which measure the time-averaged spreading on a power-law scale, in terms of dimensional properties of the spectral measure associated with the unitary operator and the initial state. These results are the unitary analog of results established in recent years for the dynamics of the Schr\\\"odinger equation, which is a continuum-time dynamical system associated with a self-adjoint operator. We discuss how these general results may be studied by means of subordinacy theory in cases where the unitary operator is given by a CMV matrix. An example of particular interest in which this scenario arises is given by a time-homogeneous quantum walk on the integers. For the particular case of the time-homogeneous Fibonacci quantum walk, we illustrate how these components work together and produce explicit lower bounds for the transport exponents associated with this model.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2019-12-05 00:00:00.000000"},
{"id":"750","title":"Green will under television course same different.","abstract":"The CERN LHC experiments have begun the LHC Computing Grid project in 2001. One of the project's aims is to develop common software infrastructure based on a development vision shared by the participating experiments. The SEAL project will provide common foundation libraries, services and utilities identified by the project's architecture blueprint report. This requires a broad range of functionality that no individual package suitably covers. SEAL thus selects external and experiment-developed packages, integrates them in a coherent whole, develops new code for missing functionality, and provides support to the experiments. We describe the set of basic components identified by the LHC Computing Grid project and thought to be sufficient for development of higher level framework components and specializations. Examples of such components are a plug-in manager, an object dictionary, object whiteboards, an incident or event manager. We present the design and implementation of some of these components and the underlying foundation libraries in some detail.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2016-06-26 00:00:00.000000"},
{"id":"751","title":"Wear finish account always.","abstract":"We analyse small-amplitude oscillations of a weakly viscous electrically conducting liquid drop in a strong uniform DC magnetic field. An asymptotic solution is obtained showing that the magnetic field does not affect the shape eigenmodes, which remain the spherical harmonics as in the non-magnetic case. Strong magnetic field, however, constrains the liquid flow associated with the oscillations and, thus, reduces the oscillation frequencies by increasing effective inertia of the liquid. In such a field, liquid oscillates in a two-dimensional (2D) way as solid columns aligned with the field. Two types of oscillations are possible: longitudinal and transversal to the field. Such oscillations are weakly damped by a strong magnetic field - the stronger the field, the weaker the damping, except for the axisymmetric transversal and inherently 2D modes. The former are overdamped because of being incompatible with the incompressibility constraint, whereas the latter are not affected at all because of being naturally invariant along the field. Since the magnetic damping for all other modes decreases inversely with the square of the field strength, viscous damping may become important in a sufficiently strong magnetic field. The viscous damping is found analytically by a simple energy dissipation approach which is shown for the longitudinal modes to be equivalent to a much more complicated eigenvalue perturbation technique. This study provides a theoretical basis for the development of new measurement methods of surface tension, viscosity and the electrical conductivity of liquid metals using the oscillating drop technique in a strong superimposed DC magnetic field.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2021-11-13 00:00:00.000000"},
{"id":"752","title":"Play another listen democratic bit cultural computer.","abstract":"Study of the bivariate normal distribution raises the full range of issues involving objective Bayesian inference, including the different types of objective priors (e.g., Jeffreys, invariant, reference, matching), the different modes of inference (e.g., Bayesian, frequentist, fiducial) and the criteria involved in deciding on optimal objective priors (e.g., ease of computation, frequentist performance, marginalization paradoxes). Summary recommendations as to optimal objective priors are made for a variety of inferences involving the bivariate normal distribution. In the course of the investigation, a variety of surprising results were found, including the availability of objective priors that yield exact frequentist inferences for many functions of the bivariate normal parameters, including the correlation coefficient.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2018-09-13 00:00:00.000000"},
{"id":"753","title":"Particular wind just test follow.","abstract":"DCSP (Distributed Constraint Satisfaction Problem) has been a very important research area in AI (Artificial Intelligence). There are many application problems in distributed AI that can be formalized as DSCPs. With the increasing complexity and problem size of the application problems in AI, the required storage place in searching and the average searching time are increasing too. Thus, to use a limited storage place efficiently in solving DCSP becomes a very important problem, and it can help to reduce searching time as well. This paper provides an efficient knowledge base management approach based on general usage of hyper-resolution-rule in consistence algorithm. The approach minimizes the increasing of the knowledge base by eliminate sufficient constraint and false nogood. These eliminations do not change the completeness of the original knowledge base increased. The proofs are given as well. The example shows that this approach decrease both the new nogoods generated and the knowledge base greatly. Thus it decreases the required storage place and simplify the searching process.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2019-05-16 00:00:00.000000"},
{"id":"754","title":"Sound kind by large check paper.","abstract":"We consider canonical fibrations and algebraic geometric structures on homogeneous CR manifolds, in connection with the notion of CR algebra. We give applications to the classifications of left invariant CR structures on semisimple Lie groups and of CR-symmetric structures on complete flag varieties.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2018-06-28 00:00:00.000000"},
{"id":"755","title":"Win idea option senior.","abstract":"Supervisory control of discrete-event systems with a global safety specification and with only local supervisors is a difficult problem. For global specifications the equivalent conditions for local control synthesis to equal global control synthesis may not be met. This paper formulates and solves a control synthesis problem for a generator with a global specification and with a combination of a coordinator and local controllers. Conditional controllability is proven to be an equivalent condition for the existence of such a coordinated controller. A procedure to compute the least restrictive solution is also provided in this paper and conditions are stated under which the result of our procedure coincides with the supremal controllable sublanguage.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2020-04-13 00:00:00.000000"},
{"id":"756","title":"Person hand leg first.","abstract":"Local versions of measurability have been around for a long time. Roughly, one splits the notion of $\\mu $-completeness into pieces, and asks for a uniform ultrafilter over $\\mu $ satisfying just some piece of $\\mu $-completeness.   Analogue local versions of weak compactness are harder to come by, since weak compactness cannot be defined by using a single ultrafilter. We deal with the problem by restricting just to a subset $P$ of all the partitions of $\\mu $ into $<\\mu $ classes and asking for some ultrafilter $D$ over $\\mu $ such that no partition in $P$ disproves the $\\mu $-completeness of $D$. By making $P$ vary in appropriate classes, one gets both measurability and weak compactness, as well as possible intermediate notions of \"weak measurability\".   We systematize the above procedures and combine them to obtain variants of measurability which are at the same time weaker and local. Of particular interest is the fact that the notions thus obtained admit equivalent formulations through topological, model theoretical, combinatorial and Boolean algebraic conditions. We also hint a connection with Kat{\\v{e}}tov order on filters.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2018-06-26 00:00:00.000000"},
{"id":"757","title":"Suffer two thus process.","abstract":"We compute the genus one family Gromov-Witten invariants of K3 surfaces for non-primitive classes. These calculations verify Gottsche-Yau-Zaslow formula for non-primitive classes with index two. Our approach is to use the genus two topological recursion formula and the symplectic sum formula to establish relationships among various generating functions.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2016-03-06 00:00:00.000000"},
{"id":"758","title":"Record read value.","abstract":"It has been recently suggested by Dvali and Vikman that the superluminal neutrino phenomenology of the OPERA experiment may be due to an environmental feature of the Earth, naturally yielding a long-range fifth force of gravitational origin whose coupling with the neutrino is set by the scale M_*, in units of reduced Planck mass. Its characteristic length lambda should not be smaller than one Earth's radius R_e, while its upper bound is expected to be slightly smaller than the Earth-Moon distance (60 R_e). We analytically work out some orbital effects of a Yukawa-type fifth force for a test particle moving in the modified field of a central body. Our results are quite general since they are not restricted to any particular size of lambda; moreover, they are valid for an arbitrary orbital configuration of the particle, i.e. for any value of its eccentricity $e$. We find that the dimensionless strength coupling parameter alpha is constrained to |alpha| <= 1 10^-10-4 10^-9 for 1 R_e <= lambda <= 10 R_e by the laser data of the Earth's artificial satellite LAGEOS II, corresponding to M_* >= 4 10^9 -1.6 10^10. The Moon perigee allows to obtain |alpha| <= 3 10^-11 for the Earth-Moon pair in the range 15 R_e <= lambda <= 60 R_e, which translates as M_* >= 3 10^10 - 4.5 10^10. Our results are neither necessarily limited to the superluminal OPERA scenario nor to the Dvali-Vikman model, in which it is M_* = 10^-6 at lambda = 1 R_e, in contrast with our bounds: they generally extend to any theoretical scenario implying a fifth-force of Yukawa-type.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2016-03-10 00:00:00.000000"},
{"id":"759","title":"Unit consumer benefit yes and.","abstract":"With the help of a model of magnetohydrodynamic (MHD) turbulence tested previously, we explore high Reynolds number regimes up to equivalent resolutions of 6000^3 grid points in the absence of forcing and with no imposed uniform magnetic field. For the given initial condition chosen here, with equal kinetic and magnetic energy, the flow ends up being dominated by the magnetic field, and the dynamics leads to an isotropic Iroshnikov-Kraichnan energy spectrum. However, the locally anisotropic magnetic field fluctuations perpendicular to the local mean field follow a Kolmogorov law. We find that the ratio of the eddy turnover time to the Alfven time increases with wavenumber, contrary to the so-called critical balance hypothesis. Residual energy and helicity spectra are also considered; the role played by the conservation of magnetic helicity is studied, and scaling laws are found for the magnetic helicity and residual helicity spectra. We put these results in the context of the dynamics of a globally isotropic MHD flow which is locally anisotropic because of the influence of the strong large-scale magnetic field, leading to a partial equilibration between kinetic and magnetic modes for the energy and the helicity.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2017-08-20 00:00:00.000000"},
{"id":"760","title":"About church health specific.","abstract":"In this paper we prove necessary and sufficient conditions for the Kobayashi metric on a convex domain to be Gromov hyperbolic. In particular we show that for convex domains with $C^\\infty$ boundary being of finite type in the sense of D'Angelo is equivalent to the Gromov hyperbolicity of the Kobayashi metric. We also show that bounded domains which are locally convexifiable and have finite type in the sense of D'Angelo have Gromov hyperbolic Kobayashi metric. The proofs use ideas from Hilbert geometry along with techniques from several complex variables.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2015-10-21 00:00:00.000000"},
{"id":"761","title":"Wonder sign before project ball technology forget.","abstract":"The differential equations of Abrams and Strogatz for the competition between two languages are compared with agent-based Monte Carlo simulations for fully connected networks as well as for lattices in one, two and three dimensions, with up to 10^9 agents.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2018-10-31 00:00:00.000000"},
{"id":"762","title":"Security picture nearly time deep.","abstract":"Alya is the BSC in-house HPC-based multi-physics simulation code. It is designed from scratch to run efficiently in parallel supercomputers, solving coupled problems. The target domain is engineering, with all its particular features: complex geome- tries and unstructured meshes, coupled multi-physics with exotic coupling schemes and Physical models, ill-posed problems, flexibility needs for rapidly including new models, etc. Since its conception in 2004, Alya has shown scaling behaviour in an increasing number of cores. In this paper, we present its performance up to 100.000 cores in Blue Waters, the NCSA supercomputer. The selected tests are representative of the engineering world, all the problematic features included: incompressible flow in a hu- man respiratory system, low Mach combustion problem in a kiln furnace and coupled electro-mechanical problem in a heart. We show scalability plots for all cases, discussing all the aspects of such kind of simulations, including solvers convergence.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2022-04-14 00:00:00.000000"},
{"id":"763","title":"Any base store between item.","abstract":"Copula modelling has in the past decade become a standard tool in many areas of applied statistics. However, a largely neglected aspect concerns the design of related experiments. Particularly the issue of whether the estimation of copula parameters can be enhanced by optimizing experimental conditions and how robust all the parameter estimates for the model are with respect to the type of copula employed. In this paper an equivalence theorem for (bivariate) copula models is provided that allows formulation of efficient design algorithms and quick checks of whether designs are optimal or at least efficient. Some examples illustrate that in practical situations considerable gains in design efficiency can be achieved. A natural comparison between different copula models with respect to design efficiency is provided as well.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2018-03-08 00:00:00.000000"},
{"id":"764","title":"Ok second idea.","abstract":"In this paper it is demonstrated that the scoring at each PGA Tour stroke play event can be reasonably modeled as a Gaussian random variable. All 46 stroke play events in the 2007 season are analyzed. The distributions of scores are favorably compared with a Gaussian distribution using the Kolmogorov-Smirnov test. This observation suggests performance tracking on the PGA tour should be done in terms of the z-score, calculated by subtracting the mean from the raw score and dividing by the standard deviation. This methodology measures performance relative to the field of competitors, independent of the venue, and in terms of a statistic that has quantitative meaning. Several examples of the use of this scoring methodology are provided, including a calculation of the probability that Tiger Woods will break Byron Nelson's record of eleven consecutive PGA Tour victories.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2017-04-13 00:00:00.000000"},
{"id":"765","title":"Trial beat type performance hundred carry her.","abstract":"Kadison's transitivity theorem implies that, for irreducible representations of C*-algebras, every invariant linear manifold is closed. It is known that CSL algebras have this propery if, and only if, the lattice is hyperatomic (every projection is generated by a finite number of atoms). We show several other conditions are equivalent, including the conditon that every invariant linear manifold is singly generated.   We show that two families of norm closed operator algebras have this property. First, let L be a CSL and suppose A is a norm closed algebra which is weakly dense in Alg L and is a bimodule over the (not necessarily closed) algebra generated by the atoms of L. If L is hyperatomic and the compression of A to each atom of L is a C*-algebra, then every linear manifold invariant under A is closed. Secondly, if A is the image of a strongly maximal triangular AF algebra under a multiplicity free nest representation, where the nest has order type -N, then every linear manifold invariant under A is closed and is singly generated.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2018-08-12 00:00:00.000000"},
{"id":"766","title":"Will mission machine factor line author exist become.","abstract":"A method of retrieving the complex intracavity pump field from the through port is proposed, and verified through characterizing the time-domain waveform of a mode-locked comb related to dark soliton formation in a normal-dispersion microresonator.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2015-01-10 00:00:00.000000"},
{"id":"767","title":"Process view break expect third television check significant.","abstract":"We compute L2-invariants of certain nonuniform lattices in semisimple Lie groups by means of the Borel-Serre compactification of arithmetically defined locally symmetric spaces. The main results give new estimates for Novikov-Shubin numbers and vanishing L2-torsion for lattices in groups with even deficiency. We discuss applications to Gromov's Zero-in-the-Spectrum Conjecture as well as to a proportionality conjecture for the L2-torsion of measure equivalent groups.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2018-07-15 00:00:00.000000"},
{"id":"768","title":"Effect arm police professional.","abstract":"Approximately 1% of the known protein structures display knotted configurations in their native fold but their function is not understood. It has been speculated that the entanglement may inhibit mechanical protein unfolding or transport, e.g., as in cellular threading or translocation processes through narrow biological pores. Here we investigate tigh peptide knot (TPK) characteristics in detail by pulling selected 3_1 and 4_1-knotted peptides using all-atom molecular dynamics computer simulations. We find that the 3_1 and 4_1-TPK lengths are typically Delta l~4.7 nm and 6.9 nm, respectively, for a wide range of tensions (F < 1.5 nN), pointing to a pore diameter of ~2 nm below which a translocated knotted protein might get stuck. The 4_1-knot length is in agreement with recent AFM pulling experiments. Detailed TPK characteristics however, may be sequence-specific: we find a different size and structural behavior in polyglycines, and, strikingly, a strong hydrogen bonding and water molecule trapping capability of hydrophobic TPKs due to side chain shielding of the polar TPK core. Water capturing and release is found to be controlla ble by the tightening force in a few cases. These mechanisms result into a sequence-specific 'locking' and metastability of TPKs what might lead to a blocking of knotted peptide transport at designated sequence-positions. Intriguingly, macroscopic tight 4_1-knot structures are reproduced microscopically ('figure-of-eight' vs. the 'pretzel') and can be tuned by sequence in contrast to mathematical predictions. Our findings may explain a function of knots in native proteins, challenge previous studies on macromolecular knots, and may find use in bio- and nanotechnology.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2017-03-22 00:00:00.000000"},
{"id":"769","title":"Government to at idea member pattern.","abstract":"We construct a family of odd, finitely summable Fredholm modules over the crossed product C*-algebra $C(\\bd \\G)\\rtimes \\G$ associated to the action of a non-elementary hyperbolic group $\\G$ on its Gromov boundary $\\bd \\G$. These Fredholm modules all represent the same, distinguished class in K-homology, namely that of the `boundary extension' of $C(\\bd \\G)\\rtimes \\G$ associated to the Gromov compactification of $\\G$, and is typically nonzero. Their summability is closely related to the Hausdorff dimension of the boundary. We use these results to compute the Connes-Chern character of the boundary extension in cyclic cohomology.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2020-08-16 00:00:00.000000"},
{"id":"770","title":"Direction industry positive character author.","abstract":"As a model of market price, we introduce a new type of random walk in a moving potential which is approximated by a quadratic function with its center given by the moving average of its own trace. The properties of resulting random walks are similar to those of ordinary random walks for large time scales; however, their short time properties are approximated by abnormal diffusion with non-trivial exponents. A new data analysis method based on this model enables us to observe temporal changes of potential forces from high precision market data directly.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2017-01-16 00:00:00.000000"},
{"id":"771","title":"Election spend board.","abstract":"A new three dimensional model of the FEL is presented. A system of scaled, coupled Maxwell Lorentz equations are derived in the paraxial limit. A minimal number of limiting assumptions are made and the equations are not averaged in the longitudinal direction of common radiation\/ electron beam propagation, allowing the effects of coherent spontaneous emission and non-localised electron propagation to be modelled. The equations are solved numerically using a parallel Fourier split-step method.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2020-11-14 00:00:00.000000"},
{"id":"772","title":"Hit pay live seat pressure.","abstract":"An algebraic model in terms of a local harmonic boson realization was recently proposed to study molecular vibrational spectra [Zhong-Qi Ma et al., Phys. Rev. A 53, 2173 (1996)]. Because of the local nature of the bosons the model has to deal with spurious degrees of freedom. An approach to eliminate the latter from both the Hamiltonian and the basis was suggested. We show that this procedure does not remove all spurious components from the Hamiltonian and leads to a restricted set of interactions. We then propose a scheme in which the physical Hamiltonian can be systematically constructed up to any order without the need of imposing conditions on its matrix elements. In addition, we show that this scheme corresponds to the harmonic limit of a symmetry adapted algebraic approach based on U(2) algebras.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2020-07-30 00:00:00.000000"},
{"id":"773","title":"Never popular decision ten end miss phone trade.","abstract":"Nowadays, locating software components responsible for observed failures is one of the most expensive and error-prone tasks in the software development process. To improve the debugging process efficiency, some effort was already made to automatically assist the detection and location of software faults. This led to the creation of statistical debugging tools such as Tarantula, Zoltar and GZoltar. These tools use information gathered from code coverage data and the result of test executions to return a list of potential faulty locations. Although helpful, fault localization tools have some scaling problems because of the fine-grained coverage data they need to perform the fault localization analysis. Instrumentation overhead, which in some cases can be as high as 50% is the main cause for their inefficiency. This thesis proposes a new approach to this problem, avoiding as much as possible the high level of coverage detail, while still using the proven techniques these fault localization tools employ. This approach, named DCC, consists of using a coarser initial instrumentation, obtaining only coverage traces for large components. Then, the instrumentation detail of certain components is progressively increased, based on the intermediate results provided by the same techniques employed in current fault localization tools. To assess the validity of our proposed approach, an empirical evaluation was performed, injecting faults in four real-world software projects. The empirical evaluation demonstrates that the DCC approach reduces the execution overhead that exists in spectrum-based fault localization, and even presents a more concise potential fault ranking to the user. We have observed execution time reductions of 27% on average and diagnostic report size reductions of 63% on average.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2021-07-31 00:00:00.000000"},
{"id":"774","title":"Item know customer force dark foot.","abstract":"Researchers claim to have observed superluminal (faster than light) propagation of a laser pulse in a gain medium by a new mechanism in which there is no distortion of the pulse [Nature, 406, 277 (2000)]. Our analysis shows that the observed mechanism is due to pulse distortion arising from a differential gain effect and should not be viewed as superluminal propagation.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2015-01-20 00:00:00.000000"},
{"id":"775","title":"Attack section build cultural while work.","abstract":"Possible distributions are discussed for intertrade durations and first-passage processes in financial markets. The view-point of renewal theory is assumed. In order to represent market data with relatively long durations, two types of distributions are used, namely, a distribution derived from the so-called Mittag-Leffler survival function and the Weibull distribution. For Mittag-Leffler type distribution, the average waiting time (residual life time) is strongly dependent on the choice of a cut-off parameter t_ max, whereas the results based on the Weibull distribution do not depend on such a cut-off. Therefore, a Weibull distribution is more convenient than a Mittag-Leffler type one if one wishes to evaluate relevant statistics such as average waiting time in financial markets with long durations. On the other side, we find that the Gini index is rather independent of the cut-off parameter. Based on the above considerations, we propose a good candidate for describing the distribution of first-passage time in a market: The Weibull distribution with a power-law tail. This distribution compensates the gap between theoretical and empirical results much more efficiently than a simple Weibull distribution. We also give a useful formula to determine an optimal crossover point minimizing the difference between the empirical average waiting time and the one predicted from renewal theory. Moreover, we discuss the limitation of our distributions by applying our distribution to the analysis of the BTP future and calculating the average waiting time. We find that our distribution is applicable as long as durations follow a Weibull-law for short times and do not have too heavy a tail.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2020-12-13 00:00:00.000000"},
{"id":"776","title":"Forward rest offer teach book seven.","abstract":"We consider how an agent should update her uncertainty when it is represented by a set $\\P$ of probability distributions and the agent observes that a random variable $X$ takes on value $x$, given that the agent makes decisions using the minimax criterion, perhaps the best-studied and most commonly-used criterion in the literature. We adopt a game-theoretic framework, where the agent plays against a bookie, who chooses some distribution from $\\P$. We consider two reasonable games that differ in what the bookie knows when he makes his choice. Anomalies that have been observed before, like time inconsistency, can be understood as arising important because different games are being played, against bookies with different information. We characterize the important special cases in which the optimal decision rules according to the minimax criterion amount to either conditioning or simply ignoring the information. Finally, we consider the relationship between conditioning and calibration when uncertainty is described by sets of probabilities.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2020-05-02 00:00:00.000000"},
{"id":"777","title":"Executive himself win political feeling me.","abstract":"We present several series of synchronizing automata with multiple parameters, generalizing previously known results. Let p and q be two arbitrary co-prime positive integers, q > p. We describe reset thresholds of the colorings of primitive digraphs with exactly one cycle of length p and one cycle of length q. Also, we study reset thresholds of the colorings of primitive digraphs with exactly one cycle of length q and two cycles of length p.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2018-10-06 00:00:00.000000"},
{"id":"778","title":"We threat Mrs believe practice usually manage.","abstract":"Let k be a field, let R be a ring of polynomials in a finite number of variables over k, let D be the ring of k-linear differential operators of R and let f be a non-zero element of R. It is well-known that R_f, with its natural D-module structure, has finite length in the category of D-modules. We give a characteristic-free proof of this fact. To the best of our knowledge this is the first characteristic-free proof.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2021-03-04 00:00:00.000000"},
{"id":"779","title":"Indicate black remember that scene hot.","abstract":"Scanning microphotoluminescence is used to characterise the fluorescence from a dye-loaded polymer deposited on a 5 x 5 nanoantenna dipole array. Vertical and horizontal scans show anisotropic emission patterns.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2019-04-13 00:00:00.000000"},
{"id":"780","title":"Cultural wait she poor.","abstract":"We consider grouping as a general characterization for problems such as clustering, community detection in networks, and multiple parametric model estimation. We are interested in merging solutions from different grouping algorithms, distilling all their good qualities into a consensus solution. In this paper, we propose a bi-clustering framework and perspective for reaching consensus in such grouping problems. In particular, this is the first time that the task of finding\/fitting multiple parametric models to a dataset is formally posed as a consensus problem. We highlight the equivalence of these tasks and establish the connection with the computational Gestalt program, that seeks to provide a psychologically-inspired detection theory for visual events. We also present a simple but powerful bi-clustering algorithm, specially tuned to the nature of the problem we address, though general enough to handle many different instances inscribed within our characterization. The presentation is accompanied with diverse and extensive experimental results in clustering, community detection, and multiple parametric model estimation in image processing applications.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2017-06-04 00:00:00.000000"},
{"id":"781","title":"Direction everything door pull protect.","abstract":"The development and validation against experimental results of a new gasoline surrogate complex kinetic mechanism is presented in this paper. The surrogate fuel is a ternary mixture of n heptane, iso octane and toluene. The full three components mechanism is based on existing n heptane\/iso octane (gasoline PRF) and toluene mechanisms which were modified and coupled for the purpose of this work. Mechanism results are compared against available experimental data from the literature. Simulations with the PRF plus toluene mechanism show that its behavior is in agreement with experimental results for most of the tested settings. These include a wide variety of thermodynamic conditions and fuel proportions in experimental configurations such as HCCI engine experiments, rapid compression machines, a shock tube and a jet stirred reactor.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2019-01-08 00:00:00.000000"},
{"id":"782","title":"Cover human key realize.","abstract":"This Paper presents the methodology of penetration of Micro-Grids (MG) in the radial distribution system (RDS). The aim of this paper is to minimize a total real power loss that descends the performance of the radial distribution system by integrating various renewable resources as Distributed Generation (DG). The combination of different types of renewable energy resources contributes a sustainable MG. These resources are optimally sized and located using evolutionary approach in various penetration levels. The optimal solutions are experimented with IEEE 33 radial distribution system using Particle Swarm Optimization (PSO) technique. The results are quite promising and authenticate its potential to solve problem in radial distribution system effectively.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2022-09-08 00:00:00.000000"},
{"id":"783","title":"Product hair war.","abstract":"Correlation filters take advantage of specific properties in the Fourier domain allowing them to be estimated efficiently: O(NDlogD) in the frequency domain, versus O(D^3 + ND^2) spatially where D is signal length, and N is the number of signals. Recent extensions to correlation filters, such as MOSSE, have reignited interest of their use in the vision community due to their robustness and attractive computational properties. In this paper we demonstrate, however, that this computational efficiency comes at a cost. Specifically, we demonstrate that only 1\/D proportion of shifted examples are unaffected by boundary effects which has a dramatic effect on detection\/tracking performance. In this paper, we propose a novel approach to correlation filter estimation that: (i) takes advantage of inherent computational redundancies in the frequency domain, and (ii) dramatically reduces boundary effects. Impressive object tracking and detection results are presented in terms of both accuracy and computational efficiency.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2017-09-11 00:00:00.000000"},
{"id":"784","title":"Page natural central against close scientist.","abstract":"Complex networks are at the core of an intense research activity. However, in most cases, intricate and costly measurement procedures are needed to explore their structure. In some cases, these measurements rely on link queries: given two nodes, it is possible to test the existence of a link between them. These tests may be costly, and thus minimizing their number while maximizing the number of discovered links is a key issue. This paper studies this problem: we observe that properties classically observed on real-world complex networks give hints for their efficient measurement; we derive simple principles and several measurement strategies based on this, and experimentally evaluate their efficiency on real-world cases. In order to do so, we introduce methods to evaluate the efficiency of strategies. We also explore the bias that different measurement strategies may induce.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2021-08-28 00:00:00.000000"},
{"id":"785","title":"Article light begin trouble old wrong lay.","abstract":"We study the typical behavior of bounded linear operators on infinite dimensional complex separable Hilbert spaces in the norm, strong-star, strong, weak polynomial and weak topologies. In particular, we investigate typical spectral properties, the problem of unitary equivalence of typical operators, and their embeddability into C_0-semigroups. Our results provide information on the applicability of Baire category methods in the theory of Hilbert space operators.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2019-12-15 00:00:00.000000"},
{"id":"786","title":"Kitchen parent lose despite direction front.","abstract":"13MW of electron cyclotron current drive (ECCD) power deposited inside the q = 1 surface is likely to reduce the sawtooth period in ITER baseline scenario below the level empirically predicted to trigger neo-classical tearing modes (NTMs). However, since the ECCD control scheme is solely predicated upon changing the local magnetic shear, it is prudent to plan to use a complementary scheme which directly decreases the potential energy of the kink mode in order to reduce the sawtooth period. In the event that the natural sawtooth period is longer than expected, due to enhanced alpha particle stabilisation for instance, this ancillary sawtooth control can be provided from > 10MW of ion cyclotron resonance heating (ICRH) power with a resonance just inside the q = 1 surface. Both ECCD and ICRH control schemes would benefit greatly from active feedback of the deposition with respect to the rational surface. If the q = 1 surface can be maintained closer to the magnetic axis, the efficacy of ECCD and ICRH schemes significantly increases, the negative effect on the fusion gain is reduced, and off-axis negative-ion neutral beam injection (NNBI) can also be considered for sawtooth control. Consequently, schemes to reduce the q = 1 radius are highly desirable, such as early heating to delay the current penetration and, of course, active sawtooth destabilisation to mediate small frequent sawteeth and retain a small q = 1 radius.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2017-01-05 00:00:00.000000"},
{"id":"787","title":"Easy tax person protect under care fish.","abstract":"We propose a series of features for the graphical user interface (GUI) of the COmputational MOdule Integrator (COMODI) \\cite{Synasc05a}\\cite{COMODI}. In view of the special requirements that a COMODI type of framework for scientific computing imposes and inspiring from existing solutions that provide advanced graphical visual programming environments, we identify those elements and associated behaviors that will have to find their way into the first release of COMODI.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2019-06-21 00:00:00.000000"},
{"id":"788","title":"Outside each fact for prevent I thought get.","abstract":"A multi-laboratory collaboration is studying the feasibility of building a muon collider, the first phase of which maybe a neutrino factory. The phase space occupied by the muons is very large and needs to be cooled several orders of magnitude for either machine, 100,000 to 1 million for the collider and ten to 100 for the factory. Ionization cooling is the base line method for muon cooling. This scheme uses hydrogen absorbers and rf re-acceleration in a long series of magnetic focusing channels to cool the muons. At Fermilab two rf cavity types are under study to provide the required cooling rf re-acceleration, a 805 MHz high gradient cavity for the collider and a 201 MHz high gradient cavity for the neutrino factory. The 805 MHz cavity currently under going cold testing is a non-periodic pi-mode cavity with the iris openings shaped to follow the contour of the beam. The 201 MHz cavity uses hollow thin metal tubes over the beam aperture to terminate the field in a pill-box type mode to increase its shunt impedance. This is possible because muons have little interactions with thin metal membranes. Details of these cavities and cold measurement data will be presented.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2020-04-28 00:00:00.000000"},
{"id":"789","title":"House fly bring rather challenge evening white.","abstract":"We characterize the \"social Web\" and argue for several features that are desirable for users of socially oriented web applications. We describe the architecture of Deme, a web content management system (WCMS) and extensible framework, and show how it implements these desired features. We then compare Deme on our desiderata with other web technologies: traditional HTML, previous open source WCMSs (illustrated by Drupal), commercial Web 2.0 applications, and open-source, object-oriented web application frameworks. The analysis suggests that a WCMS can be well suited to building social websites if it makes more of the features of object-oriented programming, such as polymorphism, and class inheritance, available to non-programmers in an accessible vocabulary.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2021-07-08 00:00:00.000000"},
{"id":"790","title":"Difference happen assume need democratic.","abstract":"We consider the four-dimensional nonholonomic distribution defined by the 4-potential of the electromagnetic field on the manifold. This distribution has a metric tensor with the Lorentzian signature $(+,-,-,-)$, therefore, the causal structure appears as in the general relativity theory. By means of the Pontryagin's maximum principle we proved that the equations of the horizontal geodesics for this distribution are the same as the equations of motion of a charged particle in the general relativity theory. This is a Kaluza -- Klein problem of classical and quantum physics solved by methods of sub-Lorentzian geometry. We study the geodesics sphere which appears in a constant magnetic field and its singular points. Sufficiently long geodesics are not optimal solutions of the variational problem and define the nonholonomic wavefront. This wavefront is limited by a convex elliptic cone. We also study variational principle approach to the problem. The Euler -- Lagrange equations are the same as those obtained by the Pontryagin's maximum principle if the restriction of the metric tensor on the distribution is the same.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2022-10-03 00:00:00.000000"},
{"id":"791","title":"Particularly sell wish themselves purpose side heavy.","abstract":"In this paper we investigate the impact of the floating-point precision and interpolation scheme on the results of direct numerical simulations (DNS) of turbulence by pseudo-spectral codes. Three different types of floating-point precision configurations show no differences in the statistical results. This implies that single precision computations allow for increased Reynolds numbers due to the reduced amount of memory needed. The interpolation scheme for obtaining velocity values at particle positions has a noticeable impact on the Lagrangian acceleration statistics. A tri-cubic scheme results in a slightly broader acceleration probability density function than a tri-linear scheme. Furthermore the scaling behavior obtained by the cubic interpolation scheme exhibits a tendency towards a slightly increased degree of intermittency compared to the linear one.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2017-07-10 00:00:00.000000"},
{"id":"792","title":"Same appear by about particular land political attorney.","abstract":"A recent study on structural properties of regular and context-free languages has greatly promoted our basic understandings of the complex behaviors of those languages. We continue the study to examine how regular languages behave when they need to cut numerous infinite languages. A particular interest rests on a situation in which a regular language needs to \"dissect\" a given infinite language into two subsets of infinite size. Every context-free language is dissected by carefully chosen regular languages (or it is REG-dissectible). In a larger picture, we show that constantly-growing languages and semi-linear languages are REG-dissectible. Under certain natural conditions, complements and finite intersections of semi-linear languages also become REG-dissectible. Restricted to bounded languages, the intersections of finitely many context-free languages and, more surprisingly, the entire Boolean hierarchy over bounded context-free languages are REG-dissectible. As an immediate application of the REG-dissectibility, we show another structural property, in which an appropriate bounded context-free language can \"separate with infinite margins\" two given nested infinite bounded context-free languages.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2015-12-25 00:00:00.000000"},
{"id":"793","title":"Fear can fear particular.","abstract":"Factor analysis refers to a statistical model in which observed variables are conditionally independent given fewer hidden variables, known as factors, and all the random variables follow a multivariate normal distribution. The parameter space of a factor analysis model is a subset of the cone of positive definite matrices. This parameter space is studied from the perspective of computational algebraic geometry. Gr\\\"obner bases and resultants are applied to compute the ideal of all polynomial functions that vanish on the parameter space. These polynomials, known as model invariants, arise from rank conditions on a symmetric matrix under elimination of the diagonal entries of the matrix. Besides revealing the geometry of the factor analysis model, the model invariants also furnish useful statistics for testing goodness-of-fit.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2016-03-12 00:00:00.000000"},
{"id":"794","title":"Begin pick material beyond team full use.","abstract":"In this paper, we explore a set of novel features for authorship attribution of documents. These features are derived from a word network representation of natural language text. As has been noted in previous studies, natural language tends to show complex network structure at word level, with low degrees of separation and scale-free (power law) degree distribution. There has also been work on authorship attribution that incorporates ideas from complex networks. The goal of our paper is to explore properties of these complex networks that are suitable as features for machine-learning-based authorship attribution of documents. We performed experiments on three different datasets, and obtained promising results.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2019-10-08 00:00:00.000000"},
{"id":"795","title":"Job crime mouth pressure build cold.","abstract":"This note introduces and studies an open set of PSL(2,C) characters of a nonabelian free group, on which the action of the outer automorphism group is properly discontinuous, and which is strictly larger than the set of discrete, faithful convex-cocompact (i.e. Schottky) characters. This implies, in particular, that the outer automorphism group does not act ergodically on the set of characters with dense image. Hence there is a difference between the geometric (discrete vs. dense) decomposition of the characters, and a natural dynamical decomposition.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2018-09-18 00:00:00.000000"},
{"id":"796","title":"North prepare matter our.","abstract":"The study of Complex Systems is considered by many to be a new scientific field, and is distinguished by being a discipline that has applications within many separate areas of scientific study. The study of Neural Networks, Traffic Patterns, Artificial Intelligence, Social Systems, and many other scientific areas can all be considered to fall within the realm of Complex Systems, and can be studied from this new perspective. The advent of more capable computer systems has allowed these systems to be simulated and modeled with far greater ease, and new understanding of computer modeling approaches has allowed the fledgling science to be studied as never before.   The preliminary focus of this paper will be to provide a general overview of the science of Complex Systems, including terminology, definitions, history, and examples. I will attempt to look at some of the most important trends in different areas of research, and give a general overview of research methods that have been used in parallel with computer modeling. Also, I will further define the areas of the science that concern themselves with computer modeling and simulation, and I will attempt to make it clear why the science only came into its own when the proper modeling and simulation tools were finally available. In addition, although there seems to be general agreement between different authors and institutes regarding the generalities of the study, there are some differences in terminology and methodology. I have attempted in this paper to bring as many elements together as possible, as far as the scope of the subject is concerned, without losing focus by studying Complex System techniques that are bound to one particular area of scientific study, unless that area is that of computer modeling.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2016-11-19 00:00:00.000000"},
{"id":"797","title":"Perhaps attack white class boy even positive.","abstract":"Time series both of microwave radiometer brightness temperature measurements at 23.8 and 31.4 GHz and of retrievals of water vapor and liquid water path from these brightness temperatures are evaluated using the detrended fluctuation analysis method. As quantified by the parameter $\\alpha$, this method (i) enables identification of the time scales over which noise dominates the time series and (ii) characterizes the temporal range of correlations in the time series. The more common spectral analysis method is also used to assess the data and its results are compared with those from detrended fluctuation analysis method. The assumption that measurements should have certain scaling properties allows the quality of the measurements to be characterized. The additional assumption that the scaling properties of the measurements of an atmospheric quantity are preserved in a useful retrieval provides a means for evaluating the retrieval itself. Applying these two assumptions to microwave radiometer measurements and retrievals demonstrates three points. First, the retrieved water vapor path during cloudy-sky periods can be dominated by noise on shorter than ~30~min time scales ($\\alpha$-exponent = 0.1) and exhibits no scaling behavior at longer time scales. However, correlations in the brightness temperatures and liquid water path retrievals are found to be consistent with a power-law behavior for time scales up to 3 hr with an $\\alpha$-exponent equal to approximately 0.3, as in other geophysical phenomena. Second, clear-sky, moist atmospheres show the expected scaling for both measurements and retrievals of the water vapor path. Third, during clear-sky, dry atmospheric days, instrument noise from the 31.4 GHz channel compromises the quality of the water vapor path retrieval.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2016-04-12 00:00:00.000000"},
{"id":"798","title":"Current always task big between spring analysis.","abstract":"A crowdsourced stream processing system (CSP) is a system that incorporates crowdsourced tasks in the processing of a data stream. This can be seen as enabling crowdsourcing work to be applied on a sample of large-scale data at high speed, or equivalently, enabling stream processing to employ human intelligence. It also leads to a substantial expansion of the capabilities of data processing systems. Engineering a CSP system requires the combination of human and machine computation elements. From a general systems theory perspective, this means taking into account inherited as well as emerging properties from both these elements. In this paper, we position CSP systems within a broader taxonomy, outline a series of design principles and evaluation metrics, present an extensible framework for their design, and describe several design patterns. We showcase the capabilities of CSP systems by performing a case study that applies our proposed framework to the design and analysis of a real system (AIDR) that classifies social media messages during time-critical crisis events. Results show that compared to a pure stream processing system, AIDR can achieve a higher data classification accuracy, while compared to a pure crowdsourcing solution, the system makes better use of human workers by requiring much less manual work effort.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2020-05-13 00:00:00.000000"},
{"id":"799","title":"Low college fill light again note better.","abstract":"In this paper, Brou\\'e's conjecture is reduced to simple groups, with an additional stability condition.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2018-07-31 00:00:00.000000"},
{"id":"800","title":"Statement able candidate away teacher hour various late.","abstract":"Hierarchies are the most common structure used to understand the world better. In galaxies, for instance, multiple-star systems are organised in a hierarchical system. Then, governmental and company organisations are structured using a hierarchy, while the Internet, which is used on a daily basis, has a space of domain names arranged hierarchically. Since Artificial Intelligence (AI) planning portrays information about the world and reasons to solve some of world's problems, Hierarchical Task Network (HTN) planning has been introduced almost 40 years ago to represent and deal with hierarchies. Its requirement for rich domain knowledge to characterise the world enables HTN planning to be very useful, but also to perform well. However, the history of almost 40 years obfuscates the current understanding of HTN planning in terms of accomplishments, planning models, similarities and differences among hierarchical planners, and its current and objective image. On top of these issues, attention attracts the ability of hierarchical planning to truly cope with the requirements of applications from the real world. We propose a framework-based approach to remedy this situation. First, we provide a basis for defining different formal models of hierarchical planning, and define two models that comprise a large portion of HTN planners. Second, we provide a set of concepts that helps to interpret HTN planners from the aspect of their search space. Then, we analyse and compare the planners based on a variety of properties organised in five segments, namely domain authoring, expressiveness, competence, performance and applicability. Furthermore, we select Web service composition as a real-world and current application, and classify and compare the approaches that employ HTN planning to solve the problem of service composition. Finally, we conclude with our findings and present directions for future work.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2018-10-16 00:00:00.000000"},
{"id":"801","title":"Data still would woman show.","abstract":"In this paper, we propose a new quality link metric, interference and bandwidth adjusted ETX (IBETX) for wireless multi-hop networks. As MAC layer affects the link performance and consequently the route quality, the metric therefore, tackles the issue by achieving twofold MAC-awareness. Firstly, interference is calculated using cross-layered approach by sending probes to MAC layer. Secondly, the nominal bit rate information is provided to all nodes in the same contention domain by considering the bandwidth sharing mechanism of 802.11. Like ETX, our metric also calculates link delivery ratios that directly affect throughput and selects those routes that bypass dense regions in the network. Simulation results by NS-2 show that IBETX gives 19% higher throughput than ETX and 10% higher than Expected Throughput (ETP). Our metric also succeeds to reduce average end-to-end delay up to 16% less than Expected Link Performance (ELP) and 24% less than ETX.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2019-07-10 00:00:00.000000"},
{"id":"802","title":"Happy card into school.","abstract":"Let X, Y be the universal covers of two compact Riemannian manifolds (with dimension not equal to 4) with negative sectional curvature. Then every quasiisometry between them lies at a finite distance from a bilipschitz homeomorphism.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2016-02-28 00:00:00.000000"},
{"id":"803","title":"Above thought reduce.","abstract":"We study the coherent orientations of the moduli spaces of holomorphic curves in Symplectic Field Theory, generalizing a construction due to Floer and Hofer. In particular we examine their behavior at multiple closed Reeb orbits under change of the asymptotic direction. The orientations are determined by a certain choice of orientation at each closed Reeb orbit, that is similar to the orientation of the unstable tangent spaces of critical points in finite--dimensional Morse theory.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2021-01-03 00:00:00.000000"},
{"id":"804","title":"Within let day might all.","abstract":"We show how to transform into programs the proofs in classical Analysis which use the existence of an ultrafilter on the integers. The method mixes the classical realizability introduced by the author, with the \"forcing\" of P. Cohen. The programs we obtain, use read and write instructions in random access memory.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2021-01-11 00:00:00.000000"},
{"id":"805","title":"Kind yourself stage quite night.","abstract":"We investigate, in the Shannon model, the security of constructions corresponding to double and (two-key) triple DES. That is, we consider F_{k1}(F_{k2}(.)) and F_{k1}(F_{k2}^{-1}(F_{k1}(.))) with the component functions being ideal ciphers. This models the resistance of these constructions to ``generic'' attacks like meet in the middle attacks. We obtain the first proof that composition actually increases the security of these constructions in some meaningful sense. We compute a bound on the probability of breaking the double cipher as a function of the number of computations of the base cipher made, and the number of examples of the composed cipher seen, and show that the success probability is the square of that for a single key cipher. The same bound holds for the two-key triple cipher. The first bound is tight and shows that meet in the middle is the best possible generic attack against the double cipher.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2019-07-07 00:00:00.000000"},
{"id":"806","title":"Size note world cause free decade.","abstract":"Let $R$ be a commutative Noetherian local ring of prime characteristic $p$. The main purposes of this paper are to show that if the injective envelope $E$ of the simple $R$-module has a structure as a torsion-free left module over the Frobenius skew polynomial ring over $R$, then $R$ has a tight closure test element (for modules) and is $F$-pure, and to relate the test ideal of $R$ to the smallest '$E$-special' ideal of $R$ of positive height.   A byproduct is an analogue of a result of Janet Cowden Vassilev: she showed, in the case where $R$ is an $F$-pure homomorphic image of an $F$-finite regular local ring, that there exists a strictly ascending chain $0 = \\tau_0 \\subset \\tau_1 \\subset ... \\subset \\tau_t = R$ of radical ideals of $R$ such that, for each $i = 0, ..., t-1$, the reduced local ring $R\/\\tau_i$ is $F$-pure and its test ideal (has positive height and) is exactly $\\tau_{i+1}\/\\tau_i$. This paper presents an analogous result in the case where $R$ is complete (but not necessarily $F$-finite) and $E$ has a structure as a torsion-free left module over the Frobenius skew polynomial ring. Whereas Cowden Vassilev's results were based on R. Fedder's criterion for $F$-purity, the arguments in this paper are based on the author's work on graded annihilators of left modules over the Frobenius skew polynomial ring.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2022-12-15 00:00:00.000000"},
{"id":"807","title":"Mean election food entire.","abstract":"Starting with two light clocks to derive time dilation expression, as many textbooks do, and then adding a third one, we work on relativistic spacetime coordinates relations for some simple events as emission, reflection and return of light pulses. Besides time dilation, we get, in the following order, Doppler k-factor, addition of velocities, length contraction, Lorentz Transformations and spacetime interval invariance. We also use Minkowski spacetime diagram to show how to interpret some few events in terms of spacetime coordinates in three different inertial frames.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2018-02-05 00:00:00.000000"},
{"id":"808","title":"Hair situation employee impact style data detail.","abstract":"By means of density, dielectric spectroscopy and sound velocity measurements we perform a systematic study on the polyoxyethylene $C_{12}E_{6}$ nonionic surfactant solutions as a function of temperature and concentration. Both density and sound velocity data, at about $34^{\\circ}C$, coincide with the value obtained for pure water. Above this temperature the density is lower than the water density whereas below it is greater, the opposite happens for the compressibility. Combining results from these different techniques we tempt a very detailed description of the evolution of the micellar interfacial properties with temperature. It is well known that nonionic surfactant solutions dehydrate, growing temperature. Our results indicate that this process is associated with a continuous change in the polymer conformation and in the local density of the micellar interface.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2017-03-02 00:00:00.000000"},
{"id":"809","title":"Around clear suggest of meeting challenge since.","abstract":"While keyword query empowers ordinary users to search vast amount of data, the ambiguity of keyword query makes it difficult to effectively answer keyword queries, especially for short and vague keyword queries. To address this challenging problem, in this paper we propose an approach that automatically diversifies XML keyword search based on its different contexts in the XML data. Given a short and vague keyword query and XML data to be searched, we firstly derive keyword search candidates of the query by a classifical feature selection model. And then, we design an effective XML keyword search diversification model to measure the quality of each candidate. After that, three efficient algorithms are proposed to evaluate the possible generated query candidates representing the diversified search intentions, from which we can find and return top-$k$ qualified query candidates that are most relevant to the given keyword query while they can cover maximal number of distinct results.At last, a comprehensive evaluation on real and synthetic datasets demonstrates the effectiveness of our proposed diversification model and the efficiency of our algorithms.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2020-06-25 00:00:00.000000"},
{"id":"810","title":"Fire per institution find company artist.","abstract":"On a commercial digital still camera (DSC) controller chip we practice a novel SOC test integration platform, solving real problems in test scheduling, test IO reduction, timing of functional test, scan IO sharing, embedded memory built-in self-test (BIST), etc. The chip has been fabricated and tested successfully by our approach. Test results justify that short test integration cost, short test time, and small area overhead can be achieved. To support SOC testing, a memory BIST compiler and an SOC testing integration system have been developed.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2019-08-27 00:00:00.000000"},
{"id":"811","title":"Change oil their fill price.","abstract":"A toroidal, quasi-linear model is proposed to study the penetration dynamics of the resonant magnetic perturbation (RMP) field into the plasma. The model couples the linear, fluid plasma response to a toroidal momentum balance equation, which includes torques induced by both fluid electromagnetic force and by (kinetic) neoclassical toroidal viscous force. The numerical results for a test toroidal equilibrium quantify the effects of various physical parameters on the field penetration and on the plasma rotation braking. The neoclassical toroidal viscous torque plays a dominant role in certain region of the plasma, for the RMP penetration problem considered in this work.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2016-02-09 00:00:00.000000"},
{"id":"812","title":"Public stuff catch investment thought trial.","abstract":"An analysis of traveling wave solutions of partial differential equation (PDE) systems with cross-diffusion is presented. The systems under study fall in a general class of the classical Keller-Segel models to describe chemotaxis. The analysis is conducted using the theory of the phase plane analysis of the corresponding wave systems without a priory restrictions on the boundary conditions of the initial PDE. Special attention is paid to families of traveling wave solutions. Conditions for existence of front-impulse, impulse-front, and front-front traveling wave solutions are formulated. In particular, the simplest mathematical model is presented that has an impulse-impulse solution; we also show that a non-isolated singular point in the ordinary differential equation (ODE) wave system implies existence of free-boundary fronts. The results can be used for construction and analysis of different mathematical models describing systems with chemotaxis.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2022-05-25 00:00:00.000000"},
{"id":"813","title":"Economy past kid indeed.","abstract":"The Conley-Zehnder index associates an integer to any continuous path of symplectic matrices starting from the identity and ending at a matrix which does not admit 1 as an eigenvalue. We give new ways to compute this index. Robbin and Salamon define a generalization of the Conley-Zehnder index for any continuous path of symplectic matrices; this generalization is half integer valued. It is based on a Maslov-type index that they define for a continuous path of Lagrangians in a symplectic vector space $(W,\\bar{\\Omega})$, having chosen a given reference Lagrangian $V$. Paths of symplectic endomorphisms of $(\\R^{2n},\\Omega_0)$ are viewed as paths of Lagrangians defined by their graphs in $(W=\\R^{2n}\\oplus \\R^{2n},\\bar{\\Omega}=\\Omega_0\\oplus -\\Omega_0)$ and the reference Lagrangian is the diagonal. Robbin and Salamon give properties of this generalized Conley-Zehnder index and an explicit formula when the path has only regular crossings. We give here an axiomatic characterization of this generalized Conley-Zehnder index. We also give an explicit way to compute it for any continuous path of symplectic matrices.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2015-02-14 00:00:00.000000"},
{"id":"814","title":"Change bit section black run others.","abstract":"Model selection and assessment with incomplete data pose challenges in addition to the ones encountered with complete data. There are two main reasons for this. First, many models describe characteristics of the complete data, in spite of the fact that only an incomplete subset is observed. Direct comparison between model and data is then less than straightforward. Second, many commonly used models are more sensitive to assumptions than in the complete-data situation and some of their properties vanish when they are fitted to incomplete, unbalanced data. These and other issues are brought forward using two key examples, one of a continuous and one of a categorical nature. We argue that model assessment ought to consist of two parts: (i) assessment of a model's fit to the observed data and (ii) assessment of the sensitivity of inferences to unverifiable assumptions, that is, to how a model described the unobserved data given the observed ones.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2020-04-03 00:00:00.000000"},
{"id":"815","title":"Actually big citizen better design.","abstract":"Before developing his 1915 General Theory of Relativity, Einstein held the \"Entwurf\" theory. Tullio Levi-Civita from Padua, one of the founders of tensor calculus, objected to a major problematic element in this theory, which reflected its global problem: its field equations were restricted to an adapted coordinate system. Einstein proved that his gravitational tensor was a covariant tensor for adapted coordinate systems. In an exchange of letters and postcards that began in March 1915 and ended in May 1915, Levi-Civita presented his objections to Einstein's above proof. Einstein tried to find ways to save his proof, and found it hard to give it up. Finally Levi-Civita convinced Einstein about a fault in his arguments. However, only in spring 1916, long after Einstein had abandoned the 1914 theory, did he finally understand the main problem with his 1914 gravitational tensor. In autumn 1915 the G\\\"ottingen brilliant mathematician David Hilbert found the central flaw in Einstein's 1914 derivation. On March 30, 1916, Einstein sent to Hilbert a letter admitting, \"The error you found in my paper of 1914 has now become completely clear to me\".","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2018-06-26 00:00:00.000000"},
{"id":"816","title":"Natural seek many only talk someone fact.","abstract":"A divide-and-conquer based approach for computing the Moore-Penrose pseudo-inverse of the combinatorial Laplacian matrix $(\\bb L^+)$ of a simple, undirected graph is proposed. % The nature of the underlying sub-problems is studied in detail by means of an elegant interplay between $\\bb L^+$ and the effective resistance distance $(\\Omega)$. Closed forms are provided for a novel {\\em two-stage} process that helps compute the pseudo-inverse incrementally. Analogous scalar forms are obtained for the converse case, that of structural regress, which entails the breaking up of a graph into disjoint components through successive edge deletions. The scalar forms in both cases, show absolute element-wise independence at all stages, thus suggesting potential parallelizability. Analytical and experimental results are presented for dynamic (time-evolving) graphs as well as large graphs in general (representing real-world networks). An order of magnitude reduction in computational time is achieved for dynamic graphs; while in the general case, our approach performs better in practice than the standard methods, even though the worst case theoretical complexities may remain the same: an important contribution with consequences to the study of online social networks.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2015-11-17 00:00:00.000000"},
{"id":"817","title":"Possible idea write various.","abstract":"For a partially ordered set P, we denote by Co(P) the lattice of order-convex subsets of P. We find three new lattice identities, (S), (U), and (B), such that the following result holds. Theorem. Let L be a lattice. Then L embeds into some lattice of the form Co(P) iff L satisfies (S), (U), and (B). Furthermore, if L has an embedding into some Co(P), then it has such an embedding that preserves the existing bounds. If L is finite, then one can take P finite, of cardinality at most $2n^2-5n+4$, where n is the number of join-irreducible elements of L. On the other hand, the partially ordered set P can be chosen in such a way that there are no infinite bounded chains in P and the undirected graph of the predecessor relation of P is a tree.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2015-06-07 00:00:00.000000"},
{"id":"818","title":"Group man attack analysis.","abstract":"We measure and stabilize the relative angle of (anti-)parallel laser beams to 5 nanoradian per root Hertz resolution by comparing the phases of radio frequency beat notes on a quadrant photodetector. The absolute accuracy is 5.1 microradian and 2.1 microradian for antiparallel and parallel beams, respectively, which is more than 6 and 16 times below the Rayleigh criterion.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2015-05-02 00:00:00.000000"},
{"id":"819","title":"Themselves back city hit early theory bank.","abstract":"The notion of Nash equilibria plays a key role in the analysis of strategic interactions in the framework of $N$ player games. Analysis of Nash equilibria is however a complex issue when the number of players is large. In this article we emphasize the role of optimal transport theory in: 1) the passage from Nash to Cournot-Nash equilibria as the number of players tends to infinity, 2) the analysis of Cournot-Nash equilibria.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2018-06-15 00:00:00.000000"},
{"id":"820","title":"Else quite color medical.","abstract":"In this paper we first show that many braid groups of low genus surfaces have their centers as direct factors. We then give a description of centralizers and normalizers of prime order elements in pure mapping class groups of surfaces with spherical quotients using automorphism groups of fundamental groups of the quotient surfaces. As an application, we use these to show that the $p$-primary part of the Farrell cohomology groups of certain mapping class groups are elementary abelian groups. At the end we compute the $p$-primary part of the Farrell cohomology of a few pure mapping class groups.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2016-11-14 00:00:00.000000"},
{"id":"821","title":"World sometimes book though.","abstract":"I combine the effects of Planck length, general relativity and Newtonian gravity in one equation, to come up with a semi-classical model of gravity in the form of deviation from Newtonian gravity. Einstein explained nuclear forces in terms of gravity (Ref. 2). This reference is explicit in expressing Einstein's attempts and describes them as misguided. My model shows Einstein was not misguided in his attempts to explain nuclear forces in terms of gravity. My model shows just the contrary. I use Planck length as what it is: minimum distance that makes any sense. I make a subatomic distinction between mass and space, a lesson learned from general relativity. General relativity is about mass telling space how to curve and space telling mass how to move. Unlike string theory, I use no imaginary dimensions. My model predicts maximum nuclear force as the limit of gravitation and clearly yields Newtonian gravity at a macroscopic scale in an unprecedented and consistent manner: Good-by to quantum gravity.   I am combining Newton, Planck and Einstein and to predict a limit of gravity as Chandrashekhar did to predict his limit.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2022-12-25 00:00:00.000000"},
{"id":"822","title":"Organization father decide travel share financial.","abstract":"An atom moving in a spatially periodic field experiences a temporary periodic perturbation and undergoes a resonance transition between atomic internal states when the transition frequency is equal to the atomic velocity divided by the field period. We demonstrated that spin nutation was induced by this resonant transition in a polarized rubidium (Rb) atomic beam passing through a magnetic lattice. The lattice was produced by current flowing through an array of parallel wires crossing the beam. This array structure, reminiscent of a multiwire chamber for particle detection, allowed the Rb beam to pass through the lattice at a variety of incident angles. The dephasing of spin nutation was reduced by varying the incident angle.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2017-05-26 00:00:00.000000"},
{"id":"823","title":"Behavior case society fund bad firm.","abstract":"This paper presents two sufficient conditions to ensure a faithful evaluation of polynomial in IEEE-754 floating point arithmetic. Faithfulness means that the computed value is one of the two floating point neighbours of the exact result; it can be satisfied using a more accurate algorithm than the classic Horner scheme. One condition here provided is an apriori bound of the polynomial condition number derived from the error analysis of the compensated Horner algorithm. The second condition is both dynamic and validated to check at the running time the faithfulness of a given evaluation. Numerical experiments illustrate the behavior of these two conditions and that associated running time over-cost is really interesting.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2015-12-06 00:00:00.000000"},
{"id":"824","title":"Happy practice choice eat parent.","abstract":"An expression for the electromagnetic field energy density in a dispersive, lossy, left-handed metamaterial, consisting of an array of split-ring resonators and an array of wires is derived. An electromagnetic field with general time-dependence is considered. The outcome is compared with previously published results. In the absence of losses, agreement with the general result for the energy density in a dispersive material is obtained. The formulae are verified using the finite-difference time-domain (FDTD) numerical method. The applicability of two commonly used permeability models to the problem of calculating the energy stored in an array of split-ring resonators is discussed.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2016-07-08 00:00:00.000000"},
{"id":"825","title":"Interesting seat kind campaign occur member.","abstract":"In recent years, the use of the automobile as the primary mode of transportation has been increasing and driving has become an important part of daily life. Driving is a multi-sensory experience as drivers rely on their senses to provide them with important information. In a vehicular context human senses are all too often limited and obstructed. Today, road accidents constitute the eighth leading cause of death. The escalation of technology has propelled new ways in which driver's senses may be augmented. The enclosed aspect of a car, allied with the configuration of the controls and displays directed towards the driver, offer significant advantages for augmented reality (AR) systems when considering the amount of immersion it can provide to the user. In addition, the inherent mobility and virtually unlimited power autonomy transform cars into perfect mobile computing platforms. However, automobiles currently present limited network connectivity and thus the created augmented objects are merely providing information captured by in-vehicle sensors, cameras and other databases. By combining the new paradigm of Vehicular Ad Hoc Networking (VANET) with AR human machine interfaces, we show that it is possible to design novel cooperative Advanced Driver Assistance Systems (ADAS), that base the creation of AR content on the information collected from neighbouring vehicles or roadside infrastructures. As such we implement prototypes of both visual and acoustic AR systems, which can significantly improve the driving experience. We believe our results contribute to the formulation of a vision where the vehicle is perceived as an extension of the body which permeates the human senses to the world outside the vessel, where the car is used as a better, multi-sensory immersive version of a mobile phone that integrates touch, vision and sound enhancements, leveraging unique properties of VANET.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2016-01-01 00:00:00.000000"},
{"id":"826","title":"Technology crime level feeling.","abstract":"There are several web platforms that people use to interact and exchange ideas, such as social networks like Facebook, Twitter, and Google+; Q&A sites like Quora and Yahoo! Answers; and myriad independent fora. However, there is a scarcity of platforms that facilitate discussion of complex subjects where people with divergent views can easily rationalize their points of view using a shared knowledge base, and leverage it towards shared objectives, e.g. to arrive at a mutually acceptable compromise.   In this paper, as a first step, we present Widescope, a novel collaborative web platform for catalyzing shared understanding of the US Federal and State budget debates in order to help users reach data-driven consensus about the complex issues involved. It aggregates disparate sources of financial data from different budgets (i.e. from past, present, and proposed) and presents a unified interface using interactive visualizations. It leverages distributed collaboration to encourage exploration of ideas and debate. Users can propose budgets ab-initio, support existing proposals, compare between different budgets, and collaborate with others in real time.   We hypothesize that such a platform can be useful in bringing people's thoughts and opinions closer. Toward this, we present preliminary evidence from a simple pilot experiment, using triadic voting (which we also formally analyze to show that is better than hot-or-not voting), that 5 out of 6 groups of users with divergent views (conservatives vs liberals) come to a consensus while aiming to halve the deficit using Widescope. We believe that tools like Widescope could have a positive impact on other complex, data-driven social issues.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2016-11-17 00:00:00.000000"},
{"id":"827","title":"Community start section.","abstract":"In this article, we describe the key features of the recently completed technical design for the International Linear Collider (ILC), a 200-500 GeV linear electron-positron collider (expandable to 1 TeV) that is based on 1.3 GHz superconducting radio-frequency (SCRF) technology. The machine parameters and detector characteristics have been chosen to complement the Large Hadron Collider physics, including the discovery of the Higgs boson, and to further exploit this new particle physics energy frontier with a precision instrument. The linear collider design is the result of nearly twenty years of R&D, resulting in a mature conceptual design for the ILC project that reflects an international consensus. We summarize the physics goals and capability of the ILC, the enabling R&D and resulting accelerator design, as well as the concepts for two complementary detectors. The ILC is technically ready to be proposed and built as a next generation lepton collider, perhaps to be built in stages beginning as a Higgs factory.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2015-06-30 00:00:00.000000"},
{"id":"828","title":"Large thing husband reason rest.","abstract":"A method is presented for obtaining rigorous error estimates for approximate solutions of the Riccati equation, with real or complex potentials. Our main tool is to derive invariant region estimates for complex solutions of the Riccati equation. We explain the general strategy for applying these estimates and illustrate the method in typical examples, where the approximate solutions are obtained by glueing together WKB and Airy solutions of corresponding one-dimensional Schrodinger equations. Our method is motivated by and has applications to the analysis of linear wave equations in the geometry of a rotating black hole.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2018-09-21 00:00:00.000000"},
{"id":"829","title":"Goal political again themselves.","abstract":"The present work is devoted to develop a computational model using the Gate Monte Carlo software for the simulation of a 6MV photon beam given by Elekta Synergy Platform medical linear accelerator treatment head. The model includes the major components of the multileaf accelerator head and a homogeneous water phantom. Calculations were performed for a photon beam with several treatment fields size ranging from 5*5 cm2 to 30*30 cm2 at 100 cm distance from source. The simulation is successfully validated by comparison with experimental distributions measured at the Regional Hassan II Oncology Center. Good agreement between simulations and measurements was observed, with dose differences of about 1.6% and 1.8% for depth doses and lateral dose profiles, respectively. The gamma index comparisons were also performed where more than 98% of the points for all simulations passed the standard quality assurance criteria of 3mm\/3%.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2017-08-12 00:00:00.000000"},
{"id":"830","title":"Final plan add television stage.","abstract":"In order to achieve high efficiency of classification in intrusion detection, a compressed model is proposed in this paper which combines horizontal compression with vertical compression. OneR is utilized as horizontal com-pression for attribute reduction, and affinity propagation is employed as vertical compression to select small representative exemplars from large training data. As to be able to computationally compress the larger volume of training data with scalability, MapReduce based parallelization approach is then implemented and evaluated for each step of the model compression process abovementioned, on which common but efficient classification methods can be directly used. Experimental application study on two publicly available datasets of intrusion detection, KDD99 and CMDC2012, demonstrates that the classification using the compressed model proposed can effectively speed up the detection procedure at up to 184 times, most importantly at the cost of a minimal accuracy difference with less than 1% on average.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2020-02-10 00:00:00.000000"},
{"id":"831","title":"Why somebody when these before quality.","abstract":"Software products evolve over time. Sometimes they evolve by adding new features, and sometimes by either fixing bugs or replacing outdated implementations with new ones. When software engineers fail to anticipate such evolution during development, they will eventually be forced to re-architect or re-build from scratch. Therefore, it has been common practice to prepare for changes so that software products are extensible over their lifetimes. However, making software extensible is challenging because it is difficult to anticipate successive changes and to provide adequate abstraction mechanisms over potential changes. Such extensibility mechanisms, furthermore, should not compromise any existing functionality during extension. Software engineers would benefit from a tool that provides a way to add extensions in a reliable way. It is natural to expect programming languages to serve this role. Extensible programming is one effort to address these issues.   In this thesis, we present type safe extensible programming using the MLPolyR language. MLPolyR is an ML-like functional language whose type system provides type-safe extensibility mechanisms at several levels. After presenting the language, we will show how these extensibility mechanisms can be put to good use in the context of product line engineering. Product line engineering is an emerging software engineering paradigm that aims to manage variations, which originate from successive changes in software.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2020-05-29 00:00:00.000000"},
{"id":"832","title":"Although above agency their way piece.","abstract":"We experimentally study the role of the forcing on gravity-capillary wave turbulence. Previous laboratory experiments using spatially localized forcing (vibrating blades) have shown that the frequency power-law exponent of the gravity wave spectrum depends on the forcing parameters. By horizontally vibrating the whole container, we observe a spectrum exponent that does not depend on the forcing parameters for both gravity and capillary regimes. This spatially extended forcing leads to a gravity spectrum exponent in better agreement with the theory than by using a spatially localized forcing. The role of the vessel shape has been also studied. Finally, the wave spectrum is found to scale linearly with the injected power for both regimes whatever the forcing type used.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2022-11-23 00:00:00.000000"},
{"id":"833","title":"Live people growth similar vote look rise.","abstract":"We develop a class of new kinetic data structures for collision detection between moving convex polytopes; the performance of these structures is sensitive to the separation of the polytopes during their motion. For two convex polygons in the plane, let $D$ be the maximum diameter of the polygons, and let $s$ be the minimum distance between them during their motion. Our separation certificate changes $O(\\log(D\/s))$ times when the relative motion of the two polygons is a translation along a straight line or convex curve, $O(\\sqrt{D\/s})$ for translation along an algebraic trajectory, and $O(D\/s)$ for algebraic rigid motion (translation and rotation). Each certificate update is performed in $O(\\log(D\/s))$ time. Variants of these data structures are also shown that exhibit \\emph{hysteresis}---after a separation certificate fails, the new certificate cannot fail again until the objects have moved by some constant fraction of their current separation. We can then bound the number of events by the combinatorial size of a certain cover of the motion path by balls.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2018-09-27 00:00:00.000000"},
{"id":"834","title":"Unit bank lot economic.","abstract":"To reduce tear and wear of machinery lubrication is essential. Lubricants form a layer between two surfaces preventing direct contact and reduce friction between moving parts and hence reduce wear. In this short letter the lubrication of two slider bearings with parallel and nonparallel is studied. First, we show that bearings with parallel plates cannot support any load. For bearings with nonparallel plates we are interested on how constant and temperature dependent viscosity affects the properties of the bearings. Also, a critical temperature for which the bearings would fail due to excess in temperature is found for both latter cases. If the viscosity is constant, the critical temperature is given by an explicit formula, while for the non-constant viscosity the critical temperature can be always found from a closed form formula involving Weber functions","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2020-09-24 00:00:00.000000"},
{"id":"835","title":"Deep investment land check chance scene story.","abstract":"We discuss the methods of Evans and Moshonov [Bayesian Analysis 1 (2006) 893--914, Bayesian Statistics and Its Applications (2007) 145--159] concerning checking for prior-data conflict and their relevance to the method proposed in this paper. [arXiv:0802.0743]","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2019-01-27 00:00:00.000000"},
{"id":"836","title":"Change sport throw short.","abstract":"We consider Metropolis Glauber dynamics for sampling proper $q$-colourings of the $n$-vertex complete $b$-ary tree when $3\\leq q\\leq b\/2\\ln(b)$. We give both upper and lower bounds on the mixing time. For fixed $q$ and $b$, our upper bound is $n^{O(b\/\\log b)}$ and our lower bound is $n^{\\Omega(b\/q \\log(b))}$, where the constants implicit in the $O()$ and $\\Omega()$ notation do not depend upon $n$, $q$ or $b$.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2015-04-10 00:00:00.000000"},
{"id":"837","title":"Within near environmental wind she team.","abstract":"The purpose of this paper is to systematically study compactness and essential norm properties of operators on a very general class of weighted Fock spaces over $\\C$. In particular, we obtain rather strong necessary and sufficient conditions for a wide class of operators (which includes operators in the Toeplitz algebra generated by bounded symbols) to be compact and we obtain related estimates on the essential norm of such operators. Finally, we discuss interesting open problems related to our results, and in particular discuss the possibility of extending our results to other generally weighted Bergman spaces on the unit ball of $\\C$.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2020-06-16 00:00:00.000000"},
{"id":"838","title":"Two often court understand someone mean.","abstract":"Although for large area detectors it is crucial to find an alternative to detect thermal neutrons because of the 3He shortage, this is not the case for small area detectors. Neutron scattering science is still growing its instruments' power and the neutron flux a detector must tolerate is increasing. For small area detectors the main effort is to expand the detectors' performances. At Institut Laue-Langevin (ILL) we developed the Multi-Blade detector which wants to increase the spatial resolution of 3He-based detectors for high flux applications. We developed a high spatial resolution prototype suitable for neutron reflectometry instruments. It exploits solid 10B-films employed in a proportional gas chamber. Two prototypes have been constructed at ILL and the results obtained on our monochromatic test beam line are presented here.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2016-04-04 00:00:00.000000"},
{"id":"839","title":"Past prevent player lawyer include.","abstract":"In recent years, ideas from statistics and scientific computing have begun to interact in increasingly sophisticated and fruitful ways with ideas from computer science and the theory of algorithms to aid in the development of improved worst-case algorithms that are useful for large-scale scientific and Internet data analysis problems. In this chapter, I will describe two recent examples---one having to do with selecting good columns or features from a (DNA Single Nucleotide Polymorphism) data matrix, and the other having to do with selecting good clusters or communities from a data graph (representing a social or information network)---that drew on ideas from both areas and that may serve as a model for exploiting complementary algorithmic and statistical perspectives in order to solve applied large-scale data analysis problems.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2016-03-18 00:00:00.000000"},
{"id":"840","title":"Job set position.","abstract":"The rapid growth of content distribution on the Internet has brought with it proportional increases in the costs of distributing content. Adding to distribution costs is the fact that digital content is easily duplicable, and hence can be shared in an illicit peer-to-peer (P2P) manner that generates no revenue for the content provider. In this paper, we study whether the content provider can recover lost revenue through a more innovative approach to distribution. In particular, we evaluate the benefits of a hybrid revenue-sharing system that combines a legitimate P2P swarm and a centralized client-server approach. We show how the revenue recovered by the content provider using a server-supported legitimate P2P swarm can exceed that of the monopolistic scheme by an order of magnitude. Our analytical results are obtained in a fluid model, and supported by stochastic simulations.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2022-07-30 00:00:00.000000"},
{"id":"841","title":"Bad case but sure defense.","abstract":"We establish asymptotic formulas for the determinants of finite Toeplitz + Hankel matrices of size N, as N goes to infinity for singular generating functions defined on the unit circle in the special case where the generating function is even, i.e., where the Toeplitz + Hankel matrices are symmetric.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2022-09-08 00:00:00.000000"},
{"id":"842","title":"Population daughter century cultural his throughout.","abstract":"Genetic association study is an essential step to discover genetic factors that are associated with a complex trait of interest. In this paper we present a novel generalized quasi-likelihood score (GQLS) test that is suitable for a study with either a quantitative trait or a binary trait. We use a logistic regression model to link the phenotypic value of the trait to the distribution of allelic frequencies. In our model, the allele frequencies are treated as a response and the trait is treated as a covariate that allows us to leave the distribution of the trait values unspecified. Simulation studies indicate that our method is generally more powerful in comparison with the family-based association test (FBAT) and controls the type I error at the desired levels. We apply our method to analyze data on Holstein cattle for an estimated breeding value phenotype, and to analyze data from the Collaborative Study of the Genetics of Alcoholism for alcohol dependence. The results show a good portion of significant SNPs and regions consistent with previous reports in the literature, and also reveal new significant SNPs and regions that are associated with the complex trait of interest.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2016-12-09 00:00:00.000000"},
{"id":"843","title":"Song detail use risk activity election ground security.","abstract":"Equivalence testing is of emerging importance in genomics studies but has hitherto been little studied in this content. In this paper, we define the notion of equivalence of gene expression and determine a `strength of evidence' measure for gene equivalence. It is common practice in genome-wide studies to rank genes according to observed gene-specific P-values or adjusted P-values, which are assumed to measure the strength of evidence against the null hypothesis of no differential gene expression. We show here, both empirically and formally, that the equivalence P-value does not satisfy the basic consistency requirements for a valid strength of evidence measure for equivalence. This means that the widely-used q-value (Storey, 2002) defined for each gene to be the minimum positive false discovery rate that would result in the inclusion of the corresponding P-value in the discovery set, cannot be translated to the equivalence testing framework. However, when represented as a posterior probability, we find that the q-value does satisfy some basic consistency requirements needed to be a credible measure of evidence for equivalence. We propose a simple estimate for the q-value from posterior probabilities of equivalence, and analyse data from a mouse stem cell microarray experiment which demonstrate the theory and methods presented here.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2015-06-27 00:00:00.000000"},
{"id":"844","title":"Attention head nearly.","abstract":"Let $f\\colon(R,\\mathfrak{m})\\rightarrow S$ be a local homomorphism of Noetherian local rings. Consider two endomorphisms \\textit{of finite length} (i.e., with zero-dimensional closed fibers) $\\varphi\\colon R\\rightarrow R$ and $\\psi\\colon S\\rightarrow S$, satisfying $\\psi\\circ f=f\\circ\\varphi$. Then $\\psi$ induces a finite length endomorphism $\\overline{\\psi}\\colon S\/f(\\mathfrak{m})S\\rightarrow S\/f(\\mathfrak{m})S$. When $f$ is flat, under the assumption that $S$ is Cohen-Macaulay we prove an additivity formula: $h_{\\mathrm{loc}}(\\psi)=h_{\\mathrm{loc}}(\\varphi)+h_{\\mathrm{loc}}(\\overline{\\psi})$ for \\textit{local entropy}.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2019-03-13 00:00:00.000000"},
{"id":"845","title":"Send indicate field.","abstract":"Molecular dynamics has been widely used to numerically solve equation of motion of classical many-particle system. It can be used to simulate many systems including biophysics, whose complexity level is determined by the involved elements. Based on this method, a numerical model had been constructed to mimic the behaviour of malaria-infected red blood cells within capillary vessel. The model was governed by three forces namely Coulomb force, normal force, and Stokes force. By utilizing two dimensional four-cells scheme, theoretical observation was carried out to test its capability. Although the parameters were chosen deliberately, all of the quantities were given arbitrary value. Despite this fact, the results were quite satisfactory. Combined with the previous results, it can be said that the proposed model were sufficient enough to mimic the malaria-infected red blood cells motion within obstructed capillary vessel.   Keywords: molecular dynamics, two-dimensional model, red-blood cell motion, malaria","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2019-05-07 00:00:00.000000"},
{"id":"846","title":"Range until sing forward build writer information.","abstract":"The Washigton Post had published allegations, that results of Russian elections \"violate Gauss's groundbreaking work on statistics.\" I show that these allegations lack scientific basis.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2022-03-15 00:00:00.000000"},
{"id":"847","title":"Personal think none.","abstract":"More than 4 orders of magnitude of cavity-linewidth narrowing in a rare-earth-ion-doped crystal cavity, emanating from strong intracavity dispersion caused by off-resonant interaction with dopant ions, is demonstrated. The dispersion profiles are engineered using optical pumping techniques creating significant semipermanent but reprogrammable changes of the rare-earth absorption profiles. Several cavity modes are shown within the spectral transmission window. Several possible applications of this phenomenon are discussed.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2021-07-28 00:00:00.000000"},
{"id":"848","title":"Successful successful side central decide.","abstract":"In the above paper an analysis has been carried out to obtain results in the Couette flow of a Newtonian fluid with viscous dissipation and temperature dependent viscosity. The fluid viscosity is an exponential function of temperature. Exact analytical solutions are obtained for the calculation of velocity and temperature. However, there are some fundamental errors in this paper which are presented herein.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2019-07-16 00:00:00.000000"},
{"id":"849","title":"War direction top teacher class.","abstract":"With the right choice of sensor, a `simple' pendulum has great potential as a seismometer with superior low frequency sensitivity.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2019-02-14 00:00:00.000000"},
{"id":"850","title":"Behind probably heavy pay you local reveal.","abstract":"An efficient implementation of the Polya-Aeppli, or geometirc compound Poisson, distribution in the statistical programming language R is presented. The implementation is available as the package polyaAeppli and consists of functions for the mass function, cumulative distribution function, quantile function and random variate generation with those parameters conventionally provided for standard univatiate probability distributions in the stats package in R","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2021-01-04 00:00:00.000000"},
{"id":"851","title":"Knowledge claim mention almost lead job opportunity.","abstract":"The Hopf order of an element $h$ of a Hopf algebra $H$ is the least $n$ such that the $n$-th Hopf power of $h$ is trivial. For some bismash product Hopf algebras obtained from factorizable groups (including Drinfeld doubles of some groups) we compute the dimensions of the spaces of elements with trivial $n$-th Hopf powers, and determine which Hopf orders of elements are possible. We discuss the behavior under twists and duality.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2017-01-03 00:00:00.000000"},
{"id":"852","title":"Occur traditional inside never buy.","abstract":"Trustworthiness especially for service oriented system is very important topic now a day in IT field of the whole world. Certain Trust Model depends on some certain values given by experts and developers. Here, main parameters for calculating trust are certainty and average rating. In this paper we have proposed an Extension of Certain Trust Model, mainly the representation portion based on probabilistic logic and fuzzy logic. This extended model can be applied in a system like cloud computing, internet, website, e-commerce, etc. to ensure trustworthiness of these platforms. The model uses the concept of fuzzy logic to add fuzziness with certainty and average rating to calculate the trustworthiness of a system more accurately. We have proposed two new parameters - trust T and behavioral probability P, which will help both the users and the developers of the system to understand its present condition easily. The linguistic variables are defined for both T and P and then these variables are implemented in our laboratory to verify the proposed trust model. We represent the trustworthiness of test system for two cases of evidence value using Fuzzy Associative Memory (FAM). We use inference rules and defuzzification method for verifying the model.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2018-11-08 00:00:00.000000"},
{"id":"853","title":"Blood admit instead control woman computer.","abstract":"In recent work on the representation theory of vertex algebras related to the Virasoro minimal models M(2,p), Adamovic and Milas discovered logarithmic analogues of (special cases of) the famous Dyson and Morris constant term identities. In this paper we show how the identities of Adamovic and Milas arise naturally by differentiating as-yet-conjectural complex analogues of the constant term identities of Dyson and Morris. We also discuss the existence of complex and logarithmic constant term identities for arbitrary root systems, and in particular prove complex and logarithmic constant term identities for the root system G_2.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2017-03-05 00:00:00.000000"},
{"id":"854","title":"Run ten seek tell reveal.","abstract":"In case of the heat flow on the free loop space of a closed Riemannian manifold non-triviality of Morse homology for semi-flows is established by constructing a natural isomorphism to singular homology of the loop space. The construction is also new in finite dimensions. The main idea is to build a Morse filtration using Conley pairs and their pre-images under the time-$T$-map of the heat flow. A crucial step is to contract each Conley pair onto its part in the unstable manifold. To achieve this we construct stable foliations for Conley pairs using the recently found backward $\\lambda$-Lemma [31]. These foliations are of independent interest [23].","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2015-04-16 00:00:00.000000"},
{"id":"855","title":"Cultural prevent least however hard water water.","abstract":"We continue studying the properties of $\\gamma_0$-compact, $\\gamma^*$-regular and $\\gamma$-normal spaces defined in [5]. We also define and discuss $\\gamma$-locally compact spaces.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2022-08-08 00:00:00.000000"},
{"id":"856","title":"Economic cell ball approach than.","abstract":"We characterize the analytic self-maps $\\phi$ of the unit disk ${\\Bbb D}$ in ${\\Bbb C}$ that induce continuous composition operators $C_\\phi$ from the log-Bloch space $\\mathcal{B}^{\\log}({\\Bbb D})$ to $\\mu$-Bloch spaces ${\\mathcal B}^\\mu({\\Bbb D})$ in terms of the sequence of quotients of the $\\mu$-Bloch semi-norm of the $n$th power of $\\phi$ and the log-Bloch semi-norm (norm) of the $n$th power $F_n$ of the identity function on ${\\Bbb D}$, where $\\mu:{\\Bbb D}\\rightarrow (0,\\infty)$ is continuous and bounded. We also obtain an expression that is equivalent to the essential norm of $C_\\phi$ between these spaces, thus characterizing $\\phi$ such that $C_\\phi$ is compact. After finding a pairwise norm equivalent family of log-Bloch type spaces that are defined on the unit ball ${\\Bbb B}_n$ of ${\\Bbb C}^n$ and include the log-Bloch space, we obtain an extension of our boundedness\/compactness\/essential norm results for $C_\\phi$ acting on ${\\mathcal B}^{\\log}$ to the case when $C_\\phi$ acts on these more general log-Bloch-type spaces.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2019-05-13 00:00:00.000000"},
{"id":"857","title":"Sense generation also could international doctor rate.","abstract":"We give new lower asymptotical estimate of constant \\[ C_n=\\sup\\biggl\\{\\frac{\\|t_n\\|_{C(\\mathbb T)}}{\\|t_n\\|_{L(\\mathbb T)}}:t_n\\text{are real trigonometric polynomials}, \\operatorname{deg}t_n<n\\biggr\\} \\] as $n\\to\\infty$. This estimate improves known bound of L.V.Taykov (1965).","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2017-04-05 00:00:00.000000"},
{"id":"858","title":"Property me house easy blood voice shoulder.","abstract":"Correlated ordinal data are often assumed to arise from an underlying latent continuous parametric distribution, with covariate effects which enter linearly. We introduce a Bayesian nonparametric regression model for univariate and multivariate ordinal responses, making no assumptions of linearity or additivity in the covariate effects, by modeling the covariates jointly with the latent responses. In standard parametric models, computational challenges arise from identifiability constraints and estimation of parameters requiring nonstandard inferential techniques. The nonparametric model is able to achieve flexible inference, while avoiding these difficulties. The utility of the modeling approach is illustrated through application to two real data sets from econometrics, as well as an ozone concentration example and a multirater agreement problem.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2020-06-09 00:00:00.000000"},
{"id":"859","title":"Write manage who the question.","abstract":"We study sparse principal components analysis in high dimensions, where $p$ (the number of variables) can be much larger than $n$ (the number of observations), and analyze the problem of estimating the subspace spanned by the principal eigenvectors of the population covariance matrix. We introduce two complementary notions of $\\ell_q$ subspace sparsity: row sparsity and column sparsity. We prove nonasymptotic lower and upper bounds on the minimax subspace estimation error for $0\\leq q\\leq1$. The bounds are optimal for row sparse subspaces and nearly optimal for column sparse subspaces, they apply to general classes of covariance matrices, and they show that $\\ell_q$ constrained estimates can achieve optimal minimax rates without restrictive spiked covariance conditions. Interestingly, the form of the rates matches known results for sparse regression when the effective noise variance is defined appropriately. Our proof employs a novel variational $\\sin\\Theta$ theorem that may be useful in other regularized spectral estimation problems.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2022-11-03 00:00:00.000000"},
{"id":"860","title":"Performance look court.","abstract":"The paper deals with asymptotic nodal geometry for the Laplace-Beltrami operator on closed surfaces. Given an eigenfunction f corresponding to a large eigenvalue, we study local asymmetry of the distribution of sign(f) with respect to the surface area. It is measured as follows: take any disc centered at the nodal line {f=0}, and pick at random a point in this disc. What is the probability that the function assumes a positive value at the chosen point? We show that this quantity may decay logarithmically as the eigenvalue goes to infinity, but never faster than that. In other words, only a mild local asymmetry may appear. The proof combines methods due to Donnelly-Fefferman and Nadirashvili with a new result on harmonic functions in the unit disc.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2016-10-22 00:00:00.000000"},
{"id":"861","title":"Because policy president color.","abstract":"This paper constitutes a background to the paper 'Quantum mechanics as \"space-time statistical mechanics\"?', arXiv:quant-ph\/0501133, presented previously by the author. But it is also a free-standing and self-contained paper. The purpose of this paper is to give the reader an increased and a deeper understanding of the special theory of relativity, and the spacetime ideas lying behind the above mentioned paper. We will here consider, discuss, define, analyse, and explain things such as, e.g., the constancy of the speed of light, synchronization, simultaneity, absolute simultaneity, absolute space and time, the ether, and spacetime. Albert Einstein's original version of the special theory of relativity is fundamentally an operational theory, free from interpretation. But the old \"Lorentzian interpretation\" and the standard \"spacetime interpretation\" of the special theory of relativity will also be considered. This paper also discusses and analyses aspects of the philosophy of science that in my opinion are relevant for an understanding of the special theory of relativity.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2018-03-19 00:00:00.000000"},
{"id":"862","title":"Central us identify last discover among art.","abstract":"We introduce in this paper an algorithm named Contextuel-E-Greedy that tackles the dynamicity of the user's content. It is based on dynamic exploration\/exploitation tradeoff and can adaptively balance the two aspects by deciding which situation is most relevant for exploration or exploitation. The experimental results demonstrate that our algorithm outperforms surveyed algorithms.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2017-06-10 00:00:00.000000"},
{"id":"863","title":"Politics voice staff type.","abstract":"Chevalley's theorem states that for any simple finite dimensional Lie algebra G (1) the restriction homomorphism of the algebra of polynomials on G onto the Cartan subalgebra H induces an isomorphism between the algebra of G-invariant polynomials on G with the algebra of W-invariant polynomals on H, where W is the Weyl group of G, (2) each G-invariant polynomial is a linear combination of the powers of traces tr r(x), where r is a finite dimensional representation of G.   None of these facts is necessarily true for simple Lie superalgebras. We reformulate Chevalley's theorem so as to embrace Lie superalgebras.   Chevalley's theorem for anti-invariant polynomials is also given.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2021-04-07 00:00:00.000000"},
{"id":"864","title":"Generation arrive if wear.","abstract":"In this paper, we attempt to revisit the problem of multi-party conferencing from a practical perspective, and to rethink the design space involved in this problem. We believe that an emphasis on low end-to-end delays between any two parties in the conference is a must, and the source sending rate in a session should adapt to bandwidth availability and congestion. We present Celerity, a multi-party conferencing solution specifically designed to achieve our objectives. It is entirely Peer-to-Peer (P2P), and as such eliminating the cost of maintaining centrally administered servers. It is designed to deliver video with low end-to-end delays, at quality levels commensurate with available network resources over arbitrary network topologies where bottlenecks can be anywhere in the network. This is in contrast to commonly assumed P2P scenarios where bandwidth bottlenecks reside only at the edge of the network. The highlight in our design is a distributed and adaptive rate control protocol, that can discover and adapt to arbitrary topologies and network conditions quickly, converging to efficient link rate allocations allowed by the underlying network. In accordance with adaptive link rate control, source video encoding rates are also dynamically controlled to optimize video quality in arbitrary and unpredictable network conditions. We have implemented Celerity in a prototype system, and demonstrate its superior performance over existing solutions in a local experimental testbed and over the Internet.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2019-06-09 00:00:00.000000"},
{"id":"865","title":"Everyone serious even how concern study similar.","abstract":"This paper contains the constructions of a real manifold version of relative K-theory, and of an extension of Karoubi's multiplicative K-theory suggested by U. Bunke (which I call ``free multiplicative K-theory'' in the sequel). Chern-Simons-Nadel type classes on relative K-theory are constructed, while it is proved that on free multiplicative K-theory, there is a notion of Chern-Weil character form, and of a Borel-type characteristic class (which is a differential form modulo exact forms) which recovers the classes $c_k$ of flat vector bundles studied by Bismut and Lott. Finally, a direct image for relative K-theory under proper submersion of compact orientable real manifolds is constructed.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2021-10-21 00:00:00.000000"},
{"id":"866","title":"Page check first father less.","abstract":"We develop an effective nonhierarchical data clustering method using an analogy to the dynamic coarse graining of a stochastic system. Analyzing the eigensystem of an interitem transition matrix identifies fuzzy clusters corresponding to the metastable macroscopic states (macrostates) of a diffusive system. A \"minimum uncertainty criterion\" determines the linear transformation from eigenvectors to cluster-defining window functions. Eigenspectrum gap and cluster certainty conditions identify the proper number of clusters. The physically motivated fuzzy representation and associated uncertainty analysis distinguishes macrostate clustering from spectral partitioning methods. Macrostate data clustering solves a variety of test cases that challenge other methods.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2021-06-02 00:00:00.000000"},
{"id":"867","title":"Pay religious big possible determine.","abstract":"Interfacial electron transfer (IET) dynamics in 1,1'-dioctadecyl-3, 3, 3', 3'-tetramethylindodicarbocyanine (DiD) dye molecules \/ indium tin oxide (ITO) film system have been probed at the ensemble and single-molecule level by recording the change of fluorescence emission intensity. By comparing the difference of the external electric current (EEC) dependence of lifetime and intensity for enambles and single molecules, it is shown that the single-molecule probe can effcienly demonstrate the IET dynamics. The backward electron transfer and electron transfer of ground state induce the single molecules fluorescence quenching when an EEC is applied to ITO film.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2020-06-23 00:00:00.000000"},
{"id":"868","title":"Same against clearly particularly save experience daughter.","abstract":"Because of the importance of object oriented methodologies, the research in developing new measure for object oriented system development is getting increased focus. The most of the metrics need to find the interactions between the objects and modules for developing necessary metric and an influential software measure that is attracting the software developers, designers and researchers. In this paper a new interactions are defined for object oriented system. Using these interactions, a parser is developed to analyze the existing architecture of the software. Within the design model, it is necessary for design classes to collaborate with one another. However, collaboration should be kept to an acceptable minimum i.e. better designing practice will introduce low coupling. If a design model is highly coupled, the system is difficult to implement, to test and to maintain overtime. In case of enhancing software, we need to introduce or remove module and in that case coupling is the most important factor to be considered because unnecessary coupling may make the system unstable and may cause reduction in the system's performance. So coupling is thought to be a desirable goal in software construction, leading to better values for external software qualities such as maintainability, reusability and so on. To test this hypothesis, a good measure of class coupling is needed. In this paper, based on the developed tool called Design Analyzer we propose a methodology to reuse an existing system with the objective of enhancing an existing Object oriented system keeping the coupling as low as possible.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2018-06-08 00:00:00.000000"},
{"id":"869","title":"Born public skill special hour.","abstract":"Wireless sensor networks benefit from communication protocols that reduce power requirements by avoiding frame collision. Time Division Media Access methods schedule transmission in slots to avoid collision, however these methods often lack scalability when implemented in \\emph{ad hoc} networks subject to node failures and dynamic topology. This paper reports a distributed algorithm for TDMA slot assignment that is self-stabilizing to transient faults and dynamic topology change. The expected local convergence time is O(1) for any size network satisfying a constant bound on the size of a node neighborhood.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2022-07-05 00:00:00.000000"},
{"id":"870","title":"General area argue traditional wait ask pull still.","abstract":"This note presents some representative methods which are based on dictionary learning (DL) for classification. We do not review the sophisticated methods or frameworks that involve DL for classification, such as online DL and spatial pyramid matching (SPM), but rather, we concentrate on the direct DL-based classification methods. Here, the \"so-called direct DL-based method\" is the approach directly deals with DL framework by adding some meaningful penalty terms. By listing some representative methods, we can roughly divide them into two categories, i.e. (1) directly making the dictionary discriminative and (2) forcing the sparse coefficients discriminative to push the discrimination power of the dictionary. From this taxonomy, we can expect some extensions of them as future researches.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2018-01-05 00:00:00.000000"},
{"id":"871","title":"Talk candidate reach threat.","abstract":"We investigate nonlinear Kerr-induced coherence effect on a superluminal probing light pulse in a gain-assisted N-type 4-level atomic system via an intense monochromatic laser field. The dispersion exhibits a novel, interesting and useful two-paired double gain lines processes. The system displays lossless characteristics similar to [L. J. Wang, A. Kuzmich, A. Dogariu, Nature \\textbf{406}, 277 (2000)] but with advantages of \\emph{multiple} \\textbf{controllable} anomalous regions, \\emph{significantly enhanced} superluminal behavior and \\textbf{relaxed} temperature, states of matter regardless of its isotropic or anisotropic conditions. Unlike the instability in [A. M. Akulshin, S. Barreiro, and A. Lezama, Phys. Rev. Lett. \\textbf{82}, 4277 (1999)], the present system also \\emph{overcomes the instable-limit} by the Kerr-induced coherence effect in the system. Indeed, the coherence enhances the group velocity remarkably by at least $-30 ms$ more than of an instable Kerr-free system with almost negligible distortion in the retrieved pulse.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2020-01-09 00:00:00.000000"},
{"id":"872","title":"Pm president mean beyond something.","abstract":"Bandwidth-starved multicore chips have become ubiquitous. It is well known that the performance of stencil codes can be improved by temporal blocking, lessening the pressure on the memory interface. We introduce a new pipelined approach that makes explicit use of shared caches in multicore environments and minimizes synchronization and boundary overhead. Benchmark results are presented for three current x86-based microprocessors, showing clearly that our optimization works best on designs with high-speed shared caches and low memory bandwidth per core. We furthermore demonstrate that simple bandwidth-based performance models are inaccurate for this kind of algorithm and employ a more elaborate, synthetic modeling procedure. Finally we show that temporal blocking can be employed successfully in a hybrid shared\/distributed-memory environment, albeit with limited benefit at strong scaling.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2019-06-08 00:00:00.000000"},
{"id":"873","title":"Situation that analysis husband reach somebody note stand.","abstract":"Template-based signal detection most often relies on computing a correlation, or a dot product, between an incoming data stream and a signal template. While such a correlation results in an ongoing estimate of the magnitude of the signal in the data stream, it does not directly indicate the presence or absence of a signal. Instead, the problem of signal detection is one of model-selection. Here we explore the use of the Bayesian odds-ratio (OR), which is the ratio of posterior probabilities of a signal-plus-noise model over a noise-only model. We demonstrate this method by applying it to simulated electroencephalographic (EEG) signals based on the P300 response, which is widely used in both Brain Computer Interface (BCI) and Brain Machine Interface (BMI) systems. The efficacy of this algorithm is demonstrated by comparing the receiver operating characteristic (ROC) curves of the OR-based (logOR) filter to the usual correlation method where we find a significant improvement in P300 detection. The logOR filter promises to improve the accuracy and speed of the detection of evoked brain responses in BCI\/BMI applications as well the detection of template signals in general.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2019-08-01 00:00:00.000000"},
{"id":"874","title":"Not establish election their.","abstract":"Using an l = 1 blazed fork-hologram at the focal plane of the Asiago 122 cm telescope, we obtained optical vortices from the stellar system Rasalgethi (alpha Herculis) and from the single star Arcturus (alpha Bootis). We have analyzed the structure of the optical vortices obtained from non-monochromatic starlight under very poor seeing conditions using a fast CCD camera to obtain speckle patterns and carry out the lucky imaging technique, alternative to adaptive optics. With the insertion of a red filter and of a Lyot stop we performed l = 1 optical vortex coronography the double star HD74010. The results are in agreement with theory and numerical simulations. Our results open the way to applications of optical vortices to ground based astronomical observations, in particular for coronagraphy with l > 1 masks. No intrinsic orbital angular momentum was detected in the starlight.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2021-09-04 00:00:00.000000"},
{"id":"875","title":"Sport six pattern suggest worker off significant.","abstract":"In a recent paper by Menzel et al. (Opt. Exp. 22, 9971 (2014)), its authors analyze the spectral red-shift effect of plasmonic resonances of metallic nano-antennas between the far-field and near-field regimes. Here, we demonstrate that their interpretation of this effect is done under the same perspective as one recently reported in Langmuir 29, 6715 (2013); however, the former is incomplete and needs some remarks and clarifications which require additional relevant concepts and arguments of physical significance.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2019-01-18 00:00:00.000000"},
{"id":"876","title":"State oil example without decide law.","abstract":"The theoretical base of the research of occupational injuries is the idea of the process as Markov chain of random variables. However the exact proof of this position was not carried out whereas the experimental passing of the hypothesis is connected always with the determined confidence limits and consequently it gives the space for alternative assumptions. In this research some databases of occupational injuries had been studied using spectral analysis techniques and the presentation of the occupational injuries as the temporal sequence of the cases (\"telegraph wave\" process type). Databases had corresponding chapters such as \"enterprise\" with number of employees about 7000, \"big enterprise\" (the number of employees about 35000), \"whole branch of industry\", \"whole enterprises of industrial region\" receiving during 10 years from different countries having distinguish system of the work organization (Russia and Italy). The behaviour of spectra on principal is not changed when vary the length of realization, resolution, smoothing, upper boundary frequency, country and year of datas. All spectra showed that the occupational injuries process has a not Markov, but deterministic polyharmonic behaviour. This phenomenon is characterized by the spectral lines with two frequencies corresponding 24 hours (circadian rythm have main amplitude) and 7 days (amplitude is two times smaller) exactly. Harmonics corresponding one month (biorythms) were not founded. The task of the futher investigations is to find the psychophysiological and biomedical processes determined and having high level of correlation with the occupational injuries process.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2022-11-25 00:00:00.000000"},
{"id":"877","title":"Firm draw perform since.","abstract":"A great variety of static analyses that compute safety properties of single-thread programs have now been developed. This paper presents a systematic method to extend a class of such static analyses, so that they handle programs with multiple POSIX-style threads. Starting from a pragmatic operational semantics, we build a denotational semantics that expresses reasoning a la assume-guarantee. The final algorithm is then derived by abstract interpretation. It analyses each thread in turn, propagating interferences between threads, in addition to other semantic information. The combinatorial explosion, ensued from the explicit consideration of all interleavings, is thus avoided. The worst case complexity is only increased by a factor n compared to the single-thread case, where n is the number of instructions in the program. We have implemented prototype tools, demonstrating the practicality of the approach.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2019-06-12 00:00:00.000000"},
{"id":"878","title":"Wife either run little.","abstract":"We show how to prepare a single molecular ion in a specific internal quantum state in a situation where the molecule is trapped and sympathetically cooled by an atomic ion and where its internal degrees of freedom are initially in thermal equilibrium with the surroundings. The scheme is based on conditional creation of correlation between the internal state of the molecule and the translational state of the collective motion of the two ions, followed by a projection measurement of this collective mode by atomic ion shelving techniques. State preparation in a large number of internal states is possible.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2022-04-01 00:00:00.000000"},
{"id":"879","title":"That job meet accept current follow.","abstract":"Several users of our AS relationship inference data (http:\/\/www.caida.org\/data\/active\/as-relationships\/), released with cs\/0604017, asked us why it contained AS relationship cycles, e.g., cases where AS A is a provider of AS B, B is a provider of C, and C is a provider of A, or other cycle types. Having been answering these questions in private communications, we have eventually decided to write down our answers here for future reference.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2015-03-06 00:00:00.000000"},
{"id":"880","title":"Indicate today very poor recent finish fly.","abstract":"We study the acceleration and collisions of rigid bodies in special relativity. After a brief historical review, we give a physical definition of the term `rigid body' in relativistic straight line motion. We show that the definition of `rigid body' in relativity differs from the usual classical definition, so there is no difficulty in dealing with rigid bodies in relativistic motion. We then describe: 1. The motion of a rigid body undergoing constant acceleration to a given velocity. 2. The acceleration of a rigid body due to an applied impulse. 3. Collisions between rigid bodies.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2015-01-05 00:00:00.000000"},
{"id":"881","title":"Fast also major concern child art.","abstract":"Automated synthesis of reactive control protocols from temporal logic specifications has recently attracted considerable attention in various applications in, for example, robotic motion planning, network management, and hardware design. An implicit and often unrealistic assumption in this past work is the availability of complete and precise sensing information during the execution of the controllers. In this paper, we use an abstraction procedure for systems with partial observation and propose a formalism to investigate effects of limitations in sensing. The abstraction procedure enables the existing synthesis methods with partial observation to be applicable and efficient for systems with infinite (or finite but large number of) states. This formalism enables us to systematically discover sensing modalities necessary in order to render the underlying synthesis problems feasible. We use counterexamples, which witness unrealizability potentially due to the limitations in sensing and the coarseness in the abstract system, and interpolation-based techniques to refine the model and the sensing modalities, i.e., to identify new sensors to be included, in such synthesis problems. We demonstrate the method on examples from robotic motion planning.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2019-09-26 00:00:00.000000"},
{"id":"882","title":"Note still upon appear.","abstract":"A saturated D-optimal design is a {+1,-1} square matrix of given order with maximal determinant. We search for saturated D-optimal designs of orders 19 and 37, and find that known matrices due to Smith, Cohn, Orrick and Solomon are optimal. For order 19 we find all inequivalent saturated D-optimal designs with maximal determinant, 2^30 x 7^2 x 17, and confirm that the three known designs comprise a complete set. For order 37 we prove that the maximal determinant is 2^39 x 3^36, and find a sample of inequivalent saturated D-optimal designs. Our method is an extension of that used by Orrick to resolve the previously smallest unknown order of 15; and by Chadjipantelis, Kounias and Moyssiadis to resolve orders 17 and 21. The method is a two-step computation which first searches for candidate Gram matrices and then attempts to decompose them. Using a similar method, we also find the complete spectrum of determinant values for {+1,-1} matrices of order 13.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2017-12-13 00:00:00.000000"},
{"id":"883","title":"Painting southern film well.","abstract":"We perform a gauge-transformation on the time-dependent Dirac equation describing the evolution of an electron in a heavy-ion collision to remove the explicit dependence on the long-range part of the interaction. We solve, in an ultra-relativistic limit, the gauged-transformed Dirac equation using light-front variables and a light-fronts representation, obtaining non-perturbative results for the free pair-creation amplitudes in the collider frame. Our result reproduces the result of second-order perturbation theory in the small charge limit while non-perturbative effects arise for realistic charges of the ions.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2016-03-30 00:00:00.000000"},
{"id":"884","title":"Seem miss everything show foreign.","abstract":"Rejoinder to \"Citation Statistics\" [arXiv:0910.3529]","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2019-03-25 00:00:00.000000"},
{"id":"885","title":"Visit reflect grow here ever away middle view.","abstract":"The theory of the basic statistical concept of (Lehmann-Scheff\\'e-)completeness is perfected by providing the theorem indicated in the title and previously overlooked for several decades. Relations to earlier results are discussed and illustrating examples are presented.   Of the two proofs offered for the main result, the first is direct and short, following the prototypical example of Landers and Rogge (1976), and the second is very short and purely statistical, utilizing the basic theory of optimal unbiased estimation in the little known version completed by Schmetterer and Strasser (1974).","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2015-03-18 00:00:00.000000"},
{"id":"886","title":"Benefit second majority director everybody whatever whatever.","abstract":"We present a theoretical study of the emission from a superluminal polarization current whose distribution pattern rotates (with an angular frequency $\\omega$) and oscillates (with a frequency $\\Omega $) at the same time, and which comprises both poloidal and toroidal components. This type of polarization current is found in recent practical machines designed to investigate superluminal emission. We find that the superluminal motion of the distribution pattern of the emitting current generates localized electromagnetic waves that do not decay spherically, i.e. that do not have an intensity diminishing like ${R_P}^{-2}$ with the distance $R_P$ from their source. The nonspherical decay of the focused wave packets that are emitted by the polarization currents does not contravene conservation of energy: the constructive interference of the constituent waves of such propagating caustics takes place within different solid angles on spheres of different radii ($R_P$) centred on the source. For a polarization current whose longitudinal distribution (over an azimuthal interval of length $2\\pi$) consists of $m$ cycles of a sinusoidal wave train, the nonspherically decaying part of the emitted radiation contains the frequencies $\\Omega \\pm m\\omega$; i.e. it contains {\\it only} the frequencies involved in the creation and implementation of the source. This is in contrast to recent studies of the spherically decaying emission, which was shown to contain much higher frequencies. The polarization of the emitted radiation is found to be linear for most configurations of the source.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2018-04-05 00:00:00.000000"},
{"id":"887","title":"North box test effort compare every middle.","abstract":"We study the temporal fluctuations in time-dependent stock prices (both individual and composite) as a stochastic phenomenon using general techniques and methods of nonequilibrium statistical mechanics. In particular, we analyze stock price fluctuations as a non-Markovian stochastic process using the first-passage statistical concepts of persistence and survival. We report the results of empirical measurements of the normalized $q$-order correlation functions $f_q(t)$, survival probability $S(t)$, and persistence probability $P(t)$ for several stock market dynamical sets. We analyze both minute-to-minute and higher frequency stock market recordings (i.e., with the sampling time $\\delta t$ of the order of days). We find that the fluctuating stock price is multifractal and the choice of $\\delta t$ has no effect on the qualitative multifractal behavior displayed by the $1\/q$-dependence of the generalized Hurst exponent $H_q$ associated with the power-law evolution of the correlation function $f_q(t)\\sim t^{H_q}$. The probability $S(t)$ of the stock price remaining above the average up to time $t$ is very sensitive to the total measurement time $t_m$ and the sampling time. The probability $P(t)$ of the stock not returning to the initial value within an interval $t$ has a universal power-law behavior, $P(t)\\sim t^{-\\theta}$, with a persistence exponent $\\theta$ close to 0.5 that agrees with the prediction $\\theta=1-H_2$. The empirical financial stocks also present an interesting feature found in turbulent fluids, the extended self-similarity.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2018-02-07 00:00:00.000000"},
{"id":"888","title":"Only prepare knowledge stock.","abstract":"We determine all the normal subgroups of the group of C^r diffeomorphisms of R^n, r = 1,2,...,infinity, except when r=n+1 or n=4, and also of the group of homeomorphisms of R^n (r=0). We also study the group A_0 of diffeomorphisms of an open manifold M that are isotopic to the identity. If M is the interior of a compact manifold with nonempty boundary, then the quotient of A_0 by the normal subgroup of diffeomorphisms that coincide with the identity near to a given end e of M is simple.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2018-07-22 00:00:00.000000"},
{"id":"889","title":"Activity film matter little former trade.","abstract":"Dedicated to the memory of Edsger W.Dijkstra.   Representation independence or relational parametricity formally characterizes the encapsulation provided by language constructs for data abstraction and justifies reasoning by simulation. Representation independence has been shown for a variety of languages and constructs but not for shared references to mutable state; indeed it fails in general for such languages. This paper formulates representation independence for classes, in an imperative, object-oriented language with pointers, subclassing and dynamic dispatch, class oriented visibility control, recursive types and methods, and a simple form of module. An instance of a class is considered to implement an abstraction using private fields and so-called representation objects. Encapsulation of representation objects is expressed by a restriction, called confinement, on aliasing. Representation independence is proved for programs satisfying the confinement condition. A static analysis is given for confinement that accepts common designs such as the observer and factory patterns. The formalization takes into account not only the usual interface between a client and a class that provides an abstraction but also the interface (often called ``protected'') between the class and its subclasses.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2016-05-17 00:00:00.000000"},
{"id":"890","title":"Because push fill.","abstract":"We first propose a simple mathematical analysis framework for the Enhanced Distributed Channel Access (EDCA) function of the recently ratified IEEE 802.11e standard. Our analysis considers the fact that the distributed random access systems exhibit cyclic behavior. The proposed model is valid for arbitrary assignments of AC-specific Arbitration Interframe Space (AIFS) values and Contention Window (CW) sizes and is the first that considers an arbitrary distribution of active Access Categories (ACs) at the stations. Validating the theoretical results via extensive simulations, we show that the proposed analysis accurately captures the EDCA saturation performance. Next, we propose a framework for multimedia capacity analysis of the EDCA function. We calculate an accurate station- and AC-specific queue utilization ratio by appropriately weighing the service time predictions of the cycle time model for different number of active stations. Based on the calculated queue utilization ratio, we design a simple model-based admission control scheme. We show that the proposed call admission control algorithm maintains satisfactory user-perceived quality for coexisting voice and video connections in an infrastructure BSS and does not present over- or under-admission problems of previously proposed models in the literature.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2017-04-06 00:00:00.000000"},
{"id":"891","title":"Energy parent happy back plant job resource ago.","abstract":"We study a condition on intersections of localizations of a domain at maximal t-ideals. This extends and generalizes earlier work of Gilmer (1967), Gilmer-Heinzer (1968), Olberding (1998), and others for Prufer domains.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2017-08-05 00:00:00.000000"},
{"id":"892","title":"Lawyer partner fill down.","abstract":"Prediction markets provide an efficient means to assess uncertain quantities from forecasters. Traditional and competitive strictly proper scoring rules have been shown to incentivize players to provide truthful probabilistic forecasts. However, we show that when those players can cooperate, these mechanisms can instead discourage them from reporting what they really believe. When players with different beliefs are able to cooperate and form a coalition, these mechanisms admit arbitrage and there is a report that will always pay coalition members more than their truthful forecasts. If the coalition were created by an intermediary, such as a web portal, the intermediary would be guaranteed a profit.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2016-02-10 00:00:00.000000"},
{"id":"893","title":"Just approach place Republican nearly skill.","abstract":"We show that several important resource allocation problems in wireless networks fit within the common framework of Constraint Satisfaction Problems (CSPs). Inspired by the requirements of these applications, where variables are located at distinct network devices that may not be able to communicate but may interfere, we define natural criteria that a CSP solver must possess in order to be practical. We term these algorithms decentralized CSP solvers. The best known CSP solvers were designed for centralized problems and do not meet these criteria. We introduce a stochastic decentralized CSP solver and prove that it will find a solution in almost surely finite time, should one exist, also showing it has many practically desirable properties. We benchmark the algorithm's performance on a well-studied class of CSPs, random k-SAT, illustrating that the time the algorithm takes to find a satisfying assignment is competitive with stochastic centralized solvers on problems with order a thousand variables despite its decentralized nature. We demonstrate the solver's practical utility for the problems that motivated its introduction by using it to find a non-interfering channel allocation for a network formed from data from downtown Manhattan.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2018-08-15 00:00:00.000000"},
{"id":"894","title":"Lose fast political suggest media against common.","abstract":"In a remarkable series of papers beginning in 1956, Charles Stein set the stage for the future development of minimax shrinkage estimators of a multivariate normal mean under quadratic loss. More recently, parallel developments have seen the emergence of minimax shrinkage estimators of multivariate normal predictive densities under Kullback--Leibler risk. We here describe these parallels emphasizing the focus on Bayes procedures and the derivation of the superharmonic conditions for minimaxity as well as further developments of new minimax shrinkage predictive density estimators including multiple shrinkage estimators, empirical Bayes estimators, normal linear model regression estimators and nonparametric regression estimators.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2018-05-11 00:00:00.000000"},
{"id":"895","title":"Yeah one black research on economic.","abstract":"We present an exploration of the rich theoretical connections between several classes of regularized models, network flows, and recent results in submodular function theory. This work unifies key aspects of these problems under a common theory, leading to novel methods for working with several important models of interest in statistics, machine learning and computer vision.   In Part 1, we review the concepts of network flows and submodular function optimization theory foundational to our results. We then examine the connections between network flows and the minimum-norm algorithm from submodular optimization, extending and improving several current results. This leads to a concise representation of the structure of a large class of pairwise regularized models important in machine learning, statistics and computer vision.   In Part 2, we describe the full regularization path of a class of penalized regression problems with dependent variables that includes the graph-guided LASSO and total variation constrained models. This description also motivates a practical algorithm. This allows us to efficiently find the regularization path of the discretized version of TV penalized models. Ultimately, our new algorithms scale up to high-dimensional problems with millions of variables.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2021-06-06 00:00:00.000000"},
{"id":"896","title":"Field loss situation opportunity employee where clear.","abstract":"The thrust benefits of lateral configurations of two-dimensional undulating fish-like bodies are investigated using high-fidelity numerical simulation. The solution of the Navier--Stokes equations is carried out with a viscous vortex particle method. Configurations of tethered pairs of fish arranged side by side are studied by varying the lateral separation distance and relative phase difference. It is shown that, in mirroring symmetry, the fish in the pair augment each other's thrust even at relatively large separations (up to ten body lengths). At small distances, this augmentation is primarily brought about by a peristaltic pumping in the gap between the fish, whereas at larger distances, the thrust is affected by subtle changes in the vortex shedding at the tail due to interactions with the other fish. In cases without symmetric undulation, one fish always draws more benefit from the interaction than the other. Finally, lateral configurations with three fish are studied with mirroring symmetry between neighboring fish. Whereas the center fish draws a net thrust benefit, this comes at the expense of a net drag on the outer two fish. Each adjacent pair in this arrangement is slightly affected by the presence of the third fish.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2018-09-09 00:00:00.000000"},
{"id":"897","title":"Action carry mean help through.","abstract":"The `no-slip' is a fundamental assumption and generally-accepted boundary condition in rheology, tribology and fluid mechanics with strong experimental support. The violations of this condition, however, are widely recognized in many situations, especially in the flow of non-Newtonian fluids. Wall slip could lead to large errors and flow instabilities, such as sharkskin formation and spurt flow, and hence complicates the analysis of fluid systems and introduces serious practical difficulties. In this article, we discuss slip at fluid-solid interface in an attempt to highlight the main issues related to this diverse complex phenomenon and its implications.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2019-09-20 00:00:00.000000"},
{"id":"898","title":"Focus find green however.","abstract":"As mobile devices with positioning capabilities continue to proliferate, data management for so-called trajectory databases that capture the historical movements of populations of moving objects becomes important. This paper considers the querying of such databases for convoys, a convoy being a group of objects that have traveled together for some time. More specifically, this paper formalizes the concept of a convoy query using density-based notions, in order to capture groups of arbitrary extents and shapes. Convoy discovery is relevant for real-life applications in throughput planning of trucks and carpooling of vehicles. Although there has been extensive research on trajectories in the literature, none of this can be applied to retrieve correctly exact convoy result sets. Motivated by this, we develop three efficient algorithms for convoy discovery that adopt the well-known filter-refinement framework. In the filter step, we apply line-simplification techniques on the trajectories and establish distance bounds between the simplified trajectories. This permits efficient convoy discovery over the simplified trajectories without missing any actual convoys. In the refinement step, the candidate convoys are further processed to obtain the actual convoys. Our comprehensive empirical study offers insight into the properties of the paper's proposals and demonstrates that the proposals are effective and efficient on real-world trajectory data.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2020-01-08 00:00:00.000000"},
{"id":"899","title":"The hotel president media such.","abstract":"The duality triads were defined in the preceding paper.(ArXiv: math.GM\/0402260 v 1 Feb. 2004). Notation, enumeration of formulas and references is therefore to be continued hereby. In this paper Fibonomial triangle and further Pascal-like triangles including q-Gaussian one are given explicit interpretation as discrete time dynamical systems as it is the case with all duality triads.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2019-09-07 00:00:00.000000"},
{"id":"900","title":"Memory social successful positive.","abstract":"Although the standard formulations of prediction problems involve fully-observed and noiseless data drawn in an i.i.d. manner, many applications involve noisy and\/or missing data, possibly involving dependence, as well. We study these issues in the context of high-dimensional sparse linear regression, and propose novel estimators for the cases of noisy, missing and\/or dependent data. Many standard approaches to noisy or missing data, such as those using the EM algorithm, lead to optimization problems that are inherently nonconvex, and it is difficult to establish theoretical guarantees on practical algorithms. While our approach also involves optimizing nonconvex programs, we are able to both analyze the statistical error associated with any global optimum, and more surprisingly, to prove that a simple algorithm based on projected gradient descent will converge in polynomial time to a small neighborhood of the set of all global minimizers. On the statistical side, we provide nonasymptotic bounds that hold with high probability for the cases of noisy, missing and\/or dependent data. On the computational side, we prove that under the same types of conditions required for statistical consistency, the projected gradient descent algorithm is guaranteed to converge at a geometric rate to a near-global minimizer. We illustrate these theoretical predictions with simulations, showing close agreement with the predicted scalings.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2020-11-07 00:00:00.000000"},
{"id":"901","title":"Market officer teach person after they.","abstract":"We prove that a Poisson-Newton formula, in a broad sense, is associated to each Dirichlet series with a meromorphic extension to the whole complex plane. These formulas simultaneously generalize the classical Poisson formula and Newton formulas for Newton sums. Classical Poisson formulas in Fourier analysis, classical summation formulas as Euler-McLaurin or Abel-Plana formulas, explicit formulas in number theory and Selberg trace formulas in Riemannian geometry appear as special cases of our general Poisson-Newton formula. We also associate to finite order meromorphic functions general Poisson-Newton formulas that yield many classical integral formulas.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2022-09-14 00:00:00.000000"},
{"id":"902","title":"Morning opportunity prepare story.","abstract":"The term legal research generally refers to the process of identifying and retrieving appropriate information necessary to support legal decision making from past case records. At present, the process is mostly manual, but some traditional technologies such as keyword searching are commonly used to speed the process up. But a keyword search is not a comprehensive search to cater to the requirements of legal research as the search result includes too many false hits in terms of irrelevant case records. Hence the present generic tools cannot be used to automate legal research.   This paper presents a framework which was developed by combining several Text Mining techniques to automate the process overcoming the difficulties in the existing methods. Further, the research also identifies the possible enhancements that could be done to enhance the effectiveness of the framework.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2017-03-09 00:00:00.000000"},
{"id":"903","title":"Hard stuff network itself short seven pay clearly.","abstract":"A new musical scale devised by the author, based on natural logarithms, is described. Most of the logarithmic pitches bear no correspondence to the twelve tones of the ancient tuning system attributed to Pythagoras, based on ratios of whole numbers, nor to the chromatic tones of scales in equal temperament used widely in the modern era. Logarithms obey a special arithmetic compared to whole and rational numbers, which can be heard in beat frequencies between tones of the scale, suggesting extended harmonic possibilities by incorporating the beat frequencies into compositions. The author uses the broad term \"non-Pythagorean\" to describe the logarithmic musical scale, as the ratios of pitches are usually irrational numbers.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2018-10-17 00:00:00.000000"},
{"id":"904","title":"Together get commercial clearly too travel.","abstract":"In this paper, we give a survey of results obtained recently by the present authors on real-variable characterizations of Bergman spaces, which are closely related to maximal and area integral functions in terms of the Bergman metric. In particular, we give a new proof of those results concerning area integral characterizations through using the method of vector-valued Calder\\'{o}n-Zygmund operators to handle Bergman singular integral operators on the complex ball. The proofs involve some sharp estimates of the Bergman kernel function and Bergman metric.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2017-07-15 00:00:00.000000"},
{"id":"905","title":"Sing base information.","abstract":"Nonnegative Matrix Factorization (NMF) is a widely used technique in many applications such as face recognition, motion segmentation, etc. It approximates the nonnegative data in an original high dimensional space with a linear representation in a low dimensional space by using the product of two nonnegative matrices. In many applications data are often partially corrupted with large additive noise. When the positions of noise are known, some existing variants of NMF can be applied by treating these corrupted entries as missing values. However, the positions are often unknown in many real world applications, which prevents the usage of traditional NMF or other existing variants of NMF. This paper proposes a Robust Nonnegative Matrix Factorization (RobustNMF) algorithm that explicitly models the partial corruption as large additive noise without requiring the information of positions of noise. In practice, large additive noise can be used to model outliers. In particular, the proposed method jointly approximates the clean data matrix with the product of two nonnegative matrices and estimates the positions and values of outliers\/noise. An efficient iterative optimization algorithm with a solid theoretical justification has been proposed to learn the desired matrix factorization. Experimental results demonstrate the advantages of the proposed algorithm.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2020-04-22 00:00:00.000000"},
{"id":"906","title":"Speech model its lose before audience according.","abstract":"We introduce a class of k-potential submanifolds in pseudo-Euclidean spaces and prove that for an arbitrary positive integer k and an arbitrary nonnegative integer p, each N-dimensional Frobenius manifold can always be locally realized as an N-dimensional k-potential submanifold in ((k + 1) N + p)-dimensional pseudo-Euclidean spaces of certain signatures. For k = 1 this construction was proposed by the present author in a previous paper (2006). The realization of concrete Frobenius manifolds is reduced to solving a consistent linear system of second-order partial differential equations.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2018-02-07 00:00:00.000000"},
{"id":"907","title":"While activity who send character wide.","abstract":"COMET is a single-pass MapReduce algorithm for learning on large-scale data. It builds multiple random forest ensembles on distributed blocks of data and merges them into a mega-ensemble. This approach is appropriate when learning from massive-scale data that is too large to fit on a single machine. To get the best accuracy, IVoting should be used instead of bagging to generate the training subset for each decision tree in the random forest. Experiments with two large datasets (5GB and 50GB compressed) show that COMET compares favorably (in both accuracy and training time) to learning on a subsample of data using a serial algorithm. Finally, we propose a new Gaussian approach for lazy ensemble evaluation which dynamically decides how many ensemble members to evaluate per data point; this can reduce evaluation cost by 100X or more.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2022-06-02 00:00:00.000000"},
{"id":"908","title":"Pick north administration couple him consider suddenly.","abstract":"In this paper we present inequalities between two generalizations of the hyperbolic metric and the j_G metric. We also prove inequalities between generalized versions of the j_G metric and Seittenranta's metric.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2021-09-01 00:00:00.000000"},
{"id":"909","title":"Describe image best property.","abstract":"In this paper, we investigate the minimax properties of Stein block thresholding in any dimension $d$ with a particular emphasis on $d=2$. Towards this goal, we consider a frame coefficient space over which minimaxity is proved. The choice of this space is inspired by the characterization provided in \\cite{BorupNielsen} of family of smoothness spaces on $\\mathbb{R}^d$, a subclass of so-called decomposition spaces \\cite{Feichtinger}. These smoothness spaces cover the classical case of Besov spaces, as well as smoothness spaces corresponding to curvelet-type constructions. Our main theoretical result investigates the minimax rates over these decomposition spaces, and shows that our block estimator can achieve the optimal minimax rate, or is at least nearly-minimax (up to a $\\log$ factor) in the least favorable situation. Another contribution is that the minimax rates given here are stated for a general noise sequence model in the transform coefficient domain beyond the usual i.i.d. Gaussian case. The choice of the threshold parameter is theoretically discussed and its optimal value is stated for some noise models such as the (non-necessarily i.i.d.) Gaussian case. We provide a simple, fast and a practical procedure. We also report a comprehensive simulation study to support our theoretical findings. The practical performance of our Stein block denoising compares very favorably to the BLS-GSM state-of-the art denoising algorithm on a large set of test images. A toolbox is made available for download on the Internet to reproduce the results discussed in this paper.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2022-09-29 00:00:00.000000"},
{"id":"910","title":"Part success fire treatment without quite brother.","abstract":"The rise of the social media sites, such as blogs, wikis, Digg and Flickr among others, underscores the transformation of the Web to a participatory medium in which users are collaboratively creating, evaluating and distributing information. The innovations introduced by social media has lead to a new paradigm for interacting with information, what we call 'social information processing'. In this paper, we study how social news aggregator Digg exploits social information processing to solve the problems of document recommendation and rating. First, we show, by tracking stories over time, that social networks play an important role in document recommendation. The second contribution of this paper consists of two mathematical models. The first model describes how collaborative rating and promotion of stories emerges from the independent decisions made by many users. The second model describes how a user's influence, the number of promoted stories and the user's social network, changes in time. We find qualitative agreement between predictions of the model and user data gathered from Digg.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2016-03-20 00:00:00.000000"},
{"id":"911","title":"Else hand get administration.","abstract":"Many open-source projects land security fixes in public repositories before shipping these patches to users. This paper presents attacks on such projects - taking Firefox as a case-study - that exploit patch metadata to efficiently search for security patches prior to shipping. Using access-restricted bug reports linked from patch descriptions, security patches can be immediately identified for 260 out of 300 days of Firefox 3 development. In response to Mozilla obfuscating descriptions, we show that machine learning can exploit metadata such as patch author to search for security patches, extending the total window of vulnerability by 5 months in an 8 month period when examining up to two patches daily. Finally we present strong evidence that further metadata obfuscation is unlikely to prevent information leaks, and we argue that open-source projects instead ought to keep security patches secret until they are ready to be released.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2019-04-20 00:00:00.000000"},
{"id":"912","title":"Alone six anyone color book make.","abstract":"The recently suggested possibility that weak vibronic transitions can be excitonically enhanced in light-harvesting complexes is studied in detail. A vibronic exciton dimer model which includes ground state vibrations is investigated using multi-configuration time-dependent Hartree method with a parameter set typical to photosynthetic light-harvesting complexes. Absorption spectra are discussed in dependence on the Coulomb coupling, the detuning of site energies, and the number of vibrational mode. Calculations of the fluorescence spectra show that the spectral densities obtained from the low temperature fluorescence line narrowing measurements of light-harvesting systems need to be corrected for the exciton effects. For the J-aggregate configuration, as in most of the light-harvesting complexes, the true spectral density has larger amplitude than what is obtained from the measurement.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2022-02-22 00:00:00.000000"},
{"id":"913","title":"Husband job walk worry focus draw.","abstract":"Laser driven plasma accelerators promise much shorter particle accelerators but their development requires detailed simulations that challenge or exceed current capabilities. We report the first direct simulations of stages up to 1 TeV from simulations using a Lorentz boosted calculation frame resulting in a million times speedup, thanks to a frame boost as high as gamma=1300. Effects of the hyperbolic rotation in Minkowski space resulting from the frame boost on the laser propagation in the plasma is shown to be key in the mitigation of a numerical instability that was limiting previous attempts.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2017-04-29 00:00:00.000000"},
{"id":"914","title":"Political daughter area above paper tonight marriage.","abstract":"The present study deals with the problem of evaluation of the recharge mechanism and the characterization of the groundwater flow system in the basement shallow aquifer, which is one of the groundwater resource in the semi-arid South region of Madagascar. Stable isotopes (deuterium and oxygen-18) and tritium are used to achieve with accuracy the hydrogeological and geochemical dynamics study. Chemical analysis is used to provide complementary information to the investigation. A space distribution of tritium concentration and isotopic composition in groundwater shows evidence of two opposite categories of aquifers, which is confirmed by the chemical analysis results and by the geological features of the study site. Some groundwater flow path directions have been identified in the study area thanks to the tritium concentration space distribution and the geological formation. Besides, the groundwater recharge of the shallow aquifers in the South of Madagascar has been characterized by the exponential mixing model.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2020-10-29 00:00:00.000000"},
{"id":"915","title":"Sometimes item upon since reduce rest claim.","abstract":"Imaging of the structure of single proteins or other biomolecules with atomic resolution would be enormously beneficial to structural biology. X-ray free-electron lasers generate highly intense and ultrashort x-ray pulses, providing a route towards imaging of single molecules with atomic resolution. The information on molecular structure is encoded in the coherent x-ray scattering signal. In contrast to crystallography there are no Bragg reflections in single molecule imaging, which means the coherent scattering is not enhanced. Consequently, a background signal from incoherent scattering deteriorates the quality of the coherent scattering signal. This background signal cannot be easily eliminated because the spectrum of incoherently scattered photons cannot be resolved by usual scattering detectors. We present an ab initio study of incoherent x-ray scattering from individual carbon atoms, including the electronic radiation damage caused by a highly intense x-ray pulse. We find that the coherent scattering pattern suffers from a significant incoherent background signal at high resolution. For high x-ray fluence the background signal becomes even dominating. Finally, based on the atomic scattering patterns, we present an estimation for the average photon count in single molecule imaging at high resolution. By varying the photon energy from 3.5 keV to 15 keV, we find that imaging at higher photon energies may improve the coherent scattering signal quality.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2020-06-18 00:00:00.000000"},
{"id":"916","title":"Structure nation guy mind bed whose shake.","abstract":"For real functions \\Phi and \\Psi that are integrable and compactly supported, we prove the norm resolvent convergence, as \\epsilon\\ goes to 0, of a family S(\\epsilon) of one-dimensional Schroedinger operators on the line of the form   S(\\epsilon)= -D^2 + \\alpha \\epsilon^{-2} \\Phi(x\/\\epsilon) + \\beta \\epsilon^{-1} \\Psi(x\/\\epsilon).   The limit results are shape-dependent: without reference to the convergence of potentials in the sense of distributions the limit operator S(0) exists and strongly depends on the pair (\\Phi,\\Psi). We show that it is impossible to assign just one self-adjoint operator to the pseudo-Hamiltonian -D^2 + \\alpha \\delta'(x) + \\beta \\delta(x), which is a symbolic notation only for a wide variety of quantum systems with quite different properties.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2021-09-08 00:00:00.000000"},
{"id":"917","title":"Change key memory red although send.","abstract":"WWW has a scale-free structure where novel information is often difficult to locate. Moreover, Intelligent agents easily get trapped in this structure. Here a novel method is put forth, which turns these traps into information repositories, supplies: We populated an Internet environment with intelligent news foragers. Foraging has its associated cost whereas foragers are rewarded if they detect not yet discovered novel information. The intelligent news foragers crawl by using the estimated long-term cumulated reward, and also have a finite sized memory: the list of most promising supplies. Foragers form an artificial life community: the most successful ones are allowed to multiply, while unsuccessful ones die out. The specific property of this community is that there is no direct communication amongst foragers but the centralized rewarding system. Still, fast division of work is achieved.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2016-06-10 00:00:00.000000"},
{"id":"918","title":"Study edge air generation describe through.","abstract":"We propose an efficient scheme for generating fake network traffic to disguise the real event notification in the presence of a global eavesdropper, which is especially relevant for the quality of service in delay-intolerant applications monitoring rare and spatially sparse events, and deployed as large wireless sensor networks with single data collector. The efficiency of the scheme that provides statistical source anonymity is achieved by partitioning network nodes randomly into several node groups. Members of the same group collectively emulate both temporal and spatial distribution of the event. Under such dummy-traffic framework of the source anonymity protection, we aim to better model the global eavesdropper, especially her way of using statistical tests to detect the real event, and to present the quality of the location protection as relative to the adversary's strength. In addition, our approach aims to reduce the per-event work spent to generate the fake traffic while, most importantly, providing a guaranteed latency in reporting the event. The latency is controlled by decoupling the routing from the fake traffic schedule. We believe that the proposed source anonymity protection strategy, and the quality evaluation framework, are well justified by the abundance of the applications that monitor a rare event with known temporal statistics, and uniform spatial distribution.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2022-05-07 00:00:00.000000"},
{"id":"919","title":"Candidate one keep network remember southern world budget.","abstract":"This provides a retrospective of the paper \"A Measure of Transaction Processing\" published in 1985. It shows that transaction processing peak performance and price-peformance have improved about 100,000x respectively and that sort\/sequential performance has approximately doubled each year (so a million fold improvement) even though processor performance plateaued in 1995.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2016-10-05 00:00:00.000000"},
{"id":"920","title":"Represent bank PM him hear.","abstract":"This paper studies the problem of testing whether a function is monotone from a nonparametric Bayesian perspective. Two new families of tests are constructed. The first uses constrained smoothing splines, together with a hierarchical stochastic-process prior that explicitly controls the prior probability of monotonicity. The second uses regression splines, together with two proposals for the prior over the regression coefficients. The finite-sample performance of the tests is shown via simulation to improve upon existing frequentist and Bayesian methods. The asymptotic properties of the Bayes factor for comparing monotone versus non-monotone regression functions in a Gaussian model are also studied. Our results significantly extend those currently available, which chiefly focus on determining the dimension of a parametric linear model.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2016-12-05 00:00:00.000000"},
{"id":"921","title":"Point race investment if be market within.","abstract":"Using the molecular dynamics method, we examine a discrete deterministic model for the motion of spherical particles in three-dimensional space. The model takes into account multiparticle collisions in arbitrary forms. Using fractional calculus we proposed an expression for the repulsive force, which is the so called fractional interaction law. We then illustrate and discuss how to control (correlate) the energy dissipation and the collisional time for an individual article within multiparticle collisions. In the multiparticle collisions we included the friction mechanism needed for the transition from coupled torsion-sliding friction through rolling friction to static friction. Analysing simple simulations we found that in the strong repulsive state binary collisions dominate. However, within multiparticle collisions weak repulsion is observed to be much stronger. The presented numerical results can be used to realistically model the impact dynamics of an individual particle in a group of colliding particles.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2019-10-17 00:00:00.000000"},
{"id":"922","title":"Reveal value account believe structure health small.","abstract":"We prove a non-commutative version of the Hilbert's 17th problem, giving a characterization of the class of non-commutative polynomials in n-undeterminates that have positive trace when evaluated in n-selfadjoint elements in arbitrary II1 von Neumann algebra. As a corollary we prove that Connes's embedding conjecture is equivalent to a statement that can be formulated entirely in the context of finite matrices.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2016-08-21 00:00:00.000000"},
{"id":"923","title":"Account scene he.","abstract":"In 2010, the Human Space Technology Initiative (HSTI) was launched by the United Nations Office for Outer Space Affairs (UNOOSA) within the United Nations Programme on Space Applications. The Initiative aims at promoting international cooperation in human spaceflight and space exploration-related activities, creating awareness among countries on the benefits of utilizing human space technology and its applications, and building capacity in microgravity education and research. HSTI has conducted a series of outreach activities and expert meetings bringing together participants from around the world. HSTI will also be implementing science and educational activities in relevant areas to raise the capacities, particularly in developing countries, in pursuit of the development goals of the United Nations, thus contributing to promoting the peaceful uses of outer space.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2021-07-26 00:00:00.000000"},
{"id":"924","title":"Opportunity answer past include him box which.","abstract":"In this paper we investigate Gromov's question: whether every one-ended word hyperbolic group contains a surface subgroup. The case of double groups is considered by studying the associated one relator groups. We show that the majority (96%) of the randomly selected double groups with three generators have the property. The experiments are performed on MAGMA software.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2016-06-16 00:00:00.000000"},
{"id":"925","title":"Member summer big own economy create role.","abstract":"The subspace Restricted Boltzmann Machine (subspaceRBM) is a third-order Boltzmann machine where multiplicative interactions are between one visible and two hidden units. There are two kinds of hidden units, namely, gate units and subspace units. The subspace units reflect variations of a pattern in data and the gate unit is responsible for activating the subspace units. Additionally, the gate unit can be seen as a pooling feature. We evaluate the behavior of subspaceRBM through experiments with MNIST digit recognition task, measuring reconstruction error and classification error.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2017-10-19 00:00:00.000000"},
{"id":"926","title":"Evidence kind dream.","abstract":"We discuss a novel kind of nonlinear coupler with one channel filled with a negative index material (NIM). The opposite directionality of the phase velocity and the energy flow in the NIM channel facilitates an effective feedback mechanism that leads to optical bistability and gap soliton formation.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2019-01-08 00:00:00.000000"},
{"id":"927","title":"Firm decade people task former decide part.","abstract":"In this paper, we compute the Clebsch-Gordan formulae and the Green rings of connected pointed tensor categories of finite type.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2015-02-25 00:00:00.000000"},
{"id":"928","title":"Threat same while talk energy voice growth.","abstract":"A special version of multi--dimensional simple waves given in [G. Boillat, {\\it J. Math. Phys.} {\\bf 11}, 1482-3 (1970)] and [G.M. Webb, R. Ratkiewicz, M. Brio and G.P. Zank, {\\it J. Plasma Phys.} {\\bf 59}, 417-460 (1998)] is employed for fully relativistic fluid and plasma flows. Three essential modes: vortex, entropy and sound modes are derived where each of them is different from its nonrelativistic analogue. Vortex and entropy modes are formally solved in both the laboratory frame and the wave frame (co-moving with the wave front) while the sound mode is formally solved only in the wave frame at ultra-relativistic temperatures. In addition, the surface which is the boundary between the permitted and forbidden regions of the solution is introduced and determined. Finally a symmetry analysis is performed for the vortex mode equation up to both point and contact transformations. Fundamental invariants and a form of general solutions of point transformations along with some specific examples are also derived.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2017-06-22 00:00:00.000000"},
{"id":"929","title":"Who final thing blood.","abstract":"We show that stabilizations of sufficiently noncommutative separable unital C*-algebras with finite nuclear dimension have the corona factorization property.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2018-12-28 00:00:00.000000"},
{"id":"930","title":"Sound number use significant view me trade available.","abstract":"Let $A$ be a $C^*$-algebra and $I$ be a closed ideal in $A$. For $x\\in A$, its image under the canonical surjection $A\\to A\/I$ is denoted by $\\dot x$, and the spectral radius of $x$ is denoted by $r(x)$. We prove that $$\\max\\{r(x), \\|\\dot x\\|\\} = \\inf \\|(1+i)^{-1}x(1+i)\\|$$ (where infimum is taken over all $i\\in I$ such that $1+i$ is invertible), which generalizes spectral radius formula of Murphy and West \\cite{MurphyWest} (Rota for $\\mathcal{B(H)}$ \\cite{Rota}). Moreover if $r(x)< \\|\\dot x\\|$ then the infimum is attained. A similar result is proved for commuting family of elements of a $C^*$-algebra. Using this we give a partial answer to an open question of C. Olsen: if $p$ is a polynomial then for \"almost every\" operator $T\\in B(H)$ there is a compact perturbation $T+K$ of $T$ such that $$\\|p(T+K)\\| = \\|p(T)\\|_e.$$   We show also that if operators $A,B$ commute, $A$ is similar to a contraction and $B$ is similar to a strict contraction then they are simultaneously similar to contractions.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2015-01-14 00:00:00.000000"},
{"id":"931","title":"Traditional room already interest gun national majority.","abstract":"To investigate the role of information flow in group formation, we introduce a model of communication and social navigation. We let agents gather information in an idealized network society, and demonstrate that heterogeneous groups can evolve without presuming that individuals have different interests. In our scenario, individuals' access to global information is constrained by local communication with the nearest neighbors on a dynamic network. The result is reinforced interests among like-minded agents in modular networks; the flow of information works as a glue that keeps individuals together. The model explains group formation in terms of limited information access and highlights global broadcasting of information as a way to counterbalance this fragmentation. To illustrate how the information constraints imposed by the communication structure affects future development of real-world systems, we extrapolate dynamics from the topology of four social networks.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2015-12-02 00:00:00.000000"},
{"id":"932","title":"Hope shoulder edge spring I.","abstract":"Valuation algebras abstract a large number of formalisms for automated reasoning and enable the definition of generic inference procedures. Many of these formalisms provide some notions of solutions. Typical examples are satisfying assignments in constraint systems, models in logics or solutions to linear equation systems.   Recently, formal requirements for the presence of solutions and a generic algorithm for solution construction based on the results of a previously executed inference scheme have been proposed in the literature. Unfortunately, the formalization of Pouly and Kohlas relies on a theorem for which we provide a counter example. In spite of that, the mainline of the theory described is correct, although some of the necessary conditions to apply some of the algorithms have to be revised. To fix the theory, we generalize some of their definitions and provide correct sufficient conditions for the algorithms. As a result, we get a more general and corrected version of the already existing theory.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2015-02-14 00:00:00.000000"},
{"id":"933","title":"Before live oil save wonder manage.","abstract":"We propose a way to control solitons in $\\chi ^{(2)}$ (quadratically-nonlinear) systems by means of periodic modulation imposed on the phase-mismatch parameter (\"mismatch management\", MM). It may be realized in the co-transmission of fundamental-frequency (FF) and second-harmonic (SH) waves in a planar optical waveguide via a long-period modulation of the usual quasi-phase-matching pattern of ferroelectric domains. The MM may also be implemented by dint of the Feshbach resonance in a harmonically-modulated magnetic field in a hybrid atomic-molecular Bose-Einstein condensate (BEC), with the atomic and molecular mean fields (MFs) playing the roles of the FF and SH, respectively. The problem is analyzed by two methods. First, we identify stability regions for spatial solitons in the MM system, in terms of the MM amplitude and period, using the MF equations for spatially-inhomogeneous configurations. In particular, an instability enclave is found inside the stability area.The robustness of the solitons is also tested against variation of the shape of the input pulse, and a threshold for the formation of stable solitons is found in terms of its power. Interactions between solitons are virtually unaffected by the MM. The second method (\\textit{parametric approximation}), going beyond the MF description, is developed for spatially-homogeneous states. It demonstrates that the MF description is valid for large modulation periods, while at smaller periods the non-MF component acquires gain, which implies destruction of MF under the action of the high-frequency MM.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2016-12-14 00:00:00.000000"},
{"id":"934","title":"Keep site though audience happen morning political.","abstract":"The aim of this note is to give a short and popular review of the ideas which led to my model of magnetic monopoles (hep-ph\/9708394) and my prediction of the second kind of electromagnetic radiation. I will also point out the many and far-reaching consequences if these magnetic photon rays would be confirmed.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2021-05-06 00:00:00.000000"},
{"id":"935","title":"Source memory investment stop concern.","abstract":"We design and simulate the motion of a new swimmer, the Quadroar, with three dimensional translation and reorientation capabilities in low Reynolds number conditions. The Quadroar is composed of an $\\texttt{I}$-shaped frame whose body link is a simple linear actuator, and four disks that can rotate about the axes of flange links. The time symmetry is broken by a combination of disk rotations and the one-dimensional expansion\/contraction of the body link. The Quadroar propels on forward and transverse straight lines and performs full three dimensional reorientation maneuvers, which enable it to swim along arbitrary trajectories. We find continuous operation modes that propel the swimmer on planar and three dimensional rosette orbits, which can be periodic or quasi-periodic. Precessing rosette orbits consist of slow lingering phases with cardioid or multiloop turns followed by directional propulsive phases. Quasi-periodic orbits allow the swimmer to access large parts of its neighboring space without using complex control strategies.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2022-12-09 00:00:00.000000"},
{"id":"936","title":"Tend we player meet create entire common.","abstract":"In this thesis I explore challenging discrete energy minimization problems that arise mainly in the context of computer vision tasks. This work motivates the use of such \"hard-to-optimize\" non-submodular functionals, and proposes methods and algorithms to cope with the NP-hardness of their optimization. Consequently, this thesis revolves around two axes: applications and approximations. The applications axis motivates the use of such \"hard-to-optimize\" energies by introducing new tasks. As the energies become less constrained and structured one gains more expressive power for the objective function achieving more accurate models. Results show how challenging, hard-to-optimize, energies are more adequate for certain computer vision applications. To overcome the resulting challenging optimization tasks the second axis of this thesis proposes approximation algorithms to cope with the NP-hardness of the optimization. Experiments show that these new methods yield good results for representative challenging problems.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2021-05-14 00:00:00.000000"},
{"id":"937","title":"Budget two least.","abstract":"We present a method for system identification of flexible objects by measuring forces and displacement during interaction with a manipulating arm. We model the object's structure and flexibility by a chain of rigid bodies connected by torsional springs. Unlike previous work, the proposed optimal control approach using variational integrators allows identification of closed loops, which include the robot arm itself. This allows using the resulting models for planning in configuration space of the robot. In order to solve the resulting problem efficiently, we develop a novel method for fast discrete-time adjoint-based gradient calculation. The feasibility of the approach is demonstrated using full physics simulation in trep and using data recorded from a 7-DOF series elastic robot arm.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2018-06-03 00:00:00.000000"},
{"id":"938","title":"Morning citizen protect.","abstract":"We consider Apollonian circle packings of a half Euclidean plane. We give necessary and sufficient conditions for two such packings to be related by a Euclidean similarity (that is, by translations, reflections, rotations and dilations) and describe explicitly the group of self-similarities of a given packing. We observe that packings with a non-trivial self-similarity correspond to positive real numbers that are the roots of quadratic polynomials with rational coefficients. This is reflected in a close connection between Apollonian circle packings and continued fractions which allows us to completely classify such packings up to similarity.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2015-08-02 00:00:00.000000"},
{"id":"939","title":"Author oil sometimes movement building score.","abstract":"We show that the higher Grothendieck-Witt groups, a.k.a. algebraic hermitian K-groups, are represented by an infinite orthogonal Grassmannian in the A1-homotopy category of smooth schemes over a regular base for which 2 is a unit in the ring of regular functions. We also give geometric models for various P1- and S1-loop spaces of hermitian K-theory.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2022-05-06 00:00:00.000000"},
{"id":"940","title":"Cost feeling people second boy day.","abstract":"Given a sample covariance matrix, we solve a maximum likelihood problem penalized by the number of nonzero coefficients in the inverse covariance matrix. Our objective is to find a sparse representation of the sample data and to highlight conditional independence relationships between the sample variables. We first formulate a convex relaxation of this combinatorial problem, we then detail two efficient first-order algorithms with low memory requirements to solve large-scale, dense problem instances.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2016-07-24 00:00:00.000000"},
{"id":"941","title":"Car little who guy safe.","abstract":"We have reinvestigated the B-X and C-X band systems of CuCl by recording the laser-induced fluorescence excitation spectra in 20400-21800 cm^{-1}. The rotational analyses in Hund's case (a) revealed unambiguously a singlet-to-singlet transition nature. The measured lifetimes of a few microseconds seem too long for singlets and too short for triplets, which we think is actually in favor of a picture of singlet ({1}^Pi and {1}^Sigma^{+})-triplet ({3}^Pi_{0,1,2}) mixed states in the B and C band systems of CuCl. The two excited states we observed in our spectra may be the singlets that have been strongly \"contaminated\" by their triplet neighbors.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2022-07-30 00:00:00.000000"},
{"id":"942","title":"One be smile they late material.","abstract":"This paper presents a probabilistic model for reasoning about the state of a system as it changes over time, both due to exogenous and endogenous influences. Our target domain is a class of medical prediction problems that are neither so urgent as to preclude careful diagnosis nor progress so slowly as to allow arbitrary testing and treatment options. In these domains there is typically enough time to gather information about the patient's state and consider alternative diagnoses and treatments, but the temporal interaction between the timing of tests, treatments, and the course of the disease must also be considered. Our approach is to elicit a qualitative structural model of the patient from a human expert---the model identifies important attributes, the way in which exogenous changes affect attribute values, and the way in which the patient's condition changes endogenously. We then elicit probabilistic information to capture the expert's uncertainty about the effects of tests and treatments and the nature and timing of endogenous state changes. This paper describes the model in the context of a problem in treating vehicle accident trauma, and suggests a method for solving the model based on the technique of sequential imputation. A complementary goal of this work is to understand and synthesize a disparate collection of research efforts all using the name ?probabilistic temporal reasoning.? This paper analyzes related work and points out essential differences between our proposed model and other approaches in the literature.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2021-10-11 00:00:00.000000"},
{"id":"943","title":"Local career easy.","abstract":"This paper describes a program that solves elementary mathematical problems, mostly in metric space theory, and presents solutions that are hard to distinguish from solutions that might be written by human mathematicians. The program is part of a more general project, which we also discuss.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2015-08-20 00:00:00.000000"},
{"id":"944","title":"Professor success outside economy security.","abstract":"We prove that it is consistent that the covering of the ideal of measure zero sets has countable cofinality.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2018-02-04 00:00:00.000000"},
{"id":"945","title":"Be trade among remain card discover.","abstract":"Security testing aims at validating software system requirements related to security properties like confidentiality, integrity, authentication, authorization, availability, and non-repudiation. Although security testing techniques are available for many years, there has been little approaches that allow for specification of test cases at a higher level of abstraction, for enabling guidance on test identification and specification as well as for automated test generation.   Model-based security testing (MBST) is a relatively new field and especially dedicated to the systematic and efficient specification and documentation of security test objectives, security test cases and test suites, as well as to their automated or semi-automated generation. In particular, the combination of security modelling and test generation approaches is still a challenge in research and of high interest for industrial applications. MBST includes e.g. security functional testing, model-based fuzzing, risk- and threat-oriented testing, and the usage of security test patterns. This paper provides a survey on MBST techniques and the related models as well as samples of new methods and tools that are under development in the European ITEA2-project DIAMONDS.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2016-06-23 00:00:00.000000"},
{"id":"946","title":"Now major so paper many little area.","abstract":"Physics and mathematics are difficult enough without the aditional burden of bad habits. In this article, we examine some helpful habits that tend to be underemphasized by many physics teachers (mainly because they seem so obvious!).","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2021-09-08 00:00:00.000000"},
{"id":"947","title":"Whether seat anything day pull civil form.","abstract":"Experimental observations suggest that proteins follow different pathways under different environmental conditions. We perform molecular dynamics simulations of a model of the SH3 domain over a broad range of temperatures, and identify distinct pathways in the folding transition. We determine the kinetic partition temperature --the temperature for which the SH3 domain undergoes a rapid folding transition with minimal kinetic barriers-- and observe that below this temperature the model protein may undergo a folding transition via multiple folding pathways. The folding kinetics is characterized by slow and fast pathways and the presence of only one or two intermediates. Our findings suggest the hypothesis that the SH3 domain, a protein for which only two-state folding kinetics was observed in previous experiments, may exhibit intermediates states under extreme experimental conditions, such as very low temperatures. A very recent report (Viguera et al., Proc. Natl. Acad. Sci. USA, 100:5730--5735, 2003) of an intermediate in the folding transition of the Bergerac mutant of the alpha-spectrin SH3 domain protein supports this hypothesis.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2020-10-26 00:00:00.000000"},
{"id":"948","title":"Anyone performance of catch politics manager.","abstract":"We study cohomologies and Hodge theory for complex manifolds with twisted differentials. In particular, we get another cohomological obstruction for manifolds in class $\\mathcal{C}$ of Fujiki. We give a Hodge-theoretical proof of the characterization of solvmanifolds in class $\\mathcal{C}$ of Fujiki, first proven by D. Arapura.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2021-07-15 00:00:00.000000"},
{"id":"949","title":"Must various until full.","abstract":"Modelling of complex systems is mainly based on the decomposition of these systems in autonomous elements, and the identification and definitio9n of possible interactions between these elements. For this, the agent-based approach is a modelling solution often proposed. Complexity can also be due to external events or internal to systems, whose main characteristics are uncertainty, imprecision, or whose perception is subjective (i.e. interpreted). Insofar as fuzzy logic provides a solution for modelling uncertainty, the concept of fuzzy agent can model both the complexity and uncertainty. This paper focuses on introducing the concept of fuzzy agent: a classical architecture of agent is redefined according to a fuzzy perspective. A pedagogical illustration of fuzzy agentification of a smart watering system is then proposed.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2019-02-18 00:00:00.000000"},
{"id":"950","title":"Statement fear white lead.","abstract":"We consider probabilistic automata on a general state space and study their computational power. The model is based on the concept of language recognition by probabilistic automata due to Rabin and models of analog computation in a noisy environment suggested by Maass and Orponen, and Maass and Sontag. Our main result is a generalization of Rabin's reduction theorem that implies that under very mild conditions, the computational power of the automaton is limited to regular languages.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2020-12-17 00:00:00.000000"},
{"id":"951","title":"Work eat main most.","abstract":"We apply a symmetry-adapted algebraic model to the vibrational excitations in D_3h and T_d molecules. A systematic procedure is used to establish the relation between the algebraic and configuration space formulations. In this way we have identified interaction terms that were absent in previous formulations of the vibron model. The inclusion of these new interactions leads to reliable spectroscopic predictions. We illustrate the method for the D_3h triatomic molecules, H_3^+, Be_3 and Na_3, and the T_d molecules, Be_4 and CH_4.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2020-12-02 00:00:00.000000"},
{"id":"952","title":"Improve any line hotel four catch guess during.","abstract":"The Fourier Entropy-Influence (FEI) conjecture of Friedgut and Kalai [FK96] seeks to relate two fundamental measures of Boolean function complexity: it states that $H[f] \\leq C Inf[f]$ holds for every Boolean function $f$, where $H[f]$ denotes the spectral entropy of $f$, $Inf[f]$ is its total influence, and $C > 0$ is a universal constant. Despite significant interest in the conjecture it has only been shown to hold for a few classes of Boolean functions.   Our main result is a composition theorem for the FEI conjecture. We show that if $g_1,...,g_k$ are functions over disjoint sets of variables satisfying the conjecture, and if the Fourier transform of $F$ taken with respect to the product distribution with biases $E[g_1],...,E[g_k]$ satisfies the conjecture, then their composition $F(g_1(x^1),...,g_k(x^k))$ satisfies the conjecture. As an application we show that the FEI conjecture holds for read-once formulas over arbitrary gates of bounded arity, extending a recent result [OWZ11] which proved it for read-once decision trees. Our techniques also yield an explicit function with the largest known ratio of $C \\geq 6.278$ between $H[f]$ and $Inf[f]$, improving on the previous lower bound of 4.615.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2016-12-22 00:00:00.000000"},
{"id":"953","title":"Answer finish political himself spend.","abstract":"We consider concepts and models for measuring inequality in the distribution of resources with a focus on how inequality varies as a function of covariates. Lorenz introduced a device for measuring inequality in the distribution of income that indicates how much the incomes below the u$^{th}$ quantile fall short of the egalitarian situation where everyone has the same income. Gini introduced a summary measure of inequality that is the average over u of the difference between the Lorenz curve and its values in the egalitarian case. More generally, measures of inequality are useful for other response variables in addition to income, e.g. wealth, sales, dividends, taxes, market share and test scores. In this paper we show that a generalized van Zwet type dispersion ordering for distributions of positive random variables induces an ordering on the Lorenz curve, the Gini coefficient and other measures of inequality. We use this result and distributional orderings based on transformations of distributions to motivate parametric and semiparametric models whose regression coefficients measure effects of covariates on inequality. In particular, we extend a parametric Pareto regression model to a flexible semiparametric regression model and give partial likelihood estimates of the regression coefficients and a baseline distribution that can be used to construct estimates of the various conditional measures of inequality.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2022-05-31 00:00:00.000000"},
{"id":"954","title":"West prevent assume information protect.","abstract":"Not all instances in a data set are equally beneficial for inferring a model of the data. Some instances (such as outliers) are detrimental to inferring a model of the data. Several machine learning techniques treat instances in a data set differently during training such as curriculum learning, filtering, and boosting. However, an automated method for determining how beneficial an instance is for inferring a model of the data does not exist. In this paper, we present an automated method that orders the instances in a data set by complexity based on the their likelihood of being misclassified (instance hardness). The underlying assumption of this method is that instances with a high likelihood of being misclassified represent more complex concepts in a data set. Ordering the instances in a data set allows a learning algorithm to focus on the most beneficial instances and ignore the detrimental ones. We compare ordering the instances in a data set in curriculum learning, filtering and boosting. We find that ordering the instances significantly increases classification accuracy and that filtering has the largest impact on classification accuracy. On a set of 52 data sets, ordering the instances increases the average accuracy from 81% to 84%.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2018-01-11 00:00:00.000000"},
{"id":"955","title":"Theory affect soldier sing box again agreement.","abstract":"Exploratory data analysis is often used to test the goodness-of-fit of sample observations to specific target distributions. A few such graphical tools have been extensively used to detect subexponential or heavy-tailed behavior in observed data. In this paper we discuss asymptotic limit behavior of two such plotting tools: the quantile-quantile plot and the mean excess plot. The weak consistency of these plots to fixed limit sets in an appropriate topology of $\\mathbb{R}^2$ has been shown in Das and Resnick (Stoch. Models 24 (2008) 103-132) and Ghosh and Resnick (Stochastic Process. Appl. 120 (2010) 1492-1517). In this paper we find asymptotic distributional limits for these plots when the underlying distributions have regularly varying right-tails. As an application we construct confidence bounds around the plots which enable us to statistically test whether the underlying distribution is heavy-tailed or not.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2018-03-19 00:00:00.000000"},
{"id":"956","title":"Write must hold team us.","abstract":"This paper discusses consistent flag bicolorings of maps and maniplexes, in their own right and as generalizations of orientations and pseudo-orientations. Furthermore, a related doubling concept is introduced, and relationships between these ideas are explored.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2021-09-29 00:00:00.000000"},
{"id":"957","title":"Computer audience recently modern feeling.","abstract":"We study the Laplace operator with Dirichlet or Neumann boundary condition on polygons in the Euclidean plane. We prove that almost every simply connected polygon with at least four vertices has simple spectrum. We also address the more general case of geodesic polygons in a constant curvature space form.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2021-04-04 00:00:00.000000"},
{"id":"958","title":"Executive family serious finish hear.","abstract":"To date, researchers have identified over 1000 different compounds contained in human breath. These molecules have both endogenous and exogenous origins and provide information about physiological processes occurring in the body as well as environment-related ingestion or absorption of contaminants1,2. While the presence and concentration of many of these molecules are poorly understood, many 'biomarker' molecules have been correlated to specific diseases and metabolic processes. Such correlations can result in non-invasive methods of health screening for a wide variety of medical conditions. In this article we present human breath analysis using an optical-frequency-comb-based trace detection system with excellent performance in all criteria: detection sensitivity, ability to identify and distinguish a large number of biomarkers, and measurement time. We demonstrate a minimum detectable absorption of 8 x 10-10 cm-1, a spectral resolution of 800 MHz, and 200 nm of spectral coverage from 1.5 to 1.7 micron where strong and unique molecular fingerprints exist for many biomarkers. We present a series of breath measurements including stable isotope ratios of CO2, breath concentrations of CO, and the presence of trace concentrations of NH3 in high concentrations of H2O.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2022-06-12 00:00:00.000000"},
{"id":"959","title":"Turn nothing special town stage picture.","abstract":"Let $M$ be a finite module over a noetherian ring $R$ with a free resolution of length 1. We consider the generalized Koszul complexes $\\mathcal{C}_{\\bar\\lambda}(t)$ associated with a map $\\bar\\lambda:M\\to\\mathcal{H}$ into a finite free $R$-module $\\mathcal{H}$ (see [IV], section 3), and investigate the homology of $\\mathcal{C}_{\\bar\\lambda}(t)$ in the special setup when $\\grade I_M=\\rank M=\\dim R$. ($I_M$ is the first non-vanishing Fitting ideal of $M$.) In this case the (interesting) homology of $\\mathcal{C}_{\\bar\\lambda}(t)$ has finite length, and we deduce some length formulas. As an application we give a short algebraic proof of an old theorem due to Greuel (see [G], Proposition 2.5). We refer to [HM] where one can find another proof by similar methods.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2016-09-24 00:00:00.000000"},
{"id":"960","title":"Simply true five quickly member build.","abstract":"We discuss a problem of handling resource reservations. The resource can be reserved for some time, it can be freed or it can be queried what is the largest amount of reserved resource during a time interval. We show that the problem has a lower bound of $\\Omega(\\log n)$ per operation on average and we give a matching upper bound algorithm. Our solution also solves a dynamic version of the related problems of a prefix sum and a partial sum.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2016-03-24 00:00:00.000000"},
{"id":"961","title":"Above accept language well bar size.","abstract":"We describe how the result in [1] extends to prove the existence of a Serre type spectral sequence converging to the symplectic homology SH_*(M) of an exact Sub-Liouville domain M in a cotangent bundle T*N. We will define a notion of a fiber-wise symplectic homology SH_*(M,q) for each point q in N, which will define a graded local coefficient system on N. The spectral sequence will then have page two isomorphic to the homology of N with coefficients in this graded local system.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2019-11-20 00:00:00.000000"},
{"id":"962","title":"Without material cup also professor.","abstract":"Operator Axiom produces new real numbers with new operators. New operators naturally produce new equations and thus extend the traditional mathematical models which are selected to describe various scientific rules. So new operators help to describe complex scientific rules which are difficult described by traditional equations and have an enormous application potential. As to the equations including new operators, engineering computation often need the approximate solutions reflecting an intuitive order relation and equivalence relation. However, the order relation and equivalence relation of real numbers are not as intuitive as those of base-b expansions. Thus, this paper introduces numerical computations to approximate all real numbers with base-b expansions.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2015-04-10 00:00:00.000000"},
{"id":"963","title":"Other entire buy tonight else.","abstract":"Symmetry is a common feature of many combinatorial problems. Unfortunately eliminating all symmetry from a problem is often computationally intractable. This paper argues that recent parameterized complexity results provide insight into that intractability and help identify special cases in which symmetry can be dealt with more tractably","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2020-06-13 00:00:00.000000"},
{"id":"964","title":"Movie reveal our receive project event.","abstract":"We have made chromium-doped, silica-based preforms and optical fibres by Modified Chemical Vapour Deposition and have studied the influence of the chemical composition of the doped region on the Cr-oxidation states and the spectroscopic properties of the samples. Chromium, introduced initially as Cr3+, is partially or totally oxidized during the fabrication process, and is stabilized in the core of the preforms and fibres as Cr3+ in octahedral coordination, and\/or as Cr4+ in distorded tetrahedral coordination (Cs). Small concentrations (~1-2 mol%) of codopants in silica, such as germanium or aluminium, suffice to promote a particular oxidation state. Particularly, 1 mol % of aluminium stabilizes all present chromium into Cr4+. The ligand field parameters, Dq, B and Dq\/B, for Cr3+ and Cr4+ are derived. It is shown that the chromium ions in our samples are in low to intermediate ligand field and that Dq and Dq\/B decrease when the aluminium content increases. The absorption cross sections of Cr3+ are similar to that reported in glasses and crystals, whereas Cr4+ has lower values than reference laser materials.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2018-10-15 00:00:00.000000"},
{"id":"965","title":"Key speech condition suddenly.","abstract":"We study the distortion of Hausdorff dimension of families of Ahlfors regular sets under quasisymmetric map $f$ between metric spaces. We show that $f$ cannot increase the dimension of \"most\" $d$-regular sets and we estimate the number of exceptional sets whose images have dimension $\\geq d' > d$; the precise statements of both results involve modulus estimates for families of measures. For planar quasiconformal maps, the general estimates imply that if $E \\subset \\reals$ is $d$-regular, then some component of $f(E \\times \\reals)$ has dimension $\\leq 2\/(d+1)$, and we construct examples to show this bound is sharp. In addition, we construct 1-dimensional sets $E$ so that $f(E \\times \\reals)$ contains no rectifiable sub-arc. These results generalize work of Balogh, Monti and Tyson \\cite{Tyson:frequency} and answer questions posed in \\cite{Tyson:frequency}, \\cite{AimPL}.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2015-06-25 00:00:00.000000"},
{"id":"966","title":"Expect beyond suggest.","abstract":"Simmons and Cardy recently predicted a formula for the probability that the chordal SLE(8\/3) path passes to the left of two points in the upper half-plane. In this paper we give a rigorous proof of their formula. Starting from this result, we derive explicit expressions for several natural connectivity functions for SLE(8\/3) bubbles conditioned to be of macroscopic size. By passing to a limit with such a bubble we construct a certain chordal restriction measure and in this way obtain a proof of a formula for the probability that two given points are between two commuting SLE(8\/3) paths. The one-point version of this result has been predicted by Gamsa and Cardy. Finally, we derive an integral formula for the second moment of the area of an SLE(8\/3) bubble conditioned to have radius 1. We evaluate the area integral numerically and relate its value to a hypothesis that the area follows the Airy distribution.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2016-03-01 00:00:00.000000"},
{"id":"967","title":"Republican where themselves our.","abstract":"The Integrated Computer Control System (ICCS) is based on a scalable software framework that is distributed over some 325 computers throughout the NIF facility. The framework provides templates and services at multiple levels of abstraction for the construction of software applications that communicate via CORBA (Common Object Request Broker Architecture). Various forms of object-oriented software design patterns are implemented as templates to be extended by application software. Developers extend the framework base classes to model the numerous physical control points, thereby sharing the functionality defined by the base classes. About 56,000 software objects each individually addressed through CORBA are to be created in the complete ICCS. Most objects have a persistent state that is initialized at system start-up and stored in a database. Additional framework services are provided by centralized server programs that implement events, alerts, reservations, message logging, database\/file persistence, name services, and process management. The ICCS software framework approach allows for efficient construction of a software system that supports a large number of distributed control points representing a complex control application.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2016-11-02 00:00:00.000000"},
{"id":"968","title":"Show policy reduce front.","abstract":"We clarify the question whether for a smooth curve of polynomials one can choose the roots smoothly and related questions. Applications to perturbation theory of operators are given.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2018-02-21 00:00:00.000000"},
{"id":"969","title":"Character eight when product age social.","abstract":"In this paper we present a portfolio LTL-satisfiability solver, called Polsat. To achieve fast satisfiability checking for LTL formulas, the tool integrates four representative LTL solvers: pltl, TRP++, NuSMV, and Aalta. The idea of Polsat is to run the component solvers in parallel to get best overall performance; once one of the solvers terminates, it stops all other solvers. Remarkably, the Polsat solver utilizes the power of modern multi-core compute clusters. The empirical experiments show that Polsat takes advantages of it. Further, Polsat is also a testing plat- form for all LTL solvers.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2017-06-11 00:00:00.000000"},
{"id":"970","title":"Just method guy reflect add both until.","abstract":"We show that a sub-homogeneous positive monotone system with bounded heterogeneous time-varying delays is globally asymptotically stable if and only if the corresponding delay-free system is globally asymptotically stable. The proof is based on an extension of a delay-independent stability result for monotone systems under constant delays by Smith to systems with bounded heterogeneous time-varying delays. Under the additional assumption of positivity and sub-homogeneous vector fields, we establish the aforementioned delay insensitivity property and derive a novel test for global asymptotic stability. If the system has a unique equilibrium point in the positive orthant, we prove that our stability test is necessary and sufficient. Specialized to positive linear systems, our results extend and sharpen existing results from the literature.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2021-10-18 00:00:00.000000"},
{"id":"971","title":"Check free share training describe per finally light.","abstract":"For digital topological spaces defined using adjacency relations, there is an established homotopy equivalence relation which parallels that of classical topology. Many classical homotopy equivalence invariants, such as the Euler characteristic and the homology groups, do not remain invariants in the digital setting. This paper develops two numeric digital homotopy invariants and begins to catalog all possible connected digital spaces on a small number of points, up to homotopy equivalence.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2022-01-25 00:00:00.000000"},
{"id":"972","title":"End reach scene already movie bank support magazine.","abstract":"In the presence of electron cyclotron current drive (ECCD), the Ohm's law of single fluid magnetohydrodynamics (MHD) is modified as ${\\bf E} + {\\bf v} \\times {\\bf B} = \\eta( {\\bf J} - {\\bf J}_{\\rm EC} )$. This paper presents a new closure relation for the EC driven current density appearing in this modified Ohm's law. The new relation faithfully represents the nonlocal character of the EC driven current and its main origin in the Fisch-Boozer effect. The closure relation is validated on both an analytical solution of an approximated Fokker-Planck equation as well as on full bounce-averaged, quasi-linear Fokker-Planck code simulations of ECCD inside rotating magnetic islands. The new model contains the model put forward by Giruzzi et al., Nucl. Fusion 39 (1999) 107, in one of its limits.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2018-03-05 00:00:00.000000"},
{"id":"973","title":"Direction natural nice.","abstract":"In this expository paper, we revisit the results of Atiyah-Singer and de Concini-Procesi-Vergne concerning the structure of the K-theory groups K_G(T_G M).","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2017-08-04 00:00:00.000000"},
{"id":"974","title":"Light remember company herself small church.","abstract":"It is shown that the face ring of a pure simplicial complex modulo $m$ generic linear forms is a ring with finite local cohomology if and only if the link of every face of dimension $m$ or more is nonsingular.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2021-10-25 00:00:00.000000"},
{"id":"975","title":"Remain marriage him beautiful thus ground house Mrs.","abstract":"We investigate the relationship between the algebra of tensor categories and the topology of framed 3-manifolds. On the one hand, tensor categories with certain algebraic properties determine topological invariants. We prove that fusion categories of nonzero global dimension are 3-dualizable, and therefore provide 3-dimensional 3-framed local field theories. We also show that all finite tensor categories are 2-dualizable, and yield categorified 2-dimensional 3-framed local field theories. On the other hand, topological properties of 3-framed manifolds determine algebraic equations among functors of tensor categories. We show that the 1-dimensional loop bordism, which exhibits a single full rotation, acts as the double dual autofunctor of a tensor category. We prove that the 2-dimensional belt-trick bordism, which unravels a double rotation, operates on any finite tensor category, and therefore supplies a trivialization of the quadruple dual. This approach produces a quadruple-dual theorem for suitably dualizable objects in any symmetric monoidal 3-category. There is furthermore a correspondence between algebraic structures on tensor categories and homotopy fixed point structures, which in turn provide structured field theories; we describe the expected connection between pivotal tensor categories and combed fixed point structures, and between spherical tensor categories and oriented fixed point structures.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2018-11-14 00:00:00.000000"},
{"id":"976","title":"Believe rule order use both investment.","abstract":"Astronomical instrumentation is most of the time faced with challenging requirements in terms of sensitivity, stability, complexity, etc., and therefore leads to high performance developments that at first sight appear to be suitable only for the specific design application at the telescope. However, their usefulness in other disciplines and for other applications is not excluded. The ERA2 facility is a lab demonstrator, based on a high-performance astronomical spectrograph, which is intended to explore the innovation potential of fiber-coupled multi-channel spectroscopy for spatially resolved spectroscopy in life science, material sciences, and other areas of research.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2016-02-29 00:00:00.000000"},
{"id":"977","title":"Alone my level car purpose.","abstract":"Tabling has been used for some time to improve efficiency of Prolog programs by memorizing answered queries. The same idea can be naturally used to memorize visited states during search for planning. In this paper we present a planner developed in the Picat language to solve the Petrobras planning problem. Picat is a novel Prolog-like language that provides pattern matching, deterministic and non-deterministic rules, and tabling as its core modelling and solving features. We demonstrate these capabilities using the Petrobras problem, where the goal is to plan transport of cargo items from ports to platforms using vessels with limited capacity. Monte Carlo Tree Search has been so far the best technique to tackle this problem and we will show that by using tabling we can achieve much better runtime efficiency and better plan quality.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2020-10-14 00:00:00.000000"},
{"id":"978","title":"Offer wall think report.","abstract":"We show that any matrix-polynomial combination of free noncommutative random variables each having an algebraic law has again an algebraic law. Our result answers a question raised by a recent paper of Shlyakhtenko and Skoufranis. The result belongs to a family of results with origins outside free probability theory, including a result of Aomoto asserting algebraicity of the Green function of random walk of quite general type on a free group.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2017-07-20 00:00:00.000000"},
{"id":"979","title":"Activity painting throw technology item name way director.","abstract":"Current directions in network routing research have not kept pace with the latest developments in network architectures, such as peer-to-peer networks, sensor networks, ad-hoc wireless networks, and overlay networks. A common characteristic among all of these new technologies is the presence of highly dynamic network topologies. Currently deployed single-path routing protocols cannot adequately cope with this dynamism, and existing multi-path algorithms make trade-offs which lead to less than optimal performance on these networks. This drives the need for routing protocols designed with the unique characteristics of these networks in mind.   In this paper we propose the notion of reachability routing as a solution to the challenges posed by routing on such dynamic networks. In particular, our formulation of reachability routing provides cost-sensitive multi-path forwarding along with loop avoidance within the confines of the Internet Protocol (IP) architecture. This is achieved through the application of reinforcement learning within a probabilistic routing framework. Following an explanation of our design decisions and a description of the algorithm, we provide an evaluation of the performance of the algorithm on a variety of network topologies. The results show consistently superior performance compared to other reinforcement learning based routing algorithms.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2016-02-25 00:00:00.000000"},
{"id":"980","title":"Half early suffer knowledge.","abstract":"We give universal upper bounds on the relative dimensions of isotypic components of a tensor product of the linear group GL(n) representations and universal upper bounds on the relative dimensions of irreducible components of a tensor product of the special linear group SL(n) representations. This problem is motivated by harmonic analysis problems, and we give some applications of this result in the theory of Beurling-Fourier algebras.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2020-04-13 00:00:00.000000"},
{"id":"981","title":"Standard charge without thing evening worry.","abstract":"We give a counterexample to a conjecture of Poon [Poo06] that any orthogonal tree in two dimensions can always be flattened by a continuous motion that preserves edge lengths and avoids self-intersection. We show our example is locked by extending results on strongly locked self-touching linkages due to Connelly, Demaine and Rote [CDR02] to allow zero-length edges as defined in [ADG07], which may be of independent interest. Our results also yield a locked tree with only eleven edges, which is the smallest known example of a locked tree.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2016-01-29 00:00:00.000000"},
{"id":"982","title":"Concern couple amount power statement make budget.","abstract":"We present fully self consistent 3D simulations of compressible Hall MHD plasma that describe spectral features relevant to the solar wind plasma. We find that a $k^{-7\/3}$ spectrum sets in for the fluctuations that are smaller than ion gyro radius. We further investigate scale dependent anisotropy led by nonlinear processes relevant to the solar wind plasma. Our work is important particularly in understanding the role of wave and nonlinear cascades in the evolution of the solar wind, structure formation at the largest scales.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2019-08-03 00:00:00.000000"},
{"id":"983","title":"Investment manager heavy role them.","abstract":"We propose a new approach for Collaborative Filtering which is based on Boolean Matrix Factorisation (BMF) and Formal Concept Analysis. In a series of experiments on real data (Movielens dataset) we compare the approach with the SVD- and NMF-based algorithms in terms of Mean Average Error (MAE). One of the experimental consequences is that it is enough to have a binary-scaled rating data to obtain almost the same quality in terms of MAE by BMF than for the SVD-based algorithm in case of non-scaled data.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2017-02-12 00:00:00.000000"},
{"id":"984","title":"Though necessary word success fish high.","abstract":"In this paper two complexity efficient soft sphere-decoder modifications are proposed for computing the max-log LLR values in iterative MIMO systems, which avoid the costly, typically needed, full enumeration and sorting (FES) procedure during the tree traversal without compromising the max-log performance. It is shown that despite the resulting increase in the number of expanded nodes, they can be more computationally efficient than the typical soft sphere decoders by avoiding the unnecessary complexity of FES.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2018-09-25 00:00:00.000000"},
{"id":"985","title":"Understand indicate training difference arm.","abstract":"Solar wind turbulence is dominated by Alfv\\'{e}nic fluctuations but the power spectral exponents somewhat surprisingly evolve toward the Kolmogorov value of -5\/3, that of hydrodynamic turbulence. We show that at 1AU the turbulence decomposes linearly into two coexistent components perpendicular and parallel to the local average magnetic field. The first of these is consistent with propagating Alfv\\'{e}n wavepackets and shows the scaling expected of Alfv\\'{e}nic turbulence, namely Irosnikov- Kraichnan. The second shows Kolmogorov scaling which we also find in the number and magnetic energy density, and Poynting flux.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2020-10-21 00:00:00.000000"},
{"id":"986","title":"World maintain beat.","abstract":"Many Artificial Intelligence tasks cannot be evaluated with a single quality criterion and some sort of weighted combination is needed to provide system rankings. A problem of weighted combination measures is that slight changes in the relative weights may produce substantial changes in the system rankings. This paper introduces the Unanimous Improvement Ratio (UIR), a measure that complements standard metric combination criteria (such as van Rijsbergen's F-measure) and indicates how robust the measured differences are to changes in the relative weights of the individual metrics. UIR is meant to elucidate whether a perceived difference between two systems is an artifact of how individual metrics are weighted.   Besides discussing the theoretical foundations of UIR, this paper presents empirical results that confirm the validity and usefulness of the metric for the Text Clustering problem, where there is a tradeoff between precision and recall based metrics and results are particularly sensitive to the weighting scheme used to combine them. Remarkably, our experiments show that UIR can be used as a predictor of how well differences between systems measured on a given test bed will also hold in a different test bed.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2020-08-09 00:00:00.000000"},
{"id":"987","title":"Team easy provide agree sister true something.","abstract":"Surveillance control and reporting (SCR) system for air threats play an important role in the defense of a country. SCR system corresponds to air and ground situation management\/processing along with information fusion, communication, coordination, simulation and other critical defense oriented tasks. Threat Evaluation and Weapon Assignment (TEWA) sits at the core of SCR system. In such a system, maximal or near maximal utilization of constrained resources is of extreme importance. Manual TEWA systems cannot provide optimality because of different limitations e.g.surface to air missile (SAM) can fire from a distance of 5Km, but manual TEWA systems are constrained by human vision range and other constraints. Current TEWA systems usually work on target-by-target basis using some type of greedy algorithm thus affecting the optimality of the solution and failing in multi-target scenario. his paper relates to a novel two-staged flexible dynamic decision support based optimal threat evaluation and weapon assignment algorithm for multi-target air-borne threats.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2017-04-13 00:00:00.000000"},
{"id":"988","title":"Color ahead treatment he bill store.","abstract":"We characterize the compactness of composition operators; in term of generalized Nevanlinna counting functions, on a large class of Hilbert spaces of analytic functions, which can be viewed between the Bergman and the Dirichlet spaces","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2018-05-24 00:00:00.000000"},
{"id":"989","title":"Alone catch Mr.","abstract":"The boundary double layer potential, or the Neumann-Poincare operator, is studied on the Sobolev space of order 1\/2 along the boundary, coinciding with the space of charges giving rise to double layer potentials with finite energy in the whole space. Poincare's program of studying the spectrum of the boundary double layer potential is developed in complete generality, on closed Lipschitz hypersurfaces in Euclidean space. Furthermore, the Neumann-Poincare operator is realized as a singular integral transform bearing similarities to the Beurling-Ahlfors transform in 2D. As an application, bounds for the spectrum of the Neumann-Poincare operator are derived from recent results in quasi-conformal mapping theory, in the case of planar curves with corners.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2017-08-20 00:00:00.000000"},
{"id":"990","title":"Final kid little never former.","abstract":"Garg and Abadi recently proved that prominent access control logics can be translated in a sound and complete way into modal logic S4. We have previously outlined how normal multimodal logics, including monomodal logics K and S4, can be embedded in simple type theory (which is also known as higher-order logic) and we have demonstrated that the higher-order theorem prover LEO-II can automate reasoning in and about them. In this paper we combine these results and describe a sound and complete embedding of different access control logics in simple type theory. Employing this framework we show that the off the shelf theorem prover LEO-II can be applied to automate reasoning in prominent access control logics.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2021-03-26 00:00:00.000000"},
{"id":"991","title":"Before sort office stay network.","abstract":"Digital media is the need of a people now a day as the alternate of paper media.As the technology grown up digital media required protection while transferring through internet or others mediums.Watermarking techniques have been developed to fulfill this requirement.This paper aims to provide a detailed survey of all watermarking techniques specially focuses on image watermarking types and its applications in today world.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2020-04-23 00:00:00.000000"},
{"id":"992","title":"Fly important person manager if imagine blue.","abstract":"In this paper it is demonstrated that a 1\/f power spectrum appears in the process originated by the superposition of many similar single-sided RTN processes with the same relaxation time. The non-relaxed regime, the Gaussian nature and the average periodicity of the resulting fluctuation, are responsible for the generation of 1\/f noise, thanks to the coincidences of these RTN processes. The decomposition of the resulting fluctuation, in a set of further single-sided RTN processes with a distribution of relaxation times, permits us to demonstrate once more the generation of the 1\/f noise.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2022-05-21 00:00:00.000000"},
{"id":"993","title":"Hit where network likely friend.","abstract":"A computationally intensive large job, granulized to concurrent pieces and operating in a dynamic environment should reduce the total processing time. However, distributing jobs across a networked environment is a tedious and difficult task. Job distribution in a Local Area Network based on Triangular Dynamic Architecture (TDA) is a mechanism that establishes a dynamic environment for job distribution, load balancing and distributed processing with minimum interaction from the user. This paper introduces TDA and discusses its architecture and shows the benefits gained by utilizing such architecture in a distributed computing environment.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2020-06-21 00:00:00.000000"},
{"id":"994","title":"For deep baby ever stock.","abstract":"A brief review of the extremal projectors for contragredient Lie (super)symmetries (finite-dimensional simple Lie algebras, basic classical Lie superalgebras, infinite-dimensional affine Kac-Moody algebras and superalgebras, as well as their quantum $q$-analogs) is given. Some bibliographic comments on the applications of extremal projectors are presented.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2016-02-26 00:00:00.000000"},
{"id":"995","title":"Edge that hand.","abstract":"We consider the escape of particles located in the middle well of a symmetric triple well potential driven sinusoidally by two forces such that the potential wells roll as in stochastic resonance and the height of the potential barrier oscillates symmetrically about a mean as in resonant activation. It has been shown that depending on their phase difference the application of these two synchronized signals may lead to a splitting of time averaged Kramers' escape rate and a preferential product distribution in a parallel chemical reaction in the steady state.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2021-03-28 00:00:00.000000"},
{"id":"996","title":"Score land floor different describe.","abstract":"Based on the cosmological results of the Planck Mission, we show that all parameters describing our Universe within the \\Lambda CDM model can be constructed from a small set of numbers known from conspiracy theory. Our finding is confirmed by recent data from high energy particle physics. This clearly demonstrates that our Universe is a plot initiated by an unknown interest group or lodge. We analyse possible scenarios for this conspiracy, and conclude that the belief in the existence of our Universe is an illusion, as previously assumed by ancient philosophers, 20th century science fiction authors and contemporary film makers.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2020-03-29 00:00:00.000000"},
{"id":"997","title":"Son reality of in check mention call computer.","abstract":"This paper introduces a simple and computationally efficient algorithm for conversion formulae between moments and cumulants. The algorithm provides just one formula for classical, boolean and free cumulants. This is realized by using a suitable polynomial representation of Abel polynomials. The algorithm relies on the classical umbral calculus, a symbolic language introduced by Rota and Taylor in 1994, that is particularly suited to be implemented by using software for symbolic computations. Here we give a MAPLE procedure. Comparisons with existing procedures, especially for conversions between moments and free cumulants, as well as examples of applications to some well-known distributions (classical and free) end the paper.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2015-11-11 00:00:00.000000"},
{"id":"998","title":"Similar describe agent magazine analysis include growth.","abstract":"The aim of this paper is to continue the study of sg-compact spaces. The class of sg-compact spaces is a proper subclass of the class of hereditarily compact spaces. In our paper we shall consider sg-compactness in product spaces. Our main result says that if a product space is sg-compact, then either all factor spaces are finite, or exactly one factor space is infinite and sg-compact and the remaining ones are finite and locally indiscrete.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2022-11-06 00:00:00.000000"},
{"id":"999","title":"Want door future try resource.","abstract":"We predict the stabilities of \\alpha-graphynes and their boron nitride analogues(\\alpha-BNyne), which are considered as competitors of graphene and two-dimensional hexagonal BN. Based on first-principles plane wave method, we investigated the stability and structural transformations of these materials at different sizes using phonon dispersion calculations and ab-initio finite temperature, molecular dynamics simulations. Depending on the number of additional atoms in the edges between the corner atoms of the hexagons, n, both \\alpha-graphyne(n) and \\alpha-BNyne(n) are stable for even n, but unstable for odd n. \\alpha-graphyne(3) undergoes a structural transformation, where the symmetry of hexagons is broken. We present the structure optimized cohesive energies, electronic, magnetic and mechanical properties of stable structures. Our calculations reveal the existence of Dirac cones in the electronic structures of \\alpha-graphynes of all sizes, where the Fermi velocities decrease with increasing n. The electronic and magnetic properties of these structures are modified by hydrogenation. A single hydrogen vacancy renders a magnetic moment of one Bohr magneton. We finally present the properties of the bilayer \\alpha-graphyne and \\alpha-BNyne structures. We expect that these layered materials can function as frameworks in various chemical and electronic applications.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2015-01-25 00:00:00.000000"},
{"id":"1000","title":"Record maintain loss majority.","abstract":"This paper introduces the Partition Tree Weighting technique, an efficient meta-algorithm for piecewise stationary sources. The technique works by performing Bayesian model averaging over a large class of possible partitions of the data into locally stationary segments. It uses a prior, closely related to the Context Tree Weighting technique of Willems, that is well suited to data compression applications. Our technique can be applied to any coding distribution at an additional time and space cost only logarithmic in the sequence length. We provide a competitive analysis of the redundancy of our method, and explore its application in a variety of settings. The order of the redundancy and the complexity of our algorithm matches those of the best competitors available in the literature, and the new algorithm exhibits a superior complexity-performance trade-off in our experiments.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2021-09-06 00:00:00.000000"},
{"id":"1001","title":"Marriage dinner significant live interesting claim.","abstract":"We investigate light propagation through materials with periodically modulated gain\/loss profile in both transverse and longitudinal directions, i.e. in material with two-dimensional modulation in space. We predict effects of self-collimation (diffraction-free propagation) of the beams, as well as superdiffusion (spatial frequency filtering) of the beams in depending on the geometry of the gain\/loss lattice, and justify the predictions by numerical simulations of the paraxial wave propagation equations.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2016-11-07 00:00:00.000000"},
{"id":"1002","title":"Scene education pay.","abstract":"In this paper, we will give a complete geometric background for the geometry of Painlev\\'e $VI$ and Garnier equations. By geometric invariant theory, we will construct a smooth coarse moduli space $M_n^{\\balpha}(\\bt, \\blambda, L) $ of stable parabolic connection on $\\BP^1$ with logarithmic poles at $D(\\bt) = t_1 + ... + t_n$ as well as its natural compactification. Moreover the moduli space $\\cR(\\cP_{n, \\bt})_{\\ba}$ of Jordan equivalence classes of $SL_2(\\C)$-representations of the fundamental group $\\pi_1(\\BP^1 \\setminus D(\\bt),\\ast)$ are defined as the categorical quotient. We define the Riemann-Hilbert correspondence $\\RH: M_n^{\\balpha}(\\bt, \\blambda, L) \\lra \\cR(\\cP_{n, \\bt})_{\\ba}$ and prove that $\\RH$ is a bimeromorphic proper surjective analytic map. Painlev\\'e and Garnier equations can be derived from the isomonodromic flows and Painlev\\'e property of these equations are easily derived from the properties of $\\RH$. We also prove that the smooth parts of both moduli spaces have natural symplectic structures and $\\RH$ is a symplectic resolution of singularities of $\\cR(\\cP_{n, \\bt})_{\\ba}$, from which one can give geometric backgrounds for other interesting phenomena, like Hamiltonian structures, B\\\"acklund transformations, special solutions of these equations.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2018-12-01 00:00:00.000000"},
{"id":"1003","title":"Cut heavy spring be ten mission.","abstract":"In microwaves, a TE-polarized rectangular-waveguide resonator with an inserted thin ferrite disk gives an example of a nonintegrable system. The interplay of reflection and transmission at the disk interfaces together with the material gyrotropy effect gives rise to whirlpool-like electromagnetic vortices in the proximity of the ferromagnetic resonance. Based on numerical simulation, we show that a character of microwave vortices in a cavity can be analyzed by means of consideration of equivalent magnetic currents. Maxwell equations allows introduction of a magnetic current as a source of the electromagnetic field. Specifically, we found that in such nonintegrable structures, magnetic gyrotropy and geometrical factors leads to the effect of symmetry breaking resulting in effective chiral magnetic currents and topological magnetic charges. As an intriguing fact, one can observe precessing behavior of the electric-dipole polarization inside a ferrite disk.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2017-07-13 00:00:00.000000"},
{"id":"1004","title":"Boy trip others thank.","abstract":"We consider scheduling problems in wireless networks with respect to flexible data rates. That is, more or less data can be transmitted per time depending on the signal quality, which is determined by the signal-to-interference-plus-noise ratio (SINR). Each wireless link has a utility function mapping SINR values to the respective data rates. We have to decide which transmissions are performed simultaneously and (depending on the problem variant) also which transmission powers are used.   In the capacity-maximization problem, one strives to maximize the overall network throughput, i.e., the summed utility of all links. For arbitrary utility functions (not necessarily continuous ones), we present an O(log n)-approximation when having n communication requests. This algorithm is built on a constant-factor approximation for the special case of the respective problem where utility functions only consist of a single step. In other words, each link has an individual threshold and we aim at maximizing the number of links whose threshold is satisfied. On the way, this improves the result in [Kesselheim, SODA 2011] by not only extending it to individual thresholds but also showing a constant approximation factor independent of assumptions on the underlying metric space or the network parameters.   In addition, we consider the latency-minimization problem. Here, each link has a demand, e.g., representing an amount of data. We have to compute a schedule of shortest possible length such that for each link the demand is fulfilled, that is the overall summed utility (or data transferred) is at least as large as its demand. Based on the capacity-maximization algorithm, we show an O(log^2 n)-approximation for this problem.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2016-02-07 00:00:00.000000"},
{"id":"1005","title":"Bank consumer understand success trouble.","abstract":"Photoionization spectroscopy of cold cesium dimers obtained by photoassociation of cold atoms in a magneto-optical trap is reported here. In particular, we report on the observation and on the spectroscopic analysis of all the excited states that have actually been used for efficient detection of cold molecules stabilized in the triplet a^3Sigma_u^+ ground state. They are: the (1)^3Sigma_g^+ state connected to the 6s+6p asymptote, the (2)^3Sigma_g^+ and (2)^3Pi_g states connected to the 6s+5d asymptote and finally the (3)^3Sigma_g^+ state connected to the 6s + 7s asymptote. The detection through these states spans a wide range of laser energies, from 8000 to 16500 cm-1, obtained with different laser dyes and techniques. Information on the initial distribution of cold molecules among the different vibrational levels of the a^3Sigma_u^+ ground state is also provided. This spectroscopic knowledge is important when conceiving schemes for quantum manipulation, population transfer and optical detection of cold cesium molecules.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2022-09-22 00:00:00.000000"},
{"id":"1006","title":"Learn pattern man lawyer free again discuss.","abstract":"In this paper we present a technique for the precise measurement of electric dipole allowed transitions in trapped ions. By applying a probe and a cooling laser in quick succession, the full transition can be probed without causing distortion from heating the ion. In addition, two probes can be utilized to measure a dispersion-like signal, which is well suited to stabilizing the laser to the transition. We have fully characterized the parameters for the measurement and find that it is possible to measure the transition frequency to better than 100kHz with an interrogation time of 30s. The long-term stability of the spectroscopy signal is determined by employing two independent ion trap systems. The first ion trap is used to stabilize the spectroscopy laser. The second ion trap is then employed to measure the stability by continuously probing the transition at two frequencies. From the Allan variance a frequency instability of better than 10$^{-10}$ is obtained for an interrogation time of 1000s.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2022-12-07 00:00:00.000000"},
{"id":"1007","title":"Add out after article shoulder why.","abstract":"We propose methods to release and analyze synthetic graphs in order to protect privacy of individual relationships captured by the social network. Proposed techniques aim at fitting and estimating a wide class of exponential random graph models (ERGMs) in a differentially private manner, and thus offer rigorous privacy guarantees. More specifically, we use the randomized response mechanism to release networks under $\\epsilon$-edge differential privacy. To maintain utility for statistical inference, treating the original graph as missing, we propose a way to use likelihood based inference and Markov chain Monte Carlo (MCMC) techniques to fit ERGMs to the produced synthetic networks. We demonstrate the usefulness of the proposed techniques on a real data example.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2017-09-06 00:00:00.000000"},
{"id":"1008","title":"Best wind fall thing form eye.","abstract":"Let $\\BS_1,...,\\BS_n$ be independent identically distributed random variables each having the standardized Bernoulli distribution with parameter $p\\in(0,1)$. Let $m_*(p):=(1+p+2p^2)\/(2\\sqrt{p-p^2}+4p^2)$ if $0<p\\le 1\/2$ and $m_*(p):=1$ if $1\/2\\le p<1$. Let $m\\ge m_*(p)$. Let $f$ be such a function that $f$ and $f''$ are nondecreasing and convex. Then it is proved that for all nonnegative numbers $c_1,...,c_n$ one has the inequality $$\\E f(c_1\\BS_1+...+c_n\\BS_n)\\le\\E f(s^{(m)}\\cdot(\\BS_1+...+\\BS_n)),$$ where $s^{(m)}:=(\\frac1n \\sum_{i=1}^n c_i^{2m})^\\frac1{2m}$. The lower bound $m_*(p)$ on $m$ is exact for each $p\\in(0,1)$. Moreover, $\\E f(c_1\\BS_1+...+c_n\\BS_n)$ is Schur-concave in $(c_1^{2m},...,c_n^{2m})$. A number of related results are presented, including ones for the ``symmetric'' case.   A number of corollaries are obtained, including upper bounds on generalized moments and tail probabilities of (super)martingales with differences of bounded asymmetry, and also upper bounds on the maximal function of such (super)martingales. It is shown that these results may be important in certain statistical applications.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2015-09-20 00:00:00.000000"},
{"id":"1009","title":"Front course after choose sport recently.","abstract":"Hilbert algebras with supremum, i.e., Hilbert algebras where the associated order is a join-semilattice were first considered by A.V. Figallo, G. Ramon and S. Saad in [11], and independently by S. Celani and D. Montangie in [7].   On the other hand, L. Monteiro introduced the notion of n-valued Hilbert algebras (see [12]). In this work, we investigate the class of n-valued Hilbert algebras with supremum, denoted Hn, i.e., n-valued Hilbert algebras where the associated order is a join-semilattice. The varieties Hn are generated by finite chains. The free Hn-algebra Freen+1(r) with r generators is studied. In particular, we determine an upper bound to the cardinal of the finitely generated free algebra Freen+1(r).","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2019-09-05 00:00:00.000000"},
{"id":"1010","title":"Light school someone.","abstract":"The Cellular Potts Model (CPM) is a robust, cell-level methodology for simulation of biological tissues and morphogenesis. Both tissue physiology and morphogenesis depend on diffusion of chemical morphogens in the extra-cellular fluid or matrix (ECM). Standard diffusion solvers applied to the cellular potts model use finite difference methods on the underlying CPM lattice. However, these methods produce a diffusing field tied to the underlying lattice, which is inaccurate in many biological situations in which cell or ECM movement causes advection rapid compared to diffusion. Finite difference schemes suffer numerical instabilities solving the resulting advection-diffusion equations. To circumvent these problems we simulate advection-diffusion within the framework of the CPM using off-lattice finite-difference methods. We define a set of generalized fluid particles which detach advection and diffusion from the lattice. Diffusion occurs between neighboring fluid particles by local averaging rules which approximate the Laplacian. Directed spin flips in the CPM handle the advective movement of the fluid particles. A constraint on relative velocities in the fluid explicitly accounts for fluid viscosity. We use the CPM to solve various diffusion examples including multiple instantaneous sources, continuous sources, moving sources and different boundary geometries and conditions to validate our approximation against analytical and established numerical solutions. We also verify the CPM results for Poiseuille flow and Taylor-Aris dispersion.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2019-07-01 00:00:00.000000"},
{"id":"1011","title":"Bar individual company bill.","abstract":"The interaction of 32.5 and 6 nm ultrashort X-ray pulses with the solid materials B4C, SiC and Si is simulated with a non-local thermodynamic equilibrium (NLTE) radiation transfer code. We study the ionization dynamics as function of depth in the material, modifications of the opacity during irradiation and estimate crater depth. Furthermore, we compare the estimated crater depth with experimental data, for fluences up to 2.2 J\/cm2. Our results show that at 32.5 nm irradiation, the opacity changes with less than a factor of 2 for B4C and Si and a factor of 3 for SiC, for fluences up to 200 J\/cm2. At a laser wavelength of 6 nm, the model predicts a dramatic decrease in opacity due to the weak inverse bremsstrahlung, increasing the crater depth for high fluences.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2019-03-21 00:00:00.000000"},
{"id":"1012","title":"Us friend bank only here.","abstract":"Current situation in studies of mean lifetimes of excited electronic-vibro-rotational states of hydrogen molecule (including the H2, D2, HD and T2 isotopomers) is reviewed in brief. All measured values of the lifetimes (published before November 2008) are collected and presented in tabular form. Complete bibliography of papers devoted to semi-empirical determination and non-empirical calculation of the lifetimes is presented. The experimental data obtained in various papers are compared with the results of semi-empirical determination and non-empirical calculations.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2020-11-28 00:00:00.000000"},
{"id":"1013","title":"Year hundred somebody east point.","abstract":"A generalized continuity equation extending the ordinary continuity equation has been found using quanternions. It is shown to be compatible with Dirac, Schrodinger, Klein-Gordon and diffusion equations. This generalized equation is Lorentz invariant. The transport properties of electrons are found to be governed by Schrodinger-like equation and not by the diffusion equation.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2016-12-24 00:00:00.000000"},
{"id":"1014","title":"Quality detail kind include alone.","abstract":"It is shown that MS Fortran-77 compilers allow to construct recursive subroutines. The recursive one-dimensional adaptive quadrature subroutine is considered in particular. Despite its extremely short body (only eleven executable statements) the subroutine proved to be very effective and competitive. It was tested on various rather complex integrands. The possibility of function calls number minimization by choosing the optimal number of Gaussian abscissas is considered. The proposed recursive procedure can be effectively applied for creating more sophisticated quadrature codes (one- or multi-dimensional) and easily incorporated into existing programs.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2019-06-17 00:00:00.000000"},
{"id":"1015","title":"Lot huge set understand become.","abstract":"It is known that the only Stein filling of the standard contact structure on S^3 is B^4. In this paper, we construct simply connected exotic compact Stein 4-manifold pairs for any Betti number $b_2 \\geq 1$; we do this by enlarging corks and plugs.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2016-11-19 00:00:00.000000"},
{"id":"1016","title":"Collection anyone education anything sell.","abstract":"The pairwise reachability problem for a multi-threaded program asks, given control locations in two threads, whether they can be simultaneously reached in an execution of the program. The problem is important for static analysis and is used to detect statements that are concurrently enabled. This problem is in general undecidable even when data is abstracted and when the threads (with recursion) synchronize only using a finite set of locks. Popular programming paradigms that limit the lock usage patterns have been identified under which the pairwise reachability problem becomes decidable. In this paper, we consider a new natural programming paradigm, called contextual locking, which ties the lock usage to calling patterns in each thread: we assume that locks are released in the same context that they were acquired and that every lock acquired by a thread in a procedure call is released before the procedure returns. Our main result is that the pairwise reachability problem is polynomial-time decidable for this new programming paradigm as well. The problem becomes undecidable if the locks are reentrant; reentrant locking is a \\emph{recursive locking} mechanism which allows a thread in a multi-threaded program to acquire the reentrant lock multiple times.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2020-02-05 00:00:00.000000"},
{"id":"1017","title":"Hope agency large science leader community customer.","abstract":"We present a method which displays all palindromes of a given length from De Bruijn words of a certain order, and also a recursive one which constructs all palindromes of length $n+1$ from the set of palindromes of length $n$. We show that the palindrome complexity function, which counts the number of palindromes of each length contained in a given word, has a different shape compared with the usual (subword) complexity function. We give upper bounds for the average number of palindromes contained in all words of length $n$, and obtain exact formulae for the number of palindromes of length 1 and 2 contained in all words of length $n$.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2021-08-06 00:00:00.000000"},
{"id":"1018","title":"Church program wish serve toward.","abstract":"The positive interpoint distances of n=p+1>1 points in dimension p are equal if and only if their sample covariance matrix is a scalar multiple of the identity.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2015-06-09 00:00:00.000000"},
{"id":"1019","title":"Pay party cup middle.","abstract":"Many real world problems naturally appear as constraints satisfaction problems (CSP), for which very efficient algorithms are known. Most of these involve the combination of two techniques: some direct propagation of constraints between variables (with the goal of reducing their sets of possible values) and some kind of structured search (depth-first, breadth-first,...). But when such blind search is not possible or not allowed or when one wants a 'constructive' or a 'pattern-based' solution, one must devise more complex propagation rules instead. In this case, one can introduce the notion of a candidate (a 'still possible' value for a variable). Here, we give this intuitive notion a well defined logical status, from which we can define the concepts of a resolution rule and a resolution theory. In order to keep our analysis as concrete as possible, we illustrate each definition with the well known Sudoku example. Part I proposes a general conceptual framework based on first order logic; with the introduction of chains and braids, Part II will give much deeper results.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2017-06-02 00:00:00.000000"},
{"id":"1020","title":"Probably difficult fund animal their trouble certainly.","abstract":"We provide faster algorithms for the problem of Gaussian summation, which occurs in many machine learning methods. We develop two new extensions - an O(Dp) Taylor expansion for the Gaussian kernel with rigorous error bounds and a new error control scheme integrating any arbitrary approximation method - within the best discretealgorithmic framework using adaptive hierarchical data structures. We rigorously evaluate these techniques empirically in the context of optimal bandwidth selection in kernel density estimation, revealing the strengths and weaknesses of current state-of-the-art approaches for the first time. Our results demonstrate that the new error control scheme yields improved performance, whereas the series expansion approach is only effective in low dimensions (five or less).","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2019-04-09 00:00:00.000000"},
{"id":"1021","title":"However cover meeting theory together responsibility fund.","abstract":"Given an exact symplectic manifold M and a support Lagrangian \\Lambda, we construct an infinity-category Lag, which we conjecture to be equivalent (after specialization of the coefficients) to the partially wrapped Fukaya category of M relative to \\Lambda. Roughly speaking, the objects of Lag are Lagrangian branes inside of M x T*(R^n), for large n, and the morphisms are Lagrangian cobordisms that are non-characteristic with respect to \\Lambda. The main theorem of this paper is that Lag is a stable infinity-category, so that its homotopy category is triangulated, with mapping cones given by an elementary construction. In particular, its shift functor is equivalent to the familiar shift of grading for Lagrangian branes.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2022-12-18 00:00:00.000000"},
{"id":"1022","title":"Reason phone identify state.","abstract":"In this work we classify the at-point regularities of set-valued mappings into two categories and then we analyze their relationship through several implications and examples. After this theoretical tour, we use the subregularity properties to deduce implicit theorems for set-valued maps. Finally, we present some applications to the study of multicriteria optimization problems.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2019-12-18 00:00:00.000000"},
{"id":"1023","title":"Fast I everything service wrong.","abstract":"Cantor's algebraic calculation of the power of the continuum contains an easily repairable error related to Cantor own way of defining the addition of cardinal numbers. The appropriate correction is suggested.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2022-09-25 00:00:00.000000"},
{"id":"1024","title":"Could pull explain difference hold.","abstract":"A new method for the computation of the posterior distribution of the number k of components in a finite mixture is presented. Two aspects of prior specification are also studied: an argument is made for the use of a Poisson(1) distribution as the prior for k; and methods are given for the selection of hyperparameter values in the mixture of normals model, with natural conjugate priors on the components parameters.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2017-04-27 00:00:00.000000"},
{"id":"1025","title":"Their according smile treatment quite.","abstract":"This is a survey paper on the space of symplectic structures on closed 4-manifolds, for the Proceedings ICCM 2004","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2015-12-06 00:00:00.000000"},
{"id":"1026","title":"Well open project bag involve during he international.","abstract":"Collective motion of self-propelled organisms or synthetic particles often termed active fluid has attracted enormous attention in broad scientific community because of it fundamentally non-equilibrium nature. Energy input and interactions among the moving units and the medium lead to complex dynamics. Here we introduce a new class of active matter, living liquid crystals (LLCs) that combine living swimming bacteria with a lyotropic liquid crystal. The physical properties of LLCs can be controlled by the amount of oxygen available to bacteria, by concentration of ingredients, or by temperature. Our studies reveal a wealth of new intriguing dynamic phenomena, caused by the coupling between the activity-triggered flow and long-range orientational order of the medium. Among these are (a) non-linear trajectories of bacterial motion guided by non-uniform director, (b) local melting of the liquid crystal caused by the bacteria-produced shear flows, (c) activity-triggered transition from a non-flowing uniform state into a flowing one-dimensional periodic pattern and its evolution into a turbulent array of topological defects, (d) birefringence-enabled visualization of microflow generated by the nanometers-thick bacterial flagella. Unlike their isotropic counterpart, the LLCs show collective dynamic effects at very low volume fraction of bacteria, on the order of 0.2%. Our work suggests an unorthodox design concept to control and manipulate the dynamic behavior of soft active matter and opens the door for potential biosensing and biomedical applications.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2021-07-03 00:00:00.000000"},
{"id":"1027","title":"Off community teacher cover drop that leg.","abstract":"In this paper, a new neuronal circuit, based on the spiking neuronal network model, is proposed in order to detect the movement direction of dynamic objects wandering around cognitive robots. Capability of our new approach in bi-directional movement detection is beholden to its symmetric configuration of the proposed circuit. With due attention to magnificence of handling of blocking problems in neuronal networks such as epilepsy, mounting both excitatory and inhibitory stimuli has been taken into account. Investigations upon applied implementation of aforementioned strategy on PIONEER cognitive robot reveals that the strategy leads to alleviation of potential level in the sensory networks. Furthermore, investigation on intrinsic delay of the circuit reveals not only the noticeable switching rate which could be acquired but the high-efficient coupling of the circuit with the other high-speed ones.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2019-03-22 00:00:00.000000"},
{"id":"1028","title":"Door thus almost protect raise.","abstract":"Numerical issues arising in computations of viscous flows in corners formed by a liquid-fluid free surface and a solid boundary are considered. It is shown that on the solid a Dirichlet boundary condition, which removes multivaluedness of velocity in the `moving contact-line problem' and gives rise to a logarithmic singularity of pressure, requires a certain modification of the standard finite-element method. This modification appears to be insufficient above a certain critical value of the corner angle where the numerical solution becomes mesh-dependent. As shown, this is due to an eigensolution, which exists for all angles and becomes dominant for the supercritical ones. A method of incorporating the eigensolution into the numerical method is described that makes numerical results mesh-independent again. Some implications of the unavoidable finiteness of the mesh size in practical applications of the finite element method in the context of the present problem are discussed.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2020-04-26 00:00:00.000000"},
{"id":"1029","title":"Church show save worker wrong.","abstract":"Markov networks are models for compactly representing complex probability distributions. They are composed by a structure and a set of numerical weights. The structure qualitatively describes independences in the distribution, which can be exploited to factorize the distribution into a set of compact functions. A key application for learning structures from data is to automatically discover knowledge. In practice, structure learning algorithms focused on \"knowledge discovery\" present a limitation: they use a coarse-grained representation of the structure. As a result, this representation cannot describe context-specific independences. Very recently, an algorithm called CSPC was designed to overcome this limitation, but it has a high computational complexity. This work tries to mitigate this downside presenting CSGS, an algorithm that uses the Grow-Shrink strategy for reducing unnecessary computations. On an empirical evaluation, the structures learned by CSGS achieve competitive accuracies and lower computational complexity with respect to those obtained by CSPC.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2016-09-24 00:00:00.000000"},
{"id":"1030","title":"Face owner include financial thousand receive structure.","abstract":"We demonstrate a new class of hollow-core Bragg fibers that are composed of concentric cylindrical silica rings separated by nanoscale support bridges. We theoretically predict and experimentally observe hollow-core confinement over an octave frequency range. The bandwidth of bandgap guiding in this new class of Bragg fibers exceeds that of other hollow-core fibers reported in the literature. With only three rings of silica cladding layers, these Bragg fibers achieve propagation loss of the order of 1 dB\/m.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2018-10-17 00:00:00.000000"},
{"id":"1031","title":"Onto send main idea property kitchen trade.","abstract":"This paper is about three classes of objects: Leonard triples, distance-regular graphs and the modules for the anticommutator spin algebra. Let $\\K$ denote an algebraically closed field of characteristic zero. Let $V$ denote a vector space over $\\K$ with finite positive dimension. A Leonard triple on $V$ is an ordered triple of linear transformations in $\\mathrm{End}(V)$ such that for each of these transformations there exists a basis for $V$ with respect to which the matrix representing that transformation is diagonal and the matrices representing the other two transformations are irreducible tridiagonal. The Leonard triples of interest to us are said to be totally B\/AB and of Bannai\/Ito type.   Totally B\/AB Leonard triples of Bannai\/Ito type arise in conjunction with the anticommutator spin algebra $\\mathcal{A}$, the unital associative $\\K$-algebra defined by generators $x,y,z$ and relations\\[xy+yx=2z,\\qquad yz+zy=2x,\\qquad zx+xz=2y.\\]   Let $D\\geq0$ denote an integer, let $Q_{D}$ denote the hypercube of diameter $D$ and let $\\tilde{Q}_{D}$ denote the antipodal quotient. Let $T$ (resp. $\\tilde{T}$) denote the Terwilliger algebra for $Q_{D}$ (resp. $\\tilde{Q}_{D}$).   We obtain the following. When $D$ is even (resp. odd), we show that there exists a unique $\\mathcal{A}$-module structure on $Q_{D}$ (resp. $\\tilde{Q}_{D}$) such that $x,y$ act as the adjacency and dual adjacency matrices respectively. We classify the resulting irreducible $\\mathcal{A}$-modules up to isomorphism. We introduce weighted adjacency matrices for $Q_{D}$, $\\tilde{Q}_{D}$. When $D$ is even (resp. odd) we show that actions of the adjacency, dual adjacency and weighted adjacency matrices for $Q_{D}$ (resp. $\\tilde{Q}_{D}$) on any irreducible $T$-module (resp. $\\tilde{T}$-module) form a totally bipartite (resp. almost bipartite) Leonard triple of Bannai\/Ito type and classify the Leonard triple up to isomorphism.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2019-10-02 00:00:00.000000"},
{"id":"1032","title":"Side actually cultural every probably imagine about then.","abstract":"The FEAST method for solving large sparse eigenproblems is equivalent to subspace iteration with an approximate spectral projector and implicit orthogonalization. This relation allows to characterize the convergence of this method in terms of the error of a certain rational approximant to an indicator function. We propose improved rational approximants leading to FEAST variants with faster convergence, in particular, when using rational approximants based on the work of Zolotarev. Numerical experiments demonstrate the possible computational savings especially for pencils whose eigenvalues are not well separated and when the dimension of the search space is only slightly larger than the number of wanted eigenvalues. The new approach improves both convergence robustness and load balancing when FEAST runs on multiple search intervals in parallel.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2018-07-11 00:00:00.000000"},
{"id":"1033","title":"Visit strategy available month dream school hit father.","abstract":"We consider semi-classical Schr{\\\"o}dinger operator $ P(h)=-h^2\\Delta +V(x)$ in ${\\mathbb R}^n$ such that the analytic potential $V$ has a non-degenerate critical point $x_0=0$ with critical value $E_0$ and we can define resonances in some fixed neighborhood of $E_0$ when $h>0$ is small enough. If the eigenvalues of the Hessian are $\\zz$-independent the resonances in $h^\\delta$-neighborhood of $E_0$ ($\\delta >0$) can be calculated explicitly as the eigenvalues of the semi-classical Birkhoff normal form. Assuming that potential is symmetric with respect to reflections about the coordinate axes we show that the classical Birkhoff normal form determines the Taylor series of the potential at $x_0.$ As a consequence, the resonances in a $h^\\delta$-neighborhood of $E_0$ determine the first $N$ terms in the Taylor series of $V$ at $x_0.$ The proof uses the recent inverse spectral results of V. Guillemin and A. Uribe.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2020-11-22 00:00:00.000000"},
{"id":"1034","title":"Lose dog listen meet management community notice.","abstract":"In order to generate synthetic basket data sets for better benchmark testing, it is important to integrate characteristics from real-life databases into the synthetic basket data sets. The characteristics that could be used for this purpose include the frequent itemsets and association rules. The problem of generating synthetic basket data sets from frequent itemsets is generally referred to as inverse frequent itemset mining. In this paper, we show that the problem of approximate inverse frequent itemset mining is {\\bf NP}-complete. Then we propose and analyze an approximate algorithm for approximate inverse frequent itemset mining, and discuss privacy issues related to the synthetic basket data set. In particular, we propose an approximate algorithm to determine the privacy leakage in a synthetic basket data set.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2019-12-28 00:00:00.000000"},
{"id":"1035","title":"State color study church power little of.","abstract":"Many mathematicians encounter k-to-1 maps only in the study of covering maps. But, of course, k-to-1 maps do not have to be open. This paper touches on covering maps, and simple maps, but concentrates on ordinary k-to-1 functions (both continuous and finitely discontinuous) from one metric continuum to another. New results, old results and ideas for further research are given; and a baker's dozen of questions are raised.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2015-11-23 00:00:00.000000"},
{"id":"1036","title":"Experience many Republican imagine answer picture expect.","abstract":"Given an i.i.d. sample from a distribution $F$ on $\\mathbb{R}$ with uniformly continuous density $p_0$, purely data-driven estimators are constructed that efficiently estimate $F$ in sup-norm loss and simultaneously estimate $p_0$ at the best possible rate of convergence over H\\\"older balls, also in sup-norm loss. The estimators are obtained by applying a model selection procedure close to Lepski's method with random thresholds to projections of the empirical measure onto spaces spanned by wavelets or $B$-splines. The random thresholds are based on suprema of Rademacher processes indexed by wavelet or spline projection kernels. This requires Bernstein-type analogs of the inequalities in Koltchinskii [Ann. Statist. 34 (2006) 2593-2656] for the deviation of suprema of empirical processes from their Rademacher symmetrizations.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2019-03-10 00:00:00.000000"},
{"id":"1037","title":"Crime left rather woman behavior prepare candidate.","abstract":"It is well known that to determine a triangle up to congruence requires three measurements: three sides, two sides and the included angle, or one side and two angles. We consider various generalizations of this fact to two and three dimensions. In particular we consider the following question: given a convex polyhedron $P$, how many measurements are required to determine $P$ up to congruence?   We show that in general the answer is that the number of measurements required is equal to the number of edges of the polyhedron. However, for many polyhedra fewer measurements suffice; in the case of the unit cube we show that nine carefully chosen measurements are enough.   We also prove a number of analogous results for planar polygons. In particular we describe a variety of quadrilaterals, including all rhombi and all rectangles, that can be determined up to congruence with only four measurements, and we prove the existence of $n$-gons requiring only $n$ measurements. Finally, we show that one cannot do better: for any sequence of $n$ distinct points in the plane one needs at least $n$ measurements to determine it up to congruence.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2015-05-07 00:00:00.000000"},
{"id":"1038","title":"State natural budget prevent.","abstract":"We find a system of two polynomial equations in two unknowns, whose solution allows to give an explicit expression of the conformal representation of a simply connected three sheeted compact Riemann surface onto the extended complex plane. This function appears in the description of the ratio asymptotic of multiple orthogonal polynomials with respect to so called Nikishin systems of two measures.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2017-05-29 00:00:00.000000"},
{"id":"1039","title":"Whether American water pressure.","abstract":"Here we describe work on learning the subcategories of verbs in a morphologically rich language using only minimal linguistic resources. Our goal is to learn verb subcategorizations for Quechua, an under-resourced morphologically rich language, from an unannotated corpus. We compare results from applying this approach to an unannotated Arabic corpus with those achieved by processing the same text in treebank form. The original plan was to use only a morphological analyzer and an unannotated corpus, but experiments suggest that this approach by itself will not be effective for learning the combinatorial potential of Arabic verbs in general. The lower bound on resources for acquiring this information is somewhat higher, apparently requiring a a part-of-speech tagger and chunker for most languages, and a morphological disambiguater for Arabic.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2022-06-28 00:00:00.000000"},
{"id":"1040","title":"Firm get control town push page crime.","abstract":"A number of settings arise in which it is of interest to predict Principal Component (PC) scores for new observations using data from an initial sample. In this paper, we demonstrate that naive approaches to PC score prediction can be substantially biased toward 0 in the analysis of large matrices. This phenomenon is largely related to known inconsistency results for sample eigenvalues and eigenvectors as both dimensions of the matrix increase. For the spiked eigenvalue model for random matrices, we expand the generality of these results, and propose bias-adjusted PC score prediction. In addition, we compute the asymptotic correlation coefficient between PC scores from sample and population eigenvectors. Simulation and real data examples from the genetics literature show the improved bias and numerical properties of our estimators.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2016-06-10 00:00:00.000000"},
{"id":"1041","title":"Less while such industry own think worker.","abstract":"In this paper we consider the classical maximum set packing problem where set cardinality is upper bounded by $k$. We show how to design a variant of a polynomial-time local search algorithm with performance guarantee $(k+2)\/3$. This local search algorithm is a special case of a more general procedure that allows to swap up to $\\Theta(\\log n)$ elements per iteration. We also design problem instances with locality gap $k\/3$ even for a wide class of exponential time local search procedures, which can swap up to $cn$ elements for a constant $c$. This shows that our analysis of this class of algorithms is almost tight.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2017-07-07 00:00:00.000000"},
{"id":"1042","title":"Top rather large.","abstract":"This paper gives a survey on the current state of Web Service Compositions and the difficulties and solutions to automated Web Service Compositions. This first gives a definition of Web Service Composition and the motivation and goal of it. It then explores into why we need automated Web Service Compositions and formally defines the domains. Techniques and solutions are proposed by the papers we surveyed to solve the current difficulty of automated Web Service Composition. Verification and future work is discussed at the end to further extend the topic.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2015-10-10 00:00:00.000000"},
{"id":"1043","title":"Onto control street after.","abstract":"It is known that all $k$-homogeneous orthogonally additive polynomials $P$ over $C(K)$ are of the form $$ P(x)=\\int_K x^k d\\mu . $$ Thus $x\\mapsto x^k$ factors all orthogonally additive polynomials through some linear form $\\mu$. We show that no such linearization is possible without homogeneity. However, we also show that every orthogonally additive holomorphic functions of bounded type $f$ over $C(K)$ is of the form $$ f(x)=\\int_K h(x) d\\mu $$ for some $\\mu$ and holomorphic $h\\colon C(K) \\to L^1(\\mu)$ of bounded type.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2017-04-01 00:00:00.000000"},
{"id":"1044","title":"Take cup avoid want another.","abstract":"Power index research has been a very active field in the last decades. Will this continue or are all the important questions solved? We argue that there are still many opportunities to conduct useful research with and on power indices. Positive and normative questions keep calling for theoretical and empirical attention. Technical and technological improvements are likely to boost applicability.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2020-01-26 00:00:00.000000"},
{"id":"1045","title":"While spend against would.","abstract":"It is shown how the study of blackbody radiation in the early twentieth century by the German physicist Max Planck gave rise to the quantum theory.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2016-12-22 00:00:00.000000"},
{"id":"1046","title":"Lose final fish key.","abstract":"We study Linial-Meshulam random 2-complexes, which are two-dimensional analogues of Erd\\H{o}s-R\\'enyi random graphs. We find the threshold for simple connectivity to be p = n^{-1\/2}. This is in contrast to the threshold for vanishing of the first homology group, which was shown earlier by Linial and Meshulam to be p = 2 log(n)\/n. We use a variant of Gromov's local-to-global theorem for linear isoperimetric inequalities to show that when p = O(n^{-1\/2 -\\epsilon}) the fundamental group is word hyperbolic. Along the way we classify the homotopy types of sparse 2-dimensional simplicial complexes and establish isoperimetric inequalities for such complexes. These intermediate results do not involve randomness and may be of independent interest.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2015-07-27 00:00:00.000000"},
{"id":"1047","title":"Position vote would throughout follow television citizen.","abstract":"We present a method of computing genus zero two-point descendant Gromov-Witten invariants via one-point invariants. We apply our method to recover some of calculations of Zinger and Popa-Zinger, as well as to obtain new calculations of two-point descendant invariants.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2015-07-26 00:00:00.000000"},
{"id":"1048","title":"Everything firm religious employee pick TV identify station.","abstract":"Ramachandran (1969, Theorem 8) has shown that for any univariate infinitely divisible distribution and any positive real number $\\alpha$, an absolute moment of order $\\alpha$ relative to the distribution exists (as a finite number) if and only if this is so for a certain truncated version of the corresponding L$\\acute{\\rm e}$vy measure. A generalized version of this result in the case of multivariate infinitely divisible distributions, involving the concept of g-moments, is given by Sato (1999, Theorem 25.3). We extend Ramachandran's theorem to the multivariate case, keeping in mind the immediate requirements under appropriate assumptions of cumulant studies of the distributions referred to; the format of Sato's theorem just referred to obviously varies from ours and seems to be having a different agenda. Also, appealing to a further criterion based on the L$\\acute{\\rm e}$vy measure, we identify in a certain class of multivariate infinitely divisible distributions the distributions that are self-decomposable; this throws new light on structural aspects of certain multivariate distributions such as the multivariate generalized hyperbolic distributions studied by Barndorff-Nielsen (1977) and others. Various points of relevance to the study are also addressed through specific examples.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2022-01-14 00:00:00.000000"},
{"id":"1049","title":"Activity them ground radio though as.","abstract":"We present a method for the direct and continuous separation of red and white blood cells from plasma at the microscale. The method is implemented in a microfluidic system with magnetic functionality. The fluidic structure within the microsystem consists of an inlet and a single microfluidic channel with multiple outlets. The magnetic functionality is provided by an array of integrated soft-magnetic elements that are embedded transverse and adjacent to the microchannel. The elements are magnetized using an external field, and once magnetized they produce a magnetic force on blood cells as they flow through the microchannel. In whole blood, white blood cells (WBCs) behave as diamagnetic microparticles, while red blood cells (RBCs) exhibit diamagnetic or paramagnetic behavior depending on the oxygenation of their hemoglobin. We study the motion of blood cells through the microchannel using a mathematical model that takes into account the magnetic, fluidic and gravitational forces on the cells. We use the model to study blood cell separation, and our analysis indicates that the microsystem is capable of separating WBC-rich plasma, deoxygenated RBC-rich plasma and cell-depleted plasma into respective outlets.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2020-01-29 00:00:00.000000"},
{"id":"1050","title":"Early road consumer information relationship.","abstract":"In this paper, we are interested in the study of beta kernel estimators from an asymptotic minimax point of view. It is well known that beta kernel estimators are, on the contrary of classical kernel estimators, \"free of boundary effect\" and thus are very useful in practice. The goal of this paper is to prove that there is a price to pay: for very regular functions or for certain losses, these estimators are not minimax. Nevertheless they are minimax for classical regularities such as regularity of order two or less than two, supposed commonly in the practice and for some classical losses.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2022-08-24 00:00:00.000000"},
{"id":"1051","title":"For we trouble catch attorney everything to remember.","abstract":"A non-equilibrium plasma was studied using classical electrodynamic field theory. Non-linear interaction terms contribute to a finite lifetime for the dressed electrodynamic field. The lifetime exhibits a $\\sim n^{-1} T_{e}^{3\/2} T_{i}^{-2}T_{r}^{1\/2}$ dependence, where $n$ is the number density, $T_{e}$ is the electron temperature, $T_{i}$ is the ion temperature, and $T_{r}$ is the temperature of the radiation field. The resulting width of the plasmon resonance is shown to decrease as equilibrium is approached. Dynamic screening leads to opaqueness of the plasma for low energy electromagnetic radiation. This leads to a quadratic correction to the quartic Stefan-Boltzmann law. We also briefly discuss the effect of dynamic screening on fusion rates. Solitonic solutions to our non-linear wave equation allow localization of positive charges, which may enhance fusion rates.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2015-05-16 00:00:00.000000"},
{"id":"1052","title":"Structure stage take affect.","abstract":"A Legendrian or transverse knot in an overtwisted contact 3-manifold is non-loose if its complement is tight and loose if its complement is overtwisted. We define three measures of the extent of non-looseness of a non-loose knot and show they are distinct.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2021-01-12 00:00:00.000000"},
{"id":"1053","title":"Expect dinner Mr but respond certain school.","abstract":"Let {X(t)} be a stationary time series with a.e. positive spectrum. Two consequences of that the bispectrum of {X(t)} is real-valued but nonzero: 1) if {X(t)} is also linear, then it is reversible; 2) {X(t),} can not be causal linear. A corollary of the first statement: if {X(t)} is linear, and the skewness of X(0) is nonzero, then third order reversibility implies reversibility. In this paper the notion of bispectrum is of a broader scope.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2015-10-10 00:00:00.000000"},
{"id":"1054","title":"None hair process.","abstract":"The Lieb-Oxford bound is a constraint upon approximate exchange-correlation functionals. We explore a non-empirical tightening of that bound in both universal and electron-number-dependent form. The test functional is PBE. Regarding both atomization energies (slightly worsened) and bond lengths (slightly bettered), we find the PBE functional to be remarkably insensitive to the value of the Lieb-Oxford bound. This both rationalizes the use of the original Lieb-Oxford constant in PBE and suggests that enhancement factors more sensitive to sharpened constraints await discovery.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2021-06-27 00:00:00.000000"},
{"id":"1055","title":"City light church much.","abstract":"Ever since Flinders Petrie undertook a theodolite survey on the Giza plateau in 1881 and drew attention to the extraordinary degree of precision with which the three colossal pyramids are oriented upon the four cardinal directions, there have been a great many suggestions as to how this was achieved and why it was of importance. Surprisingly, given the many astronomical hypotheses and speculations that have been offered in the intervening 130 years, there have been remarkably few attempts to reaffirm or improve on the basic survey data concerning the primary orientations.   This paper presents the results of a week-long Total Station survey undertaken by the authors during December 2006 whose principal aim was to clarify the basic data concerning the orientation of each side of the three large pyramids and to determine, as accurately as possible, the orientations of as many as possible of the associated structures. The principal difference between this and all previous surveys is that it focuses upon measurements of sequences of points along multiple straight and relatively well preserved structural segments, with best-fit techniques being used to provide the best estimate of their orientation, as opposed to simple triangulation between directly identified or extrapolated corners.   Our results suggest that there is only a very slight difference in orientation (c. 0.5 arc minutes) between the north-south axes of Khufu's and Khafre's pyramids, that the sides of Khafre's are more perfectly perpendicular than those of Khufu's, and that the east-west axis is closer to true cardinality in both cases. The broader context of associated structures suggests that the east-west orientation in relation to sunrise or (in one case) sunset may have been a, or even the, key factor in many cases.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2019-05-01 00:00:00.000000"},
{"id":"1056","title":"Agency image give draw.","abstract":"Duistermaat introduced the concept of ``real locus'' of a Hamiltonian manifold. In that and in others' subsequent works, it has been shown that many of the techniques developed in the symplectic category can be used to study real loci, so long as the coefficient ring is restricted to the integers modulo 2. It turns out that these results seem not necessarily to depend on the ambient symplectic structure, but rather to be topological in nature. This observation prompts the definition of ``conjugation space'' in a paper of the two authors with V. Puppe. Our main theorem in this paper gives a simple criterion for recognizing when a topological space is a conjugation space.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2022-11-16 00:00:00.000000"},
{"id":"1057","title":"Consumer beat tree rise dark design.","abstract":"Total computational costs of scientific simulations are analyzed between direct numerical simulations (DNS) and multiphysics simulations (MPS) for sound generation in musical instruments. In order to produce acoustic sound by a turbulent flow in a simple recorder-like instrument, compressible fluid dynamic calculations with a low Mach number are required around the edges and the resonator of the instrument in DNS, while incompressible fluid dynamic calculations coupled with dynamics of sound propagation based on the Lighthill's acoustic analogy are used in MPS. These strategies are evaluated not only from the viewpoint of computational performances but also from the theoretical points of view as tools for scientific simulations of complicated systems.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2019-01-05 00:00:00.000000"},
{"id":"1058","title":"Republican relationship paper after southern wonder push.","abstract":"In the field of Business Process Management formal models for the control flow of business processes have been designed since more than 15 years. Which methods are best suited to verify the bulk of these models? The first step is to select a formal language which fixes the semantics of the models. We adopt the language of Boolean systems as reference language for Boolean process models. Boolean systems form a simple subclass of coloured Petri nets. Their characteristics are low tokens to model explicitly states with a subsequent skipping of activations and arbitrary logical rules of type AND, XOR, OR etc. to model the split and join of the control flow. We apply model checking as a verification method for the safeness and liveness of Boolean systems. Model checking of Boolean systems uses the elementary theory of propositional logic, no modal operators are needed. Our verification builds on a finite complete prefix of a certain T-system attached to the Boolean system. It splits the processes of the Boolean system into a finite set of base processes of bounded length. Their behaviour translates to formulas from propositional logic. Our verification task consists in checking the satisfiability of these formulas. In addition we have implemented our model checking algorithm as a java program. The time needed to verify a given Boolean system depends critically on the number of initial tokens. Because the algorithm has to solve certain SAT-problems, polynomial complexity cannot be expected. The paper closes with the model checking of some Boolean process models which have been designed as Event-driven Process Chains.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2021-07-17 00:00:00.000000"},
{"id":"1059","title":"Land present partner fly card set institution.","abstract":"Nested words are a structured model of execution paths in procedural programs, reflecting their call and return nesting structure. Finite nested words also capture the structure of parse trees and other tree-structured data, such as XML. We provide new temporal logics for finite and infinite nested words, which are natural extensions of LTL, and prove that these logics are first-order expressively-complete. One of them is based on adding a \"within\" modality, evaluating a formula on a subword, to a logic CaRet previously studied in the context of verifying properties of recursive state machines (RSMs). The other logic, NWTL, is based on the notion of a summary path that uses both the linear and nesting structures. For NWTL we show that satisfiability is EXPTIME-complete, and that model-checking can be done in time polynomial in the size of the RSM model and exponential in the size of the NWTL formula (and is also EXPTIME-complete). Finally, we prove that first-order logic over nested words has the three-variable property, and we present a temporal logic for nested words which is complete for the two-variable fragment of first-order.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2020-07-27 00:00:00.000000"},
{"id":"1060","title":"Keep phone relationship sing improve table.","abstract":"The dependency core calculus (DCC), a simple extension of the computational lambda calculus, captures a common notion of dependency that arises in many programming language settings. This notion of dependency is closely related to the notion of information flow in security; it is sensitive not only to data dependencies that cause explicit flows, but also to control dependencies that cause implicit flows. In this paper, we study variants of DCC in which the data and control dependencies are decoupled. This allows us to consider settings where a weaker notion of dependency---one that restricts only explicit flows---may usefully coexist with DCC's stronger notion of dependency. In particular, we show how strong, noninterference-based security may be reconciled with weak, trace-based security within the same system, enhancing soundness of the latter and completeness of the former.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2015-12-18 00:00:00.000000"},
{"id":"1061","title":"Similar yes speak send education trip finally according.","abstract":"Using the principle of causality as expressed in the Kramers-Kronig relations, we derive a generalized criterion for a negative refractive index that admits imperfect transparency at an observation frequency $\\omega$. It also allows us to relate the global properties of the loss (i.e. its frequency response) to its local behaviour at $\\omega$. However, causality-based criteria rely the on the group velocity, not the Poynting vector. Since the two are not equivalent, we provide some simple examples to compare the two criteria.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2019-10-13 00:00:00.000000"},
{"id":"1062","title":"Short program group treatment thank.","abstract":"In previous papers we have introduced a sufficient condition for uniform attractivity of the origin for a class of nonlinear time-varying systems which is stated in terms of persistency of excitation (PE), a concept well known in the adaptive control and systems identification literature. The novelty of our condition, called uniform delta-PE, is that it is tailored for nonlinear functions of time and state and it allows us to prove uniform asymptotic stability. In this paper we present a new definition of u-delta-PE which is conceptually similar to but technically different from its predecessors and give several useful characterizations. We make connections between this property and similar properties previously used in the literature. We also show when this condition is necessary and sufficient for uniform (global) asymptotic stability for a large class of nonlinear time-varying systems. Finally, we show the utility of our main results on some control applications regarding feedforward systems and systems with matching nonlinearities.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2020-11-08 00:00:00.000000"},
{"id":"1063","title":"Tough finish look wall.","abstract":"We derive analytical solutions for the system of two ultracold spin-polarized fermions interacting in p wave and confined in an axially symmetric harmonic trap. To this end we utilize p-wave pseudopotential with an energy-dependent scattering volume. This allows to describe the scattering in tight trapping potentials in the presence of scattering resonances. We verify predictions of the pseudopotential treatment for some model interaction potential, obtaining an excellent agreement with exact energy levels. Then we turn to the experimentally relevant case of neutral atom interactions in the vicinity of a p-wave Feshbach resonance. In the framework of the multichannel quantum-defect theory we derive relatively simple formula for an energy-dependent scattering volume, and later we apply it to investigate the energy spectrum of trapped atoms close to the p-wave Feshbach resonance.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2022-11-19 00:00:00.000000"},
{"id":"1064","title":"Smile culture finally Democrat claim resource book.","abstract":"Lance Bryant noticed in his thesis that there was a flaw in our paper \"Associated graded rings of one-dimensional analytically irreducible rings\", J. Algebra 304 (2006), 349-358. It can be fixed by adding a condition, called the BF condition. We discuss some equivalent conditions, and show that they are fulfilled for some classes of rings, in particular for our motivating example of semigroup rings. Furthermore we discuss the connection to a similar result, stated in more generality, by Cortadella-Zarzuela. Finally we use our result to conclude when a semigroup ring in embedding dimension at most three has an associated graded which is a complete intersection.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2017-04-30 00:00:00.000000"},
{"id":"1065","title":"Simply middle author another.","abstract":"Substantial evidence indicates that major psychiatric disorders are associated with distributed neural dysconnectivity, leading to strong interest in using neuroimaging methods to accurately predict disorder status. In this work, we are specifically interested in a multivariate approach that uses features derived from whole-brain resting state functional connectomes. However, functional connectomes reside in a high dimensional space, which complicates model interpretation and introduces numerous statistical and computational challenges. Traditional feature selection techniques are used to reduce data dimensionality, but are blind to the spatial structure of the connectomes. We propose a regularization framework where the 6-D structure of the functional connectome is explicitly taken into account via the fused Lasso or the GraphNet regularizer. Our method only restricts the loss function to be convex and margin-based, allowing non-differentiable loss functions such as the hinge-loss to be used. Using the fused Lasso or GraphNet regularizer with the hinge-loss leads to a structured sparse support vector machine (SVM) with embedded feature selection. We introduce a novel efficient optimization algorithm based on the augmented Lagrangian and the classical alternating direction method, which can solve both fused Lasso and GraphNet regularized SVM with very little modification. We also demonstrate that the inner subproblems of the algorithm can be solved efficiently in analytic form by coupling the variable splitting strategy with a data augmentation scheme. Experiments on simulated data and resting state scans from a large schizophrenia dataset show that our proposed approach can identify predictive regions that are spatially contiguous in the 6-D \"connectome space,\" offering an additional layer of interpretability that could provide new insights about various disease processes.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2015-03-03 00:00:00.000000"},
{"id":"1066","title":"Explain lead score perhaps more cost.","abstract":"Combining the Hardy-Littlewood k-tuple conjecture with a heuristic application of extreme-value statistics, we propose a family of estimator formulas for predicting maximal gaps between prime k-tuples. Computations show that the estimator a(log(x\/a)-b) satisfactorily predicts the maximal gaps below x, where a is the expected average gap between the same type of k-tuples, a=O(log^k x). Heuristics suggest that maximal gaps between prime k-tuples near x are approximately a*log(x\/a), and thus have the order O(log^{k+1}x). The distribution of maximal gaps around the trend curve a*log(x\/a) is close to the Gumbel distribution. We explore two implications of this model of gaps: record gaps between primes and Legendre-type conjectures for prime k-tuples.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2021-06-29 00:00:00.000000"},
{"id":"1067","title":"Four wonder stop might her.","abstract":"A system-of-systems (SoS) is a large information processing system formed by the integration of autonomous computer systems (called constituent systems, CS), physical machines and humans for the purpose of providing new synergistic services and\/or more efficient economic processes. In a number of applications, e.g robotics, the autonomous CSs must coordinate their actions in the temporal domain to realize the desired objectives. In this paper we argue that the introduction of a proper global physical time establishes a shared view about the progress of physical time and helps to realize the temporal coordination of the autonomous CSs. The available global time can also be used to simplify the solution of many challenging problems within the SoS, such as distributed resource allocation, and helps to improve the dependability and fault-tolerance of the SoS.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2021-10-16 00:00:00.000000"},
{"id":"1068","title":"Thank employee call purpose.","abstract":"One-dimensional defect photonic crystal (Bragg waveguide) is studied from the viewpoint of the slow light problem. The calculations are presented showing that in the TiO$_2$\/SiO$_2$-based Bragg waveguide one can obtain the group index of $\\sim$ 1000 and spatial decay length of $\\sim$ 3 mm for a nanosecond-scale pulse. Distortion of the pulse due to the group index dispersion proves to be acceptable for the relative pulse delay not exceeding 10. We also analyze propagation of the light pulse in the Bragg waveguide with a quantum well inside and provide arguments showing possibility of reaching the group index of $\\sim$ 10000. To the best of our knowledge, analysis of pulse propagation in a Bragg waveguide in connection with the slow light problem has not been performed so far. We will still much appreciate any information about such studies, if any.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2016-06-26 00:00:00.000000"},
{"id":"1069","title":"Kid free stop box those doctor increase.","abstract":"The paper has been withdrawn by the author, due a gap in the proof of Theorem 6.1. The gap was discovered by M. Van den Bergh.   Theorem 6.1 is used to prove the main result of the paper, namely Theorem 0.7 (decomposition in arbitrary characteristic). At this time we do not have an alternate proof.   Other results of the paper (Theorems 0.2, 0.3, 0.6 and 3.1) are not effected by this problem, and they remain valid.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2018-04-02 00:00:00.000000"},
{"id":"1070","title":"Product read subject else.","abstract":"We study dynamical systems induced by birational automorphisms on smooth cubic surfaces defined over a number field $K$. In particular we are interested in the product of non-commuting birational Geiser involutions of the cubic surface. We present results describing the sets of $K$ and $\\bar{K}$-periodic points of the system, and give a necessary and sufficient condition for a dynamical local-global property called strong residual periodicity. Finally, we give a dynamical result relating to the Mordell--Weil problem on cubic surfaces.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2022-03-16 00:00:00.000000"},
{"id":"1071","title":"Thing color somebody stand.","abstract":"An energy efficient distributed Change Detection scheme based on Page's CUSUM algorithm was presented in \\cite{icassp}. In this paper we consider a nonparametric version of this algorithm. In the algorithm in \\cite{icassp}, each sensor runs CUSUM and transmits only when the CUSUM is above some threshold. The transmissions from the sensors are fused at the physical layer. The channel is modeled as a Multiple Access Channel (MAC) corrupted with noise. The fusion center performs another CUSUM to detect the change. In this paper, we generalize the algorithm to also include nonparametric CUSUM and provide a unified analysis.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2020-07-14 00:00:00.000000"},
{"id":"1072","title":"A card show.","abstract":"A LLRF control and data acquisition system for the 8-cavity cryomodule1 at the ILCTA has been implemented using three 33-channel ADC boards in a VXI mainframe. One card each is dedicated to the cavity probes for vector control, forward power and reverse power measurements. The system is scalable to 24 cavities or more with the commissioning of cryomodules 2 and 3 without additional hardware. The signal processing and vector control of the cavities is implemented in an FPGA and a high speed data acquisition system with up to 100 channels which stores data in external SDRAM memory. The system supports both pulsed and CW modes with a pulse rate of 5 Hz. Acquired data is transferred between pulses to auxiliary systems such as the piezo controller through the VXI slot0 controller. The performance of the vector control system is evaluated and the design of the system is described.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2021-12-31 00:00:00.000000"},
{"id":"1073","title":"Continue scene arrive environmental place appear accept.","abstract":"We study the interplay of hydrodynamic mesoscale structures and the growth of plankton in the wake of an island, and its interaction with a coastal upwelling. Our focus is on a mechanism for the emergence of localized plankton blooms in vortices. Using a coupled system of a kinematic flow mimicking the mesoscale structures behind the island and a simple three component model for the marine ecosystem, we show that the long residence times of nutrients and plankton in the vicinity of the island and the confinement of plankton within vortices are key factors for the appearance of localized plankton blooms","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2016-09-19 00:00:00.000000"},
{"id":"1074","title":"So government few cup alone action foot home.","abstract":"A priority queue is a fundamental data structure that maintains a dynamic ordered set of keys and supports the followig basic operations: insertion of a key, deletion of a key, and finding the smallest key. The complexity of the priority queue is closely related to that of sorting: A priority queue can be used to implement a sorting algorithm trivially. Thorup \\cite{thorup2007equivalence} proved that the converse is also true in the RAM model. In particular, he designed a priority queue that uses the sorting algorithm as a black box, such that the per-operation cost of the priority queue is asymptotically the same as the per-key cost of sorting. In this paper, we prove an analogous result in the external memory model, showing that priority queues are computationally equivalent to sorting in external memory, under some mild assumptions. The reduction provides a possibility for proving lower bounds for external sorting via showing a lower bound for priority queues.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2017-11-13 00:00:00.000000"},
{"id":"1075","title":"Close term thing central which.","abstract":"Adaptive and interacting Markov chain Monte Carlo algorithms (MCMC) have been recently introduced in the literature. These novel simulation algorithms are designed to increase the simulation efficiency to sample complex distributions. Motivated by some recently introduced algorithms (such as the adaptive Metropolis algorithm and the interacting tempering algorithm), we develop a general methodological and theoretical framework to establish both the convergence of the marginal distribution and a strong law of large numbers. This framework weakens the conditions introduced in the pioneering paper by Roberts and Rosenthal [J. Appl. Probab. 44 (2007) 458--475]. It also covers the case when the target distribution $\\pi$ is sampled by using Markov transition kernels with a stationary distribution that differs from $\\pi$.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2015-10-03 00:00:00.000000"},
{"id":"1076","title":"World color quickly between safe wonder.","abstract":"We prove explicit approximation hardness results for the Graphic TSP on cubic and subcubic graphs as well as the new inapproximability bounds for the corresponding instances of the (1,2)-TSP. The proof technique uses new modular constructions of simulating gadgets for the restricted cubic and subcubic instances. The modular constructions used in the paper could be also of independent interest.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2016-11-27 00:00:00.000000"},
{"id":"1077","title":"Example central wish know similar business collection she.","abstract":"An improved real-time quantum Monte Carlo procedure is presented and applied to describe the electronic transfer dynamics along molecular chains. The model consists of discrete electronic sites coupled to a thermal environment which is integrated out exactly within the path integral formulation. The approach is numerically exact and its results reduce to known analytical findings (Marcus theory, golden rule) in proper limits. Special attention is paid to the role of superexchange and sequential hopping at lower temperatures in symmetric donor-bridge-acceptor systems. In contrast to previous approximate studies, superexchange turns out to play a significant role only for extremely high lying bridges where the transfer is basically frozen or for extremely low temperatures where for weaker dissipation a description in terms of rate constants is no longer feasible. For bridges with increasing length an algebraic decrease of the yield is found for short as well as for longer bridges. The approach can be extended to electronic systems with more complicated topologies including impurities and in presence of external time dependent forces.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2019-10-14 00:00:00.000000"},
{"id":"1078","title":"Southern whom generation.","abstract":"A general notion of algebraic conditional plausibility measures is defined. Probability measures, ranking functions, possibility measures, and (under the appropriate definitions) sets of probability measures can all be viewed as defining algebraic conditional plausibility measures. It is shown that the technology of Bayesian networks can be applied to algebraic conditional plausibility measures.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2017-06-29 00:00:00.000000"},
{"id":"1079","title":"Successful decade stuff finally now four high.","abstract":"For a semi-martingale $X_t$, which forms a stochastic boundary, a rate-optimal estimator for its quadratic variation $\\langle X, X \\rangle_t$ is constructed based on observations in the vicinity of $X_t$. The problem is embedded in a Poisson point process framework, which reveals an interesting connection to the theory of Brownian excursion areas. A major application is the estimation of the integrated squared volatility of an efficient price process $X_t$ from intra-day order book quotes. We derive $n^{-1\/3}$ as optimal convergence rate of integrated squared volatility estimation in a high-frequency framework with $n$ observations (in mean). This considerably improves upon the classical $n^{-1\/4}$-rate obtained from transaction prices under microstructure noise. %An estimator based on local order statistics attaining the rate is presented.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2015-09-10 00:00:00.000000"},
{"id":"1080","title":"Suddenly make commercial popular mind.","abstract":"It is generally assumed by most of the small-angle neutron scattering (SANS) user community that a neutrons energy is unchanged during SANS measurements. Here, the scattering from water, specifically light water, was measured on the EQ-SANS instrument, a time-of-flight SANS instrument located at the Spallation Neutron Source of Oak Ridge National Laboratory. A significant inelastic process was observed in the TOF spectra of neutrons scattered from water. Analysis of the TOF spectra from the sample showed that the scattered neutrons have energies consistent with room-temperature thermal energies (~20 meV) regardless of the incident neutron energy. With the aid of Monte Carlo particle transport simulations, we conclude that the thermalization process within the sample results in faster neutrons that arrive at the detector earlier than expected based on the incident neutron energies. This thermalization process impacts the measured SANS intensities in a manner that will ultimately be sample- and temperature-dependent, necessitating careful processing of the raw data into the SANS cross-section.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2017-06-04 00:00:00.000000"},
{"id":"1081","title":"Two space own.","abstract":"Atoms from an otherwise unconfined 87Rb condensate are shown to be suspended against gravity using repeated reflections from a pulsed optical standing wave. Reflection efficiency was optimized using a triple-pulse sequence that, theoretically, provides accuracies better than 99.9%. Experimentally, up to 100 reflections are observed, leading to dynamical suspension for over 100 ms. The velocity sensitivity of the reflections can be used to determine the local gravitational acceleration. Further, a gravitationally sensitive atom interferometer was implemented using the suspended atoms, with packet coherence maintained for a similar time. These techniques could be useful for the precise measurement of gravity when it is impractical to allow atoms to fall freely over a large distance.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2021-02-17 00:00:00.000000"},
{"id":"1082","title":"Everybody call ability buy nor voice.","abstract":"We show a fixed-point property of random quotients by plain words for a wide class of CAT(0) spaces.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2017-04-16 00:00:00.000000"},
{"id":"1083","title":"Newspaper leader program begin do skill account.","abstract":"In this paper, we initiate the systematic study of solving linear programs under differential privacy. The first step is simply to define the problem: to this end, we introduce several natural classes of private linear programs that capture different ways sensitive data can be incorporated into a linear program. For each class of linear programs we give an efficient, differentially private solver based on the multiplicative weights framework, or we give an impossibility result.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2019-04-18 00:00:00.000000"},
{"id":"1084","title":"Purpose country summer couple body art.","abstract":"We show that, contrary to the common wisdom, surface plasmon poles are not involved in the imaging process in leakage radiation microscopy. Identifying the leakage radiation modes directly from a transverse magnetic potential leads us to reconsider the surface plasmon field and unfold the non-plasmonic contribution to the image formation. While both contributions interfere in the imaging process, our analysis reveals that the reassessed plasmonic field embodies a pole mathematically similar to the usual surface plasmon pole. This removes a long-standing ambiguity associated with plasmonic signals in leakage radiation microscopy.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2020-09-08 00:00:00.000000"},
{"id":"1085","title":"Example street size.","abstract":"We extend to the non-connective case a lemma of Bokstedt about the equivalence of the telescope with a more complicated homotopy colimit of symmetric spectra used in the construction of THH.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2022-08-04 00:00:00.000000"},
{"id":"1086","title":"Practice international political political how account draw.","abstract":"In this paper, we examine the CE method in the broad context of Monte Carlo Optimization (MCO) and Parametric Learning (PL), a type of machine learning. A well-known overarching principle used to improve the performance of many PL algorithms is the bias-variance tradeoff. This tradeoff has been used to improve PL algorithms ranging from Monte Carlo estimation of integrals, to linear estimation, to general statistical estimation. Moreover, as described by, MCO is very closely related to PL. Owing to this similarity, the bias-variance tradeoff affects MCO performance, just as it does PL performance.   In this article, we exploit the bias-variance tradeoff to enhance the performance of MCO algorithms. We use the technique of cross-validation, a technique based on the bias-variance tradeoff, to significantly improve the performance of the Cross Entropy (CE) method, which is an MCO algorithm. In previous work we have confirmed that other PL techniques improve the perfomance of other MCO algorithms. We conclude that the many techniques pioneered in PL could be investigated as ways to improve MCO algorithms in general, and the CE method in particular.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2016-04-17 00:00:00.000000"},
{"id":"1087","title":"Account president story hair build.","abstract":"This paper gives the first separation of quantum and classical pure (i.e., non-cryptographic) computing abilities with no restriction on the amount of available computing resources, by considering the exact solvability of a celebrated unsolvable problem in classical distributed computing, the ``leader election problem'' on anonymous networks. The goal of the leader election problem is to elect a unique leader from among distributed parties. The paper considers this problem for anonymous networks, in which each party has the same identifier. It is well-known that no classical algorithm can solve exactly (i.e., in bounded time without error) the leader election problem in anonymous networks, even if it is given the number of parties. This paper gives two quantum algorithms that, given the number of parties, can exactly solve the problem for any network topology in polynomial rounds and polynomial communication\/time complexity with respect to the number of parties, when the parties are connected by quantum communication links.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2015-11-25 00:00:00.000000"},
{"id":"1088","title":"Improve same fire wind woman understand message.","abstract":"High dimensional statistical problems arise from diverse fields of scientific research and technological development. Variable selection plays a pivotal role in contemporary statistical learning and scientific discoveries. The traditional idea of best subset selection methods, which can be regarded as a specific form of penalized likelihood, is computationally too expensive for many modern statistical applications. Other forms of penalized likelihood methods have been successfully developed over the last decade to cope with high dimensionality. They have been widely applied for simultaneously selecting important variables and estimating their effects in high dimensional statistical inference. In this article, we present a brief account of the recent developments of theory, methods, and implementations for high dimensional variable selection. What limits of the dimensionality such methods can handle, what the role of penalty functions is, and what the statistical properties are rapidly drive the advances of the field. The properties of non-concave penalized likelihood and its roles in high dimensional statistical modeling are emphasized. We also review some recent advances in ultra-high dimensional variable selection, with emphasis on independence screening and two-scale methods.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2016-10-01 00:00:00.000000"},
{"id":"1089","title":"Movie your ground quality center almost.","abstract":"In two 2006 papers, Kostant and Wallach constructed a complexified Gelfand-Zeitlin integrable system for the Lie algebra $\\fgl(n+1,\\C)$ and introduced the strongly regular elements, which are the points where the Gelfand-Zeitlin flow is Lagrangian. Later Colarusso studied the nilfibre, which consists of strongly regular elements such that each $i\\times i$ submatrix in the upper left corner is nilpotent. In this paper, we prove that every Borel subalgebra contains strongly regular elements and determine the Borel subalgebras containing elements of the nilfibre by using the theory of $K_{i}=GL(i-1,\\C) \\times GL(1,\\C)$-orbits on the flag variety for $\\fgl(i,\\C)$ for $2\\leq i\\leq n+1$. As a consequence, we obtain a more precise description of the nilfibre. The $K_{i}$-orbits contributing to the nilfibre are closely related to holomorphic and anti-holomorphic discrete series for the real Lie groups $U(i,1)$, with $i \\le n$.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2018-10-28 00:00:00.000000"},
{"id":"1090","title":"Energy treatment learn scientist interest air.","abstract":"This paper addresses the automatic recognition of handwritten temperature values in weather records. The localization of table cells is based on line detection using projection profiles. Further, a stroke-preserving line removal method which is based on gradient images is proposed. The presented digit recognition utilizes features which are extracted using a set of filters and a Support Vector Machine classifier. It was evaluated on the MNIST and the USPS dataset and our own database with about 17,000 RGB digit images. An accuracy of 99.36% per digit is achieved for the entire system using a set of 84 weather records.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2018-12-16 00:00:00.000000"},
{"id":"1091","title":"Manager off all true five through.","abstract":"The well known $g$-conjecture for homology spheres follows from the stronger conjecture that the face ring over the reals of a homology sphere, modulo a linear system of parameters, admits the strong-Lefschetz property. We prove that the strong-Lefschetz property is preserved under the following constructions on homology spheres: join, connected sum, and stellar subdivisions. The last construction is a step towards proving the $g$-conjecture for piecewise-linear spheres.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2015-07-03 00:00:00.000000"},
{"id":"1092","title":"Father lead case skin go several.","abstract":"The general relativity is the base for any exact evolutionary theory of large scale structures. We calculate the universal 2+1-dimensional plane equations of gravitational field in general relativity. Based on the equations, the evolutions of disk nebula are discussed. A system of nebula can form binary stars or single star for different conditions. While any simplified linear theory forms only a single star system. It is proved that the nonlinear interactions are very general, so the binary stars are also common.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2015-03-27 00:00:00.000000"},
{"id":"1093","title":"Project simple deal account.","abstract":"We prove that for any discrete group $G$ with finite $\\mathfrak{F}$-cohomological dimension, the Gorenstein cohomological dimension equals the $\\mathfrak{F}$-cohomological dimension. This is achieved by constructing a long exact sequence of cohomological functors, analogous to that constructed by Avramov and Martsinkovsky, containing the $\\mathfrak{F}$-cohomology and complete $\\mathfrak{F}$-cohomology. As a corollary we improve upon a theorem of Degrijse concerning subadditivity of the $\\mathfrak{F}$-cohomological dimension under group extensions.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2022-02-07 00:00:00.000000"},
{"id":"1094","title":"Investment group grow reduce.","abstract":"Today World Wide Web (WWW) has become a huge ocean of information and it is growing in size everyday. Downloading even a fraction of this mammoth data is like sailing through a huge ocean and it is a challenging task indeed. In order to download a large portion of data from WWW, it has become absolutely essential to make the crawling process parallel. In this paper we offer the architecture of a dynamic parallel Web crawler, christened as \"WEB-SAILOR,\" which presents a scalable approach based on Client-Server model to speed up the download process on behalf of a Web Search Engine in a distributed Domain-set specific environment. WEB-SAILOR removes the possibility of overlapping of downloaded documents by multiple crawlers without even incurring the cost of communication overhead among several parallel \"client\" crawling processes.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2017-11-14 00:00:00.000000"},
{"id":"1095","title":"Task help cut customer friend want.","abstract":"We develop symbolic methods of asymptotic approximations for solutions of linear ordinary differential equations and use to them stabilize numerical calculations. Our method follows classical analysis for first-order systems and higher-order scalar equations where growth behavior is expressed in terms of elementary functions. We then recast our equations in mollified form - thereby obtaining stability.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2018-08-04 00:00:00.000000"},
{"id":"1096","title":"Budget issue they.","abstract":"This article is a translation of Michael Sadowsky's original paper \"Ein elementarer Beweis f\\\"ur die Existenz eines abwickelbaren M\\\"obiusschen Bandes und die Zur\\\"uckf\\\"uhrung des geometrischen Problems auf ein Variationsproblem.\" which appeared in Sitzungsberichte der Preussischen Akademie der Wissenschaften, physikalisch-mathematische Klasse, 17. Juli 1930, Mitteilung vom 26. Juni, 412-415. Published on September 12, 1930.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2022-09-10 00:00:00.000000"},
{"id":"1097","title":"Generation including environmental value.","abstract":"This paper proposes a way to effectively compare the potential of processes to cause conflict. In discrete event systems theory, two concurrent systems are said to be in conflict if they can get trapped in a situation where they are both waiting or running endlessly, forever unable to complete their common task. The conflict preorder is a process-algebraic pre-congruence that compares two processes based on their possible conflicts in combination with other processes. This paper improves on previous theoretical descriptions of the conflict preorder by introducing less conflicting pairs as a concrete state-based characterisation. Based on this characterisation, an effective algorithm is presented to determine whether two processes are related according to the conflict preorder.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2021-06-24 00:00:00.000000"},
{"id":"1098","title":"Skill condition example own.","abstract":"This paper contains two results concerning the equivariant K-theory of toric varieties. The first is a formula for the equivariant K-groups of an arbitrary affine toric variety, generalizing the known formula for smooth ones. In fact, this result is established in a more general context, involving the K-theory of graded projective modules. The second result is a new proof of a theorem due to Vezzosi and Vistoli concerning the equivariant K-theory of smooth (not necessarily affine) toric varieties.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2020-10-22 00:00:00.000000"},
{"id":"1099","title":"Civil upon increase ten list.","abstract":"EcoTRADE is a multi player network game of a virtual biodiversity credit market. Each player controls the land use of a certain amount of parcels on a virtual landscape. The biodiversity credits of a particular parcel depend on neighboring parcels, which may be owned by other players. The game can be used to study the strategies of players in experiments or classroom games and also as a communication tool for stakeholders participating in credit markets that include spatially interdependent credits.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2017-04-14 00:00:00.000000"},
{"id":"1100","title":"Yard Mrs who last.","abstract":"Equilibrium, traveling wave, and periodic orbit solutions of pipe, channel, and plane Couette flows can now be computed precisely at Reynolds numbers above the onset of turbulence. These invariant solutions capture the complex dynamics of wall-bounded rolls and streaks and provide a framework for understanding low-Reynolds turbulent shear flows as dynamical systems. We present fluid dynamics videos of plane Couette flow illustrating periodic orbits, a close pass of turbulent flow to a periodic orbit, and heteroclinic connections between unstable equilibria.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2019-01-20 00:00:00.000000"},
{"id":"1101","title":"Wish focus total reason.","abstract":"We demonstrate the generation of self-accelerating surface plasmon beams along arbitrary caustic curvatures. These plasmonic beams are excited by free-space beams through a two-dimensional binary plasmonic phase mask, which provides the missing momentum between the two beams in the direction of propagation, and sets the required phase for the plasmonic beam in the transverse direction. We examine the cases of paraxial and non-paraxial curvatures and show that this highly versatile scheme can be designed to produce arbitrary plasmonic self-accelerating beams. Several different plasmonic beams, which accelerate along polynomial and exponential trajectories, are demonstrated both numerically and experimentally, with a direct measurement of the plasmonic light intensity using a near-field-scanning-optical-microscope.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2018-10-17 00:00:00.000000"},
{"id":"1102","title":"At action with behind west act hot.","abstract":"Analytic functions represent the state-of-the-art way of performing complex data analysis within a single SQL statement. In particular, an important class of analytic functions that has been frequently used in commercial systems to support OLAP and decision support applications is the class of window functions. A window function returns for each input tuple a value derived from applying a function over a window of neighboring tuples. However, existing window function evaluation approaches are based on a naive sorting scheme. In this paper, we study the problem of optimizing the evaluation of window functions. We propose several efficient techniques, and identify optimization opportunities that allow us to optimize the evaluation of a set of window functions. We have integrated our scheme into PostgreSQL. Our comprehensive experimental study on the TPC-DS datasets as well as synthetic datasets and queries demonstrate significant speedup over existing approaches.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2020-11-30 00:00:00.000000"},
{"id":"1103","title":"Official show know foreign writer.","abstract":"In this paper one generalizes the classical probability and imprecise probability to the notion of \"neutrosophic probability\" in order to be able to model Heisenberg's Uncertainty Principle of a particle's behavior, Schr\"dinger's Cat Theory, and the state of bosons which do not obey Pauli's Exclusion Principle (in quantum physics). Neutrosophic probability is close related to neutrosophic logic and neutrosophic set, and etymologically derived from \"neutrosophy\".","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2016-05-03 00:00:00.000000"},
{"id":"1104","title":"Action against couple would enter.","abstract":"We discuss double ionization of atoms in strong laser pulses using a reduced dimensionality model. Following the insights obtained from an analysis of the classical mechanics of the process, we confine each electron to move along the lines that point towards the two-particle Stark saddle in the presence of a field. The resulting effective two dimensional model is similar to the aligned electron model, but it enables correlated escape of electrons with equal momenta, as observed experimentally. The time-dependent solution of the Schr\\\"odinger equation allows us to discuss in detail the time dynamics of the ionization process, the formation of electronic wave packets and the development of the momentum distribution of the outgoing electrons. In particular, we are able to identify the rescattering process, simultaneous direct double ionization during the same field cycle, as well as other double ionization processes. We also use the model to study the phase dependence of the ionization process.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2019-01-11 00:00:00.000000"},
{"id":"1105","title":"Finish history challenge history television history off.","abstract":". Markov chains in time, such as simple random walks, are at the heart of probability. In space, due to the absence of an obvious definition of past and future, a range of definitions of Markovianity have been proposed. In this paper, after a brief review, we introduce a new concept of Markovianity that aims to combine spatial and temporal conditional independence.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2019-05-21 00:00:00.000000"},
{"id":"1106","title":"Four speak determine rise citizen first.","abstract":"Recently a majorization method for optimizing partition functions of log-linear models was proposed alongside a novel quadratic variational upper-bound. In the batch setting, it outperformed state-of-the-art first- and second-order optimization methods on various learning tasks. We propose a stochastic version of this bound majorization method as well as a low-rank modification for high-dimensional data-sets. The resulting stochastic second-order method outperforms stochastic gradient descent (across variations and various tunings) both in terms of the number of iterations and computation time till convergence while finding a better quality parameter setting. The proposed method bridges first- and second-order stochastic optimization methods by maintaining a computational complexity that is linear in the data dimension and while exploiting second order information about the pseudo-global curvature of the objective function (as opposed to the local curvature in the Hessian).","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2021-03-09 00:00:00.000000"},
{"id":"1107","title":"Field quality executive top.","abstract":"Microcanonical thermodynamics allows the application of statistical mechanics both to finite and even small systems and also to the largest, self-gravitating ones. However, one must reconsider the fundamental principles of statistical mechanics especially its key quantity, entropy. Whereas in conventional thermostatistics, the homogeneity and extensivity of the system and the concavity of its entropy are central conditions, these fail for the systems considered here. For example, at phase separation, the entropy, S(E), is necessarily convex to make exp[S(E)-E\/T] bimodal in E. Particularly, as inhomogeneities and surface effects cannot be scaled away, one must be careful with the standard arguments of splitting a system into two subsystems, or bringing two systems into thermal contact with energy or particle exchange. Not only the volume part of the entropy must be considered. As will be shown here, when removing constraints in regions of a negative heat capacity, the system may even relax under a flow of heat (energy) against a temperature slope. Thus the Clausius formulation of the second law: ``Heat always flows from hot to cold'', can be violated. Temperature is not a necessary or fundamental control parameter of thermostatistics. However, the second law is still satisfied and the total Boltzmann entropy increases. In the final sections of this paper, the general microscopic mechanism leading to condensation and to the convexity of the microcanonical entropy at phase separation is sketched. Also the microscopic conditions for the existence (or non-existence) of a critical end-point of the phase-separation are discussed. This is explained for the liquid-gas and the solid-liquid transition.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2015-08-21 00:00:00.000000"},
{"id":"1108","title":"Feel some stay approach.","abstract":"We study the existence of positive loops of contactomorphisms on a Liouville-fillable contact manifold $(\\Sigma,\\xi=\\ker(\\alpha))$. Previous results show that a large class of Liouville-fillable contact manifolds admit contractible positive loops. In contrast, we show that for any Liouville-fillable $(\\Sigma,\\alpha)$ with $\\dim(\\Sigma) \\geq 7$, there exists a Liouville-fillable contact structure $\\xi'$ on $\\Sigma$ which admits no positive loop at all. Further, $\\xi'$ can be chosen to agree with $\\xi$ on the complement of a Darboux ball.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2015-03-12 00:00:00.000000"},
{"id":"1109","title":"Call understand education feeling.","abstract":"In this paper the theory of flexibly-bounded rationality which is an extension to the theory of bounded rationality is revisited. Rational decision making involves using information which is almost always imperfect and incomplete together with some intelligent machine which if it is a human being is inconsistent to make decisions. In bounded rationality, this decision is made irrespective of the fact that the information to be used is incomplete and imperfect and that the human brain is inconsistent and thus this decision that is to be made is taken within the bounds of these limitations. In the theory of flexibly-bounded rationality, advanced information analysis is used, the correlation machine is applied to complete missing information and artificial intelligence is used to make more consistent decisions. Therefore flexibly-bounded rationality expands the bounds within which rationality is exercised. Because human decision making is essentially irrational, this paper proposes the theory of marginalization of irrationality in decision making to deal with the problem of satisficing in the presence of irrationality.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2015-04-24 00:00:00.000000"},
{"id":"1110","title":"Character team agree goal find believe baby forget.","abstract":"Millimeter wave technology being an emerging area is still very undeveloped. A substantial research needs to be done in this area as its applications are numerous. In the present endeavor, a rectangular patch antenna is designed on thick substrate and simulated using SONNET software, also a novel analysis technique is developed for circular patch antenna for millimeter wave frequency. The antenna is designed at 39 GHz on thick substrate and has been analyzed and simulated.The results of the theoretical analysis are in good agreement with the simulated results.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2020-06-09 00:00:00.000000"},
{"id":"1111","title":"Drug full school fish visit interesting true us.","abstract":"DNA base-gold interactions are studied theoretically at the DFT level using Au3 and Au4 clusters as simple catalytic models for Au particles. The bonding between DNA bases and gold clusters occurs via the anchoring of a Au atom to the N or O atoms of the bases. In the most stable planar base-Au3 complexes, the Au-N or Au-O anchor bonds are reinforced by N-H...Au bonds. The mechanism of formation of these nonconventional H-bonds is discussed.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2019-07-04 00:00:00.000000"},
{"id":"1112","title":"Move risk very issue power real.","abstract":"Cloud computing is a new technology widely studied in recent years. Now there are many cloud platforms both in industry and in academic circle. How to understand and use these platforms is a big issue. A detailed comparison has been presented in this paper focused on the aspects such as the architecture, characteristics, application and so on. To know the differences between open source and close source in cloud environment we mention some examples for Software-as-a-Service, Platform-as-a-Service, and Infrastructure-as-a-Service. We made comparison between them. Before conclusion we demonstrate some convergences and differences between open and closed platform, but we realized open source should be the best option.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2017-02-08 00:00:00.000000"},
{"id":"1113","title":"Ground only there.","abstract":"We present the analytical and simulated results concerning the influences of the acceleration gradient in the velocity bunching process, which is a bunch compression scheme that uses a traveling wave accelerating structure as a compressor. Our study shows that the bunch compression application with low acceleration gradient is more tolerant to phase jitter and more successful to obtain compressed electron beam with symmetrical longitudinal distribution and low energy spread. We also present a transverse emittance compensation scheme to compensate the emittance growth caused by the increasing of the space charge force in the compressing process that is easy to be adjusted for different compressing factors.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2019-05-08 00:00:00.000000"},
{"id":"1114","title":"Mouth too unit her second officer.","abstract":"We define a family of homogeneous ideals with large projective dimension and regularity relative to the number of generators and their common degree. This family subsumes and improves upon constructions given in [Cav04] and [McC]. In particular, we describe a family of three-generated homogeneous ideals in arbitrary characteristic whose projective dimension grows asymptotically as sqrt{d}^(sqrt(d) - 1).","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2022-02-21 00:00:00.000000"},
{"id":"1115","title":"How yeah anything scene director left pressure.","abstract":"Two-photon excitation spectroscopy with broad spectral span is demonstrated at Doppler-limited resolution. We describe first Fourier transform two-photon spectroscopy of an atomic sample with two mode-locked laser oscillators in a dual-comb technique. Each transition is uniquely identified by the modulation imparted by the interfering comb excitations. The temporal modulation of the spontaneous two-photon fluorescence is monitored with a single photodetector, and the spectrum is revealed by a Fourier transform.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2021-11-05 00:00:00.000000"},
{"id":"1116","title":"Civil mind great through.","abstract":"We show operation of a silicon MEMS based narrow-band optical modulator with large modulation depth by improving the electro-mechanical transducer. We demonstrate an application of the narrowband optical modulator as both the filter and optical modulator in an opto-electronic oscillator loop to obtain a 236.22 MHz Opto-Acoustic Oscillator (OAO) with phase noise of -68 dBc\/Hz at 1 kHz offset.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2019-10-25 00:00:00.000000"},
{"id":"1117","title":"Reality voice couple pull laugh trouble owner.","abstract":"In the middle of the 1980s, David Poole introduced a semantical, model-theoretic notion of specificity to the artificial-intelligence community. Since then it has found further applications in non-monotonic reasoning, in particular in defeasible reasoning. Poole tried to approximate the intuitive human concept of specificity, which seems to be essential for reasoning in everyday life with its partial and inconsistent information. His notion, however, turns out to be intricate and problematic, which --- as we show --- can be overcome to some extent by a closer approximation of the intuitive human concept of specificity. Besides the intuitive advantages of our novel specificity ordering over Poole's specificity relation in the classical examples of the literature, we also report some hard mathematical facts: Contrary to what was claimed before, we show that Poole's relation is not transitive. The present means to decide our novel specificity relation, however, show only a slight improvement over the known ones for Poole's relation, and further work is needed in this aspect.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2015-10-16 00:00:00.000000"},
{"id":"1118","title":"Body deep decision century fly yet.","abstract":"Given an elliptic action of a compact Lie group $G$ on a co-oriented contact manifold $(M,E)$ one obtains two naturally associated objects: A $G$-transversally elliptic operator $\\dirac$, and an equivariant differential form with generalised coefficients $\\mathcal{J}(E,X)$ defined in terms of a choice of contact form on $M$. We explain how the form $\\mathcal{J}(E,X)$ is natural with respect to the contact structure, and give a formula for the equivariant index of $\\dirac$ involving $\\mathcal{J}(E,X)$. A key tool is the Chern character with compact support developed by Paradan-Vergne \\cite{PV1,PV}.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2016-07-02 00:00:00.000000"},
{"id":"1119","title":"Collection family way management western forget break.","abstract":"When a planner must decide whether it has enough evidence to make a decision based on probability, it faces the sample size problem. Current planners using probabilities need not deal with this problem because they do not generate their probabilities from observations. This paper presents an event based language in which the planner's probabilities are calculated from the binomial random variable generated by the observed ratio of one type of event to another. Such probabilities are subject to error, so the planner must introspect about their validity. Inferences about the probability of these events can be made using statistics. Inferences about the validity of the approximations can be made using interval estimation. Interval estimation allows the planner to avoid making choices that are only weakly supported by the planner's evidence.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2021-07-17 00:00:00.000000"},
{"id":"1120","title":"Bed pass smile debate court pattern base.","abstract":"We explore the machine-minimizing job scheduling problem, which has a rich history in the line of research, under an online setting. We consider systems with arbitrary job arrival times, arbitrary job deadlines, and unit job execution time. For this problem, we present a lower bound 2.09 on the competitive factor of \\emph{any} online algorithms, followed by designing a 5.2-competitive online algorithm. We also point out a false claim made in an existing paper of Shi and Ye regarding a further restricted case of the considered problem. To the best of our knowledge, what we present is the first concrete result concerning online machine-minimizing job scheduling with arbitrary job arrival times and deadlines.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2016-11-07 00:00:00.000000"},
{"id":"1121","title":"Early prevent mind subject company trouble.","abstract":"When speaking of the unification of quantum mechanics and relativity, one normally refers to special relativity (SR) or to Einstein general relativity (GR). The Dirac and Klein-Gordon wave equations are an example of unification of quantum concepts and concepts falling within the domain of SR. Current relativistic QFT derives from the transcription of these equations into second quantization formalism. Many researchers hope that the unification of QFT with GR can solve the problems peculiar to QFT (divergences) and to GR (singularities). In this article, a different strategy is proposed, in an informal manner. Firstly, emphasis is laid on the importance of the transaction notion for quantum theories, introduced by Cramer in the eighties and generalized by the author of this article. In addition, the unification is discussed of QFT not with SR or with GR, but with their projective extensions (PSR, PGR respectively) introduced between 1954 and 1995 by Fantappie and Arcidiacono. The existence emerges of new fundamental constants of nature, whose significance is discussed. It is assumed that this new context can be a suitable background for the analysis of specific QFT (quark confinement, divergences, alpha-quantization of elementary particle masses and decay times) and PGR (gravitational collapse) problems.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2016-05-26 00:00:00.000000"},
{"id":"1122","title":"Yes dark market final they according plan.","abstract":"Convex polyhedra are the basis for several abstractions used in static analysis and computer-aided verification of complex and sometimes mission critical systems. For such applications, the identification of an appropriate complexity-precision trade-off is a particularly acute problem, so that the availability of a wide spectrum of alternative solutions is mandatory. We survey the range of applications of polyhedral computations in this area; give an overview of the different classes of polyhedra that may be adopted; outline the main polyhedral operations required by automatic analyzers and verifiers; and look at some possible combinations of polyhedra with other numerical abstractions that have the potential to improve the precision of the analysis. Areas where further theoretical investigations can result in important contributions are highlighted.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2020-10-14 00:00:00.000000"},
{"id":"1123","title":"Play under special.","abstract":"This paper studies the fluctuations of the signal-to-noise ratio (SNR) of minimum variance distorsionless response (MVDR) filters implementing diagonal loading in the estimation of the covariance matrix. Previous results in the signal processing literature are generalized and extended by considering both spatially as well as temporarily correlated samples. Specifically, a central limit theorem (CLT) is established for the fluctuations of the SNR of the diagonally loaded MVDR filter, under both supervised and unsupervised training settings in adaptive filtering applications. Our second-order analysis is based on the Nash-Poincar\\'e inequality and the integration by parts formula for Gaussian functionals, as well as classical tools from statistical asymptotic theory. Numerical evaluations validating the accuracy of the CLT confirm the asymptotic Gaussianity of the fluctuations of the SNR of the MVDR filter.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2015-03-11 00:00:00.000000"},
{"id":"1124","title":"Many physical worker throughout.","abstract":"Owners of a web-site are often interested in analysis of groups of users of their site. Information on these groups can help optimizing the structure and contents of the site. In this paper we use an approach based on formal concepts for constructing taxonomies of user groups. For decreasing the huge amount of concepts that arise in applications, we employ stability index of a concept, which describes how a group given by a concept extent differs from other such groups. We analyze resulting taxonomies of user groups for three target websites.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2019-12-14 00:00:00.000000"},
{"id":"1125","title":"Matter example indeed such civil.","abstract":"We develop Lagrangian Floer Theory for exact, graded, immersed Lagrangians with clean self-intersection using Seidel's setup. A positivity assumption on the index of the self intersection points is imposed to rule out certain (but not all) disc bubbles. This allows the Lagrangians to be included in the exact Fukaya category. We also study quasi-isomorphism of Lagrangians under certain exact deformations which are not Hamiltonian.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2018-08-10 00:00:00.000000"},
{"id":"1126","title":"Recently yes for decade behind discover.","abstract":"The present work falls in the line of activities promoted by the European Languguage Resource Association (ELRA) Production Committee (PCom) and raises issues in methods, procedures and tools for the reusability, creation, and management of Language Resources. A two-fold purpose lies behind this experiment. The first aim is to investigate the feasibility, define methods and procedures for combining two Italian lexical resources that have incompatible formats and complementary information into a Unified Lexicon (UL). The adopted strategy and the procedures appointed are described together with the driving criterion of the merging task, where a balance between human and computational efforts is pursued. The coverage of the UL has been maximized, by making use of simple and fast matching procedures. The second aim is to exploit this newly obtained resource for implementing the phonological and morphological layers of the CLIPS lexical database. Implementing these new layers and linking them with the already exisitng syntactic and semantic layers is not a trivial task. The constraints imposed by the model, the impact at the architectural level and the solution adopted in order to make the whole database `speak' efficiently are presented. Advantages vs. disadvantages are discussed.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2018-06-22 00:00:00.000000"},
{"id":"1127","title":"Work first magazine around.","abstract":"Software reliability is an important quality attrib-ute, often evaluated as either a function of time or of system structures. The goal of this study is to have this metric cover both for component-based software, be-cause its reliability strongly depends on the quality of constituent components and their interactions. To achieve this, we apply a convolution modeling ap-proach, based on components' execution behavior, to integrate their individual reliability evolvement and simultaneously address failure fixes in the time do-main. Modeling at the component level can be more economical to accommodate software evolution, be-cause the reliability metric can be evaluated by reus-ing the quality measures of unaffected components and adapting only to the affected ones to save cost. The adaptation capability also supports the incremental software development processes that constantly add in new components over time. Experiments were con-ducted to discuss the usefulness of this approach.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2016-06-21 00:00:00.000000"},
{"id":"1128","title":"Nation last describe decade boy crime break.","abstract":"We solve the Vlasov equation for the longitudinal distribution function and find stationary wave patterns when the distribution in the energy error is Maxwellian. In the long wavelength limit a stability criterion for linear waves has been obtained, and a Korteweg-de Vries-Burgers equation for the relevant hydrodynamic quantities has been derived.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2019-12-06 00:00:00.000000"},
{"id":"1129","title":"Wind significant military firm word.","abstract":"Beginning with a Lagrangian that is consistent with both Newtonian gravity and the momentum-velocity relation of special relativity, an approximate relativistic orbit equation is derived that describes relativistic corrections to Keplerian orbits. Specifically, corrections to a Keplerian orbit due to special relativity include: precession of perihelion, reduced radius of circular orbit, and increased eccentricity. The prediction for the rate of precession of perihelion of Mercury is in agreement with existing calculations using only special relativity, and is one sixth that derived from general relativity. All three of these corrections are qualitatively correct, though suppressed when compared to the more accurate general-relativistic corrections in this limit. The resulting orbit equation has the same form as that derived from general relativity and is easily compared to that describing Kepler's orbits. This treatment of the relativistic central-mass problem is complementary to other solutions to the relativistic Kepler problem, and is approachable by undergraduate physics majors whom have not had a course dedicated to relativity.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2019-07-26 00:00:00.000000"},
{"id":"1130","title":"Guy how them never near many.","abstract":"We consider a system of parallel straight edge dislocations and we analyse its asymptotic behaviour in the limit of many dislocations. The dislocations are represented by points in a plane, and they are arranged in vertical walls; each wall is free to move in the horizontal direction. The system is described by a discrete energy depending on the one-dimensional horizontal positions of the n walls; the energy contains contributions from repulsive pairwise interactions between all walls, a global shear stress forcing the walls to the left, and a pinned wall at x=0 that prevents the walls from leaving through the left boundary.   We study the behaviour of the energy as the number n of walls tends to infinity, and characterise this behaviour in terms of Gamma-convergence. There are five different cases, depending on the asymptotic behaviour of a single dimensionless parameter. As a consequence we obtain characterisations of the limiting behaviour of stationary states in each of these five regimes.   The results shed new light on the open problem of upscaling large numbers of dislocations. We show how various existing upscaled models arise as special cases of the theorems of this paper. The wide variety of behaviour suggests that upscaled models should incorporate more information than just dislocation densities. This additional information is encoded in the limit of the dimensionless parameter.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2016-10-31 00:00:00.000000"},
{"id":"1131","title":"Believe season attack understand ever fire shake.","abstract":"A protocol-independent secrecy theorem is established and applied to several non-trivial protocols. In particular, it is applied to protocols proposed for protecting the computation results of free-roaming mobile agents doing comparison shopping. All the results presented here have been formally proved in Isabelle by building on Larry Paulson's inductive approach. This therefore provides a library of general theorems that can be applied to other protocols.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2019-08-16 00:00:00.000000"},
{"id":"1132","title":"Improve hospital cover world hold end state.","abstract":"Experimental measurements of the extraction efficiency f of the UV-induced photoelectrons emitted from a CsI photocathode into gas mixtures of Ne with CH4, CF4, CO2 and N2 are presented; they are compared with model-simulation results. Backscattering of low- energy photoelectrons emitted into noble gas is significantly reduced by the admixture of molecular gases, with direct impact on the effective quantum efficiency. Data are provided on the dependence of f on the type and concentration of the molecular gas in the mixtures and on the electric field.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2016-10-14 00:00:00.000000"},
{"id":"1133","title":"Admit structure behavior want generation.","abstract":"Let X be a complex manifold and c a simple closed curve in X. We address the question: What conditions on c ensure the existence of a 1-dimensional complex subvariety V with boundary c in X. When X = C^n, an answer to this question involves the polynomial hull of gamma. When X = P^n, complex projective space, the projective hull hat{c} of c comes into play. One always has V contained in hat{c}, and for analytic curves they conjecturally coincide.   In this paper we establish an approximate analogue of this idea which holds without the analyticity of c. We characterize points in hat{c} as those which lie on a sequence of analytic disks whose boundaries converge down to c. This is in the spirit of work of Poletsky and of Larusson-Sigurdsson, whose work is essential here.   The results are applied to construct a remarkable example of a closed curve c in P^2, which is real analytic at all but one point, and for which the closure of hat{c} is W \\cup L where L is a projective line and W is an analytic (non-algebraic) subvariety of P^2 - L. Furthermore, hat{c} itself is the union of W with only two points on L.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2018-09-18 00:00:00.000000"},
{"id":"1134","title":"Sell style animal again son.","abstract":"Jake Goodman and Ulrich Kr\\\"ahmer have recently shown that a twisted Calabi-Yau algebra $A$ with modular automorphism $\\sigma$ and dimension $d$ can be \"untwisted,\" in the sense that the Ore extensions $A[X;\\sigma]$ and $A[X^{\\pm1};\\sigma]$ are Calabi-Yau algebras of dimension $d+1$. In this note we show that this in fact extends more generally to the case where we start with an algebra with van den Bergh duality.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2022-06-22 00:00:00.000000"},
{"id":"1135","title":"Recent point study enjoy western than.","abstract":"The MTA beam line has been specifically designed to facilitate measurements of the Fermilab Linac beam emittance and properties utilizing a long, 10m, element-free straight. Linac beam is extracted downstream of the 400-MeV electrostatic chopper located in the Booster injection line. This chopper cannot be utilized for MTA beam, and therefore the entire Linac beam pulse is directed into the MTA beamline. Pulse length manipulation is provided by the 750-keV electrostatic chopper at the upstream end of the Linac and, using this device, beam can be delivered from 8 {\\mu}sec up to the full 50 {\\mu}sec Linac pulse length.   The 10 m emittance measurement straight exploits and begins at the 12' shield wall that separates the MTA Experimental Hall and beamline stub from the Linac enclosure. A quadrupole triplet has been installed upstream of the shield wall in order to focus a large, 1.5-2\" (~95% width) beam through the shield wall and onto a profile monitor located at the exit of the shielding. Another profile monitor has been installed upstream of the shield wall, ~5 m upstream of the central, or focal-point monitor. With the triplet, a small, 0.2-0.5\" spot size was produced for the initial measurement reported here.   As will be shown in this report, a small, approximate beam waist located near a center profile monitor reduces the number of unknown linear optical parameters to two Courant-Snyder parameters, {\\beta} and {\\epsilon}, since, {\\alpha}, or the rotation of the phase ellipse can be determined by propagating the beam envelope from this waist (using the simple linear transfer matrix that describes a drift).","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2016-08-15 00:00:00.000000"},
{"id":"1136","title":"Democrat knowledge various agreement back nature.","abstract":"The aim of the present paper is to bridge the gap between the Bakry-\\'Emery and the Lott-Sturm-Villani approaches to provide synthetic and abstract notions of lower Ricci curvature bounds. We start from a strongly local Dirichlet form E admitting a Carr\\'e du champ in a Polish measure space (X,m) and a canonical distance d that induces the original topology of X. We first characterize the distinguished class of Riemannian Energy measure spaces, where the Dirichlet form E coincides with the Cheeger energy induced by d and where every function f whose energy measure with bounded density admits a continuous representative. In such a class we show that if E satisfies a suitable weak form of the Bakry-\\'Emery curvature dimension condition BE(K,$\\infty$) then the metric measure space (X,d,m) satisfies the Riemannian Ricci curvature bound RCD(K,$\\infty$), thus showing the equivalence of the two notions. Two applications are then proved: the tensorization property for Riemannian Energy spaces satisfying the Bakry-\\'Emery condition BE(K,N) (and thus the corresponding one for RCD(K,$\\infty$) spaces without assuming nonbranching) and the stability of BE(K,N) with respect to Sturm-Gromov-Hausdorff convergence.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2018-08-12 00:00:00.000000"},
{"id":"1137","title":"Very blood machine.","abstract":"Mathematics cannot anymore be assimilated to a linguistic game, where formal proofs are strongly differentiated with conjectural thinking, without building any category of knowledge to understand the passage (Wittgenstein's gist). Nowadays, philosophy has to face with the growing, exponential ramified tree of speculative mathematical thinking. Our main (problematical) theses are: 1. In mathematics, there is no empirical automatism, and no separate, physical-like motricity. 2: The irreversible-synthetical must force to complexify the exegetical game of philosophy; numerical experiments in algebra and in number theory are a kind of letting blow up all possible problems; 4. The nature of mathematical questioning still remains in question.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2019-11-10 00:00:00.000000"},
{"id":"1138","title":"Institution loss cover young vote relationship agree.","abstract":"The interplay of geometrical and topological entanglement in semiflexible knotted polymer rings confined inside a spherical cavity is investigated using advanced numerical methods. By using stringent and robust algorithms for locating knots, we characterize how the knot length lk depends on the ring contour length, Lc and the radius of the confining sphere, Rc . In the no- and strong- confinement cases we observe weak knot localization and complete knot delocalization, respectively. We show that the complex interplay of lk, Lc and Rc that seamlessly bridges these two limits can be encompassed by a simple scaling argument based on deflection theory. The same argument is used to rationalize the multiscale character of the entanglement that emerges with increasing confinement.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2017-11-08 00:00:00.000000"},
{"id":"1139","title":"Purpose PM political.","abstract":"Localisation of a source of a toxic release of biochemical aerosols in the atmosphere is a problem of great importance for public safety. Two main practical difficulties are encountered in this problem: the lack of knowledge of the likelihood function of measurements collected by biochemical sensors, and the plethora of candidate dispersion models, developed under various assumptions (e.g. meteorological conditions, terrain). Aiming to overcome these two difficulties, the paper proposes a likelihood-free approximate Bayesian computation method, which simultaneously uses a set of candidate dispersion models, to localise the source. This estimation framework is implemented via the Monte Carlo method and tested using two experimental datasets.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2016-01-16 00:00:00.000000"},
{"id":"1140","title":"That pick gun right real old adult administration.","abstract":"The Six Circles Theorem of C. Evelyn, G. Money-Coutts, and J. Tyrrell concerns chains of circles inscribed into a triangle: the first circle is inscribed in the first angle, the second circle is inscribed in the second angle and tangent to the first circle, the third circle is inscribed in the third angle and tangent to the second circle, and so on, cyclically. The theorem asserts that if all the circles touch the sides of the triangle, and not their extensions, then the chain is 6-periodic. We show that, in general, the chain is eventually 6-periodic but may have an arbitrarily long pre-period.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2018-07-10 00:00:00.000000"},
{"id":"1141","title":"Fall probably thought consider upon piece.","abstract":"We construct examples of symplectic half-flat manifolds on compact quotients of solvable Lie groups. We prove that the Calabi-Yau structures are not rigid in the class of symplectic half-flat structures. Moreover, we provide an example of a compact 6-dimensional symplectic half-flat manifold whose real part of the complex volume form is d-exact. Finally we discuss the 4-dimensional case.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2021-04-26 00:00:00.000000"},
{"id":"1142","title":"Seat simply program analysis give garden nature.","abstract":"We show that every orthogonal polyhedron homeomorphic to a sphere can be unfolded without overlap while using only polynomially many (orthogonal) cuts. By contrast, the best previous such result used exponentially many cuts. More precisely, given an orthogonal polyhedron with n vertices, the algorithm cuts the polyhedron only where it is met by the grid of coordinate planes passing through the vertices, together with Theta(n^2) additional coordinate planes between every two such grid planes.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2017-07-15 00:00:00.000000"},
{"id":"1143","title":"Off base beautiful environmental north hotel our you.","abstract":"Assuming the AND-distillation conjecture, the Pathwidth problem of determining whether a given graph G has pathwidth at most k admits no polynomial kernelization with respect to k. The present work studies the existence of polynomial kernels for Pathwidth with respect to other, structural, parameters. Our main result is that, unless NP is in coNP\/poly, Pathwidth admits no polynomial kernelization even when parameterized by the vertex deletion distance to a clique, by giving a cross-composition from Cutwidth. The cross-composition works also for Treewidth, improving over previous lower bounds by the present authors. For Pathwidth, our result rules out polynomial kernels with respect to the distance to various classes of polynomial-time solvable inputs, like interval or cluster graphs. This leads to the question whether there are nontrivial structural parameters for which Pathwidth does admit a polynomial kernelization. To answer this, we give a collection of graph reduction rules that are safe for Pathwidth. We analyze the success of these results and obtain polynomial kernelizations with respect to the following parameters: the size of a vertex cover of the graph, the vertex deletion distance to a graph where each connected component is a star, and the vertex deletion distance to a graph where each connected component has at most c vertices.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2021-09-01 00:00:00.000000"},
{"id":"1144","title":"Production teach lose executive end push.","abstract":"A paradigm of statistical mechanics of financial markets (SMFM) is fit to multivariate financial markets using Adaptive Simulated Annealing (ASA), a global optimization algorithm, to perform maximum likelihood fits of Lagrangians defined by path integrals of multivariate conditional probabilities. Canonical momenta are thereby derived and used as technical indicators in a recursive ASA optimization process to tune trading rules. These trading rules are then used on out-of-sample data, to demonstrate that they can profit from the SMFM model, to illustrate that these markets are likely not efficient. This methodology can be extended to other systems, e.g., electroencephalography. This approach to complex systems emphasizes the utility of blending an intuitive and powerful mathematical-physics formalism to generate indicators which are used by AI-type rule-based models of management.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2018-08-09 00:00:00.000000"},
{"id":"1145","title":"Else face performance money both.","abstract":"We revisit the classical decision-theoretic problem of weighted expert voting from a statistical learning perspective. In particular, we examine the consistency (both asymptotic and finitary) of the optimal Nitzan-Paroush weighted majority and related rules. In the case of known expert competence levels, we give sharp error estimates for the optimal rule. When the competence levels are unknown, they must be empirically estimated. We provide frequentist and Bayesian analyses for this situation. Some of our proof techniques are non-standard and may be of independent interest. The bounds we derive are nearly optimal, and several challenging open problems are posed. Experimental results are provided to illustrate the theory.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2015-06-17 00:00:00.000000"},
{"id":"1146","title":"By budget design field.","abstract":"When averaged over sources or disorder, cross-correlation of diffuse fields yield the Green's function between two passive sensors. This technique is applied to elastic ultrasonic waves in an open scattering slab mimicking seismic waves in the Earth's crust. It appears that the Rayleigh wave reconstruction depends on the scattering properties of the elastic slab. Special attention is paid to the specific role of bulk to Rayleigh wave coupling, which may result in unexpected phenomena like a persistent time-asymmetry in the diffuse regime.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2018-05-09 00:00:00.000000"},
{"id":"1147","title":"Suffer whether picture professional.","abstract":"Dynamical processes on complex networks such as information propagation, innovation diffusion, cascading failures or epidemic spreading are highly affected by their underlying topologies as characterized by, for instance, degree-degree correlations. Here, we introduce the concept of copulas in order to artificially generate random networks with an arbitrary degree distribution and a rich a priori degree-degree correlation (or `association') structure. The accuracy of the proposed formalism and corresponding algorithm is numerically confirmed. The derived network ensembles can be systematically deployed as proper null models, in order to unfold the complex interplay between the topology of real networks and the dynamics on top of them.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2018-01-11 00:00:00.000000"},
{"id":"1148","title":"Finish answer ground prepare.","abstract":"We study estimation and prediction in linear models where the response and the regressor variable both take values in some Hilbert space. Our main objective is to obtain consistency of a principal components based estimator for the regression operator under minimal assumptions. In particular, we avoid some inconvenient technical restrictions that have been used throughout the literature. We develop our theory in a time dependent setup which comprises as important special case the autoregressive Hilbertian model.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2017-01-17 00:00:00.000000"},
{"id":"1149","title":"Hundred little say evening analysis son.","abstract":"We prove a version of L'hospital's rule for multivariable functions, which holds for non-isolated singular points. We also give an algorithm for resolving many indeterminate limits with isolated singular points.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2020-01-21 00:00:00.000000"},
{"id":"1150","title":"Home long try south smile amount color learn.","abstract":"This paper introduces a method of navigation in a large family of tilings of the hyperbolic plane and looks at the question of possible applications in the light of the few ones which were already obtained.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2019-07-06 00:00:00.000000"},
{"id":"1151","title":"Receive doctor nearly organization third course little military.","abstract":"This paper describes a new approach to time series modeling that combines subject-matter knowledge of the system dynamics with statistical techniques in time series analysis and regression. Applications to American option pricing and the Canadian lynx data are given to illustrate this approach.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2021-06-05 00:00:00.000000"},
{"id":"1152","title":"Hear great sea live when.","abstract":"We analyze the algorithm in [Holub, 2009], which decides whether a given word is a fixed point of a nontrivial morphism. We show that it can be implemented to have complexity in O(mn), where n is the length of the word and m the size of the alphabet.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2019-08-16 00:00:00.000000"},
{"id":"1153","title":"Dark father key agreement.","abstract":"With the continuous growth in the consumer markets of mobile smartphones and increasingly in augmented reality wearable devices, several avenues of research investigate the relationships between the quality perceived by mobile users and the delivery mechanisms at play to support a high quality of experience for mobile users. In this paper, we present the first study that evaluates the relationships of mobile movie quality and the viewer-perceived quality thereof in an augmented reality setting with see-through devices. We find that participants tend to overestimate the video quality and exhibit a significant variation of accuracy that leans onto the movie content and its dynamics. Our findings, thus, can broadly impact future media adaptation and delivery mechanisms for this new display format of mobile multimedia.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2019-12-22 00:00:00.000000"},
{"id":"1154","title":"Hospital across maintain fly professional.","abstract":"We consider semiparametric location-scatter models for which the $p$-variate observation is obtained as $X=\\Lambda Z+\\mu$, where $\\mu$ is a $p$-vector, $\\Lambda$ is a full-rank $p\\times p$ matrix and the (unobserved) random $p$-vector $Z$ has marginals that are centered and mutually independent but are otherwise unspecified. As in blind source separation and independent component analysis (ICA), the parameter of interest throughout the paper is $\\Lambda$. On the basis of $n$ i.i.d. copies of $X$, we develop, under a symmetry assumption on $Z$, signed-rank one-sample testing and estimation procedures for $\\Lambda$. We exploit the uniform local and asymptotic normality (ULAN) of the model to define signed-rank procedures that are semiparametrically efficient under correctly specified densities. Yet, as is usual in rank-based inference, the proposed procedures remain valid (correct asymptotic size under the null, for hypothesis testing, and root-$n$ consistency, for point estimation) under a very broad range of densities. We derive the asymptotic properties of the proposed procedures and investigate their finite-sample behavior through simulations.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2022-04-12 00:00:00.000000"},
{"id":"1155","title":"Red total eight success.","abstract":"The sequential parameter optimization (SPOT) package for R is a toolbox for tuning and understanding simulation and optimization algorithms. Model-based investigations are common approaches in simulation and optimization. Sequential parameter optimization has been developed, because there is a strong need for sound statistical analysis of simulation and optimization algorithms. SPOT includes methods for tuning based on classical regression and analysis of variance techniques; tree-based models such as CART and random forest; Gaussian process models (Kriging), and combinations of different meta-modeling approaches. This article exemplifies how SPOT can be used for automatic and interactive tuning.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2016-01-08 00:00:00.000000"},
{"id":"1156","title":"Computer my performance above.","abstract":"Let $G$ be a finitely generated abelian-by-finite group and $k$ a field of characteristic $p\\ge 0$. The Euler class $[k_G]$ of $G$ over $k$ is the class of the trivial $kG$-module in the Grothendieck group $G_0(kG)$. We show that $[k_G]$ has finite order if and only if every $p$-regular element of $G$ has infinite centralizer in $G$. We also give a lower bound for the order of the Euler class in terms of suitable finite subgroups of $G$. This lower bound is derived from a more general result on finite-dimensional representations of smash products of Hopf algebras.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2021-08-05 00:00:00.000000"},
{"id":"1157","title":"Pass wonder fish send machine bag story.","abstract":"We investigate Matlis duals of local cohomology modules and prove that, in general, their zeroth Bass number with respect to the zero ideal is not finite. We also prove that, somewhat surprisingly, if we apply local cohomology again (i. e. to the Matlis dual of the local cohomology module), we get (under certain hypotheses) either zero or $E$, an $R$-injective hull of the residue field of the local ring $R$.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2015-05-22 00:00:00.000000"},
{"id":"1158","title":"Far cold tough others.","abstract":"We present a novel self-stabilizing algorithm for minimum spanning tree (MST) construction. The space complexity of our solution is $O(\\log^2n)$ bits and it converges in $O(n^2)$ rounds. Thus, this algorithm improves the convergence time of previously known self-stabilizing asynchronous MST algorithms by a multiplicative factor $\\Theta(n)$, to the price of increasing the best known space complexity by a factor $O(\\log n)$. The main ingredient used in our algorithm is the design, for the first time in self-stabilizing settings, of a labeling scheme for computing the nearest common ancestor with only $O(\\log^2n)$ bits.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2015-05-06 00:00:00.000000"},
{"id":"1159","title":"Report mission spring year.","abstract":"Given a finite class of functions F, the problem of aggregation is to construct a procedure with a risk as close as possible to the risk of the best element in the class. A classical procedure (PAC-Bayesian statistical learning theory (2004) Paris 6, Statistical Learning Theory and Stochastic Optimization (2001) Springer, Ann. Statist. 28 (2000) 75-87) is the aggregate with exponential weights (AEW), defined by \\[\\tilde{f}^{\\mathrm{AEW}}=\\sum_{f\\in F}\\hat{\\theta}(f)f,\\qquad where \\hat{\\theta}(f)=\\frac{\\exp(-({n}\/{T})R_n(f))}{\\sum_{g\\in F}\\exp(-({n}\/{T})R_n(g))},\\] where $T>0$ is called the temperature parameter and $R_n(\\cdot)$ is an empirical risk. In this article, we study the optimality of the AEW in the regression model with random design and in the low-temperature regime. We prove three properties of AEW. First, we show that AEW is a suboptimal aggregation procedure in expectation with respect to the quadratic risk when $T\\leq c_1$, where $c_1$ is an absolute positive constant (the low-temperature regime), and that it is suboptimal in probability even for high temperatures. Second, we show that as the cardinality of the dictionary grows, the behavior of AEW might deteriorate, namely, that in the low-temperature regime it might concentrate with high probability around elements in the dictionary with risk greater than the risk of the best function in the dictionary by at least an order of $1\/\\sqrt{n}$. Third, we prove that if a geometric condition on the dictionary (the so-called \"Bernstein condition) is assumed, then AEW is indeed optimal both in high probability and in expectation in the low-temperature regime. Moreover, under that assumption, the complexity term is essentially the logarithm of the cardinality of the set of \"almost minimizers\" rather than the logarithm of the cardinality of the entire dictionary. This result holds for small values of the temperature parameter, thus complementing an analogous result for high temperatures.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2016-02-29 00:00:00.000000"},
{"id":"1160","title":"Small another home agree and old.","abstract":"Gravity stands apart from other fundamental interactions in that it is locally equivalent to an accelerated frame and can be transformed away. Again it is indistinguishable from the geometry of space-time (which is an arena for all other basic interactions), its strength being linked with the curvature. This is a major reason why it has so far not been amenable to quantisation like other interactions. It is also evident that new ideas are required to resolve several conundrums in areas like cosmology, black hole physics, and particles at high energies. That gravity can have strong coupling at microscales has also been suggested in several contexts earlier. Here we develop some of these ideas, especially in connection with the high accelerations experienced by particles at microscales, which would be interpreted as strong local gravitational fields. The consequences are developed for various situations and possible experimental manifestations are discussed.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2020-03-12 00:00:00.000000"},
{"id":"1161","title":"Director democratic different discover student idea.","abstract":"In this manuscript, assuming that Graedel's 1991 results are correct (which implies that bounds on the solution values for optimization problems can be expressed in existential second order logic where the first order part is universal Horn), I will show that Clique and Vertex Cover can be solved in polynomial time if the input structure is ordered and contains a successor predicate. In the last section, we will argue about the validity of Graedel's 1991 results. Update: Manuscript withdrawn, because results are incorrect. If phi = phi_1 AND phi_2, and phi is a Horn formula, it does NOT mean that both phi_1 and phi_2 are Horn formulae. Furthermore, the cardinality constraint CANNOT be expressed as a universal Horn sentence in ESO (NOT even when the structure is ordered).","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2018-01-11 00:00:00.000000"},
{"id":"1162","title":"Beat at table shoulder country.","abstract":"Using interplay between surface plasmons and metamaterials, we propose a new technique for novel metamaterial designs. We show that surface plasmons existing on thin metal surfaces can be used to \"drive\" non-resonant structures in their vicinity to provide new types of electric and magnetic resonators. These resonators strictly adhere to surface plasmon dispersion of the host metal film. The operating frequency of the resultant metamaterials can be scaled to extremely high frequencies, otherwise not possible with conventional split-ring-resonator-based designs. Our approach opens new possibilities for theory and experiment in the interface of plasmonics and metamaterials to harvest many potential applications of both fields combined.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2022-08-03 00:00:00.000000"},
{"id":"1163","title":"Hard turn wish morning.","abstract":"Differential entropy and log determinant of the covariance matrix of a multivariate Gaussian distribution have many applications in coding, communications, signal processing and statistical inference. In this paper we consider in the high dimensional setting optimal estimation of the differential entropy and the log-determinant of the covariance matrix. We first establish a central limit theorem for the log determinant of the sample covariance matrix in the high dimensional setting where the dimension $p(n)$ can grow with the sample size $n$. An estimator of the differential entropy and the log determinant is then considered. Optimal rate of convergence is obtained. It is shown that in the case $p(n)\/n \\rightarrow 0$ the estimator is asymptotically sharp minimax. The ultra-high dimensional setting where $p(n) > n$ is also discussed.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2021-08-03 00:00:00.000000"},
{"id":"1164","title":"Early chair measure including.","abstract":"Acoustical measurements, electron spin resonance, and Raman spectroscopy have been employed to probe sulfur over the temperature range 80 to 180 C, which includes the polymerization transition and the supercooled liquid state. Acoustical properties (sound velocity, absorption and impedance) have been studied with both longitudinal and transverse waves at frequencies between 500 kHz and 22 MHz. The results confirm that polymeric sulfur is a solution of long chain molecules in monomeric solvent, and that the polymerization transition is not a second order phase transition, as was proposed theoretically. Sulfur is a viscous liquid, but not viscoelastic, both below and above the polymerization transition temperature. It is shown that the classical Navier-Stokes theory is not applicable to the sound absorption in liquid sulfur in the highly viscous state.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2021-02-28 00:00:00.000000"},
{"id":"1165","title":"Social agency seem security arrive name.","abstract":"Hypervolume indicator is a commonly accepted quality measure for comparing Pareto approximation set generated by multi-objective optimizers. The best known algorithm to calculate it for $n$ points in $d$-dimensional space has a run time of $O(n^{d\/2})$ with special data structures. This paper presents a recursive, vertex-splitting algorithm for calculating the hypervolume indicator of a set of $n$ non-comparable points in $d>2$ dimensions. It splits out multiple child hyper-cuboids which can not be dominated by a splitting reference point. In special, the splitting reference point is carefully chosen to minimize the number of points in the child hyper-cuboids. The complexity analysis shows that the proposed algorithm achieves $O((\\frac{d}{2})^n)$ time and $O(dn^2)$ space complexity in the worst case.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2021-12-10 00:00:00.000000"},
{"id":"1166","title":"Reality fight star surface.","abstract":"Using the theorem of residues Chiarella and Reichel derived a series that can be represented in terms of the complex error function (CEF). Here we show a simple derivation of this CEF series by Fourier expansion of the exponential function $\\exp ({- {\\tau ^2}\/4})$. Such approach explains the existence of the lower bound for the input parameter $y = \\operatorname{Im} [z]$ restricting the application of the CEF approximation. An algorithm resolving this problem for accelerated computation of the CEF with sustained high accuracy is proposed.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2015-10-11 00:00:00.000000"},
{"id":"1167","title":"Appear him training nearly fear someone.","abstract":"Computing practice today depends on visual output to drive almost all user interaction. Other senses, such as audition, may be totally neglected, or used tangentially, or used in highly restricted specialized ways. We have excellent audio rendering through D-A conversion, but we lack rich general facilities for modeling and manipulating sound comparable in quality and flexibility to graphics. We need co-ordinated research in several disciplines to improve the use of sound as an interactive information channel.   Incremental and separate improvements in synthesis, analysis, speech processing, audiology, acoustics, music, etc. will not alone produce the radical progress that we seek in sonic practice. We also need to create a new central topic of study in digital audio research. The new topic will assimilate the contributions of different disciplines on a common foundation. The key central concept that we lack is sound as a general-purpose information channel. We must investigate the structure of this information channel, which is driven by the co-operative development of auditory perception and physical sound production. Particular audible encodings, such as speech and music, illuminate sonic information by example, but they are no more sufficient for a characterization than typography is sufficient for a characterization of visual information.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2016-10-04 00:00:00.000000"},
{"id":"1168","title":"Student production several act all.","abstract":"In high-dimensional linear regression, the goal pursued here is to estimate an unknown regression function using linear combinations of a suitable set of covariates. One of the key assumptions for the success of any statistical procedure in this setup is to assume that the linear combination is sparse in some sense, for example, that it involves only few covariates. We consider a general, non necessarily linear, regression with Gaussian noise and study a related question that is to find a linear combination of approximating functions, which is at the same time sparse and has small mean squared error (MSE). We introduce a new estimation procedure, called Exponential Screening that shows remarkable adaptation properties. It adapts to the linear combination that optimally balances MSE and sparsity, whether the latter is measured in terms of the number of non-zero entries in the combination ($\\ell_0$ norm) or in terms of the global weight of the combination ($\\ell_1$ norm). The power of this adaptation result is illustrated by showing that Exponential Screening solves optimally and simultaneously all the problems of aggregation in Gaussian regression that have been discussed in the literature. Moreover, we show that the performance of the Exponential Screening estimator cannot be improved in a minimax sense, even if the optimal sparsity is known in advance. The theoretical and numerical superiority of Exponential Screening compared to state-of-the-art sparse procedures is also discussed.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2019-12-22 00:00:00.000000"},
{"id":"1169","title":"Physical someone allow when industry lose time.","abstract":"We investigate the properties of bounded operators which satisfy a certain spectral additivity condition, and use our results to study Lie and Jordan algebras of compact operators. We prove that these algebras have nontrivial invariant subspaces when their elements have sublinear or submultiplicative spectrum, and when they satisfy simple trace conditions. In certain cases we show that these conditions imply that the algebra is (simultaneously) triangularizable.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2022-09-03 00:00:00.000000"},
{"id":"1170","title":"Conference care play.","abstract":"Many popular learning algorithms (E.g. Regression, Fourier-Transform based algorithms, Kernel SVM and Kernel ridge regression) operate by reducing the problem to a convex optimization problem over a vector space of functions. These methods offer the currently best approach to several central problems such as learning half spaces and learning DNF's. In addition they are widely used in numerous application domains. Despite their importance, there are still very few proof techniques to show limits on the power of these algorithms.   We study the performance of this approach in the problem of (agnostically and improperly) learning halfspaces with margin $\\gamma$. Let $\\mathcal{D}$ be a distribution over labeled examples. The $\\gamma$-margin error of a hyperplane $h$ is the probability of an example to fall on the wrong side of $h$ or at a distance $\\le\\gamma$ from it. The $\\gamma$-margin error of the best $h$ is denoted $\\mathrm{Err}_\\gamma(\\mathcal{D})$. An $\\alpha(\\gamma)$-approximation algorithm receives $\\gamma,\\epsilon$ as input and, using i.i.d. samples of $\\mathcal{D}$, outputs a classifier with error rate $\\le \\alpha(\\gamma)\\mathrm{Err}_\\gamma(\\mathcal{D}) + \\epsilon$. Such an algorithm is efficient if it uses $\\mathrm{poly}(\\frac{1}{\\gamma},\\frac{1}{\\epsilon})$ samples and runs in time polynomial in the sample size.   The best approximation ratio achievable by an efficient algorithm is $O\\left(\\frac{1\/\\gamma}{\\sqrt{\\log(1\/\\gamma)}}\\right)$ and is achieved using an algorithm from the above class. Our main result shows that the approximation ratio of every efficient algorithm from this family must be $\\ge \\Omega\\left(\\frac{1\/\\gamma}{\\mathrm{poly}\\left(\\log\\left(1\/\\gamma\\right)\\right)}\\right)$, essentially matching the best known upper bound.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2021-12-13 00:00:00.000000"},
{"id":"1171","title":"Able though century.","abstract":"The paper presents new machine learning methods: signal composition, which classifies time-series regardless of length, type, and quantity; and self-labeling, a supervised-learning enhancement. The paper describes further the implementation of the methods on a financial search engine system using a collection of 7,881 financial instruments traded during 2011 to identify inverse behavior among the time-series.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2017-08-04 00:00:00.000000"},
{"id":"1172","title":"Bed sure approach determine ready pattern own.","abstract":"In this contribution we describe an approach to evolve composite covariance functions for Gaussian processes using genetic programming. A critical aspect of Gaussian processes and similar kernel-based models such as SVM is, that the covariance function should be adapted to the modeled data. Frequently, the squared exponential covariance function is used as a default. However, this can lead to a misspecified model, which does not fit the data well. In the proposed approach we use a grammar for the composition of covariance functions and genetic programming to search over the space of sentences that can be derived from the grammar. We tested the proposed approach on synthetic data from two-dimensional test functions, and on the Mauna Loa CO2 time series. The results show, that our approach is feasible, finding covariance functions that perform much better than a default covariance function. For the CO2 data set a composite covariance function is found, that matches the performance of a hand-tuned covariance function.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2019-05-02 00:00:00.000000"},
{"id":"1173","title":"Figure fear water this itself Republican must.","abstract":"Bohr's dictum \"Physical phenomena are observed relative to different experimental setups\" is applied to a set of binary elements that represent the smallest units of information. A description relative to \"macroscopic\" setups of such elements is formulated. This requires the introduction of a Hilbert space formalism. It is shown, that the Hilbert space is symmetric with respect to the de Sitter group SO(3,2). For macroscopic setups SO(3,2) is approximated by the Poincare group. A space-time manifold is obtained that expresses the orientation of macroscopic setups relative to each other. Individual binary elements can then be given a \"position\" relative to macroscopic reference frames. To an observer binary elements will then exhibit properties of massive particles. This informational approach to particle physics determines a mass scale, delivers interaction terms for all four interactions and is, in principle, capable of fixing coupling constants and masses. Despite its simplicity it forms a promising basis for a theoretical model that leads beyond the standard model.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2019-05-11 00:00:00.000000"},
{"id":"1174","title":"Then foot section style.","abstract":"Let ${\\cal{D}}$ = $\\{d_1, d_2, d_3, ..., d_D\\}$ be a given set of $D$ (string) documents of total length $n$. The top-$k$ document retrieval problem is to index $\\cal{D}$ such that when a pattern $P$ of length $p$, and a parameter $k$ come as a query, the index returns the $k$ most relevant documents to the pattern $P$. Hon et. al. \\cite{HSV09} gave the first linear space framework to solve this problem in $O(p + k\\log k)$ time. This was improved by Navarro and Nekrich \\cite{NN12} to $O(p + k)$. These results are powerful enough to support arbitrary relevance functions like frequency, proximity, PageRank, etc. In many applications like desktop or email search, the data resides on disk and hence disk-bound indexes are needed. Despite of continued progress on this problem in terms of theoretical, practical and compression aspects, any non-trivial bounds in external memory model have so far been elusive. Internal memory (or RAM) solution to this problem decomposes the problem into $O(p)$ subproblems and thus incurs the additive factor of $O(p)$. In external memory, these approaches will lead to $O(p)$ I\/Os instead of optimal $O(p\/B)$ I\/O term where $B$ is the block-size. We re-interpret the problem independent of $p$, as interval stabbing with priority over tree-shaped structure. This leads us to a linear space index in external memory supporting top-$k$ queries (with unsorted outputs) in near optimal $O(p\/B + \\log_B n + \\log^{(h)} n + k\/B)$ I\/Os for any constant $h${$\\log^{(1)}n =\\log n$ and $\\log^{(h)} n = \\log (\\log^{(h-1)} n)$}. Then we get $O(n\\log^*n)$ space index with optimal $O(p\/B+\\log_B n + k\/B)$ I\/Os.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2020-01-31 00:00:00.000000"},
{"id":"1175","title":"Building reveal together way likely season let.","abstract":"By means of extensive computer simulations, the authors consider the entangled coevolution of actions and social structure in a new version of a spatial Prisoner's Dilemma model that naturally gives way to a process of social differentiation. Diverse social roles emerge from the dynamics of the system: leaders are individuals getting a large payoff who are imitated by a considerable fraction of the population, conformists are unsatisfied cooperative agents that keep cooperating, and exploiters are defectors with a payoff larger than the average one obtained by cooperators. The dynamics generate a social network that can have the topology of a small world network. The network has a strong hierarchical structure in which the leaders play an essential role in sustaining a highly cooperative stable regime. But disruptions affecting leaders produce social crises described as dynamical cascades that propagate through the network.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2020-06-15 00:00:00.000000"},
{"id":"1176","title":"Street fight civil former leave threat.","abstract":"We describe how a new framework for coupling a full-PIC algorithm with a reduced PIC algorithm has been implemented into the code OSIRIS. We show that OSIRIS with this new hybrid-PIC algorithm can efficiently and accurately model high energy density scenarios such as ion acceleration in laser-solid interactions and fast ignition of fusion targets. We model for the first time the full density range of a fast ignition target in a fully self-consistent hybrid-PIC simulation, illustrating the possibility of stopping the laser generated electron flux at the core region with relatively high efficiencies. Computational speedups greater than 1000 times are demonstrated, opening the way for full-scale multi-dimensional modeling of high energy density scenarios and for the guiding of future experiments.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2019-05-09 00:00:00.000000"},
{"id":"1177","title":"Left later home must bag off main.","abstract":"Bounds on Bayesian posterior convergence rates, assuming the prior satisfies both local and global support conditions, are now readily available. In this paper we explore, in the context of density estimation, Bayesian convergence rates assuming only local prior support conditions. Our results give optimal rates under minimal conditions using very simple arguments.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2021-02-02 00:00:00.000000"},
{"id":"1178","title":"Leave rest course owner religious.","abstract":"Acyclic digraphs arise in many natural and artificial processes. Among the broader set, dynamic citation networks represent a substantively important form of acyclic digraphs. For example, the study of such networks includes the spread of ideas through academic citations, the spread of innovation through patent citations, and the development of precedent in common law systems. The specific dynamics that produce such acyclic digraphs not only differentiate them from other classes of graphs, but also provide guidance for the development of meaningful distance measures. In this article, we develop and apply our sink distance measure together with the single-linkage hierarchical clustering algorithm to both a two-dimensional directed preferential attachment model as well as empirical data drawn from the first quarter century of decisions of the United States Supreme Court. Despite applying the simplest combination of distance measures and clustering algorithms, analysis reveals that more accurate and more interpretable clusterings are produced by this scheme.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2016-09-01 00:00:00.000000"},
{"id":"1179","title":"Over will young newspaper sit.","abstract":"The paper will present a novel approach for solving face recognition problem. Our method combines 2D Principal Component Analysis (2DPCA), one of the prominent methods for extracting feature vectors, and Support Vector Machine (SVM), the most powerful discriminative method for classification. Experiments based on proposed method have been conducted on two public data sets FERET and AT&T; the results show that the proposed method could improve the classification rates.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2018-06-13 00:00:00.000000"},
{"id":"1180","title":"Size base drop couple determine.","abstract":"The calculation of network reliability in a probabilistic context has long been an issue of practical and academic importance. Conventional approaches (determination of bounds, sums of disjoint products algorithms, Monte Carlo evaluations, studies of the reliability polynomials, etc.) only provide approximations when the network's size increases, even when nodes do not fail and all edges have the same reliability p. We consider here a directed, generic graph of arbitrary size mimicking real-life long-haul communication networks, and give the exact, analytical solution for the two-terminal reliability. This solution involves a product of transfer matrices, in which individual reliabilities of edges and nodes are taken into account. The special case of identical edge and node reliabilities (p and rho, respectively) is addressed. We consider a case study based on a commonly-used configuration, and assess the influence of the edges being directed (or not) on various measures of network performance. While the two-terminal reliability, the failure frequency and the failure rate of the connection are quite similar, the locations of complex zeros of the two-terminal reliability polynomials exhibit strong differences, and various structure transitions at specific values of rho. The present work could be extended to provide a catalog of exactly solvable networks in terms of reliability, which could be useful as building blocks for new and improved bounds, as well as benchmarks, in the general case.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2016-09-02 00:00:00.000000"},
{"id":"1181","title":"War recent represent north computer.","abstract":"In the present study we attempt to incorporate the philosophical dialogue about physical reality into the instructional process of quantum mechanics. Taking into account that both scientific realism and constructivism represent, on the basis of a rather broad spectrum, prevalent philosophical currents in the domain of science education, the compatibility of their essential commitments is examined against the conceptual structure of quantum theory. It is argued in this respect that the objects of science do not simply constitute 'personal constructions' of the human mind for interpreting nature, as individualist constructivist consider, neither do they form products of a 'social construction', as sociological constructivist assume; on the contrary, they reflect objective structural aspects of the physical world. A realist interpretation of quantum mechanics, we suggest, is not only possible but also necessary for revealing the inner meaning of the theory's scientific content. It is pointed out, however, that a viable realist interpretation of quantum theory requires the abandonment or radical revision of the classical conception of physical reality and its traditional metaphysical presuppositions. To this end, we put forward an alternative to traditional realism interpretative scheme, that is in harmony with the findings of present-day quantum theory, and which, if adequately introduced into the instructional process of contemporary physics, is expected to promote the conceptual reconstruction of learners towards an appropriate view of nature.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2019-07-01 00:00:00.000000"},
{"id":"1182","title":"Role middle rate result anything stay.","abstract":"This paper describes the work towards Gujarati Ad hoc Monolingual Retrieval task for widely used Information Retrieval (IR) models. We present an indexing baseline for the Gujarati Language represented by Mean Average Precision (MAP) values. Our objective is to obtain a relative picture of a better IR model for Gujarati Language. Results show that Classical IR models like Term Frequency Inverse Document Frequency (TF_IDF) performs better when compared to few recent probabilistic IR models. The experiments helped to identify the outperforming IR models for Gujarati Language.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2021-10-19 00:00:00.000000"},
{"id":"1183","title":"Sort staff common month dog sign point population.","abstract":"Reverse nearest neighbor queries are defined as follows: Given an input point-set P, and a query point q, find all the points p in P whose nearest point in P U {q} \\ {p} is q. We give a data structure to answer reverse nearest neighbor queries in fixed-dimensional Euclidean space. Our data structure uses O(n) space, its preprocessing time is O(n log n), and its query time is O(log n).","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2021-01-13 00:00:00.000000"},
{"id":"1184","title":"Green chance style.","abstract":"This paper develops a category-theoretic approach to uncertainty, informativeness and decision-making problems. It is based on appropriate first order fuzzy logic in which not only logical connectives but also quantifiers have fuzzy interpretation. It is shown that all fundamental concepts of probability and statistics such as joint distribution, conditional distribution, etc., have meaningful analogs in new context. This approach makes it possible to utilize rich conceptual experience of statistics. Connection with underlying fuzzy logic reveals the logical semantics for fuzzy decision making. Decision-making problems within the framework of IT-categories and generalizes Bayesian approach to decision-making with a prior information are considered. It leads to fuzzy Bayesian approach in decision making and provides methods for construction of optimal strategies.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2022-06-02 00:00:00.000000"},
{"id":"1185","title":"Much buy tree huge gun truth interesting different.","abstract":"Time-series data with regular and\/or seasonal long-memory are often aggregated before analysis. Often, the aggregation scale is large enough to remove any short-memory components of the underlying process but too short to eliminate seasonal patterns of much longer periods. In this paper, we investigate the limiting correlation structure of aggregate time series within an intermediate asymptotic framework that attempts to capture the aforementioned sampling scheme. In particular, we study the autocorrelation structure and the spectral density function of aggregates from a discrete-time process. The underlying discrete-time process is assumed to be a stationary Seasonal AutoRegressive Fractionally Integrated Moving-Average (SARFIMA) process, after suitable number of differencing if necessary, and the seasonal periods of the underlying process are multiples of the aggregation size. We derive the limit of the normalized spectral density function of the aggregates, with increasing aggregation. The limiting aggregate (seasonal) long-memory model may then be useful for analyzing aggregate time-series data, which can be estimated by maximizing the Whittle likelihood. We prove that the maximum Whittle likelihood estimator (spectral maximum likelihood estimator) is consistent and asymptotically normal, and study its finite-sample properties through simulation. The efficacy of the proposed approach is illustrated by a real-life internet traffic example.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2022-05-27 00:00:00.000000"},
{"id":"1186","title":"Wrong suggest certainly push eye player arm.","abstract":"The relationship between position and momentum in quantum mechanics formally translates into a Fourier transform between the position (configuration) and momentum representations of the wave function. These two representations are usually introduced without a proper physical contextualization. Here this issue is tackled by means of a simple and pedagogical analysis of the atomic three-grating Mach-Zehnder interferometer. This analysis provides a clear picture of how both representations intertwine as well as an easy way to understand the physics underpinning this type of interferometers. Bearing in mind the physics of undergraduate courses, a simple working model of gratings consisting of evenly-spaced Gaussian slits has been considered. This model allows to explore the physics involved in these interferometers in a simple fashion combining both analytical results and numerical simulations. A clear picture of the wavefront splitting process inside the interferometer is thus provided, illustrating how the momentum is well defined along each diffraction order in spite of the complexity exhibited by the diffracted wave in configuration space. This is a key point to understand the simplified models commonly used in the literature to describe this type of interferometers, where the particular shape of the wave function is neglected and only the momentum carried along the relevant diffraction orders is considered. For completeness, the role of the third grating in the measure of transmitted atomic flux is also analyzed and discussed.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2017-01-08 00:00:00.000000"},
{"id":"1187","title":"So item all course.","abstract":"In the recent years, reversible logic has emerged as a promising technology having its applications in low power CMOS, quantum computing, nanotechnology, and optical computing. The classical set of gates such as AND, OR, and EXOR are not reversible. This paper proposes a new 4 * 4 reversible gate called TSG gate. The proposed gate is used to design efficient adder units. The most significant aspect of the proposed gate is that it can work singly as a reversible full adder i.e reversible full adder can now be implemented with a single gate only. The proposed gate is then used to design reversible ripple carry and carry skip adders. It is demonstrated that the adder architectures designed using the proposed gate are much better and optimized, compared to their existing counterparts in literature; in terms of number of reversible gates and garbage outputs. Thus, this paper provides the initial threshold to building of more complex system which can execute more complicated operations using reversible logic.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2020-09-13 00:00:00.000000"},
{"id":"1188","title":"Once own Mrs left expect party.","abstract":"We solve an open problem related to an optimal encoding of a straight line program (SLP), a canonical form of grammar compression deriving a single string deterministically. We show that an information-theoretic lower bound for representing an SLP with n symbols requires at least 2n+logn!+o(n) bits. We then present a succinct representation of an SLP; this representation is asymptotically equivalent to the lower bound. The space is at most 2n log {rho}(1 + o(1)) bits for rho leq 2sqrt{n}, while supporting random access to any production rule of an SLP in O(log log n) time. In addition, we present a novel dynamic data structure associating a digram with a unique symbol. Such a data structure is called a naming function and has been implemented using a hash table that has a space-time tradeoff. Thus, the memory space is mainly occupied by the hash table during the development of production rules. Alternatively, we build a dynamic data structure for the naming function by leveraging the idea behind the wavelet tree. The space is strictly bounded by 2n log n(1 + o(1)) bits, while supporting O(log n) query and update time.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2019-07-15 00:00:00.000000"},
{"id":"1189","title":"Significant office financial this prepare.","abstract":"The effect of a stationary electric field on a water droplet with a diameter of several tens micrometers in oil was examined. Such a droplet exhibits repetitive translational motion between the electrodes in a spontaneous manner. The state diagram of this oscillatory motion was deduced; at 0-20 V the droplet is fixed at the surface of the electrode, at 20-70 V the droplet exhibits small-amplitude oscillatory motion between the electrodes, and at 70-100 V the droplet shows large-amplitude periodic motion between the electrodes. The observed rhythmic motion is explained in a semi-quantitative manner by using differential equations, which includes the effect of charging the droplet under an electric field. We also found that twin droplets exhibit synchronized rhythmic motion between the electrodes.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2021-09-07 00:00:00.000000"},
{"id":"1190","title":"Ok hospital sing present.","abstract":"The placement and dimensioning of exit routes is informed by experimental data and theoretical models. The experimental data is still to a large extent uncertain and contradictory. In this contribution an attempt is made to understand and reconcile these differences with our own experiments.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2020-04-07 00:00:00.000000"},
{"id":"1191","title":"Relationship them him fire day what skin because.","abstract":"We use a well known problem in discrete and computational geometry (partitions of measures by $k$-fans) as a motivation and as a point of departure to illustrate many aspects, both theoretical and computational, of the problem of calculating the obstructions for the existence of equivariant maps. A variety of techniques are introduced and discussed with the emphasis on concrete and explicit calculations. This eventually leads (Theorems 18 and 19) to an almost exhaustive analysis of when such maps do or do not exist in the particular case of interest.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2020-04-03 00:00:00.000000"},
{"id":"1192","title":"Teacher assume high artist other.","abstract":"We present, visualize and analyse the similarities and differences between the controversial topics related to \"edit wars\" identified in 10 different language versions of Wikipedia. After a brief review of the related work we describe the methods developed to locate, measure, and categorize the controversial topics in the different languages. Visualizations of the degree of overlap between the top 100 lists of most controversial articles in different languages and the content related to geographical locations will be presented. We discuss what the presented analysis and visualizations can tell us about the multicultural aspects of Wikipedia and practices of peer-production. Our results indicate that Wikipedia is more than just an encyclopaedia; it is also a window into convergent and divergent social-spatial priorities, interests and preferences.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2021-08-18 00:00:00.000000"},
{"id":"1193","title":"Toward travel police against growth me middle.","abstract":"There are numerous applications which require the ability to take certain actions (e.g. distribute money, medicines, people etc.) over a geographic region. A disaster relief organization must allocate people and supplies to parts of a region after a disaster. A public health organization must allocate limited vaccine to people across a region. In both cases, the organization is trying to optimize something (e.g. minimize expected number of people with a disease). We introduce \"geospatial optimization problems\" (GOPs) where an organization has limited resources and budget to take actions in a geographic area. The actions result in one or more properties changing for one or more locations. There are also certain constraints on the combinations of actions that can be taken. We study two types of GOPs - goal-based and benefit-maximizing (GBGOP and BMGOP respectively). A GBGOP ensures that certain properties must be true at specified locations after the actions are taken while a BMGOP optimizes a linear benefit function. We show both problems to be NP-hard (with membership in NP for the associated decision problems). Additionally, we prove limits on approximation for both problems. We present integer programs for both GOPs that provide exact solutions. We also correctly reduce the number of variables in for the GBGOP integer constraints. For BMGOP, we present the BMGOP-Compute algorithm that runs in PTIME and provides a reasonable approximation guarantee in most cases.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2018-07-04 00:00:00.000000"},
{"id":"1194","title":"I field simply performance defense.","abstract":"A kissing sphere is a sphere that is tangent to a fixed reference ball. We develop in this paper a distance geometry for kissing spheres, which turns out to be a generalization of the classical Euclidean distance geometry.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2019-03-18 00:00:00.000000"},
{"id":"1195","title":"Good admit still trade ask best.","abstract":"In this paper, we study the rate of convergence of the cyclic projection algorithm applied to finitely many basic semi-algebraic convex sets. We establish an explicit convergence rate estimate which relies on the maximum degree of the polynomials that generate the basic semi-algebraic convex sets and the dimension of the underlying space. We achieve our results by exploiting the algebraic structure of the basic semi-algebraic convex sets.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2016-05-12 00:00:00.000000"},
{"id":"1196","title":"Sit small establish myself expert well edge.","abstract":"Although whether P equals NP is an important, open problem in computer science, and although Jaeger's 2008 paper, \"Solving the P\/NP Problem Under Intrinsic Uncertainty\" (arXiv:0811.0463) presents an attempt at tackling the problem by discussing the possibility that all computation is uncertain to some degree, there are a number of logical oversights present in that paper which preclude it from serious consideration toward having resolved P-versus-NP. There are several differences between the model of computation presented in Jaeger's paper and the standard model, as well as several bold assumptions that are not well supported in Jaeger's paper or in the literature. In addition, we find several omissions of rigorous proof that ultimately weaken this paper to a point where it cannot be considered a candidate solution to the P-versus-NP problem.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2019-10-13 00:00:00.000000"},
{"id":"1197","title":"What watch during take until.","abstract":"Perhaps surprisingly, it is possible to predict how long an algorithm will take to run on a previously unseen input, using machine learning techniques to build a model of the algorithm's runtime as a function of problem-specific instance features. Such models have important applications to algorithm analysis, portfolio-based algorithm selection, and the automatic configuration of parameterized algorithms. Over the past decade, a wide variety of techniques have been studied for building such models. Here, we describe extensions and improvements of existing models, new families of models, and -- perhaps most importantly -- a much more thorough treatment of algorithm parameters as model inputs. We also comprehensively describe new and existing features for predicting algorithm runtime for propositional satisfiability (SAT), travelling salesperson (TSP) and mixed integer programming (MIP) problems. We evaluate these innovations through the largest empirical analysis of its kind, comparing to a wide range of runtime modelling techniques from the literature. Our experiments consider 11 algorithms and 35 instance distributions; they also span a very wide range of SAT, MIP, and TSP instances, with the least structured having been generated uniformly at random and the most structured having emerged from real industrial applications. Overall, we demonstrate that our new models yield substantially better runtime predictions than previous approaches in terms of their generalization to new problem instances, to new algorithms from a parameterized space, and to both simultaneously.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2018-05-19 00:00:00.000000"},
{"id":"1198","title":"Official window usually participant above study morning.","abstract":"We apply a fundamental definition of time delay, as the difference between the time a particle spends within a finite region of a potential and the time a free particle spends in the same region, to determine results for photoionization of an electron by an extreme ultraviolet (XUV) laser field using numerical simulations on a grid. Our numerical results are in good agreement with those of the Wigner-Smith time delay, obtained as the derivative of the phase shift of the scattering wave packet with respect to its energy, for the short-range Yukawa potential. In case of the Coulomb potential we obtain time delays for any finite region, while - as expected - the results do not converge as the size of the region increases towards infinity. The impact of an ultrashort near-infrared probe pulse on the time delay is analyzed for both the Yukawa as well as the Coulomb potential and is found to be small for intensities below $10^{13}$ W\/cm$^2$.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2019-08-03 00:00:00.000000"},
{"id":"1199","title":"Knowledge well television agent.","abstract":"The cross-entropy method (CE) developed by R. Rubinstein is an elegant practical principle for simulating rare events. The method approximates the probability of the rare event by means of a family of probabilistic models. The method has been extended to optimization, by considering an optimal event as a rare event. CE works rather good when dealing with deterministic function optimization. Now, it appears that two conditions are needed for a good convergence of the method. First, it is necessary to have a family of models sufficiently flexible for discriminating the optimal events. Indirectly, it appears also that the function to be optimized should be deterministic. The purpose of this paper is to consider the case of partially discriminating model family, and of stochastic functions. It will be shown on simple examples that the CE could fail when relaxing these hypotheses. Alternative improvements of the CE method are investigated and compared on random examples in order to handle this issue.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2015-08-21 00:00:00.000000"},
{"id":"1200","title":"Phone campaign name oil.","abstract":"We study the so-called the traveling tournament problem (TTP), to find an optimal tournament schedule. Differently from the original TTP, in which the total travel distance of all the participants is the objective function to minimize, we instead seek to maximize the fairness of the round robin tournament schedule of the Korean Baseball League. The standard deviation of the travel distances of teams is defined as the energy function, and the Metropolis Monte-Carlo method combined with the simulated annealing technique is applied to find the ground state configuration. The resulting tournament schedule is found to satisfy all the constraint rules set by the Korean Baseball Organization, but with drastically increased fairness in traveling distances.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2022-03-29 00:00:00.000000"},
{"id":"1201","title":"Maintain spring entire something entire.","abstract":"This paper studied what shall be called the Long equation: that is the system of nonlinear equation $R^{12}R^{13}=R^{13}R^{12}$ and $R^{12}R^{23}= R^{23}R^{12}$. Any solution of this system supplies us a solution for the integrability solution of Knizhnic-Zamolodchikov equation. We shall approach this equation by introducing a new class of bialgebras, which we call Long bialgebras. A FRT type theorem is given: in the finite case any solution of the above equation is a co-homotety where the vector spase is a comodule over a Long bialgebra.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2016-06-17 00:00:00.000000"},
{"id":"1202","title":"Piece figure campaign institution wind type establish two.","abstract":"Accurate ro-vibrational energies, eigenfunctions, radial densities, expectation values are presented for the exponential-type Manning-Rosen (MR) potential. Bound states accurate up to ten significant figure are obtained by employing a simple, reliable generalized pseudospectral method. \\emph{All} 55 eigenstates with $n \\leq 10$ are treated for arbitrary values of potential parameters, covering a wide range of interaction, through a \\emph{non-uniform, optimal} spatial radial discretization. A detailed investigation has been made on energy changes with respect to \\emph{screening and other} potential parameters. A systematic estimation of \\emph{critical} screening parameters are given for these eigenstates. Special emphasis has been given to \\emph{higher} states and in the vicinity of \\emph{critical screening} region. A thorough comparison with literature results is made wherever possible. This \\emph{surpasses} the accuracy of \\emph{all} other existing methods currently available. Several \\emph{new} states are reported for the first time. In short, a simple, efficient scheme for accurate calculation of this and other molecular potentials is offered.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2015-04-22 00:00:00.000000"},
{"id":"1203","title":"Table partner plant.","abstract":"Operating frequency of a pipelined circuit is determined by the delay of the slowest pipeline stage. However, under statistical delay variation in sub-100nm technology regime, the slowest stage is not readily identifiable and the estimation of the pipeline yield with respect to a target delay is a challenging problem. We have proposed analytical models to estimate yield for a pipelined design based on delay distributions of individual pipe stages. Using the proposed models, we have shown that change in logic depth and imbalance between the stage delays can improve the yield of a pipeline. A statistical methodology has been developed to optimally design a pipeline circuit for enhancing yield. Optimization results show that, proper imbalance among the stage delays in a pipeline improves design yield by 9% for the same area and performance (and area reduction by about 8.4% under a yield constraint) over a balanced design.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2018-04-17 00:00:00.000000"},
{"id":"1204","title":"Much network rest can us six simply.","abstract":"We study Witt groups of smooth curves and surfaces over algebraically closed fields of characteristic not two. In both dimensions, we determine both the classical Witt group and Balmer's shifted Witt groups. In the case of curves, the results are supplemented with a complete description of the (shifted) Grothendieck-Witt groups.   In a second step, we analyse the relationship of Witt groups of smooth complex curves and surfaces with their real topological K-groups. They turn out to be surprisingly close: for all curves and for all projective surfaces of geometric genus zero, the Witt groups may be identified with the quotients of their even KO-groups by the images of their complex topological K-groups under realification.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2022-01-07 00:00:00.000000"},
{"id":"1205","title":"Find tonight certain series wear.","abstract":"In this paper we study the equidistribution of expanding horospheres in infinite volume geometrically finite rank one locally symmetric manifolds and apply it to the orbital counting problem in apollonian sphere packing.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2015-04-13 00:00:00.000000"},
{"id":"1206","title":"Example wife read source station shoulder.","abstract":"We present a conjecture regarding the expectation of the maxima of $L^2$ norms of sub-vectors of a Gaussian vector; this has application to nonlinear reconstruction.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2016-08-23 00:00:00.000000"},
{"id":"1207","title":"Prepare everybody suffer.","abstract":"Recent advances in Micro-Electro-Mechanical Systems (MEMS) technology, integrated circuits, and wireless communication have allowed the realization of Wireless Body Area Networks (WBANs). WBANs promise unobtrusive ambulatory health monitoring for a long period of time and provide real-time updates of the patient's status to the physician. They are widely used for ubiquitous healthcare, entertainment, and military applications. This paper reviews the key aspects of WBANs for numerous applications. We present a WBAN infrastructure that provides solutions to on-demand, emergency, and normal traffic. We further discuss in-body antenna design and low-power MAC protocol for WBAN. In addition, we briefly outline some of the WBAN applications with examples. Our discussion realizes a need for new power-efficient solutions towards in-body and on-body sensor networks.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2020-07-21 00:00:00.000000"},
{"id":"1208","title":"None subject see policy wind strategy.","abstract":"We give an upper bound of a Hamiltonian displacement energy of a unit disk cotangent bundle $D^*M$ in a cotangent bundle $T^*M$, when the base manifold $M$ is an open Riemannian manifold. Our main result is that the displacement energy is not greater than $C r(M)$, where $r(M)$ is the inner radius of $M$, and $C$ is a dimensional constant. As an immediate application, we study symplectic embedding problems of unit disk cotangent bundles. Moreover, combined with results in symplectic geometry, our main result shows the existence of short periodic billiard trajectories and short geodesic loops.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2019-02-03 00:00:00.000000"},
{"id":"1209","title":"Peace state analysis wall.","abstract":"The connection between the poloidal and the toroidal rotation of plasma in tokamak is important for the high confinement regimes, in particular in reactor regime. The sudden onset of closed convection structures in the poloidal section, due to the baroclinic production of vorticity, will sustain a fast increase of the poloidal velocity and a substantial effect on the toroidal rotation. However this is limited to the short time of the onset transition. In real plasma however there is random generation and suppression of convection cells and the sequence of these transient events can prove able to sustain the effect on the toroidal rotation. We formulate a simplified model which consists of a laminar sheared, regular, flow situated at the boundary of a region of drift-wave turbulence. Vortical structures, randomly generated in this turbulent region are spontaneously advected toward the flow and are absorbed there, sustaining with their vortical content, the sheared flow. We examine this dynamics in the wavenumber $\\mathbf{k}$ space, using reasonable approximations. We derive a system of equations (which is a class of Davey-Stewartson system) and find that indeed, the vortices advected and absorbed into the layer can preserve its regular, poloidal, flow.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2018-10-06 00:00:00.000000"},
{"id":"1210","title":"Member scene story join reflect region.","abstract":"An innovative way of calculating the von Mises distribution (VMD) of image entropy is introduced in this paper. The VMD's concentration parameter and some fitness parameter that will be later defined, have been analyzed in the experimental part for determining their suitability as a image quality assessment measure in some particular distortions such as Gaussian blur or additive Gaussian noise. To achieve such measure, the local R\\'{e}nyi entropy is calculated in four equally spaced orientations and used to determine the parameters of the von Mises distribution of the image entropy. Considering contextual images, experimental results after applying this model show that the best-in-focus noise-free images are associated with the highest values for the von Mises distribution concentration parameter and the highest approximation of image data to the von Mises distribution model. Our defined von Misses fitness parameter experimentally appears also as a suitable no-reference image quality assessment indicator for no-contextual images.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2020-04-10 00:00:00.000000"},
{"id":"1211","title":"Radio teach million describe finally.","abstract":"Let $f:A \\to B$ be a ring homomorphism and $J$ an ideal of $B$. In this paper, we initiate a systematic study of a new ring construction called the \"amalgamation of $A$ with $B$ along $J$ with respect to $f$\". This construction finds its roots in a paper by J.L. Dorroh appeared in 1932 and provides a general frame for studying the amalgamated duplication of a ring along an ideal, introduced and studied by D'Anna and Fontana in 2007, and other classical constructions such as the $A+ XB[X]$ and $A+ XB[[X]]$ constructions, the CPI-extensions of Boisen and Sheldon, the $D+M$ constructions and the Nagata's idealization.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2022-11-01 00:00:00.000000"},
{"id":"1212","title":"Industry bar idea arm land.","abstract":"Recently, the problems of evaluating performances of switches and routers have been formulated as online problems, and a great amount of results have been presented. In this paper, we focus on managing outgoing packets (called {\\em egress traffic}) on switches that support Quality of Service (QoS), and analyze the performance of one of the most fundamental scheduling policies {\\em Priority Queuing} ($PQ$) using competitive analysis. We formulate the problem of managing egress queues as follows: An output interface is equipped with $m$ queues, each of which has a buffer of size $B$. The size of a packet is unit, and each buffer can store up to $B$ packets simultaneously. Each packet is associated with one of $m$ priority values $\\alpha_{j}$ ($1 \\leq j \\leq m$), where $\\alpha_{1} \\leq \\alpha_{2} \\leq \\cdots \\leq \\alpha_{m}$, $\\alpha_{1} = 1$, and $\\alpha_{m} = \\alpha$ and the task of an online algorithm is to select one of $m$ queues at each scheduling step. The purpose of this problem is to maximize the sum of the values of the scheduled packets. For any $B$ and any $m$, we show that the competitive ratio of $PQ$ is exactly $2 - \\min_{x \\in [1, m-1] } \\{ \\frac{ \\alpha_{x+1} }{ \\sum_{j = 1}^{x+1} \\alpha_{j} } \\}$. That is, we conduct a complete analysis of the performance of $PQ$ using worst case analysis. Moreover, we show that no deterministic online algorithm can have a competitive ratio smaller than $1 + \\frac{ \\alpha^3 + \\alpha^2 + \\alpha }{ \\alpha^4 + 4 \\alpha^3 + 3 \\alpha^2 + 4 \\alpha + 1 }$.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2022-02-12 00:00:00.000000"},
{"id":"1213","title":"Head think real once too drive affect.","abstract":"Detailed modeling of processors and high performance cycle-accurate simulators are essential for today's hardware and software design. These problems are challenging enough by themselves and have seen many previous research efforts. Addressing both simultaneously is even more challenging, with many existing approaches focusing on one over another. In this paper, we propose the Reduced Colored Petri Net (RCPN) model that has two advantages: first, it offers a very simple and intuitive way of modeling pipelined processors; second, it can generate high performance cycle-accurate simulators. RCPN benefits from all the useful features of Colored Petri Nets without suffering from their exponential growth in complexity. RCPN processor models are very intuitive since they are a mirror image of the processor pipeline block diagram. Furthermore, in our experiments on the generated cycle-accurate simulators for XScale and StrongArm processor models, we achieved an order of magnitude (~15 times) speedup over the popular SimpleScalar ARM simulator.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2018-12-22 00:00:00.000000"},
{"id":"1214","title":"Over above pressure particular could big.","abstract":"We study sparse approximation by greedy algorithms. We prove the Lebesgue-type inequalities for the Weak Chebyshev Greedy Algorithm (WCGA), a generalization of the Weak Orthogonal Matching Pursuit to the case of a Banach space. The main novelty of these results is a Banach space setting instead of a Hilbert space setting. The results are proved for redundant dictionaries satisfying certain conditions. Then we apply these general results to the case of bases. In particular, we prove that the WCGA provides almost optimal sparse approximation for the trigonometric system in $L_p$, $2\\le p<\\infty$.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2018-05-18 00:00:00.000000"},
{"id":"1215","title":"Her stock interesting idea official medical.","abstract":"A standard approach to model reduction of large-scale higher-order linear dynamical systems is to rewrite the system as an equivalent first-order system and then employ Krylov-subspace techniques for model reduction of first-order systems. This paper presents some results about the structure of the block-Krylov subspaces induced by the matrices of such equivalent first-order formulations of higher-order systems. Two general classes of matrices, which exhibit the key structures of the matrices of first-order formulations of higher-order systems, are introduced. It is proved that for both classes, the block-Krylov subspaces induced by the matrices in these classes can be viewed as multiple copies of certain subspaces of the state space of the original higher-order system.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2020-10-18 00:00:00.000000"},
{"id":"1216","title":"Summer traditional food without.","abstract":"We describe the voting farm, a tool which implements a distributed software voting mechanism for a number of parallel message passing systems. The tool, developed in the framework of EFTOS (Embedded Fault-Tolerant Supercomputing), can be used in stand-alone mode or in conjunction with other EFTOS fault tolerance tools. In the former case, we describe how the mechanism can be exploited, e.g., to implement restoring organs ($N\\!$-modular redundancy systems with $N\\!$-replicated voters); in the latter case, we show how it is possible for the user to implement in an easy and effective way a number of different recovery strategies via a custom, high-level language. Combining such strategies with the basic fault masking capabilities of the voting tool makes it possible to set up complex fault-tolerant systems such as, for instance, $N$-and-$M$-spare systems or gracefully degrading voting farms. We also report about the impact that our tool can have on reliability, and we show how, besides structural design goals like fault transparency, our tool achieves replication transparency, a high degree of flexibility and ease-of-use, and good performance.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2015-09-09 00:00:00.000000"},
{"id":"1217","title":"Real finish reason.","abstract":"We adapt the formalism of the statistical theory of 2D turbulence in the case where the Casimir constraints are replaced by the specification of a prior vorticity distribution. A new relaxation equation is obtained for the evolution of the coarse-grained vorticity. It can be used as a thermodynamical parametrization of forced 2D turbulence (determined by the prior), or as a numerical algorithm to construct arbitrary nonlinearly dynamically stable stationary solutions of the 2D Euler equation.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2020-07-07 00:00:00.000000"},
{"id":"1218","title":"Risk meeting reach toward.","abstract":"We obtain the functional defining the price and quality of sample readings of the generalized velocities. It is shown that the optimal sampling frequency, in the sense of minimizing the functional quality and price depends on the sampling of the upper cutoff frequency of the analog signal of the order of the generalized velocities measured by the generalized coordinates, the frequency properties of the analog input filter and a maximum sampling rate for analog-digital converter (ADC). An example of calculating the frequency quantization for two-tier ADC with an input RC filter.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2021-12-14 00:00:00.000000"},
{"id":"1219","title":"Bit school single state present.","abstract":"With the rapid development of online social media, online shopping sites and cyber-physical systems, heterogeneous information networks have become increasingly popular and content-rich over time. In many cases, such networks contain multiple types of objects and links, as well as different kinds of attributes. The clustering of these objects can provide useful insights in many applications. However, the clustering of such networks can be challenging since (a) the attribute values of objects are often incomplete, which implies that an object may carry only partial attributes or even no attributes to correctly label itself; and (b) the links of different types may carry different kinds of semantic meanings, and it is a difficult task to determine the nature of their relative importance in helping the clustering for a given purpose. In this paper, we address these challenges by proposing a model-based clustering algorithm. We design a probabilistic model which clusters the objects of different types into a common hidden space, by using a user-specified set of attributes, as well as the links from different relations. The strengths of different types of links are automatically learned, and are determined by the given purpose of clustering. An iterative algorithm is designed for solving the clustering problem, in which the strengths of different types of links and the quality of clustering results mutually enhance each other. Our experimental results on real and synthetic data sets demonstrate the effectiveness and efficiency of the algorithm.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2019-03-24 00:00:00.000000"},
{"id":"1220","title":"Director fly drug page practice kitchen true.","abstract":"An extremely sensitive temperature measurement MEMS device is developed based on the principle of structural deflection in a bi-material cantilever caused by a difference in thermal expansion coefficients. A dual-beam asymmetrical geometry is used to produce a torsional response from the device. An analytical model is developed to predict the performance and optimize the free parameters of the device. In this work, it is performed to analyze the flexural and torsional eigenfrequencies as well as confirm the theoretical predictions of DC and AC response. Lastly, a procedure is developed to allow fabrication of the device using equipment available in the Columbia University clean room.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2020-11-05 00:00:00.000000"},
{"id":"1221","title":"Customer can former mouth I worker off.","abstract":"We investigate properties that intuitively ought to be satisfied by graph clustering quality functions, that is, functions that assign a score to a clustering of a graph. Graph clustering, also known as network community detection, is often performed by optimizing such a function. Two axioms tailored for graph clustering quality functions are introduced, and the four axioms introduced in previous work on distance based clustering are reformulated and generalized for the graph setting. We show that modularity, a standard quality function for graph clustering, does not satisfy all of these six properties. This motivates the derivation of a new family of quality functions, adaptive scale modularity, which does satisfy the proposed axioms. Adaptive scale modularity has two parameters, which give greater flexibility in the kinds of clusterings that can be found. Standard graph clustering quality functions, such as normalized cut and unnormalized cut, are obtained as special cases of adaptive scale modularity.   In general, the results of our investigation indicate that the considered axiomatic framework covers existing `good' quality functions for graph clustering, and can be used to derive an interesting new family of quality functions.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2021-11-18 00:00:00.000000"},
{"id":"1222","title":"Although find ago themselves success machine.","abstract":"Preference queries are relational algebra or SQL queries that contain occurrences of the winnow operator (\"find the most preferred tuples in a given relation\"). Such queries are parameterized by specific preference relations. Semantic optimization techniques make use of integrity constraints holding in the database. In the context of semantic optimization of preference queries, we identify two fundamental properties: containment of preference relations relative to integrity constraints and satisfaction of order axioms relative to integrity constraints. We show numerous applications of those notions to preference query evaluation and optimization. As integrity constraints, we consider constraint-generating dependencies, a class generalizing functional dependencies. We demonstrate that the problems of containment and satisfaction of order axioms can be captured as specific instances of constraint-generating dependency entailment. This makes it possible to formulate necessary and sufficient conditions for the applicability of our techniques as constraint validity problems. We characterize the computational complexity of such problems.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2016-06-06 00:00:00.000000"},
{"id":"1223","title":"By possible same tax oil measure.","abstract":"Hamilton's principle does not formally apply to systems whose boundary conditions lie outside configuration space, but extensions are possible using certain \"natural\" boundary conditions that allow action extremization. With the single conjecture that only such action-extremizing boundaries can be physically realized, the classical relativistic scalar field becomes subject to certain quantization conditions upon measurement. These conditions appear to be analogous to Bohr-Sommerfeld quantization, and are derived explicitly for the case of angular momentum measurements of a classical scalar field.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2015-02-24 00:00:00.000000"},
{"id":"1224","title":"Onto again production catch language.","abstract":"It is well known that the Classical theory of the electron reached the limits of its description at time intervals of the order of $10^{-23} secs$, that is the Compton time. It is widely believed that below these time intervals Classical Electrodynamics doesn't work and that a Quantum description is required. Using the Lorentz Dirac and the Dirac equations of the electron, we point out that in fact there is a convergence of the two descriptions at the Compton scale.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2022-12-09 00:00:00.000000"},
{"id":"1225","title":"Ten space despite word employee describe.","abstract":"The free decay of MHD turbulence at large Reynolds numbers is studied numerically using a shell model. We study the statistical properties based on representative sample of realisations (128 realisations for each type of initial conditions) over the period of $10^5$ large-scale turnover times. The performed simulations show that the force-free non-helical MHD turbulence can demonstrate two different scenarios of evolution in spite of similar initial conditions. Within the first scenario, the cross-helicity accumulation is so fast that the energy cascade vanishes before significant magnetic energy dissipates. Then the system approaches the state of maximal cross-helicity. Within the second scenario, the cascade process continues to remain active until time $10^4$ in units of large-scale turnover time. Then the magnetic field becomes vastly helical due to magnetic helicity conservation. Thus the magnetic energy does not dissipate with kinetic energy.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2015-03-15 00:00:00.000000"},
{"id":"1226","title":"Certainly fish seek many leader.","abstract":"Methodological contributions: This paper introduces a family of kernels for analyzing (anatomical) trees endowed with vector valued measurements made along the tree. While state-of-the-art graph and tree kernels use combinatorial tree\/graph structure with discrete node and edge labels, the kernels presented in this paper can include geometric information such as branch shape, branch radius or other vector valued properties. In addition to being flexible in their ability to model different types of attributes, the presented kernels are computationally efficient and some of them can easily be computed for large datasets (N of the order 10.000) of trees with 30-600 branches. Combining the kernels with standard machine learning tools enables us to analyze the relation between disease and anatomical tree structure and geometry. Experimental results: The kernels are used to compare airway trees segmented from low-dose CT, endowed with branch shape descriptors and airway wall area percentage measurements made along the tree. Using kernelized hypothesis testing we show that the geometric airway trees are significantly differently distributed in patients with Chronic Obstructive Pulmonary Disease (COPD) than in healthy individuals. The geometric tree kernels also give a significant increase in the classification accuracy of COPD from geometric tree structure endowed with airway wall thickness measurements in comparison with state-of-the-art methods, giving further insight into the relationship between airway wall thickness and COPD. Software: Software for computing kernels and statistical tests is available at http:\/\/image.diku.dk\/aasa\/software.php.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2021-08-08 00:00:00.000000"},
{"id":"1227","title":"Performance rate far whether.","abstract":"We construct small covers and quasitoric manifolds over a given $n$-colored simple polytope $P^n$ with interesting properties. Their Stiefel-Whitney classes are calculated and used as obstruction to immersions and embeddings into Euclidean spaces. In the case $n$ is a power of two we get the sharpest bounds.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2017-02-24 00:00:00.000000"},
{"id":"1228","title":"Action responsibility nearly.","abstract":"Volterra and polynomial regression models play a major role in nonlinear system identification and inference tasks. Exciting applications ranging from neuroscience to genome-wide association analysis build on these models with the additional requirement of parsimony. This requirement has high interpretative value, but unfortunately cannot be met by least-squares based or kernel regression methods. To this end, compressed sampling (CS) approaches, already successful in linear regression settings, can offer a viable alternative. The viability of CS for sparse Volterra and polynomial models is the core theme of this work. A common sparse regression task is initially posed for the two models. Building on (weighted) Lasso-based schemes, an adaptive RLS-type algorithm is developed for sparse polynomial regressions. The identifiability of polynomial models is critically challenged by dimensionality. However, following the CS principle, when these models are sparse, they could be recovered by far fewer measurements. To quantify the sufficient number of measurements for a given level of sparsity, restricted isometry properties (RIP) are investigated in commonly met polynomial regression settings, generalizing known results for their linear counterparts. The merits of the novel (weighted) adaptive CS algorithms to sparse polynomial modeling are verified through synthetic as well as real data tests for genotype-phenotype analysis.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2022-06-29 00:00:00.000000"},
{"id":"1229","title":"Stage address number produce maintain money traditional.","abstract":"New generation in vitro high-throughput screening (HTS) assays for the assessment of engineered nanomaterials provide an opportunity to learn how these particles interact at the cellular level, particularly in relation to injury pathways. These types of assays are often characterized by small sample sizes, high measurement error and high dimensionality, as multiple cytotoxicity outcomes are measured across an array of doses and durations of exposure. In this paper we propose a probability model for the toxicity profiling of engineered nanomaterials. A hierarchical structure is used to account for the multivariate nature of the data by modeling dependence between outcomes and thereby combining information across cytotoxicity pathways. In this framework we are able to provide a flexible surface-response model that provides inference and generalizations of various classical risk assessment parameters. We discuss applications of this model to data on eight nanoparticles evaluated in relation to four cytotoxicity parameters.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2022-01-07 00:00:00.000000"},
{"id":"1230","title":"Day future per strong military.","abstract":"We have studied transportation network, namely a road network of the Moscow region and airline network of the Russian Federation. We have constructed corresponding networks and studied degree distribution and length distribution for these networks, as well as the dependences on the average clustering coefficients and the nearest neighbours average degree as a function of the vertex degree. In conclusion we discuss degree and length distributions in the framework of the nonextensive statistics, using the maximum entropy approach and the model with additive and multiplicative noise. We present a procedure of fitting the results of the data processing to the q-type distribution which allows the fractal dimension definition of the networks under study.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2016-09-27 00:00:00.000000"},
{"id":"1231","title":"Tax doctor dark method news give without area.","abstract":"We perform full-scale numerical simulation of instability of weakly nonlinear waves on the surface of deep fluid. We show that the instability development leads to chaotization and formation of wave turbulence.   We study instability both of propagating and standing waves. We studied separately pure capillary wave unstable due to three-wave interactions and pure gravity waves unstable due to four-wave interactions. The theoretical description of instabilities in all cases is included into the article. The numerical algorithm used in these and many other previous simulations performed by authors is described in details.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2020-01-20 00:00:00.000000"},
{"id":"1232","title":"Small tree arm store.","abstract":"We propose a novel and efficient method, that we shall call TopRank in the following paper, for detecting change-points in high-dimensional data. This issue is of growing concern to the network security community since network anomalies such as Denial of Service (DoS) attacks lead to changes in Internet traffic. Our method consists of a data reduction stage based on record filtering, followed by a nonparametric change-point detection test based on $U$-statistics. Using this approach, we can address massive data streams and perform anomaly detection and localization on the fly. We show how it applies to some real Internet traffic provided by France-T\\'el\\'ecom (a French Internet service provider) in the framework of the ANR-RNRT OSCAR project. This approach is very attractive since it benefits from a low computational load and is able to detect and localize several types of network anomalies. We also assess the performance of the TopRank algorithm using synthetic data and compare it with alternative approaches based on random aggregation.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2022-09-15 00:00:00.000000"},
{"id":"1233","title":"Front address budget bad shake sort result.","abstract":"We investigate the leading systematic effects in ro-vibrational spectroscopy of the molecular hydrogen ions H2+ and HD+, in order to assess their potential for the realization of optical clocks that would be sensitive to possible variations of the proton-to-electron mass ratio. Both two-photon (2E1) and quadrupole (E2) transitions are considered. In view of the weakness of these transitions, most attention is devoted to the light shift induced by the probe laser, which we express as a function of the transition amplitude, differential dynamic polarizability and clock interrogation times. Transition amplitudes and dynamic polarizabilites including the effect of hyperfine structure are then calculated in a full three-body approach to get a precise evaluation of the light shift. Together with the quadrupole and Zeeman shifts that are obtained from previous works, these results provide a realistic estimate of the achievable accuracy. We show that the lightshift is the main limiting factor in the case of two-photon transitions, both in H2+ and HD+, leading to expected accuracy levels close to 5 10-16 in the best cases. Quadrupole transitions have even more promising properties and may allow reaching or going beyond 10-16.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2017-11-21 00:00:00.000000"},
{"id":"1234","title":"Fish Congress card practice.","abstract":"Processors may find some elementary operations to be faster than the others. Although an operation may be conceptually as simple as some other operation, the processing speeds of the two can vary. A clever programmer will always try to choose the faster instructions for the job. This paper presents an algorithm to display squares of 1st N natural numbers without using multiplication (* operator). Instead, the same work can be done using addition (+ operator). The results can also be used to compute the sum of those squares. If we compare the normal method of computing the squares of 1st N natural numbers with this method, we can conclude that the algorithm discussed in the paper is more optimized in terms of time complexity.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2017-10-21 00:00:00.000000"},
{"id":"1235","title":"Nor fight central keep.","abstract":"The discrete distribution clustering algorithm, namely D2-clustering, has demonstrated its usefulness in image classification and annotation where each object is represented by a bag of weighed vectors. The high computational complexity of the algorithm, however, limits its applications to large-scale problems. We present a parallel D2-clustering algorithm with substantially improved scalability. A hierarchical structure for parallel computing is devised to achieve a balance between the individual-node computation and the integration process of the algorithm. Additionally, it is shown that even with a single CPU, the hierarchical structure results in significant speed-up. Experiments on real-world large-scale image data, Youtube video data, and protein sequence data demonstrate the efficiency and wide applicability of the parallel D2-clustering algorithm. The loss in clustering accuracy is minor in comparison with the original sequential algorithm.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2021-12-01 00:00:00.000000"},
{"id":"1236","title":"Feel section smile but into break.","abstract":"We present a data dependent generalization bound for a large class of regularized algorithms which implement structured sparsity constraints. The bound can be applied to standard squared-norm regularization, the Lasso, the group Lasso, some versions of the group Lasso with overlapping groups, multiple kernel learning and other regularization schemes. In all these cases competitive results are obtained. A novel feature of our bound is that it can be applied in an infinite dimensional setting such as the Lasso in a separable Hilbert space or multiple kernel learning with a countable number of kernels.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2020-02-05 00:00:00.000000"},
{"id":"1237","title":"Him others whole every station end.","abstract":"Vortex element methods are often used to efficiently simulate incompressible flows using Lagrangian techniques. Use of the FMM (Fast Multipole Method) allows considerable speed up of both velocity evaluation and vorticity evolution terms in these methods. Both equations require field evaluation of constrained (divergence free) vector valued quantities (velocity, vorticity) and cross terms from these. These are usually evaluated by performing several FMM accelerated sums of scalar harmonic functions.   We present a formulation of the vortex methods based on the Lamb-Helmholtz decomposition of the velocity in terms of two scalar potentials. In its original form, this decomposition is not invariant with respect to translation, violating a key requirement for the FMM. One of the key contributions of this paper is a theory for translation for this representation. The translation theory is developed by introducing \"conversion\" operators, which enable the representation to be restored in an arbitrary reference frame. Using this form, extremely efficient vortex element computations can be made, which need evaluation of just two scalar harmonic FMM sums for evaluating the velocity and vorticity evolution terms. Details of the decomposition, translation and conversion formulae, and sample numerical results are presented.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2016-01-18 00:00:00.000000"},
{"id":"1238","title":"Together a do benefit moment process.","abstract":"We derive a standard Lorentz code (SLC) of motion by exploring rigid double transformations of, so-called, 'master space-induced' supersymmetry (MS-SUSY), subject to certain rules. The renormalizable and actually finite flat-space field theories with $N_{max}=4$ supersymmetries in four dimensions, if only such symmetries are fundamental to nature, yield the possible 'extension of Lorentz code' (ELC), at which the SLC violating new physics appears. In the framework of local MS-SUSY, we address the inertial effects. We argue that a space-time deformation of MS is the origin of inertia effects that can be observed by us. We go beyond the hypothesis of locality. This allows to improve the relevant geometrical structures referred to the noninertial frame in Minkowski space for an arbitrary velocities and characteristic acceleration lengths. This framework furnishes justification for the introduction of the 'weak' principle of equivalence, i.e., the 'universality of free fall'. The implications of the inertia effects in the more general post-Riemannian geometry are briefly discussed.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2018-10-05 00:00:00.000000"},
{"id":"1239","title":"Rate better leg pass worker hotel.","abstract":"We present results from direct numerical simulations of the Boussinesq equations in the presence of rotation and\/or stratification, both in the vertical direction. The runs are forced isotropically and randomly at small scales and have spatial resolutions of up to $1024^3$ grid points and Reynolds numbers of $\\approx 1000$. We first show that solutions with negative energy flux and inverse cascades develop in rotating turbulence, whether or not stratification is present. However, the purely stratified case is characterized instead by an early-time, highly anisotropic transfer to large scales with almost zero net isotropic energy flux. This is consistent with previous studies that observed the development of vertically sheared horizontal winds, although only at substantially later times. However, and unlike previous works, when sufficient scale separation is allowed between the forcing scale and the domain size, the total energy displays a perpendicular (horizontal) spectrum with power law behavior compatible with $\\sim k_\\perp^{-5\/3}$, including in the absence of rotation. In this latter purely stratified case, such a spectrum is the result of a direct cascade of the energy contained in the large-scale horizontal wind, as is evidenced by a strong positive flux of energy in the parallel direction at all scales including the largest resolved scales.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2022-03-31 00:00:00.000000"},
{"id":"1240","title":"Season anything pay best.","abstract":"Grid computing has enabled pooling a very large number of heterogeneous resource administered by different security domains. Applications are dynamically deployed on the resources available at the time. Dynamic nature of the resources and applications requirements makes needs the grid middleware to support the ability of migrating a running application to a different resource. Especially, Grid applications are typically long running and thus stoping them and starting them from scratch is not a feasible option. This paper presents an overview of migration support in a java based grid middleware called DGET. Migration support in DGET includes multi-threaded migration and asynchronous migration as well.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2022-02-07 00:00:00.000000"},
{"id":"1241","title":"General local individual professor beautiful environmental.","abstract":"We wish to tile a rectangle or a torus with only vertical and horizontal bars of a given length, such that the number of bars in every column and row equals given numbers. We present results for particular instances and for a more general problem, while leaving open the initial problem.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2020-01-31 00:00:00.000000"},
{"id":"1242","title":"Beyond growth born they leader take tree.","abstract":"We describe the cone of Hilbert functions of artinian graded modules finitely generated in degree 0 over the polynomial ring R = k[x, y] with the non-standard grading deg(x) = 1 and deg(y) = n, where n is any natural number.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2020-01-05 00:00:00.000000"},
{"id":"1243","title":"Science effect parent bank mouth collection.","abstract":"Given an integer $\\kappa\\geq2$, we introduce a class of nearly integrable systems on $\\mathbb{A}^3$, of the form $$ H_n(\\theta,r)=\\frac12 \\Vert r\\Vert ^2+\\tfrac{1}{n} U(\\theta_2,\\theta_3)+f_n(\\theta,r) $$ where $U\\in C^\\kappa(\\mathbb{T}^2)$ is a generic potential function and $f_n$ a $C^{\\kappa-1}$ additional perturbation such that $\\Vert f_n\\Vert_{C^{\\kappa-1}(\\mathbb{A}^3)}\\leq \\tfrac{1}{n}$, so that $H_n$ is a perturbation of the completely integrable system $h(r)=\\frac12\\Vert r\\Vert ^2$.   Let $\\Pi:\\mathbb{A}^3\\to\\mathbb{R}^3$ be the canonical projection. We prove that for each $\\delta>0$, there exists $n_0$ such that for $n\\geq n_0$, the system $H_n$ admits an orbit $\\Gamma_n$ at energy $\\frac12$ whose projection $\\Pi(\\Gamma_n)$ is $\\delta$-dense in $\\Pi(H_n^{-1}(\\tfrac{1}{2}))$, in the sense that the $\\delta$-neighborhood of $\\Pi(\\Gamma_n)$ in $\\mathbb{R}^3$ covers $\\Pi(H_n^{-1}(\\frac{1}{2}))$.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2020-12-14 00:00:00.000000"},
{"id":"1244","title":"Join film scene plan seat situation.","abstract":"A graph $G$ is 3-colorable if and only if it maps homomorphically to the complete 3-vertex graph $K_3$. The last condition can be checked by a $k$-consistency algorithm where the parameter $k$ has to be chosen large enough, dependent on $G$. Let $W(G)$ denote the minimum $k$ sufficient for this purpose. For a non-3-colorable graph $G$, $W(G)$ is equal to the minimum $k$ such that $G$ can be distinguished from $K_3$ in the $k$-variable existential-positive first-order logic. We define the dynamic width of the 3-colorability problem as the function $W(n)=\\max_G W(G)$, where the maximum is taken over all non-3-colorable $G$ with $n$ vertices.   The assumption $\\mathrm{NP}\\ne\\mathrm{P}$ implies that $W(n)$ is unbounded. Indeed, a lower bound $W(n)=\\Omega(\\log\\log n\/\\log\\log\\log n)$ follows unconditionally from the work of Nesetril and Zhu on bounded treewidth duality. The Exponential Time Hypothesis implies a much stronger bound $W(n)=\\Omega(n\/\\log n)$ and indeed we unconditionally prove that $W(n)=\\Omega(n)$. In fact, an even stronger statement is true: A first-order sentence distinguishing any 3-colorable graph on $n$ vertices from any non-3-colorable graph on $n$ vertices must have $\\Omega(n)$ variables.   On the other hand, we observe that $W(G)\\le 3\\,\\alpha(G)+1$ and $W(G)\\le n-\\alpha(G)+1$ for every non-3-colorable graph $G$ with $n$ vertices, where $\\alpha(G)$ denotes the independence number of $G$. This implies that $W(n)\\le\\frac34\\,n+1$, improving on the trivial upper bound $W(n)\\le n$.   We also show that $W(G)>\\frac1{16}\\, g(G)$ for every non-3-colorable graph $G$, where $g(G)$ denotes the girth of $G$.   Finally, we consider the function $W(n)$ over planar graphs and prove that $W(n)=\\Theta(\\sqrt n)$ in the case.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2021-12-31 00:00:00.000000"},
{"id":"1245","title":"Mr yard reflect catch lose.","abstract":"Multimedia Information security becomes a important part for the organization's intangible assets. Level of confidence and stakeholder trusted are performance indicator as successes organization, it is imperative for organizations to use Information Security Management System (ISMS) to effectively manage their multimedia information assets. The main objective of this paper is to Provide a novel practical framework approach to the development of ISMS, Called by the I-SolFramework, implemented in multimedia information security architecture (MISA), it divides a problem into six object domains or six layers, namely organization,stakeholders, tool & technology, policy, knowledge, and culture. In addition, this framework also introduced novelty algorithm and mathematic models as measurement and assessment tools of MISA parameters.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2021-12-05 00:00:00.000000"},
{"id":"1246","title":"Tell available spring admit.","abstract":"As the communication industry has connected distant corners of the globe using advances in network technology, intruders or attackers have also increased attacks on networking infrastructure commensurately. System administrators can attempt to prevent such attacks using intrusion detection tools and systems. There are many commercially available signature-based Intrusion Detection Systems (IDSs). However, most IDSs lack the capability to detect novel or previously unknown attacks. A special type of IDSs, called Anomaly Detection Systems, develop models based on normal system or network behavior, with the goal of detecting both known and unknown attacks. Anomaly detection systems face many problems including high rate of false alarm, ability to work in online mode, and scalability. This paper presents a selective survey of incremental approaches for detecting anomaly in normal system or network traffic. The technological trends, open problems, and challenges over anomaly detection using incremental approach are also discussed.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2015-07-19 00:00:00.000000"},
{"id":"1247","title":"Red give against store whom catch.","abstract":"The formalism of the models with Petri networks provides a sound theoretical base, supported by powerful mathematical methods able to extract information necessary for the formalism and simulation of the real system that provides features of competition and synchronization. The paper presents a model based on a Petri net, in order to extract information relative to the technological producing process of a food additive.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2017-10-28 00:00:00.000000"},
{"id":"1248","title":"Coach sometimes because range.","abstract":"This paper has been withdrawn by the author due to a crucial sign error in Theorem 3.4.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2019-11-07 00:00:00.000000"},
{"id":"1249","title":"Story operation page effort or.","abstract":"Consider a set of order statistics that arise from sorting samples from two different populations, each with their own, possibly different distribution function. The probability that these order statistics fall in disjoint, ordered intervals, and that of the smallest statistics, a certain number come from the first populations, are given in terms of the two distribution functions. The result is applied to computing the joint probability of the number of rejections and the number of false rejections for the Benjamini-Hochberg false discovery rate procedure.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2020-12-20 00:00:00.000000"},
{"id":"1250","title":"Site heart walk themselves state think.","abstract":"We show that a symplectic isotopy that is a $C^0$ limit of Hamiltonian isotopies is itself Hamiltonian, if the corresponding sequence of generating Hamiltonians converge in $L^{(1, \\infty)}$ topology.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2015-10-16 00:00:00.000000"},
{"id":"1251","title":"Fast plan decade entire.","abstract":"Given a Gaussian random walk (or a Wiener process), possibly with drift, observed through noise, we consider the problem of estimating its first-passage time $\\tau_\\ell$ of a given level $\\ell$ with a stopping time $\\eta$ defined over the noisy observation process.   Main results are upper and lower bounds on the minimum mean absolute deviation $\\inf_\\eta \\ex|\\eta-\\tau_\\ell|$ which become tight as $\\ell\\to\\infty$. Interestingly, in this regime the estimation error does not get smaller if we allow $ \\eta$ to be an arbitrary function of the entire observation process, not necessarily a stopping time.   In the particular case where there is no drift, we show that it is impossible to track $\\tau_\\ell$: $\\inf_\\eta \\ex|\\eta-\\tau_\\ell|^p=\\infty$ for any $\\ell>0$ and $p\\geq1\/2$.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2022-08-23 00:00:00.000000"},
{"id":"1252","title":"Last take newspaper offer eight involve line.","abstract":"Motivated by the problem of dealing with incomplete or imprecise acquisition of data in computer vision and computer graphics, we extend results concerning the stability of persistent homology with respect to function perturbations to results concerning the stability with respect to domain perturbations. Domain perturbations can be measured in a number of different ways. An important method to compare domains is the Hausdorff distance. We show that by encoding sets using the distance function, the multidimensional matching distance between rank invariants of persistent homology groups is always upperly bounded by the Hausdorff distance between sets. Moreover we prove that our construction maintains information about the original set. Other well known methods to compare sets are considered, such as the symmetric difference distance between classical sets and the sup-distance between fuzzy sets. Also in these cases we present results stating that the multidimensional matching distance between rank invariants of persistent homology groups is upperly bounded by these distances. An experiment showing the potential of our approach concludes the paper.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2022-09-18 00:00:00.000000"},
{"id":"1253","title":"Visit guess national pattern money production order.","abstract":"We give a lower bound for the bottom of the $L^2$ differential form spectrum on hyperbolic manifolds, generalizing thus a well-known result due to Sullivan and Corlette in the function case. Our method is based on the study of the resolvent associated with the Hodge-de Rham Laplacian and leads to applications for the (co)homology and topology of certain classes of hyperbolic manifolds.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2020-02-26 00:00:00.000000"},
{"id":"1254","title":"Film response soldier important cup.","abstract":"Recently, extending work by Karshon, Kessler and Pinsonnault, Borisov and McDuff showed that a given symplectic manifold $(M,\\omega)$ has a finite number of distinct toric structures. Moreover, McDuff also showed a product of two projective spaces $\\bC P^r\\times \\bC P^s$ with any given symplectic form has a unique toric structure provided that $r,s\\geq 2$. In contrast, the product $\\bC P^r \\times \\bC P^1$ can be given infinitely many distinct toric structures, though only a finite number of these are compatible with each given symplectic form $\\omega$. In this paper we extend these results by considering the possible toric structures on a toric symplectic manifold $(M,\\omega)$ with $\\dim H^2(M)=2$. In particular, all such manifolds are $\\bC P^r$ bundles over $\\bC P^s$ for some $r,s$. We show that there is a unique toric structure if $r<s$, and also that if $r,s\\geq 2$ then $M$ has at most finitely many distinct toric structures that are compatible with any symplectic structure on $M$. Thus, in this case the finiteness result does not depend on fixing the symplectic structure. We will also give other examples where $(M,\\omega)$ has a unique toric structure, such as the case where $(M,\\omega)$ is monotone.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2016-06-28 00:00:00.000000"},
{"id":"1255","title":"Dog home almost management west after.","abstract":"The possible transport of fibers by fluid flow in fractures is investigated experimentally in transparent models using flexible polyester thread (mean diameter $280 \\mu\\mathrm{m}$) and Newtonian and shear thinning fluids. In the case of smooth parallel walls, fibers of finite length $\\ell = 20-150 \\mathrm{mm}$ move at a constant velocity of the order of the maximum fluid velocity in the aperture. In contrast, for fibers lying initially at the inlet side of the model and dragged by the flow inside it, the velocity increases with the depth of penetration (this results from the lower velocity - and drag - in the inlet part). In both cases, the friction of the fiber with the smooth walls is weak. For rough self-affine walls and a continuous gradient of the local mean aperture transverse to the flow, transport of the fibers by a water flow is only possible in the region of larger aperture ($\\bar{a} \\gtrsim 1.1 \\mathrm{mm}$) and is of \"stop and go\" type at low velocities. Time dependent distorsions of the fiber are also often observed. When water is replaced by a shear thinning polymer solution, the fibers move faster and continuously in high aperture regions and their friction with the walls is reduced. Fiber transport becomes also possible in narrower regions where irreversible pinning occurred for water. In a third rough model with no global aperture gradient but with rough walls and a channelization parallel to the mean flow, fiber transport was only possible in shear-thinning flows and pinning and entanglement effects were studied.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2017-06-16 00:00:00.000000"},
{"id":"1256","title":"Form voice teacher bit serve officer rather.","abstract":"MiBoard (Multiplayer Interactive Board Game) is an online, turn-based board game, which is a supplement of the iSTART (Interactive Strategy Training for Active Reading and Thinking) application. MiBoard is developed to test the hypothesis that integrating game characteristics (point rewards, game-like interaction, and peer feedback) into the iSTART trainer will significantly improve its effectiveness on students' learning. It was shown by M. Rowe that a physical board game did in fact enhance students' performance. MiBoard is a computer-based version of Rowe's board game that eliminates constraints on locality while retaining the crucial practice components that were the game's objective. MiBoard gives incentives for participation and provides a more enjoyable and social practice environment compared to the online individual practice component of the original trainer.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2020-04-08 00:00:00.000000"},
{"id":"1257","title":"Maintain ability effort oil property mother history.","abstract":"We introduce the Picard group of corings. We extend the well-known exact sequence from algebras and coalgebras over fields to corings. We extend the Aut-Pic property to corings and we give some new examples of corings having this property. Finally, we give the corresponding exact sequences for the category of entwined modules over an entwining structure, the category of Doi-Koppinen-Hopf modules over a Doi-Koppinen structure, and the category of graded modules by a $G$-set, where $G$ is a group.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2019-04-03 00:00:00.000000"},
{"id":"1258","title":"End professor election third.","abstract":"That the logarithmic distribution manifests itself in the random as well as in the deterministic (multiplication processes) has long intrigued researchers in Benford's Law. In this article it is argued that it springs from one common intrinsic feature of their density curves. On the other hand, the profound dichotomy between the random and the deterministic in the context of Benford's Law is noted here, acknowledging the need to distinguish between them. From its very inception, the field has been suffering from a profound confusion and mixing of these two very different logarithmic flavors, causing mistaken conclusions. One example is Allaart's proof of equality of sums along digital lines, which can only be applied to deterministic processes. Random data lack this equality and consistently show significantly larger sums for lower digits, thus rendering any attempt at test of summation equality irrelevant and futile in the context of forensic analysis regarding accounting and financial fraud detection.   Another digital regularity is suggested here, one that is found in logarithmic as well as non-logarithmic random data sets. In addition, chains of distributions that are linked via parameter selection are found to be logarithmic, either in the limit where the number of the sequences in the chain approaches infinity, or where the distributions generating the parameters are themselves logarithmic.   A new forensic data analysis method in the context of fraud detection is suggested here even for data types that do not obey Benford's Law, and in particularly regarding tax evasion applications. This can also serve as a robust forensic tool to investigate fraudulent fake data provided by the sophisticated cheater already aware of Benford's Law, a challenge that would become increasing problematic to tax authorities in the future as Benford's Law becomes almost common knowledge.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2022-01-30 00:00:00.000000"},
{"id":"1259","title":"Method painting culture shoulder rule cut task.","abstract":"In the paper $\\lambda$-method Mitrinovic-Vasic is applied aiming to improve Fink's inequality, and Shafer's inequality for arcus sinus function is observed.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2022-05-31 00:00:00.000000"},
{"id":"1260","title":"Task win beautiful allow large close.","abstract":"A function based nonlinear least squares estimation (FNLSE) method is proposed and investigated in parameter estimation of Jelinski-Moranda software reliability model. FNLSE extends the potential fitting functions of traditional least squares estimation (LSE), and takes the logarithm transformed nonlinear least squares estimation (LogLSE) as a special case. A novel power transformation function based nonlinear least squares estimation (powLSE) is proposed and applied to the parameter estimation of Jelinski-Moranda model. Solved with Newton-Raphson method, Both LogLSE and powLSE of Jelinski-Moranda models are applied to the mean time between failures (MTBF) predications on six standard software failure time data sets. The experimental results demonstrate the effectiveness of powLSE with optimal power index compared to the classical least--squares estimation (LSE), maximum likelihood estimation (MLE) and LogLSE in terms of recursively relative error (RE) index and Braun statistic index.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2019-02-01 00:00:00.000000"},
{"id":"1261","title":"Fall also present sing real even history.","abstract":"Simplification of fractional powers of positive rational numbers and of sums, products and powers of such numbers is taught in beginning algebra. Such numbers can often be expressed in many ways, as this article discusses in some detail. Since they are such a restricted subset of algebraic numbers, it might seem that good simplification of them must already be implemented in all widely used computer algebra systems. However, the algorithm taught in beginning algebra uses integer factorization, which can consume unacceptable time for the large numbers that often arise within computer algebra. Therefore some systems apparently use various ad hoc techniques that can return an incorrect result because of not simplifying to 0 the difference between two equivalent such expressions. Even systems that avoid this flaw often do not return the same result for all equivalent such input forms, or return an unnecessarily bulky result that does not have any other compensating useful property. This article identifies some of these deficiencies, then describes the advantages and disadvantages of various alternative forms and how to overcome the deficiencies without costly integer factorization.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2017-09-30 00:00:00.000000"},
{"id":"1262","title":"Understand alone career choose among.","abstract":"Let $G$ be a unimodular Lie group, $X$ a compact manifold with boundary, and $M$ be the total space of a principal bundle $G\\to M\\to X$ so that $M$ is also a complex manifold satisfying a local subelliptic estimate. In this work, we show that if $G$ acts by holomorphic transformations in $M$, then the Laplacian $\\square=\\bar\\partial^{*}\\bar\\partial+\\bar\\partial\\bar\\partial^{*}$ on $M$ has the following properties: The kernel of $\\square$ restricted to the forms $\\Lambda^{p,q}$ with $q>0$ is a closed, $G$-invariant subspace in $L^{2}(M,\\Lambda^{p,q})$ of finite $G$-dimension. Secondly, we show that if $q>0$, then the image of $\\square$ contains a closed, $G$-invariant subspace of finite codimension in $L^{2}(M,\\Lambda^{p,q})$. These two properties taken together amount to saying that $\\square$ is a $G$-Fredholm operator. In similar circumstances, the boundary Laplacian $\\square_b$ has similar properties.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2020-12-20 00:00:00.000000"},
{"id":"1263","title":"Month know month change community.","abstract":"The q-composite key predistribution scheme [1] is used prevalently for secure communications in large-scale wireless sensor networks (WSNs). Prior work [2]-[4] explores topological properties of WSNs employing the q-composite scheme for q = 1 with unreliable communication links modeled as independent on\/off channels. In this paper, we investigate topological properties related to the node degree in WSNs operating under the q-composite scheme and the on\/off channel model. Our results apply to general q and are stronger than those reported for the node degree in prior work even for the case of q being 1. Specifically, we show that the number of nodes with certain degree asymptotically converges in distribution to a Poisson random variable, present the asymptotic probability distribution for the minimum degree of the network, and establish the asymptotically exact probability for the property that the minimum degree is at least an arbitrary value. Numerical experiments confirm the validity of our analytical findings.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2021-07-29 00:00:00.000000"},
{"id":"1264","title":"Usually avoid town away current individual public.","abstract":"We study certain symplectic quotients of n-fold products of complex projective m-space by the unitary group acting diagonally. After studying nonemptiness and smoothness these quotients we construct the action-angle variables, defined on an open dense subset of an integrable Hamiltonian system. The semiclassical quantization of this system reproduces formulas from the representation theory of the unitary group.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2016-04-10 00:00:00.000000"},
{"id":"1265","title":"Great blood hair first south quite.","abstract":"This paper is written to provide an insight into the physics and engineering that go into power delivery of the future. Topics covered are Fault Current Limiters (FCL) including Superconducting FCL and Emission Limited FCL; Lightning and Restoration Preparedness; Compressed-Gas-Insulated Delivery; Evaporative Cooling Delivery; Advanced Delivery Technologies Requiring Big Breakthroughs such as Conducting Polymers, Electron-Beam Delivery, Microwave Delivery, and Laser-Beam Delivery.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2018-02-10 00:00:00.000000"},
{"id":"1266","title":"Phone difference central left respond model.","abstract":"A famous characterization theorem due to C.F. Gauss states that the maximum likelihood estimator (MLE) of the parameter in a location family is the sample mean for all samples of all sample sizes if and only if the family is Gaussian. There exist many extensions of this result in diverse directions, most of them focussing on location and scale families. In this paper, we propose a unified treatment of this literature by providing general MLE characterization theorems for one-parameter group families (with particular attention on location and scale parameters). In doing so, we provide tools for determining whether or not a given such family is MLE-characterizable, and, in case it is, we define the fundamental concept of minimal necessary sample size at which a given characterization holds. Many of the cornerstone references on this topic are retrieved and discussed in the light of our findings, and several new characterization theorems are provided. Of particular interest is that one part of our work, namely the introduction of so-called equivalence classes for MLE characterizations, is a modernized version of Daniel Bernoulli's viewpoint on maximum likelihood estimation.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2021-05-20 00:00:00.000000"},
{"id":"1267","title":"Once always job.","abstract":"We offer a new method for determining the wind source term for energy and momentum fluxes transfer from the atmosphere to the wind-driven sea. This new source-term formulation is based on extensive analysis of experimental data collected at different sites around the world. It is shown that this new wind source term to be consistent both with numerical solution of exact equation for resonant four-wave interactions and available experimental data.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2017-03-21 00:00:00.000000"},
{"id":"1268","title":"Manager difficult my field word late person.","abstract":"We experimentally characterize Hopf bifurcation phenomena at femtojoule energy scales in a multi-atom cavity quantum electrodynamical (cavity QED) system, and demonstrate how such behaviors can be exploited in the design of all-optical memory and modulation devices. The data are analyzed using a semiclassical model that explicitly treats heterogeneous coupling of atoms to the cavity mode. Our results highlight the interest of cavity QED systems for ultra-low power photonic signal processing as well as for fundamental studies of mesoscopic nonlinear dynamics.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2016-10-23 00:00:00.000000"},
{"id":"1269","title":"Onto minute involve return study against.","abstract":"This paper discusses our investigation into the evolution of cooperative players in an online business environment. We explain our design of an incentive based system with its foundation over binary reputation system whose proportion of reward or punishment is a function of transaction value and the players past history of cooperation. We compare the evolution of cooperation in our setting with non-incentive based environment and our findings show that the incentive based method is more suitable for the evolution of trustworthy players.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2019-03-11 00:00:00.000000"},
{"id":"1270","title":"Miss church especially five condition increase.","abstract":"This paper presents deductive programming for scheduling scenario generation. Modeling for solution is achieved through program transformations. First, declarative model for scheduling problem domain is introduced. After that model is interpreted as scheduling domain language and as predicate transition Petri net. Generated reachability tree presents search space with solutions. At the end results are discussed and analyzed.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2021-08-05 00:00:00.000000"},
{"id":"1271","title":"Six next high according evening price.","abstract":"We introduce a new technique for evaluation of series with zeta coefficients and also for evaluation of certain integrals involving the logGamma function. This technique is based on Hankel integral representations of the Hurwitz zeta, the Lerch Zeta, the Digamma and logGamma functions.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2020-10-09 00:00:00.000000"},
{"id":"1272","title":"Black get rise sea.","abstract":"Recent observations of distant supernovae show that the universe, contrary to popular belief, is expanding for ever. Similarly, recent experiments at the Superkamiokande facility demonstrate that the Neutrino has a non vanishing mass. Both these discoveries necessitate, at the very least, a re-examination of conventional theories-the Big Bang Theory and the Standard Model. On the other hand, neither has quantum gravity yielded the desired results, nor can String Theory be taken as the last word. We briefly examine this scenario, and in this light consider the recent description of Fermions in terms of the Kerr-Newman metric and the related model of Fluctuational Cosmology. All this is not only consistent with known physics including the latest results alluded to, but also explains hitherto inexplicable empirical facts like the handedness of the Neutrino or the large number relations of Cosmology and so on. It is shown that this scheme leads to a unified description of the fundamental interactions. At the same time, pleasingly, we recover the usual quark picture at the Compton wavelength scale and the Big Bang scenario at the Planck scale.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2019-03-05 00:00:00.000000"},
{"id":"1273","title":"Mention throw dark thought suggest how.","abstract":"We tackle the problem of data-structure rewriting including pointer redirections. We propose two basic rewrite steps: (i) Local Redirection and Replacement steps the aim of which is redirecting specific pointers determined by means of a pattern, as well as adding new information to an existing data ; and (ii) Global Redirection steps which are aimed to redirect all pointers targeting a node towards another one. We define these two rewriting steps following the double pushout approach. We define first the category of graphs we consider and then define rewrite rules as pairs of graph homomorphisms of the form \"L <- K ->R\". Unfortunately, inverse pushouts (complement pushouts) are not unique in our setting and pushouts do not always exist. Therefore, we define rewriting steps so that a rewrite rule can always be performed once a matching is found.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2022-08-19 00:00:00.000000"},
{"id":"1274","title":"Cover church to leader.","abstract":"We propose an easy-to-use methodology to allocate one of the groups which have been previously built from a complete learning data base, to new individuals. The learning data base contains continuous and categorical variables for each individual. The groups (clusters) are built by using only the continuous variables and described with the help of the categorical ones. For the new individuals, only the categorical variables are available, and it is necessary to define a model which computes the probabilities to belong to each of the clusters, by using only the categorical variables. Then this model provides a decision rule to assign the new individuals and gives an efficient tool to decision-makers. This tool is shown to be very efficient for customers allocation in consumer clusters for marketing purposes, for example.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2017-10-18 00:00:00.000000"},
{"id":"1275","title":"New open community little modern sound each sort.","abstract":"The EU DataGrid has deployed a grid testbed at approximately 20 sites across Europe, with several hundred registered users. This paper describes authorisation systems produced by GridPP and currently used on the EU DataGrid Testbed, including local Unix pool accounts and fine-grained access control with Access Control Lists and Grid-aware filesystems, fileservers and web developement environments.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2020-04-13 00:00:00.000000"},
{"id":"1276","title":"Single student top decade too rich heart think.","abstract":"Heap data is potentially unbounded and seemingly arbitrary. This survey provides a high level view of the abstraction techniques used for compile time analysis of heap data. We view a heap abstraction as consisting of two features: a heap model to represent the heap memory and a summarization technique for bounding the heap representation. We classify the models as storeless, store based, and hybrid. We describe various summarization techniques based on k-limiting, allocation sites, patterns, variables, other generic predicates, and logic. We describe how these summarization techniques have been adopted in the literature for different heap models.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2022-11-04 00:00:00.000000"},
{"id":"1277","title":"Much church firm significant off however.","abstract":"We present a bicategorical perspective on derived Morita theory for rings, DG algebras, and spectra. This perspective draws a connection between Morita theory and the bicategorical Yoneda Lemma, yielding a conceptual unification of Morita theory in derived and bicategorical contexts. This is motivated by study of Rickard's theorem for derived equivalences of rings and of Morita theory for ring spectra, which we present in Sections 2 and 4. Along the way, we gain an understanding of the barriers to Morita theory for DG algebras and give a conceptual explanation for the counterexample of Dugger and Shipley.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2020-01-03 00:00:00.000000"},
{"id":"1278","title":"Left guess wide his work she challenge.","abstract":"A model for the large-scale circulation (LSC) dynamics of turbulent Rayleigh-Benard convection is presented. It consists of two stochastic ordinary differential equations motivated by the Navier-Stokes equation, one each for the strength and the azimuthal orientation of the LSC. Stochastic forces represent phenomenologically the action of the turbulent fluctuations on the LSC. Without adjustable parameters, the model yields a meandering LSC with occasional rotations, and with more rare cessations that occur a few times per day -- differing only by about a factor of two from experiment. Also as in experiments, the distribution of LSC orientation-change is uniform for cessations and a power law for rotations.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2015-04-01 00:00:00.000000"},
{"id":"1279","title":"Sell push station require buy shoulder become.","abstract":"In this paper, we consider the finite tiling problem which was proved undecidable in the Euclidean plane by Jarkko Kari in 1994. Here, we prove that the same problem for the hyperbolic plane is also undecidable.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2018-08-08 00:00:00.000000"},
{"id":"1280","title":"Seem home upon evidence usually evening system.","abstract":"The vector autoregressive (VAR) model has been widely used for modeling temporal dependence in a multivariate time series. For large (and even moderate) dimensions, the number of AR coefficients can be prohibitively large, resulting in noisy estimates, unstable predictions and difficult-to-interpret temporal dependence. To overcome such drawbacks, we propose a 2-stage approach for fitting sparse VAR (sVAR) models in which many of the AR coefficients are zero. The first stage selects non-zero AR coefficients based on an estimate of the partial spectral coherence (PSC) together with the use of BIC. The PSC is useful for quantifying the conditional relationship between marginal series in a multivariate process. A refinement second stage is then applied to further reduce the number of parameters. The performance of this 2-stage approach is illustrated with simulation results. The 2-stage approach is also applied to two real data examples: the first is the Google Flu Trends data and the second is a time series of concentration levels of air pollutants.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2015-05-22 00:00:00.000000"},
{"id":"1281","title":"Seven camera carry name people reality.","abstract":"Two types of low cost-per-iteration gradient descent methods have been extensively studied in parallel. One is online or stochastic gradient descent (OGD\/SGD), and the other is randomzied coordinate descent (RBCD). In this paper, we combine the two types of methods together and propose online randomized block coordinate descent (ORBCD). At each iteration, ORBCD only computes the partial gradient of one block coordinate of one mini-batch samples. ORBCD is well suited for the composite minimization problem where one function is the average of the losses of a large number of samples and the other is a simple regularizer defined on high dimensional variables. We show that the iteration complexity of ORBCD has the same order as OGD or SGD. For strongly convex functions, by reducing the variance of stochastic gradients, we show that ORBCD can converge at a geometric rate in expectation, matching the convergence rate of SGD with variance reduction and RBCD.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2019-12-07 00:00:00.000000"},
{"id":"1282","title":"Thing deal really general.","abstract":"Existence of a stationary mode for a Hamiltonian dynamic system of two point vortexes with different signs on different latitudes of a uniform rotating sphere complying with observed data is stated. It is shown that such mode realization is possible only in the case when the more intensive cyclonic vortex has greater latitude than that of the anticyclonic vortex. A criterion of exponential instability of the stationary vortex mode taken into account impact of the polar vortexes is obtained. Compliance of the theory to observed data and reanalysis for coupled quasi-stationary systems of cyclonic and anticyclonic atmosphere action centers above oceans in the Northern Hemisphere is considered.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2017-12-12 00:00:00.000000"},
{"id":"1283","title":"Region lose trade race film Democrat question animal.","abstract":"The implementation of reliable and efficient geometric algorithms is a challenging task. The reason is the following conflict: On the one hand, computing with rounded arithmetic may question the reliability of programs while, on the other hand, computing with exact arithmetic may be too expensive and hence inefficient. One solution is the implementation of controlled perturbation algorithms which combine the speed of floating-point arithmetic with a protection mechanism that guarantees reliability, nonetheless.   This paper is concerned with the performance analysis of controlled perturbation algorithms in theory. We answer this question with the presentation of a general analysis tool box. This tool box is separated into independent components which are presented individually with their interfaces. This way, the tool box supports alternative approaches for the derivation of the most crucial bounds. We present three approaches for this task. Furthermore, we have thoroughly reworked the concept of controlled perturbation in order to include rational function based predicates into the theory; polynomial based predicates are included anyway. Even more we introduce object-preserving perturbations. Moreover, the tool box is designed such that it reflects the actual behavior of the controlled perturbation algorithm at hand without any simplifying assumptions.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2019-08-02 00:00:00.000000"},
{"id":"1284","title":"Box indeed together analysis.","abstract":"We embed Safe Recursion on Notation (SRN) into Light Affine Logic by Levels (LALL), derived from the logic L4. LALL is an intuitionistic deductive system, with a polynomial time cut elimination strategy.   The embedding allows to represent every term t of SRN as a family of proof nets |t|^l in LALL. Every proof net |t|^l in the family simulates t on arguments whose bit length is bounded by the integer l. The embedding is based on two crucial features. One is the recursive type in LALL that encodes Scott binary numerals, i.e. Scott words, as proof nets. Scott words represent the arguments of t in place of the more standard Church binary numerals. Also, the embedding exploits the \"fuzzy\" borders of paragraph boxes that LALL inherits from L4 to \"freely\" duplicate the arguments, especially the safe ones, of t. Finally, the type of |t|^l depends on the number of composition and recursion schemes used to define t, namely the structural complexity of t. Moreover, the size of |t|^l is a polynomial in l, whose degree depends on the structural complexity of t.   So, this work makes closer both the predicative recursive theoretic principles SRN relies on, and the proof theoretic one, called \/stratification\/, at the base of Light Linear Logic.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2015-01-29 00:00:00.000000"},
{"id":"1285","title":"Might produce entire ahead enter former building nature.","abstract":"Photothermal microscopy has recently complemented single molecule fluorescence microscopy by the detection of individual nano-objects in absorption. Photothermal techniques gain their superior sensitivity by exploiting a heat induced refractive index change around the absorbing nano-object. Numerous new applications to nanoparticles, nanorods and even single molecules have been reported all refering to the fact that photothermal microscopy is an extinction measurement on a heat induced refractive index profile. Here, we show that the actual physical mechanism generating a photothermal signal from a single molecule\/particle is fundamentally different from the assumed extinction measurement. Combining photothermal microscopy, light scattering microscopy as well as accurate Mie scattering calculations to single gold nanoparticles, we reveal that the detection mechanism is quantitatively explained by a nanolensing effect of the long range refractive index profile. Our results lay the foundation for future developments and quantitative applications of single molecule absorption microscopy.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2018-12-18 00:00:00.000000"},
{"id":"1286","title":"Walk suddenly maintain different face between.","abstract":"Active diffusiophoresis - swimming through interaction with a self-generated, neutral, solute gradient - is a paradigm for autonomous motion at the micrometer scale. We study this propulsion mechanism within a linear response theory. Firstly, we consider several aspects relating to the dynamics of the swimming particle. We extend established analytical formulae to describe small swimmers, which interact with their environment on a finite lengthscale. Solute convection is also taken into account. Modeling of the chemical reaction reveals a coupling between the angular distribution of reactivity on the swimmer and the concentration field. This effect, which we term \"reaction induced concentration distortion\", strongly influences the particle speed. Building on these insights, we employ irreversible, linear thermodynamics to formulate an energy balance. This approach highlights the importance of solute convection for a consistent treatment of the energetics. The efficiency of swimming is calculated numerically and approximated analytically. Finally, we define an efficiency of transport for swimmers which are moving in random directions. It is shown that this efficiency scales as the inverse of the macroscopic distance over which transport is to occur.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2022-04-29 00:00:00.000000"},
{"id":"1287","title":"Long message summer agent defense election nice.","abstract":"We report on the development of the HEC2 (High Energy Compression and Current) charge breeder, a possible high performance successor to REXEBIS at ISOLDE. The new breeder would match the performance of the HIE-ISOLDE linac upgrade and make full use of the possible installation of a storage ring at ISOLDE (the TSR@ISOLDE initiative [1]). Dictated by ion beam acceptance and capacity requirements, the breeder features a 2-3.5 A electron beam. In many cases very high charge states, including bare ions up to Z=70 and Li\/Na-like up to Z=92 could be requested for experiments in the storage ring, therefore, electron beam energies up to 150 keV are required. The electron-beam current density needed for producing ions with such high charge states at an injection rate into TSR of 0.5-1 Hz is between 10 and 20 kA\/cm2, which agrees with the current density needed to produce A\/q<4.5 ions for the HIE-ISOLDE linac with a maximum repetition rate of 100 Hz. The first operation of a prototype electron gun with a pulsed electron beam of 1.5 A and 30 keV was demonstrated in a joint experiment with BNL [2]. In addition, we report on further development aiming to achieve CW operation of an electron beam having a geometrical transverse ion-acceptance matching the injection of 1+ ions (11.5 {\\mu}m), and an emittance\/energy spread of the extracted ion beam matching the downstream mass separator and RFQ (0.08 {\\mu}m normalized \/ +\/- 1% ).","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2020-04-20 00:00:00.000000"},
{"id":"1288","title":"Reflect high change feeling large.","abstract":"Recently, Bert, Wang and Striz [1, 2] applied the differential quadrature (DQ) and harmonic differential quadrature (HDQ) methods to analyze static and dynamic behaviors of anisotropic plates. Their studies showed that the methods were conceptually simple and computationally efficient in comparison to other numerical techniques. Based on some recent work by the present author [3, 4], the purpose of this note is to further simplify the formulation effort and improve computing efficiency in applying the DQ and HDQ methods for these cases.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2019-07-03 00:00:00.000000"},
{"id":"1289","title":"Authority shake south most position close beyond.","abstract":"Let $(M^m,g)$ be a m-dimensional complete Riemannian manifold which satisfies the n-Sobolev inequality and on which the volume growth is comparable to the one of $\\R^n$ for big balls; if the Hodge Laplacian on 1-forms is strongly positive and the Ricci tensor is in $L^{\\frac{n}{2}\\pm \\epsilon}$ for an $\\epsilon>0$, then we prove a Gaussian estimate on the heat kernel of the Hodge Laplacian on 1-forms. This allows us to prove that, under the same hypotheses, the Riesz transform $d\\Delta^{-1\/2}$ is bounded on $L^p$ for all $1","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2021-01-10 00:00:00.000000"},
{"id":"1290","title":"Argue network life hope white.","abstract":"Electromagnetic interactions between colliding heavy ions at the Large Hadron Collider (LHC) at CERN will give rise to localized beam losses that may quench superconducting magnets, apart from contributing significantly to the luminosity decay. To quantify their impact on the operation of the collider, we have used a three-step simulation approach, which consists of optical tracking, a Monte-Carlo shower simulation and a thermal network model of the heat flow inside a magnet. We present simulation results for the case of Pb ion operation in the LHC, with focus on the ALICE interaction region, and show that the expected heat load during nominal Pb operation is 40% above the quench level. This limits the maximum achievable luminosity. Furthermore, we discuss methods of monitoring the losses and possible ways to alleviate their effect.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2021-09-24 00:00:00.000000"},
{"id":"1291","title":"Early senior interview off sign.","abstract":"We consider different aspects of the problem of cosmological singularity such as the BKL oscillatory approach to singularity, the new features of the cosmological dynamics in the neighbourhood of the singularity in multidimensional and superstring cosmological models and their connections with such a modern branch of mathematics as infinite-dimensional Lie algebras. Besides, we consider some new types of cosmological singularities which were widely discussed during last decade after the discovery of the phenomenon of cosmic acceleration.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2022-08-28 00:00:00.000000"},
{"id":"1292","title":"Leader feel wait fear candidate natural.","abstract":"Symmetries are playing a very prominent role in natural sciences. In mathematics as the language of physics, symmetries are treated within the framework of group theory, which provides the tools to classify natural laws and physical objects like elementary particles. The present work discusses aspects of relativistic quantum field theory as the mathematical theory of particle physics which are relevant for the modern description of elementary particles and their associated fields hitherto considered as fundamental building blocks of the theory. Due to the abstract nature of quantum field theory, these aspects can only be touched by their exemplification within a review.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2019-08-21 00:00:00.000000"},
{"id":"1293","title":"Wait themselves soldier action election level religious perhaps.","abstract":"The research area of Networked Control Systems (NCS) has been the topic of intensive study in the last decade. In this paper we give a contribution to this research line by addressing symbolic control design of (possibly unstable) nonlinear NCS with specifications expressed in terms of automata. We first derive symbolic models that are shown to approximate the given NCS in the sense of (alternating) approximate simulation. We then address symbolic control design with specifications expressed in terms of automata. We finally derive efficient algorithms for the synthesis of the proposed symbolic controllers that cope with the inherent computational complexity of the problem at hand.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2017-04-09 00:00:00.000000"},
{"id":"1294","title":"Really wear for trip.","abstract":"An effective way to increase the noise robustness of automatic speech recognition is to label noisy speech features as either reliable or unreliable (missing) prior to decoding, and to replace the missing ones by clean speech estimates. We present a novel method to obtain such clean speech estimates. Unlike previous imputation frameworks which work on a frame-by-frame basis, our method focuses on exploiting information from a large time-context. Using a sliding window approach, denoised speech representations are constructed using a sparse representation of the reliable features in an overcomplete basis of fixed-length exemplar fragments. We demonstrate the potential of our approach with experiments on the AURORA-2 connected digit database.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2021-10-24 00:00:00.000000"},
{"id":"1295","title":"Effect require control.","abstract":"In this paper we look at some of the design issues that affect the success of multimodal displays that combine acoustic and haptic modalities. First, issues affecting successful sonification design are explored and suggestions are made about how the language of electroacoustic music can assist. Next, haptic interaction is introduced in the light of this discussion, particularly focusing on the roles of gesture and mimesis. Finally, some observations are made regarding some of the issues that arise when the haptic and acoustic modalities are combined in the interface. This paper looks at examples of where auditory and haptic interaction have been successfully combined beyond the strict confines of the human-computer application interface (musical instruments in particular) and discusses lessons that may be drawn from these domains and applied to the world of multimodal human-computer interaction. The argument is made that combined haptic-auditory interaction schemes can be thought of as musical instruments and some of the possible ramifications of this are raised.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2018-05-13 00:00:00.000000"},
{"id":"1296","title":"Toward east throughout type vote capital.","abstract":"Minimizing the number of dropped User Datagram Protocol (UDP) messages in a network is regarded as a challenge by researchers. This issue represents serious problems for many protocols particularly those that depend on sending messages as part of their strategy, such us service discovery protocols. This paper proposes and evaluates an algorithm to predict the minimum period of time required between two or more consecutive messages and suggests the minimum queue sizes for the routers, to manage the traffic and minimise the number of dropped messages that has been caused by either congestion or queue overflow or both together. The algorithm has been applied to the Universal Plug and Play (UPnP) protocol using ns2 simulator. It was tested when the routers were connected in two configurations; as a centralized and de centralized. The message length and bandwidth of the links among the routers were taken in the consideration. The result shows Better improvement in number of dropped messages `among the routers.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2020-12-28 00:00:00.000000"},
{"id":"1297","title":"Type act wish control.","abstract":"We describe arbitrary multiplicative differential forms on Lie groupoids infinitesimally, i.e., in terms of Lie algebroid data. This description is based on the study of linear differential forms on Lie algebroids and encompasses many known integration results related to Poisson geometry. We also revisit multiplicative multivector fields and their infinitesimal counterparts, drawing a parallel between the two theories.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2021-02-15 00:00:00.000000"},
{"id":"1298","title":"Miss policy describe ball cut east address.","abstract":"We study almost real spectral triples on quantum lens spaces, as orbit spaces of free actions of cyclic groups on the spectral geometry on the quantum group $SU_q(2)$. These spectral triples are given by weakening some of the conditions of a real spectral triple. We classify the irreducible almost real spectral triples on quantum lens spaces and we study unitary equivalences of such quantum lens spaces. We show that if $r$ is coprime to $p$, the $C^*$-algebras corresponding to the quantum lens spaces $L_q(p,r)$ and $L_q(p,1)$ are isomorphic. Also, we show that all such quantum lens spaces are Seifert fibrations over quantum teardrops, and calculate the Dirac spectrum on the base space coming from this fibration.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2020-12-29 00:00:00.000000"},
{"id":"1299","title":"Today attorney usually respond mother find next.","abstract":"The stabilizer code is the most general algebraic construction of quantum error-correcting codes proposed so far. A stabilizer code can be constructed from a self-orthogonal subspace of a symplectic space over a finite field. We propose a construction method of such a self-orthogonal space using an algebraic curve. By using the proposed method we construct an asymptotically good sequence of binary stabilizer codes. As a byproduct we improve the Ashikhmin-Litsyn-Tsfasman bound of quantum codes. The main results in this paper can be understood without knowledge of quantum mechanics.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2015-09-04 00:00:00.000000"},
{"id":"1300","title":"President college production direction again hear.","abstract":"We develop a general theory of spatial solitons in a liquid crystalline medium exhibiting a nonlinearity with an arbitrary degree of effective nonlocality. The model accounts the observability of \"accessible solitons\" and establishes an important link with parametric solitons.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2016-01-18 00:00:00.000000"},
{"id":"1301","title":"The fish culture side firm book agency.","abstract":"Document clustering and topic modeling are two closely related tasks which can mutually benefit each other. Topic modeling can project documents into a topic space which facilitates effective document clustering. Cluster labels discovered by document clustering can be incorporated into topic models to extract local topics specific to each cluster and global topics shared by all clusters. In this paper, we propose a multi-grain clustering topic model (MGCTM) which integrates document clustering and topic modeling into a unified framework and jointly performs the two tasks to achieve the overall best performance. Our model tightly couples two components: a mixture component used for discovering latent groups in document collection and a topic model component used for mining multi-grain topics including local topics specific to each cluster and global topics shared across clusters.We employ variational inference to approximate the posterior of hidden variables and learn model parameters. Experiments on two datasets demonstrate the effectiveness of our model.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2020-04-08 00:00:00.000000"},
{"id":"1302","title":"Information me wind fast one picture.","abstract":"For the planning of large pedestrian facilities, the movement of pedestrians in various situations has to be modelled. Many tools for pedestrian planning are based on cellular automata (CA), discrete in space and time, some use self driven pargticles (SDP), continuous in space and time. It is common experience that CA have problems with modelling sharp bends in wide corridors. They tend to move the pedestrians to the innermost lanes far too strongly, thereby reducing the capacity of the facility. With SDP, the problem seems to be less pronounced but still present. With CA, we compare the performance of two standard shortest distance based static floors on 90 and 180 degree bends with a newly defined one. For SDP, we demonstrate how variations in the modeling of the momentary destination of the agents influence trajectories and capacity.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2018-10-17 00:00:00.000000"},
{"id":"1303","title":"Media after good ability natural discussion report.","abstract":"The convergence of the projection algorithm for solving the convex feasibility problem for a family of closed convex sets, is in connection with the regularity properties of the family. In the paper [18] are pointed out four cases of such a family depending of the two characteristics: the emptiness and boudedness of the intersection of the family. The case four (the interior of the intersection is empty and the intersection itself is bounded) is unsolved. In this paper we give a (partial) answer for the case four: in the case of two closed convex sets in R3 the regularity property holds.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2021-07-13 00:00:00.000000"},
{"id":"1304","title":"Hour huge little movement some nice.","abstract":"We study here schedulers for a class of rules that naturally arise in the context of rule-based constraint programming. We systematically derive a scheduler for them from a generic iteration algorithm of Apt [2000]. We apply this study to so-called membership rules of Apt and Monfroy [2001]. This leads to an implementation that yields for these rules a considerably better performance than their execution as standard CHR rules.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2018-10-04 00:00:00.000000"},
{"id":"1305","title":"Service executive have collection loss.","abstract":"We discuss an elementary problem in electrostatics: What does the charge distribution look like for a free charge on a strictly one-dimensional wire of finite length? To the best of our knowledge this question has so far not been discussed anywhere. One notices that a solution of this problem is not as simple as it might appear at first sight.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2018-11-01 00:00:00.000000"},
{"id":"1306","title":"Break everything recent consumer main thought.","abstract":"We propose a multiresolution Gaussian process to capture long-range, non-Markovian dependencies while allowing for abrupt changes. The multiresolution GP hierarchically couples a collection of smooth GPs, each defined over an element of a random nested partition. Long-range dependencies are captured by the top-level GP while the partition points define the abrupt changes. Due to the inherent conjugacy of the GPs, one can analytically marginalize the GPs and compute the conditional likelihood of the observations given the partition tree. This property allows for efficient inference of the partition itself, for which we employ graph-theoretic techniques. We apply the multiresolution GP to the analysis of Magnetoencephalography (MEG) recordings of brain activity.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2022-09-27 00:00:00.000000"},
{"id":"1307","title":"Fact affect floor fight institution quite.","abstract":"A theorem of Tits - Vinberg allows to build action of a Coxeter group $\\Gamma$ on a properly convex open set $\\Omega$ of the real projective space, thanks to the data $P$ of a polytope and reflection across its facets. We give sufficient conditions for such action to be of finite covolume, convex-cocompact or geometrically finite. We describe an hypothesis that make those conditions necessary. Under this hypothesis, we describe the Zariski closure of $\\Gamma$, find the maximal $\\Gamma$-invariant convex, when there is a unique $\\Gamma$-invariant convex, when the convex $\\Omega$ is strictly convex, when we can find a $\\Gamma$-invariant convex $\\Omega'$ which is strictly convex.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2016-06-03 00:00:00.000000"},
{"id":"1308","title":"Top never blue law station.","abstract":"We propose efficient nonparametric statistics to compare medical imaging modalities in multi-reader multi-test data and to compare markers in longitudinal ROC data. The proposed methods are based on the weighted area under the ROC curve which includes the area under the curve and the partial area under the curve as special cases. The methods maximize the local power for detecting the difference between imaging modalities. The asymptotic results of the proposed methods are developed under a complex correlation structure. Our simulation studies show that the proposed statistics result in much better powers than existing statistics. We applied the proposed statistics to an endometriosis diagnosis study.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2022-10-09 00:00:00.000000"},
{"id":"1309","title":"Information past nothing bring each.","abstract":"The technique of laser-assisted nanoimprinting lithography (LAN) has been proposed to utilize an excimer laser to irradiate through a quartz mold and melts a thin polymer film on the substrate for micro- to nano-scaled fabrications. In the present study, the novel concept of that copper was adopted as the substrate instead of silicon, which is conventionally used, was proposed. The micro\/nano structures on the copper substrate could be fabricated by chemical\/electrochemical etching or electroforming ; following by the patterns have been transferred onto the substrate using LAN process. Alternatives of the substrate materials could lead versatile applications in micro\/nano-fabrication. To demonstrate the feasibility of this concept numerically, this study introduced optical multiple reflection theory to perform both analytical and numerical modeling during the process and to predict the thermal response theoretically.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2021-02-24 00:00:00.000000"},
{"id":"1310","title":"Central debate response speak interest guy expect.","abstract":"Common algorithms for computationally simulating Langevin dynamics must discretize the stochastic differential equations of motion. These resulting finite time step integrators necessarily have several practical issues in common: Microscopic reversibility is violated, the sampled stationary distribution differs from the desired equilibrium distribution, and the work accumulated in nonequilibrium simulations is not directly usable in estimators based on nonequilibrium work theorems. Here, we show that even with a time-independent Hamiltonian, finite time step Langevin integrators can be thought of as a driven, nonequilibrium physical process. Once an appropriate work-like quantity is defined -- here called the shadow work -- recently developed nonequilibrium fluctuation theorems can be used to measure or correct for the errors introduced by the use of finite time steps. In particular, we demonstrate that amending estimators based on nonequilibrium work theorems to include this shadow work removes the time step dependent error from estimates of free energies. We also quantify, for the first time, the magnitude of deviations between the sampled stationary distribution and the desired equilibrium distribution for equilibrium Langevin simulations of solvated systems of varying size. While these deviations can be large, they can be eliminated altogether by Metropolization or greatly diminished by small reductions in the time step. Through this connection with driven processes, further developments in nonequilibrium fluctuation theorems can provide additional analytical tools for dealing with errors in finite time step integrators.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2020-05-12 00:00:00.000000"},
{"id":"1311","title":"Key democratic issue economic answer relate former.","abstract":"Despite providing similar functionality, multiple network services may require the use of different interfaces to access the functionality, and this problem will only get worse with the widespread deployment of ubiquitous computing environments. One way around this problem is to use interface adapters that adapt one interface into another. Chaining these adapters allows flexible interface adaptation with fewer adapters, but the loss incurred due to imperfect interface adaptation must be considered. This paper outlines a mathematical basis for analyzing the chaining of lossy interface adapters. We also show that the problem of finding an optimal interface adapter chain is NP-complete.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2022-12-22 00:00:00.000000"},
{"id":"1312","title":"Dark pretty trade heart great national choose.","abstract":"Procedural content generation (PCG) has recently become one of the hottest topics in computational intelligence and AI game researches. Among a variety of PCG techniques, search-based approaches overwhelmingly dominate PCG development at present. While SBPCG leads to promising results and successful applications, it poses a number of challenges ranging from representation to evaluation of the content being generated. In this paper, we present an alternative yet generic PCG framework, named learning-based procedure content generation (LBPCG), to provide potential solutions to several challenging problems in existing PCG techniques. By exploring and exploiting information gained in game development and public beta test via data-driven learning, our framework can generate robust content adaptable to end-user or target players on-line with minimal interruption to their experience. Furthermore, we develop enabling techniques to implement the various models required in our framework. For a proof of concept, we have developed a prototype based on the classic open source first-person shooter game, Quake. Simulation results suggest that our framework is promising in generating quality content.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2018-10-24 00:00:00.000000"},
{"id":"1313","title":"Assume standard pay street allow article with.","abstract":"In this paper, we present an algorithm for minimizing the difference between two submodular functions using a variational framework which is based on (an extension of) the concave-convex procedure [17]. Because several commonly used metrics in machine learning, like mutual information and conditional mutual information, are submodular, the problem of minimizing the difference of two submodular problems arises naturally in many machine learning applications. Two such applications are learning discriminatively structured graphical models and feature selection under computational complexity constraints. A commonly used metric for measuring discriminative capacity is the EAR measure which is the difference between two conditional mutual information terms. Feature selection taking complexity considerations into account also fall into this framework because both the information that a set of features provide and the cost of computing and using the features can be modeled as submodular functions. This problem is NP-hard, and we give a polynomial time heuristic for it. We also present results on synthetic data to show that classifiers based on discriminative graphical models using this algorithm can significantly outperform classifiers based on generative graphical models.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2020-02-20 00:00:00.000000"},
{"id":"1314","title":"Media time pay space adult vote.","abstract":"Floating particles that are initially distributed uniformly on the surface of a turbulent fluid, subsequently coagulate, until finally a steady state is reached. This being so, they manifestly form a compressible system. In this experiment, the information dimension D_1, and the Lyapunov exponents of the coagulated floaters, are measured. The trajectories and the velocity fields of the particles are captured in a sequence of rapidly acquired images. Then the velocity sequence is randomly shuffled in time to generate new trajectories. This analysis mimics the Kraichnan ensemble and yields properties of a velocity correlation function that is delta-correlated in time (but not in space). The measurements are compared with theoretical expectations and with simulations of Boffetta et al., that closely mimic the laboratory experiment reported here.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2021-02-05 00:00:00.000000"},
{"id":"1315","title":"None no between above knowledge appear show.","abstract":"We present the first time-resolved cryogenic observations of Forster energy transfer in large, monodisperse lead sulphide quantum dots with ground state transitions near 1.5 um (0.83 eV), in environments from 160 K to room temperature. The observed temperature-dependent dipole-dipole transfer rate occurs in the range of (30-50 ns)^(-1), measured with our confocal single-photon counting setup at 1.5 um wavelengths. By temperature-tuning the dots, 94% efficiency of resonant energy transfer can be achieved for donor dots. The resonant transfer rates match well with proposed theoretical models.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2018-05-16 00:00:00.000000"},
{"id":"1316","title":"Impact leg commercial child interview.","abstract":"We introduce a concept of a W-graph ideal in a Coxeter group. The main goal of this paper is to describe how to construct a W-graph from a given W-graph ideal. The principal application of this idea is in type A, where it provides an algorithm for the construction of W-graphs for Specht modules.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2019-01-24 00:00:00.000000"},
{"id":"1317","title":"Person smile talk word then range by.","abstract":"Domain specific software architecture aims at software reuse through construction of domain architecture reference model. The constructed reference model presents a set of individual components and their interaction points. When starting on a new large software project, the design engineer starts with pre-constructed model, which can be easily browsed and picks up opportunities of use in the new solution design. This report discusses application of domain reference design methods by deriving domain specific reference architecture for a product ordering system in a design center. The product in this case is instock and special order blinds from different manufacturers in a large supply store. The development of mature domain specific reference software architecture for this domain is not the objective of this report. However, this report would like to capture the method used in one such process and that is the primary concern of this report. This report lists subjective details of such a process applied to the domain of ordering custom and instock blinds from a large home construction and goods supply store. This report also describes the detailed process of derivation of knowledge models, unified knowledge models and the reference architecture for this domain. However, this domain model is only partially complete which may not be used for any real applications. This report is a result of a course project undertaken while studying this methodology.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2017-07-11 00:00:00.000000"},
{"id":"1318","title":"Especially sister strong series apply finally magazine.","abstract":"The problem of estimating the tail index from truncated data is addressed in Chakrabarty and Samorodnitsky (2009). In that paper, a sample based (and hence random) choice of k is suggested, and it is shown that the choice leads to a consistent estimator of the inverse of the tail index. In this paper, the second order behavior of the Hill estimator with that choice of k is studied, under some additional assumptions. In the untruncated situation, it is well known that asymptotic normality of the Hill estimator follows from the assumption of second order regular variation of the underlying distribution. Motivated by this, we show the same in the truncated case in light of the second order regular variation.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2020-03-18 00:00:00.000000"},
{"id":"1319","title":"Action certain size direction room end notice region.","abstract":"A graph is a path graph if it is the intersection graph of a family of subpaths of a tree. In 1970, Renz asked for a characterizaton of path graphs by forbidden induced subgraphs. Here we answer this question by listing all graphs that are not path graphs and are minimal with this property.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2017-08-18 00:00:00.000000"},
{"id":"1320","title":"Look young group information sometimes go manager.","abstract":"For Project X Fermilab Main Injector will be required to provide up to 2.3 MW to a neutrino production target at energies between 60 and 120 GeV. To accomplish the above power levels 3 times the current beam intensity will need to be accelerated. In addition the injection energy of Main Injector will need to be as low as 6 GeV. The current 30 year old Main Injector radio frequency system will not be able to provide the required power and a new system will be required. The specifications of the new system will be described.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2021-07-20 00:00:00.000000"},
{"id":"1321","title":"Win give man part.","abstract":"Charge Coupled Devices (CCDs) have been successfully used in several high energy physics experiments over the past two decades. Their high spatial resolution and thin sensitive layers make them an excellent tool for studying short-lived particles. The Linear Collider Flavour Identification (LCFI) collaboration is developing Column-Parallel CCDs (CPCCDs) for the vertex detector of a future Linear Collider. The CPCCDs can be read out many times faster than standard CCDs, significantly increasing their operating speed. An Analytic Model has been developed for the determination of the charge transfer inefficiency (CTI) of a CPCCD. The CTI values determined with the Analytic Model agree largely with those from a full TCAD simulation. The Analytic Model allows efficient study of the variation of the CTI on parameters like readout frequency, operating temperature and occupancy.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2021-07-15 00:00:00.000000"},
{"id":"1322","title":"Real democratic member must form travel.","abstract":"We study the minimal resultant divisor of self-maps of the projective line over a number field or a function field and its relation to the conductor. The guiding focus is the exploration of a dynamical analog to Theorem 1.1, which bounds the degree of the minimal discriminant of an elliptic surface in terms of the conductor. We study minimality and semi-stability, considering what conditions imply minimality (Theorem 4.4) and whether semi-stable models and presentations are minimal, proving results in the degree two case (Theorems 4.6, 4.7). We prove the singular reduction of a semi-stable presentation coincides with the bad reduction (Theorem 3.1). Given an elliptic curve over a function field with semi-stable bad reduction, we show the associated Lattes map has unstable bad reduction (Theorem 3.6). Degree 2 maps in normal form with semi-stable bad reduction are used to construct a counterexample (Theorem 2.1) to a natural dynamical analog to Theorem 1.1. Finally, we consider the notion of \"critical bad reduction,\" and show that a dynamical analog to Theorem 1.1 may still be possible using the locus of critical bad reduction to define the conductor (Theorem 4.10, Theorem 4.13).","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2021-10-07 00:00:00.000000"},
{"id":"1323","title":"Ask break own mention even.","abstract":"In this paper, we describe a connection that exists among (a) the number of singular points along the trajectory of Toda flow, (b) the cohomology of a compact subgroup $K$, and (c) the number of points of a Chevalley group $K({\\mathbb F}_q)$ related to $K$ over a finite field ${\\mathbb F}_q$. The Toda lattice is defined for a real split semisimple Lie algebra $\\mathfrak g$, and $K$ is a maximal compact Lie subgroup of $G$ associated to $\\mathfrak g$. Relations are also obtained between the singularities of the Toda flow and the integral cohomology of the real flag manifold $G\/B$ with $B$ the Borel subgroup of $G$ (here we have $G\/B=K\/T$ with a finite group $T$). We also compute the maximal number of singularities of the Toda flow for any real split semisimple algebra, and find that this number gives the multiplicity of the singularity at the intersection of the varieties defined by the zero set of Schur polynomials.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2018-06-10 00:00:00.000000"},
{"id":"1324","title":"Standard authority form age coach world experience.","abstract":"Consider a diagram of quasi-categories that admit and functors that preserve limits or colimits of a fixed shape. We show that any weighted limit whose weight is a projective cofibrant simplicial functor is again a quasi-category admitting these (co)limits and that they are preserved by the functors in the limit cone. In particular, the Bousfield-Kan homotopy limit of a diagram of quasi-categories admit any limits or colimits existing in and preserved by the functors in that diagram. In previous work, we demonstrated that the quasi-category of algebras for a homotopy coherent monad could be described as a weighted limit with projective cofibrant weight, so these results immediately provide us with important (co)completeness results for quasi-categories of algebras. These generalise most of the classical categorical results, except for a well known theorem which shows that limits lift to the category of algebras for any monad, regardless of whether its functor part preserves those limits. The second half of this paper establishes this more general result in the quasi-categorical setting: showing that the monadic forgetful functor of the quasi-category of algebras for a homotopy coherent monad creates all limits that exist in the base quasi-category, without further assumption on the monad. This proof relies upon a more delicate and explicit analysis of the particular weight used to define quasi-categories of algebras.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2016-08-12 00:00:00.000000"},
{"id":"1325","title":"Prove remember nearly security growth left budget.","abstract":"The number of categorical observations that are unique in a sample and also unique, or rare, in the population is commonly used to measure the overall risk of disclosure in the sample data. Many authors have attempted to estimate risk by employing parametric models on cross classifications of the key variables, i.e. multi-way contingency tables of those categorical variables that permit the identification of individuals in the sample. In particular, parametric log-linear models or local smoothing polynomial models have been employed to capture the underlying probability structure of the contingency table. This paper proposes a nonparametric approach assuming a Poisson model with rates explained by a log-linear mixed model with Dirichlet process random effects. Risk estimates are obtained by carrying out a fully Bayesian treatment of the proposed model. The main finding is that parametric all two-way interactions log-linear models and semi-parametric log-linear models with main effects only produce roughly equivalent risk estimates. This fact is observed in applications to real data, and suggests that the latter can be adopted as \"default\" models, as they are able to produce reasonably good risk estimates and also to defuse potential shortcomings of traditional log-linear models.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2021-07-07 00:00:00.000000"},
{"id":"1326","title":"East could challenge meet station various trouble beautiful.","abstract":"A generalization of Young's inequality for convolution with sharp constant is conjectured for scenarios where more than two functions are being convolved, and it is proven for certain parameter ranges. The conjecture would provide a unified proof of recent entropy power inequalities of Barron and Madiman, as well as of a (conjectured) generalization of the Brunn-Minkowski inequality. It is shown that the generalized Brunn-Minkowski conjecture is true for convex sets; an application of this to the law of large numbers for random sets is described.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2015-01-24 00:00:00.000000"},
{"id":"1327","title":"Themselves too military himself Congress car west claim.","abstract":"We present designs of 2D isotropic, disordered photonic materials of arbitrary size with complete band gaps blocking all directions and polarizations. The designs with the largest gaps are obtained by a constrained optimization method that starts from a hyperuniform disordered point pattern, an array of points whose number variance within a spherical sampling window grows more slowly than the volume. We argue that hyperuniformity, combined with uniform local topology and short-range geometric order, can explain how complete photonic band gaps are possible without long-range translational order. We note the ramifications for electronic and phononic band gaps in disordered materials.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2021-03-19 00:00:00.000000"},
{"id":"1328","title":"Site thousand direction point nice center summer expect.","abstract":"In this theoretical and numerical paper, we derive the adjoint equations for a thermo-acoustic system consisting of an infinite-rate chemistry diffusion flame coupled with duct acoustics. We then calculate the thermo-acoustic system's linear global modes (i.e. the frequency\/growth rate of oscillations, together with their mode shapes), and the global modes' receptivity to species injection, sensitivity to base-state perturbations, and structural sensitivity to advective-velocity perturbations. We then compare these with the Rayleigh index. The receptivity analysis shows the regions of the flame where open-loop injection of fuel or oxidizer will have most influence on the thermo-acoustic oscillation. We find that the flame is most receptive at its tip. The base-state sensitivity analysis shows the influence of each parameter on the frequency\/growth rate. We find that perturbations to the stoichiometric mixture fraction, the fuel slot width, and the heat-release parameter have most influence, while perturbations to the P\\'eclet number have least influence. These sensitivities oscillate: e.g. positive perturbations to the fuel slot width either stabilizes or destabilizes the system, depending on the operating point. This analysis reveals that, as expected from a simple model, the phase delay between velocity and heat-release fluctuations is the key parameter in determining the sensitivities. It also reveals that this thermo-acoustic system is exceedingly sensitive to changes in the base state. The structural-sensitivity analysis shows the influence of perturbations to the advective flame velocity. The regions of highest sensitivity are around the stoichiometric line close to the inlet, showing where velocity models need to be most accurate.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2015-09-14 00:00:00.000000"},
{"id":"1329","title":"Benefit serve financial hand relationship court.","abstract":"In this work, dynamic Bayesian multinets are introduced where a Markov chain state at time t determines conditional independence patterns between random variables lying within a local time window surrounding t. It is shown how information-theoretic criterion functions can be used to induce sparse, discriminative, and class-conditional network structures that yield an optimal approximation to the class posterior probability, and therefore are useful for the classification task. Using a new structure learning heuristic, the resulting models are tested on a medium-vocabulary isolated-word speech recognition task. It is demonstrated that these discriminatively structured dynamic Bayesian multinets, when trained in a maximum likelihood setting using EM, can outperform both HMMs and other dynamic Bayesian networks with a similar number of parameters.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2022-12-15 00:00:00.000000"},
{"id":"1330","title":"Doctor bed thing position interest.","abstract":"Poincar\\'e's approach to the three body problem has often been celebrated as a starting point of chaos theory in relation to the investigation of dynamical systems. Yet, Poincar\\'e's strategy can also be analyzed as molded on - or casted in - some specific algebraic practices for manipulating systems of linear equations. These practices shed new light on both the novelty and the collective dimensions of Poincar\\'e's M\\'ethodes nouvelles. As the structure of a cast-iron building may be less noticeable than its creative fa\\c{c}ade, the algebraic cast of Poincar\\'e's strategy is broken out of the mold in generating the novel methods of celestial mechanics. But as the various components that are mixed in some casting process can still be detected in the resulting alloy, the algebraic cast of the M\\'ethodes nouvelles points to some collective dimensions of Poincar\\'e's methods. An edited version of the present preprint is to be published in the journal \\textit{L'astronomie} under the title \"L'approche de Poincar\\`E sur le probl\\\"Eme des trois corps\". This publication is an abstract in French language of a forthcoming paper - \"The algebraic cast of Poincar\\`E's \\textit{M\\`Ethodes nouvelles}\" - which will develop its main claims as well as the historiographical and mathematical issues raised in section 4 and section 5.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2018-01-25 00:00:00.000000"},
{"id":"1331","title":"Program environmental adult court prevent ahead before international.","abstract":"An interesting issue in fluid dynamics is represented by the possible existence of inverse kinetic theories (IKT) which are able to deliver, in a suitable sense, the complete set of fluid equations which are associated to a prescribed fluid. From the mathematical viewpoint this involves the formal description of a fluid by means of a classical dynamical system which advances in time the relevant fluid fields. The possibility of defining an IKT for the 3D incompressible Navier-Stokes equations (INSE), recently investigated (Ellero \\textit{et al}, 2004-2007) raises the interesting question whether the theory can be applied also to thermofluids, in such a way to satisfy also the second principle of thermodynamics. The goal of this paper is to prove that such a generalization is actually possible, by means of a suitable \\textit{extended phase-space formulation}. We consider, as a reference test, the case of non-isentropic incompressible thermofluids, whose dynamics is described by the Fourier and the incompressible Navier-Stokes equations, the latter subject to the conditions of validity of the Boussinesq approximation.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2018-12-31 00:00:00.000000"},
{"id":"1332","title":"As from movie us.","abstract":"In this paper we discuss extending the operating wavelength range of tunable Regenerative Amplifier FELs to shorter wavelengths than current design proposals, notably into the XUV regions of the spectrum and beyond where the reflectivity of broadband optics is very low. Simulation studies are presented which demonstrate the development of good temporal coherence in generic systems with a broadband radiation feedback of less than one part in ten thousand.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2019-03-06 00:00:00.000000"},
{"id":"1333","title":"Price want charge beautiful almost.","abstract":"A set of necessary and sufficient conditions for a sequence of moment generating functions to converge to a moment generating function on an interval (a,b) not necessarily containing 0, is given. The result is derived using recent results by Mukherjea, et al. (2006) and Chareka (2007).","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2016-09-09 00:00:00.000000"},
{"id":"1334","title":"Agreement view cell central century.","abstract":"Applications of wavelet transform to the field of health care signals have paved the way for implementing revolutionary approaches in detecting the presence of certain abnormalities in human health patterns. There were extensive studies carried out using primary wavelets in various signals like Electrocardiogram (ECG), sonogram etc. with a certain amount of success. On the other hand analysis using secondary wavelets which inherits the characteristics of a set of variations available in signals like ECG can be a promise to detect diseases with ease. Here a method to create a generalized adapted wavelet is presented which contains the information of QRS pattern collected from an anomaly sample space. The method has been tested and found to be successful in locating the position of R peak in noise embedded ECG signal.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2016-03-05 00:00:00.000000"},
{"id":"1335","title":"Early candidate note baby cost system successful.","abstract":"In this paper we examine a novel addition to the known methods for learning Bayesian networks from data that improves the quality of the learned networks. Our approach explicitly represents and learns the local structure in the conditional probability tables (CPTs), that quantify these networks. This increases the space of possible models, enabling the representation of CPTs with a variable number of parameters that depends on the learned local structures. The resulting learning procedure is capable of inducing models that better emulate the real complexity of the interactions present in the data. We describe the theoretical foundations and practical aspects of learning local structures, as well as an empirical evaluation of the proposed method. This evaluation indicates that learning curves characterizing the procedure that exploits the local structure converge faster than these of the standard procedure. Our results also show that networks learned with local structure tend to be more complex (in terms of arcs), yet require less parameters.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2020-09-06 00:00:00.000000"},
{"id":"1336","title":"Able writer leg attack page read light.","abstract":"We generalize W*-superrigidity results about Bernoulli actions of rigid groups to general mixing Gaussian actions. We thus obtain the following: If \\Gamma\\ is any ICC group which is w-rigid (i.e. it contains an infinite normal subgroup with the relative property (T)) then any mixing Gaussian action \\sigma\\ of \\Gamma\\ is W*-superrigid. More precisely, if \\rho\\ is another free ergodic action of a group \\Lambda\\ such that the crossed-product von Neumann algebras associated with \\rho\\ and \\sigma\\ are isomorphic, then \\Lambda\\ and \\Gamma\\ are isomorphic, and the actions \\rho\\ and \\sigma\\ are conjugate. We prove a similar statement whenever \\Gamma\\ is a non-amenable ICC product of two infinite groups.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2019-09-13 00:00:00.000000"},
{"id":"1337","title":"College individual run cell leave wish.","abstract":"This expository paper describes the various methods that have yielded partial results on the conjecture that if n > 2, then no lattice in SL(n,R) has a faithful action on the circle (by homeomorphisms). Topics include amenability, Kazhdan's property (T), bounded cohomology, bounded generation, and the Reeb-Thurston Stability Theorem.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2019-04-16 00:00:00.000000"},
{"id":"1338","title":"Option standard at third yourself effort.","abstract":"This paper presents a rewriting-logic-based modeling and analysis technique for physical systems, with focus on thermal systems. The contributions of this paper can be summarized as follows: (i) providing a framework for modeling and executing physical systems, where both the physical components and their physical interactions are treated as first-class citizens; (ii) showing how heat transfer problems in thermal systems can be modeled in Real-Time Maude; (iii) giving the implementation in Real-Time Maude of a basic numerical technique for executing continuous behaviors in object-oriented hybrid systems; and (iv) illustrating these techniques with a set of incremental case studies using realistic physical parameters, with examples of simulation and model checking analyses.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2021-06-09 00:00:00.000000"},
{"id":"1339","title":"Report style yourself last process.","abstract":"Extremely asymmetrical scattering (EAS) is a highly resonant type of Bragg scattering with a strong resonant increase of the scattered wave amplitude inside and outside the grating. EAS is realized when the scattered wave propagates parallel to the grating boundaries. We present a rigorous algorithm for the analysis of non-steady-state EAS, and investigate the relaxation of the incident and scattered wave amplitudes to their steady-state values. Non-steady-state EAS of bulk TE electromagnetic waves is analyzed in narrow and wide, slanted, holographic gratings. Typical relaxation times are determined and compared with previous rough estimations. Physical explanation of the predicted effects is presented.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2022-05-27 00:00:00.000000"},
{"id":"1340","title":"Water energy image painting prevent.","abstract":"We determine the computational complexity of approximately counting the total weight of variable assignments for every complex-weighted Boolean constraint satisfaction problem (or CSP) with any number of additional unary (i.e., arity 1) constraints, particularly, when degrees of input instances are bounded from above by a fixed constant. All degree-1 counting CSPs are obviously solvable in polynomial time. When the instance's degree is more than two, we present a dichotomy theorem that classifies all counting CSPs admitting free unary constraints into exactly two categories. This classification theorem extends, to complex-weighted problems, an earlier result on the approximation complexity of unweighted counting Boolean CSPs of bounded degree. The framework of the proof of our theorem is based on a theory of signature developed from Valiant's holographic algorithms that can efficiently solve seemingly intractable counting CSPs. Despite the use of arbitrary complex weight, our proof of the classification theorem is rather elementary and intuitive due to an extensive use of a novel notion of limited T-constructibility. For the remaining degree-2 problems, in contrast, they are as hard to approximate as Holant problems, which are a generalization of counting CSPs.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2019-10-26 00:00:00.000000"},
{"id":"1341","title":"Get manager newspaper structure.","abstract":"In this paper we explore the applicability of the unsupervised machine learning technique of Self Organizing Maps (SOM) to estimate galaxy photometric redshift probability density functions (PDFs). This technique takes a spectroscopic training set, and maps the photometric attributes, but not the redshifts, to a two dimensional surface by using a process of competitive learning where neurons compete to more closely resemble the training data multidimensional space. The key feature of a SOM is that it retains the topology of the input set, revealing correlations between the attributes that are not easily identified. We test three different 2D topological mapping: rectangular, hexagonal, and spherical, by using data from the DEEP2 survey. We also explore different implementations and boundary conditions on the map and also introduce the idea of a random atlas where a large number of different maps are created and their individual predictions are aggregated to produce a more robust photometric redshift PDF. We also introduced a new metric, the $I$-score, which efficiently incorporates different metrics, making it easier to compare different results (from different parameters or different photometric redshift codes). We find that by using a spherical topology mapping we obtain a better representation of the underlying multidimensional topology, which provides more accurate results that are comparable to other, state-of-the-art machine learning algorithms. Our results illustrate that unsupervised approaches have great potential for many astronomical problems, and in particular for the computation of photometric redshifts.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2020-05-15 00:00:00.000000"},
{"id":"1342","title":"Artist stay Democrat tough.","abstract":"The limit behavior of inductive logic programs has not been explored, but when considering incremental or online inductive learning algorithms which usually run ongoingly, such behavior of the programs should be taken into account. An example is given to show that some inductive learning algorithm may not be correct in the long run if the limit behavior is not considered. An inductive logic program is convergent if given an increasing sequence of example sets, the program produces a corresponding sequence of the Horn logic programs which has the set-theoretic limit, and is limit-correct if the limit of the produced sequence of the Horn logic programs is correct with respect to the limit of the sequence of the example sets. It is shown that the GOLEM system is not limit-correct. Finally, a limit-correct inductive logic system, called the prioritized GOLEM system, is proposed as a solution.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2020-08-05 00:00:00.000000"},
{"id":"1343","title":"Whatever success act almost.","abstract":"Concurrent data structures are the data sharing side of parallel programming. Data structures give the means to the program to store data, but also provide operations to the program to access and manipulate these data. These operations are implemented through algorithms that have to be efficient. In the sequential setting, data structures are crucially important for the performance of the respective computation. In the parallel programming setting, their importance becomes more crucial because of the increased use of data and resource sharing for utilizing parallelism.   The first and main goal of this chapter is to provide a sufficient background and intuition to help the interested reader to navigate in the complex research area of lock-free data structures. The second goal is to offer the programmer familiarity to the subject that will allow her to use truly concurrent methods.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2021-01-23 00:00:00.000000"},
{"id":"1344","title":"Stand history measure positive citizen military.","abstract":"A large class of machine-learning problems in natural language require the characterization of linguistic context. Two characteristic properties of such problems are that their feature space is of very high dimensionality, and their target concepts refer to only a small subset of the features in the space. Under such conditions, multiplicative weight-update algorithms such as Winnow have been shown to have exceptionally good theoretical properties. We present an algorithm combining variants of Winnow and weighted-majority voting, and apply it to a problem in the aforementioned class: context-sensitive spelling correction. This is the task of fixing spelling errors that happen to result in valid words, such as substituting \"to\" for \"too\", \"casual\" for \"causal\", etc. We evaluate our algorithm, WinSpell, by comparing it against BaySpell, a statistics-based method representing the state of the art for this task. We find: (1) When run with a full (unpruned) set of features, WinSpell achieves accuracies significantly higher than BaySpell was able to achieve in either the pruned or unpruned condition; (2) When compared with other systems in the literature, WinSpell exhibits the highest performance; (3) The primary reason that WinSpell outperforms BaySpell is that WinSpell learns a better linear separator; (4) When run on a test set drawn from a different corpus than the training set was drawn from, WinSpell is better able than BaySpell to adapt, using a strategy we will present that combines supervised learning on the training set with unsupervised learning on the (noisy) test set.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2021-09-21 00:00:00.000000"},
{"id":"1345","title":"Difference my early information safe.","abstract":"Given an implicit $n\\times n$ matrix $A$ with oracle access $x^TA x$ for any $x\\in \\mathbb{R}^n$, we study the query complexity of randomized algorithms for estimating the trace of the matrix. This problem has many applications in quantum physics, machine learning, and pattern matching. Two metrics are commonly used for evaluating the estimators: i) variance; ii) a high probability multiplicative-approximation guarantee. Almost all the known estimators are of the form $\\frac{1}{k}\\sum_{i=1}^k x_i^T A x_i$ for $x_i\\in \\mathbb{R}^n$ being i.i.d. for some special distribution.   Our main results are summarized as follows. We give an exact characterization of the minimum variance unbiased estimator in the broad class of linear nonadaptive estimators (which subsumes all the existing known estimators). We also consider the query complexity lower bounds for any (possibly nonlinear and adaptive) estimators: (1) We show that any estimator requires $\\Omega(1\/\\epsilon)$ queries to have a guarantee of variance at most $\\epsilon$. (2) We show that any estimator requires $\\Omega(\\frac{1}{\\epsilon^2}\\log \\frac{1}{\\delta})$ queries to achieve a $(1\\pm\\epsilon)$-multiplicative approximation guarantee with probability at least $1 - \\delta$. Both above lower bounds are asymptotically tight.   As a corollary, we also resolve a conjecture in the seminal work of Avron and Toledo (Journal of the ACM 2011) regarding the sample complexity of the Gaussian Estimator.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2017-01-12 00:00:00.000000"},
{"id":"1346","title":"Door prepare he threat federal probably media.","abstract":"Multivariate time series (MTS) data such as time course gene expression data in genomics are often collected to study the dynamic nature of the systems. These data provide important information about the causal dependency among a set of random variables. In this paper, we introduce a computationally efficient algorithm to learn directed acyclic graphs (DAGs) based on MTS data, focusing on learning the local structure of a given target variable. Our algorithm is based on learning all parents (P), all children (C) and some descendants (D) (PCD) iteratively, utilizing the time order of the variables to orient the edges. This time series PCD-PCD algorithm (tsPCD-PCD) extends the previous PCD-PCD algorithm to dependent observations and utilizes composite likelihood ratio tests (CLRTs) for testing the conditional independence. We present the asymptotic distribution of the CLRT statistic and show that the tsPCD-PCD is guaranteed to recover the true DAG structure when the faithfulness condition holds and the tests correctly reject the null hypotheses. Simulation studies show that the CLRTs are valid and perform well even when the sample sizes are small. In addition, the tsPCD-PCD algorithm outperforms the PCD-PCD algorithm in recovering the local graph structures. We illustrate the algorithm by analyzing a time course gene expression data related to mouse T-cell activation.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2022-08-02 00:00:00.000000"},
{"id":"1347","title":"Better wall reveal pressure central.","abstract":"This paper investigates a method of Handwritten English Character Recognition using Artificial Neural Network (ANN). This work has been done in offline Environment for non correlated characters, which do not possess any linear relationships among them. We test that whether the particular tested character belongs to a cluster or not. The implementation is carried out in Matlab environment and successfully tested. Fifty-two sets of English alphabets are used to train the ANN and test the network. The algorithms are tested with 26 capital letters and 26 small letters. The testing result showed that the proposed ANN based algorithm showed a maximum recognition rate of 85%.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2019-08-16 00:00:00.000000"},
{"id":"1348","title":"Field hour agreement remain.","abstract":"Great strides have been made in the field of reconstructing past temperatures based on models relating temperature to temperature-sensitive paleoclimate proxies. One of the goals of such reconstructions is to assess if current climate is anomalous in a millennial context. These regression based approaches model the conditional mean of the temperature distribution as a function of paleoclimate proxies (or vice versa). Some of the recent focus in the area has considered methods which help reduce the uncertainty inherent in such statistical paleoclimate reconstructions, with the ultimate goal of improving the confidence that can be attached to such endeavors. A second important scientific focus in the subject area is the area of forward models for proxies, the goal of which is to understand the way paleoclimate proxies are driven by temperature and other environmental variables. In this paper we introduce novel statistical methodology for (1) quantile regression with autoregressive residual structure, (2) estimation of corresponding model parameters, (3) development of a rigorous framework for specifying uncertainty estimates of quantities of interest, yielding (4) statistical byproducts that address the two scientific foci discussed above. Our statistical methodology demonstrably produces a more robust reconstruction than is possible by using conditional-mean-fitting methods. Our reconstruction shares some of the common features of past reconstructions, but also gains useful insights. More importantly, we are able to demonstrate a significantly smaller uncertainty than that from previous regression methods. In addition, the quantile regression component allows us to model, in a more complete and flexible way than least squares, the conditional distribution of temperature given proxies. This relationship can be used to inform forward models relating how proxies are driven by temperature.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2018-09-08 00:00:00.000000"},
{"id":"1349","title":"Mrs chair house beyond.","abstract":"This essay intends to present a novel approach to the concept of \"transaction\" in quantum physics. Breaking with Cramer's original theory, the transaction is not connected to the simultaneously retarded and advanced spacetime propagation of classical fields, as in the spirit of Wheeler-Feynman electrodynamics. Instead, the transaction is seen as an archetypal structure intrinsic within the quantum formalism. The present approach is advantageous in that, while preserving the essential point of Cramer's theory, is also fully consistent with the standard quantum formalism. In particular, it has the advantage of avoiding the introduction of elements which are completely extraneous to quantum formalism (such as the propagation of real physical waves in four-dimensional spacetime, the phase difference between offer and confirmation waves which is necessary for the elimination of \"tails\", the echoing mechanism, etc.)","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2021-07-27 00:00:00.000000"},
{"id":"1350","title":"Those part summer you hand success.","abstract":"In this paper, I propose a technique for recovering quantum dynamical information from imaginary-time data via the resolution of a one-dimensional Hamburger moment problem. It is shown that the quantum autocorrelation functions are uniquely determined by and can be reconstructed from their sequence of derivatives at origin. A general class of reconstruction algorithms is then identified, according to Theorem 3. The technique is advocated as especially effective for a certain class of quantum problems in continuum space, for which only a few moments are necessary. For such problems, it is argued that the derivatives at origin can be evaluated by Monte Carlo simulations via estimators of finite variances in the limit of an infinite number of path variables. Finally, a maximum entropy inversion algorithm for the Hamburger moment problem is utilized to compute the quantum rate of reaction for a one-dimensional symmetric Eckart barrier.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2018-11-30 00:00:00.000000"},
{"id":"1351","title":"Low actually value prepare have nature write.","abstract":"Let $(X,\\omega)$ be a compact K\\\"ahler manifold. We obtain uniform H\\\"older regularity for solutions to the complex Monge-Amp\\`ere equation on $X$ with $L^p$ right hand side, $p>1$. The same regularity is furthermore proved on the ample locus in any big cohomology class. We also study the range $\\MAH(X,\\omega)$ of the complex Monge-Amp\\`ere operator acting on $\\omega$-plurisubharmonic H\\\"older continuous functions. We show that this set is convex, by sharpening Ko{\\l}odziej's result that measures with $L^p$-density belong to $\\MAH(X,\\omega)$ and proving that $\\MAH(X,\\omega)$ has the \"$L^p$-property\", $p>1$. We also describe accurately the symmetric measures it contains.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2016-08-29 00:00:00.000000"},
{"id":"1352","title":"Least family know.","abstract":"We show that various types of equilibrium play an important part in the behaviour of the troposphere. In analogy to the electro-chemical potential (well-known in solid-state physics and electro-chemistry) a gravito-chemical potential and a gravito-thermo-chemical potential, as well as the corresponding equilibria are introduced. We shall show that (a) the isothermal atmosphere is characterized by a constant gravito-chemical potential; (b) the well-mixed or adiabatic atmosphere is characterized by a constant gravito-thermo-chemical potential. Thus, a linear decrease of the temperature with the vertical coordinate corresponds to a state of equilibrium.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2018-07-25 00:00:00.000000"},
{"id":"1353","title":"Defense for sit partner off few us for.","abstract":"Numerical simulations of beam-beam effects in the electron-positron Phi-factory DAPhNE taking into account the measured cubic nonlinearities have shown that the nonlinearities have a strong impact on the collider luminosity performance. The numerical results explain many of experimental observations made during collisions in both single and multibunch regimes.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2015-11-12 00:00:00.000000"},
{"id":"1354","title":"It smile seven.","abstract":"Let D be a piecewise smooth bounded convex Reinhardt domain in C^2. Assume that the symbols f and g are continuous on the closure of D and harmonic on the disks in the boundary of D. We show that if the product of Hankel operators H^*_f H_g is compact on the Bergman space of D, then on any disk in the boundary of D, either f or g is holomorphic.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2017-04-26 00:00:00.000000"},
{"id":"1355","title":"Yard national could his.","abstract":"Modern students encounter big, messy data sets long before setting foot in our classrooms. Many of our students need to develop skills in exploratory data analysis and multivariate analysis techniques for their jobs after college, but these topics are not covered in introductory statistics courses. This case study describes my experience in designing and teaching a course on multivariate data analysis with no pre-requisites, using real data, active learning, and other activities to help students tackle the material.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2020-12-04 00:00:00.000000"},
{"id":"1356","title":"Information Mr three opportunity concern world month.","abstract":"This is the third one of three papers I have presented as an application of the Basic Unit System concept, a complex mathematical unit presented in The Basic Unit System concept and The Principle of Synergy. In this case this Bus concept is used as a powerful tool to obtain again those gravitational field equations of normal planets, deviation from them as that of Mercury, but also a proposal made by the astronomer Micheal Disney in his book the Hidden Universe about Dark Matter. The emerging proposal is then to see the cosmic system as a Steady Open System, state that is continually exchanging energy, matter and information, and in it Dark gravity bodies can be seen as gravity compensators of the whole system. But then appear new forces when the whole system is considered.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2015-12-21 00:00:00.000000"},
{"id":"1357","title":"People concern decision child.","abstract":"We prove that a resolution of singularities of any finite covering of the projective plane branched along a Hurwitz curve $\\bar H$ and, maybe, along a line \"at infinity\" can be embedded as a symplectic submanifold into some projective algebraic manifold equipped with an integer K\\\"{a}hler symplectic form (assuming that if $\\bar H$ has negative nodes, then the covering is non-singular over them). For cyclic coverings we can realize this embeddings into a rational algebraic 3--fold. Properties of the Alexander polynomial of $\\bar{H}$ are investigated and applied to the calculation of the first Betti number $b_1(\\bar X_n)$ of a resolution $\\bar X_n$ of singularities of $n$-sheeted cyclic coverings of $\\mathbb C\\mathbb P^2$ branched along $\\bar H$ and, maybe, along a line \"at infinity\". We prove that $b_1(\\bar X_n)$ is even if $\\bar H$ is an irreducible Hurwitz curve but, in contrast to the algebraic case, that it can take any non-negative value in the case when $\\bar H$ consists of several irreducible components.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2017-06-15 00:00:00.000000"},
{"id":"1358","title":"Table skill Congress over box across.","abstract":"Inference based on the penalized density ratio model is proposed and studied. The model under consideration is specified by assuming that the log--likelihood function of two unknown densities is of some parametric form. The model has been extended to cover multiple samples problems while its theoretical properties have been investigated using large sample theory. A main application of the density ratio model is testing whether two, or more, distributions are equal. We extend these results by arguing that the penalized maximum empirical likelihood estimator has less mean square error than that of the ordinary maximum likelihood estimator, especially for small samples. In fact, penalization resolves any existence problems of estimators and a modified Wald type test statistic can be employed for testing equality of the two distributions. A limited simulation study supports further the theory.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2021-11-26 00:00:00.000000"},
{"id":"1359","title":"Use customer themselves nation.","abstract":"We analyze international co-authorship relations in the Social Science Citation Index 2011 using all citable items in the DVD-version of this index. Network statistics indicate four groups of nations: (i) an Asian-Pacific one to which all Anglo-Saxon nations (including the UK and Ireland) are attributed; (ii) a continental European one including also the Latin-American countries; (iii) the Scandinavian nations; and (iv) a community of African nations. Within the EU-28 (including Croatia), eleven of the EU-15 states have dominant positions. Collapsing the EU-28 into a single node leads to a bi-polar structure between the US and EU-28; China is part of the US-pole. We develop an information-theoretical test to distinguish whether international collaborations or domestic collaborations prevail; the results are mixed, but the international dimension is more important than the national one in the aggregated sets (this was found in both SSCI and SCI). In France, however, the national distribution is more important than the international one, while the reverse is true for most European nations in the core group (UK, Germany, the Netherlands, etc.). Decomposition of the USA in terms of states shows a similarly mixed result; more US states are domestically oriented in SSCI, whereas more internationally in SCI. The international networks have grown during the last decades in addition to the national ones, but not by replacing them.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2015-09-18 00:00:00.000000"},
{"id":"1360","title":"Hospital feel effect small.","abstract":"Using the relation proposed by Weinberg in 1972, combining quantum and cosmological parameters, we prove that the self gravitational potential energy of any fundamental particle is a quantum, with physical properties independent of the mass of the particle. It is a universal quantum of gravitational energy, and its physical properties depend only on the cosmological scale factor R and the physical constants \\hbar and c. We propose a modification of the Weinberg's relation, keeping the same numerical value, but substituting the cosmological parameter H\/c by 1\/R.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2016-11-13 00:00:00.000000"},
{"id":"1361","title":"Pressure policy room news economy major.","abstract":"A solution to Einstein's field equations via the Friedman equations is shown to produce a cosmological model that is in exact agreement with the measurements made by the dark energy astronomers. All the essential physical parameters are obtained as epoch dependent functions all in closed form. The equations of state are obtained for total density, non-dark energy density and dark energy density. An interpretation of the structure involving a dark energy mass distribution that is twice the usual value is shown to clarify greatly the physical significance of the mathematics. It is asserted that the astronomer's measurements together with the mathematical model proves that the universe is permeated uniformly with a positive mass density that caries a negative gravitational constant, -G, characteristic. This mass component is identified with the dark energy content of the universe that has been postulated to explain the observed acceleration. Another result implied by the model is that there is twice the amount of dark energy that is usually considered to be present. This last point is analysed in more detail in appendix 1 using Einstein's field equations. Five additional appendices, 2, 3, 4, 5 and 6 in which isothermal gravitational dark matter equilibrium and the galactic rotations curve flatness problem are examined in detail. Appendix 5 is concerned with mass clumping and expressing gravitational isothermal equilibrium constraints using a cosmological Schr\\\"odinger equation to demonstrate the existence of a new quantum force involved with galactic stability. Appendix 6 is concerned with gravitational quantization. Each appendix has its own abstract.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2021-04-17 00:00:00.000000"},
{"id":"1362","title":"Watch perhaps war research.","abstract":"As a step toward analyzing second-harmonic generation (SHG) from crystalline Si nanospheres in glass, we develop an anisotropic bond model (ABM) that expresses SHG in terms of physically meaningful parameters and provides a detailed understanding of the basic physics of SHG on the atomic scale. Nonlinear-optical (NLO) responses are calculated classically via the four fundamental steps of optics: evaluate the local field at a given bond site, solve the force equation for the acceleration of the charge, calculate the resulting radiation, then superpose the radiation from all charges. The ABM goes beyond previous bond models by including the complete set of underlying contributions: retardation (RD), spatial-dispersion (SD), and magnetic (MG) effects, in addition to the anharmonic restoring force acting on the bond charge. We apply the ABM to obtain analytic expressions for SHG from amorphous materials under Gaussian-beam excitation. These materials represent an interesting test case not only because they are ubiquitous but also because the anharmonic-force contribution that dominates the SHG response of crystalline materials and ordered interfaces vanishes by symmetry. Using the paraxial-ray approximation, we reduce the results to the isotropic case in two limits, that where the linear restoring force dominates (glasses), and that where it is absent (metals). Both forward- and backscattering geometries are discussed. Estimated signal strengths and conversion efficiencies for fused silica appear to be in general agreement with data, where available. Predictions are made that allow additional critical tests of these results.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2022-06-21 00:00:00.000000"},
{"id":"1363","title":"Change five section listen subject others.","abstract":"Let $\\lambda>0$, $p\\in((2\\lz+1)\/(2\\lz+2), 1]$, and $\\triangle_\\lambda\\equiv-\\frac{d^2}{dx^2}-\\frac{2\\lambda}{x} \\frac d{dx}$ be the Bessel operator. In this paper, the authors establish the characterizations of atomic Hardy spaces $H^p((0, \\infty), dm_\\lambda)$ associated with $\\triangle_\\lambda$ in terms of the radial maximal function, the nontangential maximal function, the grand maximal function, the Littlewood-Paley $g$-function and the Lusin-area function, where $dm_\\lambda(x)\\equiv x^{2\\lambda}\\,dx$. As an application, the authors further obtain the Riesz transform characterization of these Hardy spaces.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2015-10-08 00:00:00.000000"},
{"id":"1364","title":"Reveal voice dream heavy only.","abstract":"We report the results of observations of H- beam instabilities at the Fermilab Linac. By intentionally creating \"high\" background pressure with different gases in the 750 keV transport line we observed coherent transverse beam oscillations. The minimal pulse length required to observe oscillations and the frequency of oscillations are functions of pressure and mass of the background gas. The oscillations are present in both transverse planes and very quickly reach saturation in amplitude growth. The observed characteristics of beam oscillations are in quantitative agreement with \"fast beam-ion instability\" described by Raubenheimer and Zimmermann. Effects described here are occur far from the normal operating range of the Fermilab Linac but may be important for many future high intensity accelerators.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2018-05-21 00:00:00.000000"},
{"id":"1365","title":"Reality foreign prepare from key nature.","abstract":"Let f be a computable function from finite sequences of 0's and 1's to real numbers. We prove that strong f-randomness implies strong f-randomness relative to a PA-degree. We also prove: if X is strongly f-random and Turing reducible to Y where Y is Martin-L\"of random relative to Z, then X is strongly f-random relative to Z. In addition, we prove analogous propagation results for other notions of partial randomness, including non-K-triviality and autocomplexity. We prove that f-randomness relative to a PA-degree implies strong f-randomness, hence f-randomness does not imply f-randomness relative to a PA-degree.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2015-02-03 00:00:00.000000"},
{"id":"1366","title":"Become still teach various man go expect popular.","abstract":"We propose a new architecture for difficult image processing operations, such as natural edge detection or thin object segmentation. The architecture is based on a simple combination of convolutional neural networks with the nearest neighbor search.   We focus our attention on the situations when the desired image transformation is too hard for a neural network to learn explicitly. We show that in such situations, the use of the nearest neighbor search on top of the network output allows to improve the results considerably and to account for the underfitting effect during the neural network training. The approach is validated on three challenging benchmarks, where the performance of the proposed architecture matches or exceeds the state-of-the-art.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2019-04-17 00:00:00.000000"},
{"id":"1367","title":"Benefit American people manage such morning.","abstract":"An integrated program is described, starting with muon experiments in the Booster era, continuing with a 2 MW target station, a 4 GeV Neutrino Factory and a 3 TeV Muon Collider, all driven by Project X. This idea provides an integrated approach to the Intensity and Energy Frontiers at Fermilab.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2018-03-16 00:00:00.000000"},
{"id":"1368","title":"Tend accept sea chance author however.","abstract":"There is a large discrepancy in our understanding of uncapacitated and capacitated versions of network location problems. This is perhaps best illustrated by the classical k-center problem: there is a simple tight 2-approximation algorithm for the uncapacitated version whereas the first constant factor approximation algorithm for the general version with capacities was only recently obtained by using an intricate rounding algorithm that achieves an approximation guarantee in the hundreds.   Our paper aims to bridge this discrepancy. For the capacitated k-center problem, we give a simple algorithm with a clean analysis that allows us to prove an approximation guarantee of 9. It uses the standard LP relaxation and comes close to settling the integrality gap (after necessary preprocessing), which is narrowed down to either 7, 8 or 9. The algorithm proceeds by first reducing to special tree instances, and then solves such instances optimally. Our concept of tree instances is quite versatile, and applies to natural variants of the capacitated k-center problem for which we also obtain improved algorithms. Finally, we give evidence to show that more powerful preprocessing could lead to better algorithms, by giving an approximation algorithm that beats the integrality gap for instances where all non-zero capacities are uniform.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2019-04-07 00:00:00.000000"},
{"id":"1369","title":"Industry put couple coach once.","abstract":"This paper exploits a simplified version of the mixture of multivariate t-factor analyzers (MtFA) for robust mixture modelling and clustering of high-dimensional data that frequently contain a number of outliers. Two classes of eight parsimonious t mixture models are introduced and computation of maximum likelihood estimates of parameters is achieved using the alternating expectation conditional maximization (AECM) algorithm. The usefulness of the methodology is illustrated through applications of image compression and compact facial representation.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2020-08-29 00:00:00.000000"},
{"id":"1370","title":"Chair miss future budget court.","abstract":"We build an agent-based model of incarceration based on the SIS model of infectious disease propagation. Our central hypothesis is that the observed racial disparities in incarceration rates between Black and White Americans can be explained as the result of differential sentencing between the two demographic groups. We demonstrate that if incarceration can be spread through a social influence network, then even relatively small differences in sentencing can result in the large disparities in incarceration rates. Controlling for effects of transmissibility, susceptibility, and influence network structure, our model reproduces the observed large disparities in incarceration rates given the differences in sentence lengths for White and Black drug offenders in the United States without extensive parameter tuning. We further establish the suitability of the SIS model as applied to incarceration, as the observed structural patterns of recidivism are an emergent property of the model. In fact, our model shows a remarkably close correspondence with California incarceration data, without requiring any parameter tuning. This work advances efforts to combine the theories and methods of epidemiology and criminology.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2018-02-21 00:00:00.000000"},
{"id":"1371","title":"Break across window hold speech maintain.","abstract":"An efficient speech to text converter for mobile application is presented in this work. The prime motive is to formulate a system which would give optimum performance in terms of complexity, accuracy, delay and memory requirements for mobile environment. The speech to text converter consists of two stages namely front-end analysis and pattern recognition. The front end analysis involves preprocessing and feature extraction. The traditional voice activity detection algorithms which track only energy cannot successfully identify potential speech from input because the unwanted part of the speech also has some energy and appears to be speech. In the proposed system, VAD that calculates energy of high frequency part separately as zero crossing rate to differentiate noise from speech is used. Mel Frequency Cepstral Coefficient (MFCC) is used as feature extraction method and Generalized Regression Neural Network is used as recognizer. MFCC provides low word error rate and better feature extraction. Neural Network improves the accuracy. Thus a small database containing all possible syllable pronunciation of the user is sufficient to give recognition accuracy closer to 100%. Thus the proposed technique entertains realization of real time speaker independent applications like mobile phones, PDAs etc.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2016-10-31 00:00:00.000000"},
{"id":"1372","title":"Grow never despite rock operation if wait.","abstract":"It has been claimed by others that observed temporal correlations of terrestrial cloud cover with `the cosmic ray intensity' are causal. The possibility arises, therefore, of a connection between cosmic rays and Global Warming. If true, the implications would be very great. We have examined this claim to look for evidence to corroborate it. So far we have not found any and so our tentative conclusions are to doubt it. Such correlations as appear are more likely to be due to the small variations in solar irradiance, which, of course, correlate with cosmic rays. We estimate that less than 15% of the 11-year cycle warming variations are due to cosmic rays and less than 2% of the warming over the last 35 years is due to this cause.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2017-06-09 00:00:00.000000"},
{"id":"1373","title":"Health left however buy movement.","abstract":"A famous theorem of D. Orlov describes the derived bounded category of coherent sheaves on projective hypersurfaces in terms of an algebraic construction called graded matrix factorizations. In this article, I implement a proposal of E. Segal to prove Orlov's theorem in the Calabi-Yau setting using a globalization of the category of graded matrix factorizations (graded D-branes). Let X be a projective hypersurface. Already, Segal has established an equivalence between Orlov's category of graded matrix factorizations and the category of graded D-branes on the canonical bundle K of the ambient projective space. To complete the picture, I give an equivalence between the homotopy category of graded D-branes on K and Dcoh(X). This can be achieved directly and by deforming K to the normal bundle of X, embedded in K and invoking a global version of Kn\\\"{o}rrer periodicity. We also discuss an equivalence between graded D-branes on a general smooth quasi-projective variety and on the formal neighborhood of the singular locus of the zero fiber of the potential.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2021-02-19 00:00:00.000000"},
{"id":"1374","title":"Floor environment without avoid shake country fill experience.","abstract":"We investigate the behavior of the Generalized Likelihood Ratio Test (GLRT) (Fan, Zhang and Zhang [Ann. Statist. 29 (2001) 153-193]) for time varying coefficient models where the regressors and errors are non-stationary time series and can be cross correlated. It is found that the GLRT retains the minimax rate of local alternative detection under weak dependence and non-stationarity. However, in general, the Wilks phenomenon as well as the classic residual bootstrap are sensitive to either conditional heteroscedasticity of the errors, non-stationarity or temporal dependence. An averaged test is suggested to alleviate the sensitivity of the test to the choice of bandwidth and is shown to be more powerful than tests based on a single bandwidth. An alternative wild bootstrap method is proposed and shown to be consistent when making inference of time varying coefficient models for non-stationary time series.","psed_classification_id":"58","for_commercialization":"0","date_uploaded":"2022-06-30 00:00:00.000000"},
{"id":"1375","title":"Hour receive better first least effort cold middle.","abstract":"We present results of a study of four-wave mixing in Rb vapour with highly nonlinear susceptibility, using both homodyne and heterodyne detection. We demonstrate that the spectra have different appearances for media possessing electromagnetically induced transparency and electromagnetically induced absorption, and for different relative polarizations of the drive and probe fields. We show that these differences allow the contributions of different processes responsible for the enhanced Kerr nonlinearity of the media to be distinguished.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2019-07-20 00:00:00.000000"},
{"id":"1376","title":"Sound religious dream society year evening hotel.","abstract":"The iterative scaling procedure (ISP) is an algorithm which computes a sequence of matrices, starting from some given matrix. The objective is to find a matrix 'proportional' to the given matrix, having given row and column sums. In many cases, for example if the initial matrix is strictly positive, the sequence is convergent. In the general case, it is known that the sequence has at most two limit points. When these are distinct, convergence can be slow. We give an efficient algorithm which finds these limit points, invoking the ISP only on instances for which the procedure is convergent.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2016-02-02 00:00:00.000000"},
{"id":"1377","title":"Admit class hand already quality decide issue.","abstract":"Ventilation aims at providing a sufficient air renewal for ensuring a good indoor air quality (IAQ), yet building energy policies are leading to adapting various ventilation strategies minimising energy losses through air renewal. A recent IAQ evaluation campaign in French dwellings shows important pollution of living spaces by VOCs such as formaldehyde, acetaldehyde or hexanal, particularly in buildings equipped with a garage. Besides, radon emission from soil is a subject of concern in many countries. Several studies are done to understand its release mode and deal with the spread of this carcinogen gas. This paper aims to experimentally assess a contaminant spread from a house basement using mechanical exhaust and balanced ventilation systems, and natural ventilation.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2021-06-23 00:00:00.000000"},
{"id":"1378","title":"At up media last campaign protect.","abstract":"Given a graph of interactions, a module (also called a community or cluster) is a subset of nodes whose fitness is a function of the statistical significance of the pairwise interactions of nodes in the module. The topic of this paper is a model-based community finding approach, commonly referred to as modularity clustering, that was originally proposed by Newman and has subsequently been extremely popular in practice. Various heuristic methods are currently employed for finding the optimal solution. However, the exact computational complexity of this approach is still largely unknown.   To this end, we initiate a systematic study of the computational complexity of modularity clustering. Due to the specific quadratic nature of the modularity function, it is necessary to study its value on sparse graphs and dense graphs separately. Our main results include a (1+\\eps)-inapproximability for dense graphs and a logarithmic approximation for sparse graphs. We make use of several combinatorial properties of modularity to get these results. These are the first non-trivial approximability results beyond the previously known NP-hardness results.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2018-10-02 00:00:00.000000"},
{"id":"1379","title":"Light successful keep think.","abstract":"Direct coupling of the fast magnetosonic wave to the electrons has been studied on the tokamak TORE SUPRA. Preliminary experiments were dedicated to optimise the scenario for Fast Wave Electron Heating (FWEH) and Current Drive (FWCD). In a first part, thermal kinetic and diamagnetic energy are compared when fast wave is applied to the plasma in two different regimes: 1\/ the minority hydrogen heating scenario (ICRH), 2\/ the direct electron damping. Effects of ion resonant layers, marginally present in the plasma in the later regime (FWEH), is then presented and discussed.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2019-10-07 00:00:00.000000"},
{"id":"1380","title":"Campaign forward action fund religious bad.","abstract":"In today's Web, Web Services are created and updated on the fly. For answering complex needs of users, the construction of new web services based on existing ones is required. It has received a great attention from different communities. This problem is known as web services composition. However, it is one of big challenge problems of recent years in a distributed and dynamic environment. Web services can be composed manually but it is a time consuming task. The automatic web service composition is one of the key features for future the semantic web. The various approaches in field of web service compositions proposed by the researchers. In this paper, we propose a novel architecture for semantic web service composition using clustering and Ant colony algorithm.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2019-11-21 00:00:00.000000"},
{"id":"1381","title":"They thought appear eight sea project source.","abstract":"In this paper we develop homology and cohomology theories which play the same role for real projective varieties that Lawson homology and morphic cohomology play for projective varieties respectively. They have nice properties such as the existence of long exact sequences, the homotopy invariance, the Lawson suspension property, the homotopy property for bundle projection, the splitting principle, the cup product, the slant product and the natural transformations to singular theories. The Friedlander-Lawson moving lemma is used to prove a duality theorem between these two theories. This duality theorem is compatible with the $\\Z_2$-Poincar\\'e duality for real projective varieties with connected full real points.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2021-07-28 00:00:00.000000"},
{"id":"1382","title":"Use away rest hear tend Republican trade.","abstract":"The classical algorithm for solving B\\\"uchi games requires time $O(n\\cdot m)$ for game graphs with $n$ states and $m$ edges. For game graphs with constant outdegree, the best known algorithm has running time $O(n^2\/\\log n)$. We present two new algorithms for B\\\"uchi games. First, we give an algorithm that performs at most $O(m)$ more work than the classical algorithm, but runs in time O(n) on infinitely many graphs of constant outdegree on which the classical algorithm requires time $O(n^2)$. Second, we give an algorithm with running time $O(n\\cdot m\\cdot\\log\\delta(n)\/\\log n)$, where $1\\le\\delta(n)\\le n$ is the outdegree of the game graph. Note that this algorithm performs asymptotically better than the classical algorithm if $\\delta(n)=O(\\log n)$.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2015-04-04 00:00:00.000000"},
{"id":"1383","title":"And artist country.","abstract":"Just as dessins d'enfants parameterise coverings of a two-sphere with three ramification points, higher dessins d'enfants parameterise such coverings with an arbitrary number of ramification points. We study operations of absolute Galois groups upon them which are constructed similarly to Grothendieck's Galois operation on classical dessins d'enfants. It turns out that these operations truly depend, in quite a strong way, on choosing a complex structure on the covered sphere. Furthermore, a generalisation of Belyi's theorem to arbitrary finite subsets of the projective line over the algebraic numbers with at least three elements is proved, and we present a connection between the Galois action on 4-dessins d'enfants and complex multiplication theory.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2019-05-05 00:00:00.000000"},
{"id":"1384","title":"Floor room herself mouth chair cultural.","abstract":"We develop a relativistic lattice Boltzmann (LB) model, providing a more accurate description of dissipative phenomena in relativistic hydrodynamics than previously available with existing LB schemes. The procedure applies to the ultra-relativistic regime, in which the kinetic energy (temperature) far exceeds the rest mass energy, although the extension to massive particles and\/or low temperatures is conceptually straightforward. In order to improve the description of dissipative effects, the Maxwell-Juettner distribution is expanded in a basis of orthonormal polynomials, so as to correctly recover the third order moment of the distribution function. In addition, a time dilatation is also applied, in order to preserve the compatibility of the scheme with a cartesian cubic lattice. To the purpose of comparing the present LB model with previous ones, the time transformation is also applied to a lattice model which recovers terms up to second order, namely up to energy-momentum tensor. The approach is validated through quantitative comparison between the second and third order schemes with BAMPS (the solution of the full relativistic Boltzmann equation), for moderately high viscosity and velocities, and also with previous LB models in the literature. Excellent agreement with BAMPS and more accurate results than previous relativistic lattice Boltzmann models are reported.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2020-11-14 00:00:00.000000"},
{"id":"1385","title":"Us style available friend how claim.","abstract":"In this note we investigate the structure of the space $\\Jj$ of smooth almost complex structures on $S^2\\times S^2$ that are compatible with some symplectic form. This space has a natural stratification that changes as the cohomology class of the form changes and whose properties are very closely connected to the topology of the group of symplectomorphisms of $S^2\\times S^2$.   By globalizing standard gluing constructions in the theory of stable maps, we show that the strata of $\\Jj$ are Fr\\'echet manifolds of finite codimension, and that the normal link of each stratum is a finite dimensional stratified space. The topology of these links turns out to be surprisingly intricate, and we work out certain cases. Our arguments apply also to other ruled surfaces, though they give complete information only for bundles over $S^2$ and $T^2$.","psed_classification_id":"54","for_commercialization":"1","date_uploaded":"2021-04-21 00:00:00.000000"},
{"id":"1386","title":"Want school science.","abstract":"We obtain a complete classification of the locally finite algebras and the operator algebras, given as algebraic inductive limits and Banach algebraic inductive limits respectively, of direct systems:   A_1 contained in A_2 contained in A_3 and so on.   Here the A_k are 2n-cycle algebras, where n is at least 3 and the inclusions are of rigid type. The complete isomorphism invariant is essentially the triple (K_0(A), H_1(A), Sigma(A)) where K_0(A) is viewed as a scaled ordered group, H_1(A) is a partial isometry homology group and Sigma(A), contained in the direct sum of K_0(A) and H_1(A), is the 2n-cycle joint scale.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2020-01-20 00:00:00.000000"},
{"id":"1387","title":"Five add control number amount.","abstract":"Physical theories ought to be built up from colloquial notions such as 'long bodies', 'energetic sources' etc. in terms of which one can define pre-theoretic ordering relations such as 'longer than', 'more energetic than'. One of the questions addressed in previous work is how to make the transition from these pre-theoretic notions to quantification, such as making the transition from the ordering relation of 'longer than' (if one body covers the other) to the notion of how much longer. In similar way we introduce dynamical notions 'more impulse' (if in a collision one object overruns the other) and 'more energetic' (if the effect of one source exceeds the effect of the other). In a physical model - built by coupling congruent standard actions - those basic pre-theoretic notions become measurable. We uncover the origin of (basic) physical quantities of Energy, Momentum and Inertial Mass. From physical and methodical principles - without mathematical presuppositions - we derive all equations of (classical and relativistic) Dynamics and ultimately the principle of least action.","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2020-01-10 00:00:00.000000"},
{"id":"1388","title":"Wish general green anyone shoulder.","abstract":"Let A be a unital C* algebra with involution * represented in a Hilbert space H, G the group of invertible elements of A, U the unitary group of A, G^s the set of invertible selfadjoint elements of A, Q={e in G : e^2 = 1} the space of reflections and P = Q\\cap U. For any positive a in G consider the a-unitary group U_a={g in G : a^{-1} g^* a = g^{-1}}, i.e. the elements which are unitary with respect to the scalar product <\\xi,\\eta>_a = <a \\xi,\\eta> for \\xi, \\eta in H. If \\pi denotes the map that assigns to each invertible element its unitary part in the polar decomposition, we show that the restriction \\pi|_{U_a}: U_a \\to U is a diffeomorphism, that \\pi(U_a \\cap Q) = P and that \\pi(U_a\\cap G^s) = U_a\\cap G^s = {u in G: u=u^*=u^{-1} and au = ua}.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2015-10-17 00:00:00.000000"},
{"id":"1389","title":"Push less trip if voice foreign.","abstract":"Computer Aided Diagnosis (CAD) system has been developed for the early detection of breast cancer, one of the most deadly cancer for women. The benign of mammogram has different texture from malignant. There are fifty mammogram images used in this work which are divided for training and testing. Therefore, the selection of the right texture to determine the level of accuracy of CAD system is important. The first and second order statistics are the texture feature extraction methods which can be used on a mammogram. This work classifies texture descriptor into nine groups where the extraction of features is classified using backpropagation learning with two types of multi-layer perceptron (MLP). The best texture descriptor as selected when the value of regression 1 appears in both the MLP-1 and the MLP-2 with the number of epoches less than 1000. The results of testing show that the best selected texture descriptor is the second order (combination) using all direction (0, 45, 90 and 135) that have twenty four descriptors.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2015-06-15 00:00:00.000000"},
{"id":"1390","title":"Test difference keep large.","abstract":"We present an efficient and accurate algorithm for principal component analysis (PCA) of a large set of two dimensional images, and, for each image, the set of its uniform rotations in the plane and its reflection. The algorithm starts by expanding each image, originally given on a Cartesian grid, in the Fourier-Bessel basis for the disk. Because the images are bandlimited in the Fourier domain, we use a sampling criterion to truncate the Fourier-Bessel expansion such that the maximum amount of information is preserved without the effect of aliasing. The constructed covariance matrix is invariant to rotation and reflection and has a special block diagonal structure. PCA is efficiently done for each block separately. This Fourier-Bessel based PCA detects more meaningful eigenimages and has improved denoising capability compared to traditional PCA for a finite number of noisy images.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2018-05-02 00:00:00.000000"},
{"id":"1391","title":"Technology suffer environment light.","abstract":"This mini-course of 20 lectures aims at highlights of spectral theory for self-adjoint partial differential operators, with a heavy emphasis on problems with discrete spectrum. Part I: Discrete Spectrum (ODE preview, Laplacian - computable spectra, Schroedinger - computable spectra, Discrete spectral theorem via sesquilinear forms, Laplace eigenfunctions, Natural boundary conditions, Magnetic Laplacian, Schroedinger in confining well, Variational characterizations, Monotonicity of eigenvalues, Weyl's asymptotic, Polya's conjecture, Reaction-diffusion stability, Thin fluid film stability) Part II: Continuous Spectrum (Laplacian on whole space, Schroedinger with $-2sech^2$ potential, Selfadjoint operators, Spectra: discrete and continuous, Discrete spectrum revisited)","psed_classification_id":"46","for_commercialization":"1","date_uploaded":"2021-05-11 00:00:00.000000"},
{"id":"1392","title":"Moment position eat have outside chair TV house.","abstract":"We propose a novel approach for efficient tuning of the transmission characteristics of metamaterials through a continuous adjustment of the lattice structure, and confirm it experimentally in the microwave range. The concept is rather general and applicable to various metamaterials as long as the effective medium description is valid. The demonstrated continuous tuning of metamaterial response is highly desirable for a number of emerging applications of metamaterials including sensors, filters, switches, realizable in a wide frequency range.","psed_classification_id":"89","for_commercialization":"0","date_uploaded":"2018-04-29 00:00:00.000000"},
{"id":"1393","title":"In tend the happy professional surface herself friend.","abstract":"Scheduling is a critical and challenging resource allocation mechanism for multihop wireless networks. It is well known that scheduling schemes that favor links with larger queue length can achieve high throughput performance. However, these queue-length-based schemes could potentially suffer from large (even infinite) packet delays due to the well-known last packet problem, whereby packets belonging to some flows may be excessively delayed due to lack of subsequent packet arrivals. Delay-based schemes have the potential to resolve this last packet problem by scheduling the link based on the delay the packet has encountered. However, characterizing throughput-optimality of these delay-based schemes has largely been an open problem in multihop wireless networks (except in limited cases where the traffic is single-hop.) In this paper, we investigate delay-based scheduling schemes for multihop traffic scenarios with fixed routes. We develop a scheduling scheme based on a new delay metric, and show that the proposed scheme achieves optimal throughput performance. Further, we conduct simulations to support our analytical results, and show that the delay-based scheduler successfully removes excessive packet delays, while it achieves the same throughput region as the queue-length-based scheme.","psed_classification_id":"47","for_commercialization":"1","date_uploaded":"2015-05-15 00:00:00.000000"},
{"id":"1394","title":"Fear challenge talk onto stop shoulder.","abstract":"Consider a gambler and a prophet who observe a sequence of independent, non-negative numbers. The gambler sees the numbers one-by-one whereas the prophet sees the entire sequence at once. The goal of both is to decide on fractions of each number they want to keep so as to maximize the weighted fractional sum of the numbers chosen.   The classic result of Krengel and Sucheston (1977-78) asserts that if both the gambler and the prophet can pick one number, then the gambler can do at least half as well as the prophet. Recently, Kleinberg and Weinberg (2012) have generalized this result to settings where the numbers that can be chosen are subject to a matroid constraint.   In this note we go one step further and show that the bound carries over to settings where the fractions that can be chosen are subject to a polymatroid constraint. This bound is tight as it is already tight for the simple setting where the gambler and the prophet can pick only one number. An interesting application of our result is in mechanism design, where it leads to improved results for various problems.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2016-02-04 00:00:00.000000"},
{"id":"1395","title":"Large clear old Congress can see size.","abstract":"Datasets of different characteristics are needed by the research community for experimental purposes. However, real data may be difficult to obtain due to privacy concerns. Moreover, real data may not meet specific characteristics which are needed to verify new approaches under certain conditions. Given these limitations, the use of synthetic data is a viable alternative to complement the real data. In this report, we describe the process followed to generate synthetic data using Benerator, a publicly available tool. The results show that the synthetic data preserves a high level of accuracy compared to the original data. The generated datasets correspond to microdata containing records with social, economic and demographic data which mimics the distribution of aggregated statistics from the 2011 Irish Census data.","psed_classification_id":"89","for_commercialization":"1","date_uploaded":"2021-06-13 00:00:00.000000"},
{"id":"1396","title":"Reflect every state goal yard at.","abstract":"Kiefer and Wolfowitz [Z. Wahrsch. Verw. Gebiete 34 (1976) 73--85] showed that if $F$ is a strictly curved concave distribution function (corresponding to a strictly monotone density $f$), then the Maximum Likelihood Estimator $\\hat{F}_n$, which is, in fact, the least concave majorant of the empirical distribution function $\\mathbb {F}_n$, differs from the empirical distribution function in the uniform norm by no more than a constant times $(n^{-1}\\log n)^{2\/3}$ almost surely. We review their result and give an updated version of their proof. We prove a comparable theorem for the class of distribution functions $F$ with convex decreasing densities $f$, but with the maximum likelihood estimator $\\hat{F}_n$ of $F$ replaced by the least squares estimator $\\widetilde{F}_n$: if $X_1,..., X_n$ are sampled from a distribution function $F$ with strictly convex density $f$, then the least squares estimator $\\widetilde{F}_n$ of $F$ and the empirical distribution function $\\mathbb {F}_n$ differ in the uniform norm by no more than a constant times $(n^{-1}\\log n)^{3\/5}$ almost surely. The proofs rely on bounds on the interpolation error for complete spline interpolation due to Hall [J. Approximation Theory 1 (1968) 209--218], Hall and Meyer [J. Approximation Theory 16 (1976) 105--122], building on earlier work by Birkhoff and de Boor [J. Math. Mech. 13 (1964) 827--835]. These results, which are crucial for the developments here, are all nicely summarized and exposited in de Boor [A Practical Guide to Splines (2001) Springer, New York].","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2018-06-28 00:00:00.000000"},
{"id":"1397","title":"Down carry successful decade protect official sit.","abstract":"We study the $C^*$-algebras related to Mishchenko's version of asymptotic homomorphisms. In particular we show that their different versions are weakly homotopy equivalent but not isomorphic to each other. We give also the continuous version for these algebras.","psed_classification_id":"47","for_commercialization":"0","date_uploaded":"2017-10-19 00:00:00.000000"},
{"id":"1398","title":"Join many call head American not.","abstract":"Image resampling is a necessary component of any operation that changes the size of an image or its geometry.   Methods tuned for natural image upsampling (roughly speaking, image enlargement) are analyzed and developed with a focus on their ability to preserve diagonal features and suppress overshoots. Monotone, locally bounded and almost monotone \"direct\" interpolation and filtering methods, as well as face split and vertex split surface subdivision methods, alone or in combination, are studied. Key properties are established by way of proofs and counterexamples as well as numerical experiments involving 1D curve and 2D diagonal data resampling.   In addition, the Remez minimax method for the computation of low-cost polynomial approximations of low-pass filter kernels tuned for natural image downsampling (roughly speaking, image reduction) is refactored for relative error minimization in the presence of roots in the interior of the interval of approximation and so that even and odd functions are approximated with like polynomials. The accuracy and frequency response of the approximations are tabulated and plotted against the original, establishing their rapid convergence.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2016-09-16 00:00:00.000000"},
{"id":"1399","title":"Nothing democratic but low.","abstract":"This paper addresses the problem of classifying observations when features are context-sensitive, especially when the testing set involves a context that is different from the training set. The paper begins with a precise definition of the problem, then general strategies are presented for enhancing the performance of classification algorithms on this type of problem. These strategies are tested on three domains. The first domain is the diagnosis of gas turbine engines. The problem is to diagnose a faulty engine in one context, such as warm weather, when the fault has previously been seen only in another context, such as cold weather. The second domain is speech recognition. The context is given by the identity of the speaker. The problem is to recognize words spoken by a new speaker, not represented in the training set. The third domain is medical prognosis. The problem is to predict whether a patient with hepatitis will live or die. The context is the age of the patient. For all three domains, exploiting context results in substantially more accurate classification.","psed_classification_id":"54","for_commercialization":"0","date_uploaded":"2017-11-03 00:00:00.000000"},
{"id":"1400","title":"About to old provide dream unit when.","abstract":"Let $R$ be a commutative local uniserial ring of length $n$, $p$ a generator of the maximal ideal, and $k$ the radical factor field. The pairs $(B,A)$ where $B$ is a finitely generated $R$-module and $A\\subset B$ a submodule of $B$ such that $p^mA=0$ form the objects in the category $S_m(R)$. We show that in case $m=2$ the categories $S_m(R)$ are in fact quite similar to each other: If also $R'$ is a commutative local uniserial ring of length $n$ and with radical factor field $k$, then the categories $S_2(R)\/\\mathcal N_R$ and $S_2(R')\/\\mathcal N_{R'}$ are equivalent for certain nilpotent categorical ideals $N_R$ and $N_{R'}$. As an application, we recover the known classification of all pairs $(B,A)$ where $B$ is a finitely generated abelian group and $A\\subset B$ a subgroup of $B$ which is $p^2$-bounded for a given prime number $p$.","psed_classification_id":"46","for_commercialization":"0","date_uploaded":"2022-11-21 00:00:00.000000"},
{"id":"1401","title":"Should small six indeed statement space see positive.","abstract":"In thermally fluctuating long linear polymeric chain in solution, the ends come from time to time into a direct contact or a close vicinity of each other. At such an instance, the chain can be regarded as a closed one and thus will form a knot or rather a virtual knot. Several earlier studies of random knotting demonstrated that simpler knots show their highest occurrence for shorter random walks than more complex knots. However up to now there were no rules that could be used to predict the optimal length of a random walk, i.e. the length for which a given knot reaches its highest occurrence. Using numerical simulations, we show here that a power law accurately describes the relation between the optimal lengths of random walks leading to the formation of different knots and the previously characterized lengths of ideal knots of the corresponding type.","psed_classification_id":"58","for_commercialization":"1","date_uploaded":"2022-06-22 00:00:00.000000"}
]
}
]
